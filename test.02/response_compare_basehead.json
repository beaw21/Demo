{
    "url": "https://api.github.com/repos/apache/flink/compare/release-1.12...release-1.13",
    "html_url": "https://github.com/apache/flink/compare/release-1.12...release-1.13",
    "permalink_url": "https://github.com/apache/flink/compare/apache:f07bfa6...apache:09f8688",
    "diff_url": "https://github.com/apache/flink/compare/release-1.12...release-1.13.diff",
    "patch_url": "https://github.com/apache/flink/compare/release-1.12...release-1.13.patch",
    "base_commit": {
        "sha": "f07bfa6427a3fc47abc3ab254381e78c6bfbd139",
        "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZjA3YmZhNjQyN2EzZmM0N2FiYzNhYjI1NDM4MWU3OGM2YmZiZDEzOQ==",
        "commit": {
            "author": {
                "name": "Till Rohrmann",
                "email": "trohrmann@apache.org",
                "date": "2021-07-20T13:36:46Z"
            },
            "committer": {
                "name": "Chesnay Schepler",
                "email": "chesnay@apache.org",
                "date": "2021-07-26T14:57:48Z"
            },
            "message": "[FLINK-23417][tests] Harden MiniClusterITCase.testHandleBatchJobsWhenNotEnoughSlot\n\nThis commit hardens the MiniClusterITCase.testHandleBatchJobsWhenNotEnoughSlot by configuring\na higher ResourceManagerOptions.STANDALONE_CLUSTER_STARTUP_PERIOD_TIME than JobManagerOptions.\nSLOT_REQUEST_TIMEOUT. This ensures that the slot request times out instead of being failed by\nthe SlotManager.",
            "tree": {
                "sha": "18bb01db4aba29fc7f8d61f10286930105dc8266",
                "url": "https://api.github.com/repos/apache/flink/git/trees/18bb01db4aba29fc7f8d61f10286930105dc8266"
            },
            "url": "https://api.github.com/repos/apache/flink/git/commits/f07bfa6427a3fc47abc3ab254381e78c6bfbd139",
            "comment_count": 0,
            "verification": {
                "verified": false,
                "reason": "unsigned",
                "signature": null,
                "payload": null
            }
        },
        "url": "https://api.github.com/repos/apache/flink/commits/f07bfa6427a3fc47abc3ab254381e78c6bfbd139",
        "html_url": "https://github.com/apache/flink/commit/f07bfa6427a3fc47abc3ab254381e78c6bfbd139",
        "comments_url": "https://api.github.com/repos/apache/flink/commits/f07bfa6427a3fc47abc3ab254381e78c6bfbd139/comments",
        "author": {
            "login": "tillrohrmann",
            "id": 5756858,
            "node_id": "MDQ6VXNlcjU3NTY4NTg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tillrohrmann",
            "html_url": "https://github.com/tillrohrmann",
            "followers_url": "https://api.github.com/users/tillrohrmann/followers",
            "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
            "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
            "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
            "repos_url": "https://api.github.com/users/tillrohrmann/repos",
            "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
            "type": "User",
            "site_admin": false
        },
        "committer": {
            "login": "zentol",
            "id": 5725237,
            "node_id": "MDQ6VXNlcjU3MjUyMzc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/zentol",
            "html_url": "https://github.com/zentol",
            "followers_url": "https://api.github.com/users/zentol/followers",
            "following_url": "https://api.github.com/users/zentol/following{/other_user}",
            "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
            "organizations_url": "https://api.github.com/users/zentol/orgs",
            "repos_url": "https://api.github.com/users/zentol/repos",
            "events_url": "https://api.github.com/users/zentol/events{/privacy}",
            "received_events_url": "https://api.github.com/users/zentol/received_events",
            "type": "User",
            "site_admin": false
        },
        "parents": [{
            "sha": "bfcd31048ef0c3d7b8722f55cdf27307cc86ac96",
            "url": "https://api.github.com/repos/apache/flink/commits/bfcd31048ef0c3d7b8722f55cdf27307cc86ac96",
            "html_url": "https://github.com/apache/flink/commit/bfcd31048ef0c3d7b8722f55cdf27307cc86ac96"
        }]
    },
    "merge_base_commit": {
        "sha": "c008907d2a629449c8d0ad9725d13b0604fc2141",
        "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6YzAwODkwN2QyYTYyOTQ0OWM4ZDBhZDk3MjVkMTNiMDYwNGZjMjE0MQ==",
        "commit": {
            "author": {
                "name": "Aditya Agarwal",
                "email": "adityag2511@gmail.com",
                "date": "2020-11-25T16:39:55Z"
            },
            "committer": {
                "name": "Yun Tang",
                "email": "myasuka@live.com",
                "date": "2020-11-26T02:38:06Z"
            },
            "message": "[FLINK-19998] Remove site.baseurl from {% link %} tags",
            "tree": {
                "sha": "8ce86b7e290142c607d0cf91822d638e8fff9a7c",
                "url": "https://api.github.com/repos/apache/flink/git/trees/8ce86b7e290142c607d0cf91822d638e8fff9a7c"
            },
            "url": "https://api.github.com/repos/apache/flink/git/commits/c008907d2a629449c8d0ad9725d13b0604fc2141",
            "comment_count": 0,
            "verification": {
                "verified": false,
                "reason": "unsigned",
                "signature": null,
                "payload": null
            }
        },
        "url": "https://api.github.com/repos/apache/flink/commits/c008907d2a629449c8d0ad9725d13b0604fc2141",
        "html_url": "https://github.com/apache/flink/commit/c008907d2a629449c8d0ad9725d13b0604fc2141",
        "comments_url": "https://api.github.com/repos/apache/flink/commits/c008907d2a629449c8d0ad9725d13b0604fc2141/comments",
        "author": {
            "login": "vintageplayer",
            "id": 17234935,
            "node_id": "MDQ6VXNlcjE3MjM0OTM1",
            "avatar_url": "https://avatars.githubusercontent.com/u/17234935?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/vintageplayer",
            "html_url": "https://github.com/vintageplayer",
            "followers_url": "https://api.github.com/users/vintageplayer/followers",
            "following_url": "https://api.github.com/users/vintageplayer/following{/other_user}",
            "gists_url": "https://api.github.com/users/vintageplayer/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/vintageplayer/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/vintageplayer/subscriptions",
            "organizations_url": "https://api.github.com/users/vintageplayer/orgs",
            "repos_url": "https://api.github.com/users/vintageplayer/repos",
            "events_url": "https://api.github.com/users/vintageplayer/events{/privacy}",
            "received_events_url": "https://api.github.com/users/vintageplayer/received_events",
            "type": "User",
            "site_admin": false
        },
        "committer": {
            "login": "Myasuka",
            "id": 1709104,
            "node_id": "MDQ6VXNlcjE3MDkxMDQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1709104?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Myasuka",
            "html_url": "https://github.com/Myasuka",
            "followers_url": "https://api.github.com/users/Myasuka/followers",
            "following_url": "https://api.github.com/users/Myasuka/following{/other_user}",
            "gists_url": "https://api.github.com/users/Myasuka/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Myasuka/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Myasuka/subscriptions",
            "organizations_url": "https://api.github.com/users/Myasuka/orgs",
            "repos_url": "https://api.github.com/users/Myasuka/repos",
            "events_url": "https://api.github.com/users/Myasuka/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Myasuka/received_events",
            "type": "User",
            "site_admin": false
        },
        "parents": [{
            "sha": "4cc1da96e88ddc6166181a7f83c891761db283a1",
            "url": "https://api.github.com/repos/apache/flink/commits/4cc1da96e88ddc6166181a7f83c891761db283a1",
            "html_url": "https://github.com/apache/flink/commit/4cc1da96e88ddc6166181a7f83c891761db283a1"
        }]
    },
    "status": "diverged",
    "ahead_by": 2310,
    "behind_by": 676,
    "total_commits": 2310,
    "commits": [{
            "sha": "c8b31602a5554d7f53bb198177c211ca20492dc3",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6YzhiMzE2MDJhNTU1NGQ3ZjUzYmIxOTgxNzdjMjExY2EyMDQ5MmRjMw==",
            "commit": {
                "author": {
                    "name": "Dian Fu",
                    "email": "dianfu@apache.org",
                    "date": "2021-05-07T06:40:25Z"
                },
                "committer": {
                    "name": "Dian Fu",
                    "email": "dianfu@apache.org",
                    "date": "2021-05-07T06:41:18Z"
                },
                "message": "[hotfix][docs][python] Add an overview page for Python UDFs",
                "tree": {
                    "sha": "6966351931e1afb224c7a98b9d58a38a6261a720",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/6966351931e1afb224c7a98b9d58a38a6261a720"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/c8b31602a5554d7f53bb198177c211ca20492dc3",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/c8b31602a5554d7f53bb198177c211ca20492dc3",
            "html_url": "https://github.com/apache/flink/commit/c8b31602a5554d7f53bb198177c211ca20492dc3",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/c8b31602a5554d7f53bb198177c211ca20492dc3/comments",
            "author": {
                "login": "dianfu",
                "id": 5466492,
                "node_id": "MDQ6VXNlcjU0NjY0OTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5466492?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dianfu",
                "html_url": "https://github.com/dianfu",
                "followers_url": "https://api.github.com/users/dianfu/followers",
                "following_url": "https://api.github.com/users/dianfu/following{/other_user}",
                "gists_url": "https://api.github.com/users/dianfu/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dianfu/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dianfu/subscriptions",
                "organizations_url": "https://api.github.com/users/dianfu/orgs",
                "repos_url": "https://api.github.com/users/dianfu/repos",
                "events_url": "https://api.github.com/users/dianfu/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dianfu/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "dianfu",
                "id": 5466492,
                "node_id": "MDQ6VXNlcjU0NjY0OTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5466492?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dianfu",
                "html_url": "https://github.com/dianfu",
                "followers_url": "https://api.github.com/users/dianfu/followers",
                "following_url": "https://api.github.com/users/dianfu/following{/other_user}",
                "gists_url": "https://api.github.com/users/dianfu/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dianfu/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dianfu/subscriptions",
                "organizations_url": "https://api.github.com/users/dianfu/orgs",
                "repos_url": "https://api.github.com/users/dianfu/repos",
                "events_url": "https://api.github.com/users/dianfu/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dianfu/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "36ba407f119fdf7271f9380fe5d779c0163ddd63",
                "url": "https://api.github.com/repos/apache/flink/commits/36ba407f119fdf7271f9380fe5d779c0163ddd63",
                "html_url": "https://github.com/apache/flink/commit/36ba407f119fdf7271f9380fe5d779c0163ddd63"
            }]
        },
        {
            "sha": "8094c0f85bd3e3382bcc19d5097ef51c93ad3f82",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ODA5NGMwZjg1YmQzZTMzODJiY2MxOWQ1MDk3ZWY1MWM5M2FkM2Y4Mg==",
            "commit": {
                "author": {
                    "name": "Robert Metzger",
                    "email": "rmetzger@apache.org",
                    "date": "2021-05-06T08:51:21Z"
                },
                "committer": {
                    "name": "Robert Metzger",
                    "email": "rmetzger@apache.org",
                    "date": "2021-05-07T06:43:06Z"
                },
                "message": "[hotfix][docs] Re-introduce note about FLINK_CONF_DIR\n\nThis closes #15845",
                "tree": {
                    "sha": "8ecd09fb6569300c5275aa006f4b99fb2a203832",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/8ecd09fb6569300c5275aa006f4b99fb2a203832"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/8094c0f85bd3e3382bcc19d5097ef51c93ad3f82",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/8094c0f85bd3e3382bcc19d5097ef51c93ad3f82",
            "html_url": "https://github.com/apache/flink/commit/8094c0f85bd3e3382bcc19d5097ef51c93ad3f82",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/8094c0f85bd3e3382bcc19d5097ef51c93ad3f82/comments",
            "author": {
                "login": "rmetzger",
                "id": 89049,
                "node_id": "MDQ6VXNlcjg5MDQ5",
                "avatar_url": "https://avatars.githubusercontent.com/u/89049?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rmetzger",
                "html_url": "https://github.com/rmetzger",
                "followers_url": "https://api.github.com/users/rmetzger/followers",
                "following_url": "https://api.github.com/users/rmetzger/following{/other_user}",
                "gists_url": "https://api.github.com/users/rmetzger/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rmetzger/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rmetzger/subscriptions",
                "organizations_url": "https://api.github.com/users/rmetzger/orgs",
                "repos_url": "https://api.github.com/users/rmetzger/repos",
                "events_url": "https://api.github.com/users/rmetzger/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rmetzger/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "rmetzger",
                "id": 89049,
                "node_id": "MDQ6VXNlcjg5MDQ5",
                "avatar_url": "https://avatars.githubusercontent.com/u/89049?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rmetzger",
                "html_url": "https://github.com/rmetzger",
                "followers_url": "https://api.github.com/users/rmetzger/followers",
                "following_url": "https://api.github.com/users/rmetzger/following{/other_user}",
                "gists_url": "https://api.github.com/users/rmetzger/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rmetzger/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rmetzger/subscriptions",
                "organizations_url": "https://api.github.com/users/rmetzger/orgs",
                "repos_url": "https://api.github.com/users/rmetzger/repos",
                "events_url": "https://api.github.com/users/rmetzger/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rmetzger/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "c8b31602a5554d7f53bb198177c211ca20492dc3",
                "url": "https://api.github.com/repos/apache/flink/commits/c8b31602a5554d7f53bb198177c211ca20492dc3",
                "html_url": "https://github.com/apache/flink/commit/c8b31602a5554d7f53bb198177c211ca20492dc3"
            }]
        },
        {
            "sha": "da9cb972bea65b47e2bfb20cebb1dd859ae338f9",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZGE5Y2I5NzJiZWE2NWI0N2UyYmZiMjBjZWJiMWRkODU5YWUzMzhmOQ==",
            "commit": {
                "author": {
                    "name": "Robert Metzger",
                    "email": "rmetzger@apache.org",
                    "date": "2021-05-06T08:44:15Z"
                },
                "committer": {
                    "name": "Robert Metzger",
                    "email": "rmetzger@apache.org",
                    "date": "2021-05-07T06:43:19Z"
                },
                "message": "[hotfix] Make reactive warning less strong, clarifications",
                "tree": {
                    "sha": "d3526e828850b9ce5dfa799870d119892c2be0ec",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/d3526e828850b9ce5dfa799870d119892c2be0ec"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/da9cb972bea65b47e2bfb20cebb1dd859ae338f9",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/da9cb972bea65b47e2bfb20cebb1dd859ae338f9",
            "html_url": "https://github.com/apache/flink/commit/da9cb972bea65b47e2bfb20cebb1dd859ae338f9",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/da9cb972bea65b47e2bfb20cebb1dd859ae338f9/comments",
            "author": {
                "login": "rmetzger",
                "id": 89049,
                "node_id": "MDQ6VXNlcjg5MDQ5",
                "avatar_url": "https://avatars.githubusercontent.com/u/89049?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rmetzger",
                "html_url": "https://github.com/rmetzger",
                "followers_url": "https://api.github.com/users/rmetzger/followers",
                "following_url": "https://api.github.com/users/rmetzger/following{/other_user}",
                "gists_url": "https://api.github.com/users/rmetzger/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rmetzger/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rmetzger/subscriptions",
                "organizations_url": "https://api.github.com/users/rmetzger/orgs",
                "repos_url": "https://api.github.com/users/rmetzger/repos",
                "events_url": "https://api.github.com/users/rmetzger/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rmetzger/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "rmetzger",
                "id": 89049,
                "node_id": "MDQ6VXNlcjg5MDQ5",
                "avatar_url": "https://avatars.githubusercontent.com/u/89049?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rmetzger",
                "html_url": "https://github.com/rmetzger",
                "followers_url": "https://api.github.com/users/rmetzger/followers",
                "following_url": "https://api.github.com/users/rmetzger/following{/other_user}",
                "gists_url": "https://api.github.com/users/rmetzger/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rmetzger/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rmetzger/subscriptions",
                "organizations_url": "https://api.github.com/users/rmetzger/orgs",
                "repos_url": "https://api.github.com/users/rmetzger/repos",
                "events_url": "https://api.github.com/users/rmetzger/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rmetzger/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "8094c0f85bd3e3382bcc19d5097ef51c93ad3f82",
                "url": "https://api.github.com/repos/apache/flink/commits/8094c0f85bd3e3382bcc19d5097ef51c93ad3f82",
                "html_url": "https://github.com/apache/flink/commit/8094c0f85bd3e3382bcc19d5097ef51c93ad3f82"
            }]
        },
        {
            "sha": "d5ce4c2e3f51de5a66a3c307f926907f8cbaa853",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZDVjZTRjMmUzZjUxZGU1YTY2YTNjMzA3ZjkyNjkwN2Y4Y2JhYTg1Mw==",
            "commit": {
                "author": {
                    "name": "Dian Fu",
                    "email": "dianfu@apache.org",
                    "date": "2021-05-07T06:56:54Z"
                },
                "committer": {
                    "name": "Dian Fu",
                    "email": "dianfu@apache.org",
                    "date": "2021-05-07T06:57:53Z"
                },
                "message": "[hotfix][docs][python] Add introduction about the open method in Python DataStream API",
                "tree": {
                    "sha": "6f169fd5c5d01f71f957f3d8808f6957cbd7de87",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/6f169fd5c5d01f71f957f3d8808f6957cbd7de87"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/d5ce4c2e3f51de5a66a3c307f926907f8cbaa853",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/d5ce4c2e3f51de5a66a3c307f926907f8cbaa853",
            "html_url": "https://github.com/apache/flink/commit/d5ce4c2e3f51de5a66a3c307f926907f8cbaa853",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/d5ce4c2e3f51de5a66a3c307f926907f8cbaa853/comments",
            "author": {
                "login": "dianfu",
                "id": 5466492,
                "node_id": "MDQ6VXNlcjU0NjY0OTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5466492?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dianfu",
                "html_url": "https://github.com/dianfu",
                "followers_url": "https://api.github.com/users/dianfu/followers",
                "following_url": "https://api.github.com/users/dianfu/following{/other_user}",
                "gists_url": "https://api.github.com/users/dianfu/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dianfu/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dianfu/subscriptions",
                "organizations_url": "https://api.github.com/users/dianfu/orgs",
                "repos_url": "https://api.github.com/users/dianfu/repos",
                "events_url": "https://api.github.com/users/dianfu/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dianfu/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "dianfu",
                "id": 5466492,
                "node_id": "MDQ6VXNlcjU0NjY0OTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5466492?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dianfu",
                "html_url": "https://github.com/dianfu",
                "followers_url": "https://api.github.com/users/dianfu/followers",
                "following_url": "https://api.github.com/users/dianfu/following{/other_user}",
                "gists_url": "https://api.github.com/users/dianfu/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dianfu/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dianfu/subscriptions",
                "organizations_url": "https://api.github.com/users/dianfu/orgs",
                "repos_url": "https://api.github.com/users/dianfu/repos",
                "events_url": "https://api.github.com/users/dianfu/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dianfu/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "da9cb972bea65b47e2bfb20cebb1dd859ae338f9",
                "url": "https://api.github.com/repos/apache/flink/commits/da9cb972bea65b47e2bfb20cebb1dd859ae338f9",
                "html_url": "https://github.com/apache/flink/commit/da9cb972bea65b47e2bfb20cebb1dd859ae338f9"
            }]
        },
        {
            "sha": "d1df147b2f737c60b57c8f6d267596e11e5e06e8",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZDFkZjE0N2IyZjczN2M2MGI1N2M4ZjZkMjY3NTk2ZTExZTVlMDZlOA==",
            "commit": {
                "author": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-05-05T09:59:55Z"
                },
                "committer": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-05-07T07:54:02Z"
                },
                "message": "[FLINK-22406][tests] Add RestClusterClient to MiniClusterWithClientResource",
                "tree": {
                    "sha": "3623498c57900a061e96c8804840eaf03895097b",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/3623498c57900a061e96c8804840eaf03895097b"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/d1df147b2f737c60b57c8f6d267596e11e5e06e8",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/d1df147b2f737c60b57c8f6d267596e11e5e06e8",
            "html_url": "https://github.com/apache/flink/commit/d1df147b2f737c60b57c8f6d267596e11e5e06e8",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/d1df147b2f737c60b57c8f6d267596e11e5e06e8/comments",
            "author": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "d5ce4c2e3f51de5a66a3c307f926907f8cbaa853",
                "url": "https://api.github.com/repos/apache/flink/commits/d5ce4c2e3f51de5a66a3c307f926907f8cbaa853",
                "html_url": "https://github.com/apache/flink/commit/d5ce4c2e3f51de5a66a3c307f926907f8cbaa853"
            }]
        },
        {
            "sha": "5b7e87f7c4c39bbc13c459be97b7d7b4102d0f45",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NWI3ZTg3ZjdjNGMzOWJiYzEzYzQ1OWJlOTdiN2Q3YjQxMDJkMGY0NQ==",
            "commit": {
                "author": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-04-23T07:55:25Z"
                },
                "committer": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-05-07T07:57:48Z"
                },
                "message": "[FLINK-22406][coordination][tests] Stabilize ReactiveModeITCase",
                "tree": {
                    "sha": "eda36ec1dfc40ec5bb66b69ecf46e2ff1f59d9be",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/eda36ec1dfc40ec5bb66b69ecf46e2ff1f59d9be"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/5b7e87f7c4c39bbc13c459be97b7d7b4102d0f45",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/5b7e87f7c4c39bbc13c459be97b7d7b4102d0f45",
            "html_url": "https://github.com/apache/flink/commit/5b7e87f7c4c39bbc13c459be97b7d7b4102d0f45",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/5b7e87f7c4c39bbc13c459be97b7d7b4102d0f45/comments",
            "author": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "d1df147b2f737c60b57c8f6d267596e11e5e06e8",
                "url": "https://api.github.com/repos/apache/flink/commits/d1df147b2f737c60b57c8f6d267596e11e5e06e8",
                "html_url": "https://github.com/apache/flink/commit/d1df147b2f737c60b57c8f6d267596e11e5e06e8"
            }]
        },
        {
            "sha": "0d75adb0bb46fcaba9377d1b8c078a587063ee5d",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MGQ3NWFkYjBiYjQ2ZmNhYmE5Mzc3ZDFiOGMwNzhhNTg3MDYzZWU1ZA==",
            "commit": {
                "author": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-04-23T17:25:54Z"
                },
                "committer": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-05-07T08:23:10Z"
                },
                "message": "[FLINK-22419][coordination][tests] Rework RpcEndpoint delay tests",
                "tree": {
                    "sha": "72d90374ae567b089c05f2b748dd72085fab175f",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/72d90374ae567b089c05f2b748dd72085fab175f"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/0d75adb0bb46fcaba9377d1b8c078a587063ee5d",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/0d75adb0bb46fcaba9377d1b8c078a587063ee5d",
            "html_url": "https://github.com/apache/flink/commit/0d75adb0bb46fcaba9377d1b8c078a587063ee5d",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/0d75adb0bb46fcaba9377d1b8c078a587063ee5d/comments",
            "author": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "5b7e87f7c4c39bbc13c459be97b7d7b4102d0f45",
                "url": "https://api.github.com/repos/apache/flink/commits/5b7e87f7c4c39bbc13c459be97b7d7b4102d0f45",
                "html_url": "https://github.com/apache/flink/commit/5b7e87f7c4c39bbc13c459be97b7d7b4102d0f45"
            }]
        },
        {
            "sha": "0bb8ae72efa3fa7aaf82c97d1adbb0c5ae504b0b",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MGJiOGFlNzJlZmEzZmE3YWFmODJjOTdkMWFkYmIwYzVhZTUwNGIwYg==",
            "commit": {
                "author": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-05-05T10:51:09Z"
                },
                "committer": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-05-07T08:27:49Z"
                },
                "message": "[FLINK-22560][build] Move generic filters/transformers into general shade-plugin configuration",
                "tree": {
                    "sha": "85edabfcac662cd88032623b88929d3b60ef6b36",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/85edabfcac662cd88032623b88929d3b60ef6b36"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/0bb8ae72efa3fa7aaf82c97d1adbb0c5ae504b0b",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/0bb8ae72efa3fa7aaf82c97d1adbb0c5ae504b0b",
            "html_url": "https://github.com/apache/flink/commit/0bb8ae72efa3fa7aaf82c97d1adbb0c5ae504b0b",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/0bb8ae72efa3fa7aaf82c97d1adbb0c5ae504b0b/comments",
            "author": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "0d75adb0bb46fcaba9377d1b8c078a587063ee5d",
                "url": "https://api.github.com/repos/apache/flink/commits/0d75adb0bb46fcaba9377d1b8c078a587063ee5d",
                "html_url": "https://github.com/apache/flink/commit/0d75adb0bb46fcaba9377d1b8c078a587063ee5d"
            }]
        },
        {
            "sha": "1c9da058d8be3d21fd87e8a177ddcb50f04db7f9",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MWM5ZGEwNThkOGJlM2QyMWZkODdlOGExNzdkZGNiNTBmMDRkYjdmOQ==",
            "commit": {
                "author": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-05-04T08:41:14Z"
                },
                "committer": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-05-07T08:27:55Z"
                },
                "message": "[FLINK-22560][build] Filter maven metadata directory",
                "tree": {
                    "sha": "cd38c4ea005b86a216353d71402c2f6aa34cb558",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/cd38c4ea005b86a216353d71402c2f6aa34cb558"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/1c9da058d8be3d21fd87e8a177ddcb50f04db7f9",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/1c9da058d8be3d21fd87e8a177ddcb50f04db7f9",
            "html_url": "https://github.com/apache/flink/commit/1c9da058d8be3d21fd87e8a177ddcb50f04db7f9",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/1c9da058d8be3d21fd87e8a177ddcb50f04db7f9/comments",
            "author": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "0bb8ae72efa3fa7aaf82c97d1adbb0c5ae504b0b",
                "url": "https://api.github.com/repos/apache/flink/commits/0bb8ae72efa3fa7aaf82c97d1adbb0c5ae504b0b",
                "html_url": "https://github.com/apache/flink/commit/0bb8ae72efa3fa7aaf82c97d1adbb0c5ae504b0b"
            }]
        },
        {
            "sha": "79a0dd87b58404bae5e365be921070cbad1998a2",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NzlhMGRkODdiNTg0MDRiYWU1ZTM2NWJlOTIxMDcwY2JhZDE5OThhMg==",
            "commit": {
                "author": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-05-05T11:18:11Z"
                },
                "committer": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-05-07T08:28:00Z"
                },
                "message": "[FLINK-22560][build] Add dedicated name to flink-dist shade-plugin execution",
                "tree": {
                    "sha": "2377bd7b4ecfecfb39d63d5b687e4f3497337e72",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/2377bd7b4ecfecfb39d63d5b687e4f3497337e72"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/79a0dd87b58404bae5e365be921070cbad1998a2",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/79a0dd87b58404bae5e365be921070cbad1998a2",
            "html_url": "https://github.com/apache/flink/commit/79a0dd87b58404bae5e365be921070cbad1998a2",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/79a0dd87b58404bae5e365be921070cbad1998a2/comments",
            "author": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "1c9da058d8be3d21fd87e8a177ddcb50f04db7f9",
                "url": "https://api.github.com/repos/apache/flink/commits/1c9da058d8be3d21fd87e8a177ddcb50f04db7f9",
                "html_url": "https://github.com/apache/flink/commit/1c9da058d8be3d21fd87e8a177ddcb50f04db7f9"
            }]
        },
        {
            "sha": "60b604425b97e759c0d3d8f62b3a24d656dd6e4c",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NjBiNjA0NDI1Yjk3ZTc1OWMwZDNkOGY2MmIzYTI0ZDY1NmRkNmU0Yw==",
            "commit": {
                "author": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-05-04T08:41:46Z"
                },
                "committer": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-05-07T08:28:04Z"
                },
                "message": "[FLINK-22555][build][python] Exclude leftover jboss files",
                "tree": {
                    "sha": "15bc28206df7e2e10ed10e4bbd72918107ec3474",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/15bc28206df7e2e10ed10e4bbd72918107ec3474"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/60b604425b97e759c0d3d8f62b3a24d656dd6e4c",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/60b604425b97e759c0d3d8f62b3a24d656dd6e4c",
            "html_url": "https://github.com/apache/flink/commit/60b604425b97e759c0d3d8f62b3a24d656dd6e4c",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/60b604425b97e759c0d3d8f62b3a24d656dd6e4c/comments",
            "author": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "79a0dd87b58404bae5e365be921070cbad1998a2",
                "url": "https://api.github.com/repos/apache/flink/commits/79a0dd87b58404bae5e365be921070cbad1998a2",
                "html_url": "https://github.com/apache/flink/commit/79a0dd87b58404bae5e365be921070cbad1998a2"
            }]
        },
        {
            "sha": "7d569e6f56d203d6cd0eaeb43b2f0b99db345bba",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6N2Q1NjllNmY1NmQyMDNkNmNkMGVhZWI0M2IyZjBiOTlkYjM0NWJiYQ==",
            "commit": {
                "author": {
                    "name": "Dian Fu",
                    "email": "dianfu@apache.org",
                    "date": "2021-05-07T12:40:29Z"
                },
                "committer": {
                    "name": "Dian Fu",
                    "email": "dianfu@apache.org",
                    "date": "2021-05-07T12:41:14Z"
                },
                "message": "[hotfix][docs] Fix typo in dependency_management.md",
                "tree": {
                    "sha": "516f3c464b64246e64ba1d2bf37ba071505c994d",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/516f3c464b64246e64ba1d2bf37ba071505c994d"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/7d569e6f56d203d6cd0eaeb43b2f0b99db345bba",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/7d569e6f56d203d6cd0eaeb43b2f0b99db345bba",
            "html_url": "https://github.com/apache/flink/commit/7d569e6f56d203d6cd0eaeb43b2f0b99db345bba",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/7d569e6f56d203d6cd0eaeb43b2f0b99db345bba/comments",
            "author": {
                "login": "dianfu",
                "id": 5466492,
                "node_id": "MDQ6VXNlcjU0NjY0OTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5466492?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dianfu",
                "html_url": "https://github.com/dianfu",
                "followers_url": "https://api.github.com/users/dianfu/followers",
                "following_url": "https://api.github.com/users/dianfu/following{/other_user}",
                "gists_url": "https://api.github.com/users/dianfu/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dianfu/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dianfu/subscriptions",
                "organizations_url": "https://api.github.com/users/dianfu/orgs",
                "repos_url": "https://api.github.com/users/dianfu/repos",
                "events_url": "https://api.github.com/users/dianfu/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dianfu/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "dianfu",
                "id": 5466492,
                "node_id": "MDQ6VXNlcjU0NjY0OTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5466492?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dianfu",
                "html_url": "https://github.com/dianfu",
                "followers_url": "https://api.github.com/users/dianfu/followers",
                "following_url": "https://api.github.com/users/dianfu/following{/other_user}",
                "gists_url": "https://api.github.com/users/dianfu/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dianfu/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dianfu/subscriptions",
                "organizations_url": "https://api.github.com/users/dianfu/orgs",
                "repos_url": "https://api.github.com/users/dianfu/repos",
                "events_url": "https://api.github.com/users/dianfu/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dianfu/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "60b604425b97e759c0d3d8f62b3a24d656dd6e4c",
                "url": "https://api.github.com/repos/apache/flink/commits/60b604425b97e759c0d3d8f62b3a24d656dd6e4c",
                "html_url": "https://github.com/apache/flink/commit/60b604425b97e759c0d3d8f62b3a24d656dd6e4c"
            }]
        },
        {
            "sha": "a102549f08759e177074dad286fef2f56176d005",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6YTEwMjU0OWYwODc1OWUxNzcwNzRkYWQyODZmZWYyZjU2MTc2ZDAwNQ==",
            "commit": {
                "author": {
                    "name": "Arvid Heise",
                    "email": "arvid@ververica.com",
                    "date": "2021-05-04T16:01:18Z"
                },
                "committer": {
                    "name": "Arvid Heise",
                    "email": "AHeise@users.noreply.github.com",
                    "date": "2021-05-07T15:24:55Z"
                },
                "message": "[FLINK-17170][kinesis] Move KinesaliteContainer to flink-connector-kinesis.\n\nThis testcontainer will be used in an ITCase in the next commit.\n\nAlso move system properties required for test into pom.xml.",
                "tree": {
                    "sha": "fed87dcdf40a54263dd197a06787bac596012238",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/fed87dcdf40a54263dd197a06787bac596012238"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/a102549f08759e177074dad286fef2f56176d005",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/a102549f08759e177074dad286fef2f56176d005",
            "html_url": "https://github.com/apache/flink/commit/a102549f08759e177074dad286fef2f56176d005",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/a102549f08759e177074dad286fef2f56176d005/comments",
            "author": {
                "login": "AHeise",
                "id": 4559103,
                "node_id": "MDQ6VXNlcjQ1NTkxMDM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/4559103?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/AHeise",
                "html_url": "https://github.com/AHeise",
                "followers_url": "https://api.github.com/users/AHeise/followers",
                "following_url": "https://api.github.com/users/AHeise/following{/other_user}",
                "gists_url": "https://api.github.com/users/AHeise/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/AHeise/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/AHeise/subscriptions",
                "organizations_url": "https://api.github.com/users/AHeise/orgs",
                "repos_url": "https://api.github.com/users/AHeise/repos",
                "events_url": "https://api.github.com/users/AHeise/events{/privacy}",
                "received_events_url": "https://api.github.com/users/AHeise/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "AHeise",
                "id": 4559103,
                "node_id": "MDQ6VXNlcjQ1NTkxMDM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/4559103?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/AHeise",
                "html_url": "https://github.com/AHeise",
                "followers_url": "https://api.github.com/users/AHeise/followers",
                "following_url": "https://api.github.com/users/AHeise/following{/other_user}",
                "gists_url": "https://api.github.com/users/AHeise/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/AHeise/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/AHeise/subscriptions",
                "organizations_url": "https://api.github.com/users/AHeise/orgs",
                "repos_url": "https://api.github.com/users/AHeise/repos",
                "events_url": "https://api.github.com/users/AHeise/events{/privacy}",
                "received_events_url": "https://api.github.com/users/AHeise/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "7d569e6f56d203d6cd0eaeb43b2f0b99db345bba",
                "url": "https://api.github.com/repos/apache/flink/commits/7d569e6f56d203d6cd0eaeb43b2f0b99db345bba",
                "html_url": "https://github.com/apache/flink/commit/7d569e6f56d203d6cd0eaeb43b2f0b99db345bba"
            }]
        },
        {
            "sha": "282f9a3d5505a5aa58d7d9cca466939610d41ed3",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MjgyZjlhM2Q1NTA1YTVhYTU4ZDdkOWNjYTQ2NjkzOTYxMGQ0MWVkMw==",
            "commit": {
                "author": {
                    "name": "Arvid Heise",
                    "email": "arvid@ververica.com",
                    "date": "2021-05-04T07:38:30Z"
                },
                "committer": {
                    "name": "Arvid Heise",
                    "email": "AHeise@users.noreply.github.com",
                    "date": "2021-05-07T15:24:55Z"
                },
                "message": "[FLINK-17170][kinesis] Fix deadlock during stop-with-savepoint.\n\nDuring stop-with-savepoint cancel is called under lock in legacy sources. Thus, if the fetcher is trying to emit a record at the same time, it cannot obtain the checkpoint lock. This behavior leads to a deadlock while cancel awaits the termination of the fetcher.\nThe fix is to mostly rely on the termination inside the run method. As a safe-guard, close also awaits termination where close is always caused without lock.",
                "tree": {
                    "sha": "051ad1de9927b2efee78885a852741de8baf0f60",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/051ad1de9927b2efee78885a852741de8baf0f60"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/282f9a3d5505a5aa58d7d9cca466939610d41ed3",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/282f9a3d5505a5aa58d7d9cca466939610d41ed3",
            "html_url": "https://github.com/apache/flink/commit/282f9a3d5505a5aa58d7d9cca466939610d41ed3",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/282f9a3d5505a5aa58d7d9cca466939610d41ed3/comments",
            "author": {
                "login": "AHeise",
                "id": 4559103,
                "node_id": "MDQ6VXNlcjQ1NTkxMDM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/4559103?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/AHeise",
                "html_url": "https://github.com/AHeise",
                "followers_url": "https://api.github.com/users/AHeise/followers",
                "following_url": "https://api.github.com/users/AHeise/following{/other_user}",
                "gists_url": "https://api.github.com/users/AHeise/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/AHeise/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/AHeise/subscriptions",
                "organizations_url": "https://api.github.com/users/AHeise/orgs",
                "repos_url": "https://api.github.com/users/AHeise/repos",
                "events_url": "https://api.github.com/users/AHeise/events{/privacy}",
                "received_events_url": "https://api.github.com/users/AHeise/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "AHeise",
                "id": 4559103,
                "node_id": "MDQ6VXNlcjQ1NTkxMDM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/4559103?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/AHeise",
                "html_url": "https://github.com/AHeise",
                "followers_url": "https://api.github.com/users/AHeise/followers",
                "following_url": "https://api.github.com/users/AHeise/following{/other_user}",
                "gists_url": "https://api.github.com/users/AHeise/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/AHeise/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/AHeise/subscriptions",
                "organizations_url": "https://api.github.com/users/AHeise/orgs",
                "repos_url": "https://api.github.com/users/AHeise/repos",
                "events_url": "https://api.github.com/users/AHeise/events{/privacy}",
                "received_events_url": "https://api.github.com/users/AHeise/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "a102549f08759e177074dad286fef2f56176d005",
                "url": "https://api.github.com/repos/apache/flink/commits/a102549f08759e177074dad286fef2f56176d005",
                "html_url": "https://github.com/apache/flink/commit/a102549f08759e177074dad286fef2f56176d005"
            }]
        },
        {
            "sha": "67e545dc3fc21d1c8e97c94f633adf2177463cc8",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NjdlNTQ1ZGMzZmMyMWQxYzhlOTdjOTRmNjMzYWRmMjE3NzQ2M2NjOA==",
            "commit": {
                "author": {
                    "name": "Timo Walther",
                    "email": "twalthr@apache.org",
                    "date": "2021-05-07T16:31:02Z"
                },
                "committer": {
                    "name": "Timo Walther",
                    "email": "twalthr@apache.org",
                    "date": "2021-05-07T16:34:03Z"
                },
                "message": "[hotfix][docs] Mention new StreamTableEnvironment.fromDataStream in release notes",
                "tree": {
                    "sha": "d8d8d80ffc3bbda9325ad9aacfcc11f34b680ecf",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/d8d8d80ffc3bbda9325ad9aacfcc11f34b680ecf"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/67e545dc3fc21d1c8e97c94f633adf2177463cc8",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/67e545dc3fc21d1c8e97c94f633adf2177463cc8",
            "html_url": "https://github.com/apache/flink/commit/67e545dc3fc21d1c8e97c94f633adf2177463cc8",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/67e545dc3fc21d1c8e97c94f633adf2177463cc8/comments",
            "author": {
                "login": "twalthr",
                "id": 5746567,
                "node_id": "MDQ6VXNlcjU3NDY1Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5746567?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/twalthr",
                "html_url": "https://github.com/twalthr",
                "followers_url": "https://api.github.com/users/twalthr/followers",
                "following_url": "https://api.github.com/users/twalthr/following{/other_user}",
                "gists_url": "https://api.github.com/users/twalthr/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/twalthr/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/twalthr/subscriptions",
                "organizations_url": "https://api.github.com/users/twalthr/orgs",
                "repos_url": "https://api.github.com/users/twalthr/repos",
                "events_url": "https://api.github.com/users/twalthr/events{/privacy}",
                "received_events_url": "https://api.github.com/users/twalthr/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "twalthr",
                "id": 5746567,
                "node_id": "MDQ6VXNlcjU3NDY1Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5746567?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/twalthr",
                "html_url": "https://github.com/twalthr",
                "followers_url": "https://api.github.com/users/twalthr/followers",
                "following_url": "https://api.github.com/users/twalthr/following{/other_user}",
                "gists_url": "https://api.github.com/users/twalthr/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/twalthr/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/twalthr/subscriptions",
                "organizations_url": "https://api.github.com/users/twalthr/orgs",
                "repos_url": "https://api.github.com/users/twalthr/repos",
                "events_url": "https://api.github.com/users/twalthr/events{/privacy}",
                "received_events_url": "https://api.github.com/users/twalthr/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "282f9a3d5505a5aa58d7d9cca466939610d41ed3",
                "url": "https://api.github.com/repos/apache/flink/commits/282f9a3d5505a5aa58d7d9cca466939610d41ed3",
                "html_url": "https://github.com/apache/flink/commit/282f9a3d5505a5aa58d7d9cca466939610d41ed3"
            }]
        },
        {
            "sha": "a1d356aad9acf4752f793d4fbd66f7f2e110eaee",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6YTFkMzU2YWFkOWFjZjQ3NTJmNzkzZDRmYmQ2NmY3ZjJlMTEwZWFlZQ==",
            "commit": {
                "author": {
                    "name": "Timo Walther",
                    "email": "twalthr@apache.org",
                    "date": "2021-05-07T16:36:12Z"
                },
                "committer": {
                    "name": "Timo Walther",
                    "email": "twalthr@apache.org",
                    "date": "2021-05-07T16:36:12Z"
                },
                "message": "[hotfix][docs] Mention new StreamTableEnvironment.fromDataStream in Chinese release notes",
                "tree": {
                    "sha": "b1b99e3952633446c25c17c3ecfd70f6dbb23161",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/b1b99e3952633446c25c17c3ecfd70f6dbb23161"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/a1d356aad9acf4752f793d4fbd66f7f2e110eaee",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/a1d356aad9acf4752f793d4fbd66f7f2e110eaee",
            "html_url": "https://github.com/apache/flink/commit/a1d356aad9acf4752f793d4fbd66f7f2e110eaee",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/a1d356aad9acf4752f793d4fbd66f7f2e110eaee/comments",
            "author": {
                "login": "twalthr",
                "id": 5746567,
                "node_id": "MDQ6VXNlcjU3NDY1Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5746567?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/twalthr",
                "html_url": "https://github.com/twalthr",
                "followers_url": "https://api.github.com/users/twalthr/followers",
                "following_url": "https://api.github.com/users/twalthr/following{/other_user}",
                "gists_url": "https://api.github.com/users/twalthr/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/twalthr/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/twalthr/subscriptions",
                "organizations_url": "https://api.github.com/users/twalthr/orgs",
                "repos_url": "https://api.github.com/users/twalthr/repos",
                "events_url": "https://api.github.com/users/twalthr/events{/privacy}",
                "received_events_url": "https://api.github.com/users/twalthr/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "twalthr",
                "id": 5746567,
                "node_id": "MDQ6VXNlcjU3NDY1Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5746567?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/twalthr",
                "html_url": "https://github.com/twalthr",
                "followers_url": "https://api.github.com/users/twalthr/followers",
                "following_url": "https://api.github.com/users/twalthr/following{/other_user}",
                "gists_url": "https://api.github.com/users/twalthr/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/twalthr/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/twalthr/subscriptions",
                "organizations_url": "https://api.github.com/users/twalthr/orgs",
                "repos_url": "https://api.github.com/users/twalthr/repos",
                "events_url": "https://api.github.com/users/twalthr/events{/privacy}",
                "received_events_url": "https://api.github.com/users/twalthr/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "67e545dc3fc21d1c8e97c94f633adf2177463cc8",
                "url": "https://api.github.com/repos/apache/flink/commits/67e545dc3fc21d1c8e97c94f633adf2177463cc8",
                "html_url": "https://github.com/apache/flink/commit/67e545dc3fc21d1c8e97c94f633adf2177463cc8"
            }]
        },
        {
            "sha": "908752919e2f7518eaa5e38f4b36e796caa57baf",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6OTA4NzUyOTE5ZTJmNzUxOGVhYTVlMzhmNGIzNmU3OTZjYWE1N2JhZg==",
            "commit": {
                "author": {
                    "name": "HuangXiao",
                    "email": "hx36w35@163.com",
                    "date": "2021-05-08T05:08:10Z"
                },
                "committer": {
                    "name": "Xintong Song",
                    "email": "tonysong820@gmail.com",
                    "date": "2021-05-08T06:16:35Z"
                },
                "message": "[FLINK-22355][docs] Fix simple task manager memory model image\n\nThis closes #15862",
                "tree": {
                    "sha": "a2b2a879f3efdb83bc7d6aac43f0c5745f63bb97",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/a2b2a879f3efdb83bc7d6aac43f0c5745f63bb97"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/908752919e2f7518eaa5e38f4b36e796caa57baf",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCgAdFiEEGsvLF58sbVnbyFd20SHP9Sk+Y18FAmCWLMMACgkQ0SHP9Sk+\nY19eyQ/7BNZcsiMPabZ/d+2HwZsQbMhWfkzbhyjx1wohOO6NyAeMeqEpTfeeKMIh\nFc5p2Pn1Aix5OWjeRBpnbM7+BwcFOMDXeWu8ZPAV406V3il2oEAzSgkvBExhhr5T\n9zzGpRQM5f/8g/2iYlf5gqNJX/oot/3KC8d2IRW+aZm4huaoR3iNs2w5zfwNXd2t\no+37Wdx1pFZbaglbPDTFV0l2QqfS8Wu4yGccIlutolOPxt4+/WMDm9SmftXvT6a1\n8uRQidMaSA1bLQx4NoAyDbIva5xG3Aln4kadeFFyAdRfE8jaSscf2z2w+xu4bI1y\nU1MuqIb3/fIiYdMek/Ku3kcWL9rNFD144FqqIhuuNWWdOArjwt28oWepVtz0x2rs\nN157a8R/w1e385pi1KzM7UsagDEgw0l++9C3Vj8tfMx3GiToKlhScmbiRf/iJ1DF\n4Nf+lU0+g/Ciey2HqcHZ9EF6UWrlvNf/PGw1u7UYXj+miungLGwS9qJhkC4T1RmB\nAazUj4mhrNo5dD4Q97ujq5FDoYNZYpJpYBWSfgVTlkLZtdPejUaOsgGdDxk6VOAm\nwhCDc34ClPEL1iuvcy2i8r3aZV2S87l3QFpR/XLmPBFUunxC8QzTOVhRQ7sgQ0R9\nLGTYOqj9vxZ6TYZt1FHuAwbwjtE0bxDfJa9QQnDJLMs0/QzS13g=\n=eOSn\n-----END PGP SIGNATURE-----",
                    "payload": "tree a2b2a879f3efdb83bc7d6aac43f0c5745f63bb97\nparent a1d356aad9acf4752f793d4fbd66f7f2e110eaee\nauthor HuangXiao <hx36w35@163.com> 1620450490 +0800\ncommitter Xintong Song <tonysong820@gmail.com> 1620454595 +0800\n\n[FLINK-22355][docs] Fix simple task manager memory model image\n\nThis closes #15862\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/908752919e2f7518eaa5e38f4b36e796caa57baf",
            "html_url": "https://github.com/apache/flink/commit/908752919e2f7518eaa5e38f4b36e796caa57baf",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/908752919e2f7518eaa5e38f4b36e796caa57baf/comments",
            "author": {
                "login": "Shawn-Hx",
                "id": 18097476,
                "node_id": "MDQ6VXNlcjE4MDk3NDc2",
                "avatar_url": "https://avatars.githubusercontent.com/u/18097476?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/Shawn-Hx",
                "html_url": "https://github.com/Shawn-Hx",
                "followers_url": "https://api.github.com/users/Shawn-Hx/followers",
                "following_url": "https://api.github.com/users/Shawn-Hx/following{/other_user}",
                "gists_url": "https://api.github.com/users/Shawn-Hx/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/Shawn-Hx/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/Shawn-Hx/subscriptions",
                "organizations_url": "https://api.github.com/users/Shawn-Hx/orgs",
                "repos_url": "https://api.github.com/users/Shawn-Hx/repos",
                "events_url": "https://api.github.com/users/Shawn-Hx/events{/privacy}",
                "received_events_url": "https://api.github.com/users/Shawn-Hx/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "xintongsong",
                "id": 6509172,
                "node_id": "MDQ6VXNlcjY1MDkxNzI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6509172?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/xintongsong",
                "html_url": "https://github.com/xintongsong",
                "followers_url": "https://api.github.com/users/xintongsong/followers",
                "following_url": "https://api.github.com/users/xintongsong/following{/other_user}",
                "gists_url": "https://api.github.com/users/xintongsong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/xintongsong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/xintongsong/subscriptions",
                "organizations_url": "https://api.github.com/users/xintongsong/orgs",
                "repos_url": "https://api.github.com/users/xintongsong/repos",
                "events_url": "https://api.github.com/users/xintongsong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/xintongsong/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "a1d356aad9acf4752f793d4fbd66f7f2e110eaee",
                "url": "https://api.github.com/repos/apache/flink/commits/a1d356aad9acf4752f793d4fbd66f7f2e110eaee",
                "html_url": "https://github.com/apache/flink/commit/a1d356aad9acf4752f793d4fbd66f7f2e110eaee"
            }]
        },
        {
            "sha": "4ba54dd11c88411228e7330f3894ae3f481df26f",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NGJhNTRkZDExYzg4NDExMjI4ZTczMzBmMzg5NGFlM2Y0ODFkZjI2Zg==",
            "commit": {
                "author": {
                    "name": "Dian Fu",
                    "email": "dianfu@apache.org",
                    "date": "2021-05-08T13:05:20Z"
                },
                "committer": {
                    "name": "Dian Fu",
                    "email": "dianfu@apache.org",
                    "date": "2021-05-08T13:06:00Z"
                },
                "message": "[hotfix][docs] Correct the examples in Python DataStream API",
                "tree": {
                    "sha": "7e6632dbb0e4325f9d444aefbaabd327a15c9ece",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/7e6632dbb0e4325f9d444aefbaabd327a15c9ece"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/4ba54dd11c88411228e7330f3894ae3f481df26f",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/4ba54dd11c88411228e7330f3894ae3f481df26f",
            "html_url": "https://github.com/apache/flink/commit/4ba54dd11c88411228e7330f3894ae3f481df26f",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/4ba54dd11c88411228e7330f3894ae3f481df26f/comments",
            "author": {
                "login": "dianfu",
                "id": 5466492,
                "node_id": "MDQ6VXNlcjU0NjY0OTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5466492?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dianfu",
                "html_url": "https://github.com/dianfu",
                "followers_url": "https://api.github.com/users/dianfu/followers",
                "following_url": "https://api.github.com/users/dianfu/following{/other_user}",
                "gists_url": "https://api.github.com/users/dianfu/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dianfu/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dianfu/subscriptions",
                "organizations_url": "https://api.github.com/users/dianfu/orgs",
                "repos_url": "https://api.github.com/users/dianfu/repos",
                "events_url": "https://api.github.com/users/dianfu/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dianfu/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "dianfu",
                "id": 5466492,
                "node_id": "MDQ6VXNlcjU0NjY0OTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5466492?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dianfu",
                "html_url": "https://github.com/dianfu",
                "followers_url": "https://api.github.com/users/dianfu/followers",
                "following_url": "https://api.github.com/users/dianfu/following{/other_user}",
                "gists_url": "https://api.github.com/users/dianfu/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dianfu/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dianfu/subscriptions",
                "organizations_url": "https://api.github.com/users/dianfu/orgs",
                "repos_url": "https://api.github.com/users/dianfu/repos",
                "events_url": "https://api.github.com/users/dianfu/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dianfu/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "908752919e2f7518eaa5e38f4b36e796caa57baf",
                "url": "https://api.github.com/repos/apache/flink/commits/908752919e2f7518eaa5e38f4b36e796caa57baf",
                "html_url": "https://github.com/apache/flink/commit/908752919e2f7518eaa5e38f4b36e796caa57baf"
            }]
        },
        {
            "sha": "388d80733b7b9ede38602c5d8b49c659eb00542d",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6Mzg4ZDgwNzMzYjdiOWVkZTM4NjAyYzVkOGI0OWM2NTllYjAwNTQyZA==",
            "commit": {
                "author": {
                    "name": "mans2singh",
                    "email": "mans2singh@users.noreply.github.com",
                    "date": "2021-05-09T21:22:28Z"
                },
                "committer": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-05-09T21:22:54Z"
                },
                "message": "[hotfix][docs] Fix image links",
                "tree": {
                    "sha": "60306fbb3ca4510dc0df072285a9859736058f02",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/60306fbb3ca4510dc0df072285a9859736058f02"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/388d80733b7b9ede38602c5d8b49c659eb00542d",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/388d80733b7b9ede38602c5d8b49c659eb00542d",
            "html_url": "https://github.com/apache/flink/commit/388d80733b7b9ede38602c5d8b49c659eb00542d",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/388d80733b7b9ede38602c5d8b49c659eb00542d/comments",
            "author": {
                "login": "mans2singh",
                "id": 8467404,
                "node_id": "MDQ6VXNlcjg0Njc0MDQ=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8467404?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/mans2singh",
                "html_url": "https://github.com/mans2singh",
                "followers_url": "https://api.github.com/users/mans2singh/followers",
                "following_url": "https://api.github.com/users/mans2singh/following{/other_user}",
                "gists_url": "https://api.github.com/users/mans2singh/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/mans2singh/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/mans2singh/subscriptions",
                "organizations_url": "https://api.github.com/users/mans2singh/orgs",
                "repos_url": "https://api.github.com/users/mans2singh/repos",
                "events_url": "https://api.github.com/users/mans2singh/events{/privacy}",
                "received_events_url": "https://api.github.com/users/mans2singh/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "4ba54dd11c88411228e7330f3894ae3f481df26f",
                "url": "https://api.github.com/repos/apache/flink/commits/4ba54dd11c88411228e7330f3894ae3f481df26f",
                "html_url": "https://github.com/apache/flink/commit/4ba54dd11c88411228e7330f3894ae3f481df26f"
            }]
        },
        {
            "sha": "cfa9a398ccb73ce38f9df0478bcbe547013c756b",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6Y2ZhOWEzOThjY2I3M2NlMzhmOWRmMDQ3OGJjYmU1NDcwMTNjNzU2Yg==",
            "commit": {
                "author": {
                    "name": "Leonard Xu",
                    "email": "xbjtdcq@gmail.com",
                    "date": "2021-05-08T07:40:30Z"
                },
                "committer": {
                    "name": "Timo Walther",
                    "email": "twalthr@apache.org",
                    "date": "2021-05-10T07:23:30Z"
                },
                "message": "[FLINK-22559][table-planner] The consumed DataType of ExecSink should only consider physical columns\n\nThis closes #15864.",
                "tree": {
                    "sha": "1e03945195463ad6b97abfafc9fa04ebd67413d6",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/1e03945195463ad6b97abfafc9fa04ebd67413d6"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/cfa9a398ccb73ce38f9df0478bcbe547013c756b",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/cfa9a398ccb73ce38f9df0478bcbe547013c756b",
            "html_url": "https://github.com/apache/flink/commit/cfa9a398ccb73ce38f9df0478bcbe547013c756b",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/cfa9a398ccb73ce38f9df0478bcbe547013c756b/comments",
            "author": {
                "login": "leonardBang",
                "id": 5163645,
                "node_id": "MDQ6VXNlcjUxNjM2NDU=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5163645?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/leonardBang",
                "html_url": "https://github.com/leonardBang",
                "followers_url": "https://api.github.com/users/leonardBang/followers",
                "following_url": "https://api.github.com/users/leonardBang/following{/other_user}",
                "gists_url": "https://api.github.com/users/leonardBang/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/leonardBang/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/leonardBang/subscriptions",
                "organizations_url": "https://api.github.com/users/leonardBang/orgs",
                "repos_url": "https://api.github.com/users/leonardBang/repos",
                "events_url": "https://api.github.com/users/leonardBang/events{/privacy}",
                "received_events_url": "https://api.github.com/users/leonardBang/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "twalthr",
                "id": 5746567,
                "node_id": "MDQ6VXNlcjU3NDY1Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5746567?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/twalthr",
                "html_url": "https://github.com/twalthr",
                "followers_url": "https://api.github.com/users/twalthr/followers",
                "following_url": "https://api.github.com/users/twalthr/following{/other_user}",
                "gists_url": "https://api.github.com/users/twalthr/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/twalthr/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/twalthr/subscriptions",
                "organizations_url": "https://api.github.com/users/twalthr/orgs",
                "repos_url": "https://api.github.com/users/twalthr/repos",
                "events_url": "https://api.github.com/users/twalthr/events{/privacy}",
                "received_events_url": "https://api.github.com/users/twalthr/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "388d80733b7b9ede38602c5d8b49c659eb00542d",
                "url": "https://api.github.com/repos/apache/flink/commits/388d80733b7b9ede38602c5d8b49c659eb00542d",
                "html_url": "https://github.com/apache/flink/commit/388d80733b7b9ede38602c5d8b49c659eb00542d"
            }]
        },
        {
            "sha": "3a9d14457f886937b8604607dee10d1046323dc7",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6M2E5ZDE0NDU3Zjg4NjkzN2I4NjA0NjA3ZGVlMTBkMTA0NjMyM2RjNw==",
            "commit": {
                "author": {
                    "name": "Dawid Wysakowicz",
                    "email": "dwysakowicz@apache.org",
                    "date": "2021-05-07T14:51:46Z"
                },
                "committer": {
                    "name": "Dawid Wysakowicz",
                    "email": "dwysakowicz@apache.org",
                    "date": "2021-05-10T09:21:07Z"
                },
                "message": "[FLINK-22596] Active timeout is not triggered if there were no barriers\n\nThe active timeout did not take effect if it elapsed before the first\nbarrier arrived. The reason is that we did not reset the future for\ncheckpoint complete on barrier announcement. Therefore we considered the\ncompleted status for previous checkpoint when evaluating the timeout for\ncurrent checkpoint.",
                "tree": {
                    "sha": "9fdfda114ac744691a32886762a69bfa65de2fba",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/9fdfda114ac744691a32886762a69bfa65de2fba"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/3a9d14457f886937b8604607dee10d1046323dc7",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEE6pOkNbTiybTJ9TP2MdLdEL/BWi0FAmCY+wMACgkQMdLdEL/B\nWi0bVQ/+KdBYGUbs2P9BHGmUNRQn4b625q3pVBXr8kH3om8t9yihBnw7xLLsxNqp\n8cgesIorFZ9sE0dttZTHkIbORgNy/qtPamTw36ZbtJhJVY7YNN0pnLGSPXYkkkOc\nAYWAc0YNdlamz48kyNHp+m54XoJzdsRY9+UbBGWiaMGEUnV3SOhHOKeeZ8b7sE6d\nFb8CaaMR2aM9Rp6veaNjhpPpG5CycyWQUH2CYie7yOMDgkygJuKN9uwUgAw7UApF\nH7HPoQ3Hm52DHCXkueoWPvakDFxQLkkGqqp0rE7s8iS6f/AisAh3qAi95CK+dr42\nUX5ZzXRuYVTjLy0v1Rcd/ttViaVtRJeiSU1VgC/R8D0QTLIgtxgyOYwfj319pmn5\n/GXeEI6of+ewwRA1OlaNL7g7bLME27NYejU/+gU4Y2ojwsHKpSt7qeqwJ5V73KbZ\nwRpbeLsEsQDtZH7L1HA9UTg1P5erYdNnksQthN8LTgEijF7cZGpUn6gw26UzZQl1\nPLrR/2rD8gPrWro0I7pna4Izq0H+OjwU2ppIv4slylE3xvznSeGErCwHQZKB3uVs\noepGY27ciA+9Y+nZ/msYRDuo4mjkD8qja6LRy/viXcYLYKoslZxdAmD84GzgyeEO\n1PhKN1Ueoyc2LFRBKRaKK+OwxJV+VdYCYUIC7foKQT2EoKdIyb0=\n=UQMt\n-----END PGP SIGNATURE-----",
                    "payload": "tree 9fdfda114ac744691a32886762a69bfa65de2fba\nparent cfa9a398ccb73ce38f9df0478bcbe547013c756b\nauthor Dawid Wysakowicz <dwysakowicz@apache.org> 1620399106 +0200\ncommitter Dawid Wysakowicz <dwysakowicz@apache.org> 1620638467 +0200\n\n[FLINK-22596] Active timeout is not triggered if there were no barriers\n\nThe active timeout did not take effect if it elapsed before the first\nbarrier arrived. The reason is that we did not reset the future for\ncheckpoint complete on barrier announcement. Therefore we considered the\ncompleted status for previous checkpoint when evaluating the timeout for\ncurrent checkpoint.\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/3a9d14457f886937b8604607dee10d1046323dc7",
            "html_url": "https://github.com/apache/flink/commit/3a9d14457f886937b8604607dee10d1046323dc7",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/3a9d14457f886937b8604607dee10d1046323dc7/comments",
            "author": {
                "login": "dawidwys",
                "id": 6242259,
                "node_id": "MDQ6VXNlcjYyNDIyNTk=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6242259?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dawidwys",
                "html_url": "https://github.com/dawidwys",
                "followers_url": "https://api.github.com/users/dawidwys/followers",
                "following_url": "https://api.github.com/users/dawidwys/following{/other_user}",
                "gists_url": "https://api.github.com/users/dawidwys/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dawidwys/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dawidwys/subscriptions",
                "organizations_url": "https://api.github.com/users/dawidwys/orgs",
                "repos_url": "https://api.github.com/users/dawidwys/repos",
                "events_url": "https://api.github.com/users/dawidwys/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dawidwys/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "dawidwys",
                "id": 6242259,
                "node_id": "MDQ6VXNlcjYyNDIyNTk=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6242259?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dawidwys",
                "html_url": "https://github.com/dawidwys",
                "followers_url": "https://api.github.com/users/dawidwys/followers",
                "following_url": "https://api.github.com/users/dawidwys/following{/other_user}",
                "gists_url": "https://api.github.com/users/dawidwys/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dawidwys/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dawidwys/subscriptions",
                "organizations_url": "https://api.github.com/users/dawidwys/orgs",
                "repos_url": "https://api.github.com/users/dawidwys/repos",
                "events_url": "https://api.github.com/users/dawidwys/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dawidwys/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "cfa9a398ccb73ce38f9df0478bcbe547013c756b",
                "url": "https://api.github.com/repos/apache/flink/commits/cfa9a398ccb73ce38f9df0478bcbe547013c756b",
                "html_url": "https://github.com/apache/flink/commit/cfa9a398ccb73ce38f9df0478bcbe547013c756b"
            }]
        },
        {
            "sha": "4e47654664bce1ea80d925de6a4ffc73e9421408",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NGU0NzY1NDY2NGJjZTFlYTgwZDkyNWRlNmE0ZmZjNzNlOTQyMTQwOA==",
            "commit": {
                "author": {
                    "name": "Timo Walther",
                    "email": "twalthr@apache.org",
                    "date": "2021-05-03T14:44:27Z"
                },
                "committer": {
                    "name": "Timo Walther",
                    "email": "twalthr@apache.org",
                    "date": "2021-05-10T09:22:14Z"
                },
                "message": "[FLINK-22537][docs] Add documentation how to interact with DataStream API\n\nThis closes #15837.",
                "tree": {
                    "sha": "2a3e179594abd821a1e8680c56c257c73715beff",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/2a3e179594abd821a1e8680c56c257c73715beff"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/4e47654664bce1ea80d925de6a4ffc73e9421408",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/4e47654664bce1ea80d925de6a4ffc73e9421408",
            "html_url": "https://github.com/apache/flink/commit/4e47654664bce1ea80d925de6a4ffc73e9421408",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/4e47654664bce1ea80d925de6a4ffc73e9421408/comments",
            "author": {
                "login": "twalthr",
                "id": 5746567,
                "node_id": "MDQ6VXNlcjU3NDY1Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5746567?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/twalthr",
                "html_url": "https://github.com/twalthr",
                "followers_url": "https://api.github.com/users/twalthr/followers",
                "following_url": "https://api.github.com/users/twalthr/following{/other_user}",
                "gists_url": "https://api.github.com/users/twalthr/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/twalthr/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/twalthr/subscriptions",
                "organizations_url": "https://api.github.com/users/twalthr/orgs",
                "repos_url": "https://api.github.com/users/twalthr/repos",
                "events_url": "https://api.github.com/users/twalthr/events{/privacy}",
                "received_events_url": "https://api.github.com/users/twalthr/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "twalthr",
                "id": 5746567,
                "node_id": "MDQ6VXNlcjU3NDY1Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5746567?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/twalthr",
                "html_url": "https://github.com/twalthr",
                "followers_url": "https://api.github.com/users/twalthr/followers",
                "following_url": "https://api.github.com/users/twalthr/following{/other_user}",
                "gists_url": "https://api.github.com/users/twalthr/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/twalthr/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/twalthr/subscriptions",
                "organizations_url": "https://api.github.com/users/twalthr/orgs",
                "repos_url": "https://api.github.com/users/twalthr/repos",
                "events_url": "https://api.github.com/users/twalthr/events{/privacy}",
                "received_events_url": "https://api.github.com/users/twalthr/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "3a9d14457f886937b8604607dee10d1046323dc7",
                "url": "https://api.github.com/repos/apache/flink/commits/3a9d14457f886937b8604607dee10d1046323dc7",
                "html_url": "https://github.com/apache/flink/commit/3a9d14457f886937b8604607dee10d1046323dc7"
            }]
        },
        {
            "sha": "3ff9eb7029784349fb135e6849b745ba82c7b8c0",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6M2ZmOWViNzAyOTc4NDM0OWZiMTM1ZTY4NDliNzQ1YmE4MmM3YjhjMA==",
            "commit": {
                "author": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-05-06T13:29:01Z"
                },
                "committer": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-05-10T10:07:32Z"
                },
                "message": "[FLINK-22577][tests] Harden KubernetesLeaderElectionAndRetrievalITCase\n\nThis commit introduces closing logic to the TestingLeaderElectionEventHandler which would\notherwise forward calls after the KubernetesLeaderElectionDriver is closed.\n\nThis closes #15856.",
                "tree": {
                    "sha": "08c798e60c536c84c269ae430c9fabfd09f8f163",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/08c798e60c536c84c269ae430c9fabfd09f8f163"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/3ff9eb7029784349fb135e6849b745ba82c7b8c0",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEEuUmfpp7/Xe7rw8H1un5Bh8b3PYIFAmCZBeQACgkQun5Bh8b3\nPYLgoA/9Fv31E2yteZE1m3V3MOufiUkvPofEu1DIX/l6LVf+YgmeYabLAO6zr3JC\nKn9FJBjfXj8FO7u4qtIcgCorpEmBPrDiUuSeZHUqFWyiZan+WOZbXYgQhTW47drs\nVbMZKvh0sQCqkCremrSSJDTnSzqHZ/I3QUpbDgnOoAXhd9ySca7k84qMbOjeL1xp\nU4H6wnhtmAjhZuBPOm66SozcGqGF0AU5dik5JXRsBx5K+W1k3Ak8d/0cubJrZA1u\nIFr4SqDB355dkJ04wfs7toGvhscgGAk6AvcfcssZ9rOnKFAG8YG5CbcxbU+9Z8XF\nLT48daaBSJfKJnP/GHBEuD2+WHqUmdQZqCiHWvRS3Z0NJrTpbT7XYtJURDDxl/w1\nkIOreMxtRwu7v3MryJNs8JMzCVGwouPajyPyCCu7V3G6X8FRhcMLFbqGash3u0/u\nCfhZfBzHsyRm4ujaHRlB2rKwFvPm9bdB8daBtKkBHbxLR58IG+GIV7m+vilTUW1j\nfxOKcqOrQqTLV9iFgmMhKJ+EwhFGRCQTvVQKM9neVdRqSwywh43RMfrscTZeyNjy\nrJvOnWWubGlOuKAEtSOU3IHBdDPRbnyj7DX/ZCM2VxDwv18zxNAjdL9ki6rtNECG\ndq9CowR4kPjcutLphDVGjVX5VRH8om0TozHoYnGlRQ3uB+8Fs7o=\n=3JMJ\n-----END PGP SIGNATURE-----",
                    "payload": "tree 08c798e60c536c84c269ae430c9fabfd09f8f163\nparent 4e47654664bce1ea80d925de6a4ffc73e9421408\nauthor Till Rohrmann <trohrmann@apache.org> 1620307741 +0200\ncommitter Till Rohrmann <trohrmann@apache.org> 1620641252 +0200\n\n[FLINK-22577][tests] Harden KubernetesLeaderElectionAndRetrievalITCase\n\nThis commit introduces closing logic to the TestingLeaderElectionEventHandler which would\notherwise forward calls after the KubernetesLeaderElectionDriver is closed.\n\nThis closes #15856.\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/3ff9eb7029784349fb135e6849b745ba82c7b8c0",
            "html_url": "https://github.com/apache/flink/commit/3ff9eb7029784349fb135e6849b745ba82c7b8c0",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/3ff9eb7029784349fb135e6849b745ba82c7b8c0/comments",
            "author": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "4e47654664bce1ea80d925de6a4ffc73e9421408",
                "url": "https://api.github.com/repos/apache/flink/commits/4e47654664bce1ea80d925de6a4ffc73e9421408",
                "html_url": "https://github.com/apache/flink/commit/4e47654664bce1ea80d925de6a4ffc73e9421408"
            }]
        },
        {
            "sha": "ce7c78ca72ce86df0b4a28fbd3233b89da3238e1",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6Y2U3Yzc4Y2E3MmNlODZkZjBiNGEyOGZiZDMyMzNiODlkYTMyMzhlMQ==",
            "commit": {
                "author": {
                    "name": "Roman Khachatryan",
                    "email": "khachatryan.roman@gmail.com",
                    "date": "2021-04-27T22:02:33Z"
                },
                "committer": {
                    "name": "Roman",
                    "email": "khachatryan.roman@gmail.com",
                    "date": "2021-05-10T12:26:31Z"
                },
                "message": "[FLINK-21181][runtime] Wait for Invokable cancellation before releasing network resources",
                "tree": {
                    "sha": "e7b8b008b4e9edadea11119a66c9c0f15f018f56",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/e7b8b008b4e9edadea11119a66c9c0f15f018f56"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/ce7c78ca72ce86df0b4a28fbd3233b89da3238e1",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/ce7c78ca72ce86df0b4a28fbd3233b89da3238e1",
            "html_url": "https://github.com/apache/flink/commit/ce7c78ca72ce86df0b4a28fbd3233b89da3238e1",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/ce7c78ca72ce86df0b4a28fbd3233b89da3238e1/comments",
            "author": {
                "login": "rkhachatryan",
                "id": 3939322,
                "node_id": "MDQ6VXNlcjM5MzkzMjI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3939322?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rkhachatryan",
                "html_url": "https://github.com/rkhachatryan",
                "followers_url": "https://api.github.com/users/rkhachatryan/followers",
                "following_url": "https://api.github.com/users/rkhachatryan/following{/other_user}",
                "gists_url": "https://api.github.com/users/rkhachatryan/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rkhachatryan/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rkhachatryan/subscriptions",
                "organizations_url": "https://api.github.com/users/rkhachatryan/orgs",
                "repos_url": "https://api.github.com/users/rkhachatryan/repos",
                "events_url": "https://api.github.com/users/rkhachatryan/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rkhachatryan/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "rkhachatryan",
                "id": 3939322,
                "node_id": "MDQ6VXNlcjM5MzkzMjI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3939322?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rkhachatryan",
                "html_url": "https://github.com/rkhachatryan",
                "followers_url": "https://api.github.com/users/rkhachatryan/followers",
                "following_url": "https://api.github.com/users/rkhachatryan/following{/other_user}",
                "gists_url": "https://api.github.com/users/rkhachatryan/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rkhachatryan/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rkhachatryan/subscriptions",
                "organizations_url": "https://api.github.com/users/rkhachatryan/orgs",
                "repos_url": "https://api.github.com/users/rkhachatryan/repos",
                "events_url": "https://api.github.com/users/rkhachatryan/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rkhachatryan/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "3ff9eb7029784349fb135e6849b745ba82c7b8c0",
                "url": "https://api.github.com/repos/apache/flink/commits/3ff9eb7029784349fb135e6849b745ba82c7b8c0",
                "html_url": "https://github.com/apache/flink/commit/3ff9eb7029784349fb135e6849b745ba82c7b8c0"
            }]
        },
        {
            "sha": "1088b8726732d5121a40a88f38e2fe0bcefffb37",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MTA4OGI4NzI2NzMyZDUxMjFhNDBhODhmMzhlMmZlMGJjZWZmZmIzNw==",
            "commit": {
                "author": {
                    "name": "Jark Wu",
                    "email": "jark@apache.org",
                    "date": "2021-05-11T02:19:58Z"
                },
                "committer": {
                    "name": "Jark Wu",
                    "email": "jark@apache.org",
                    "date": "2021-05-11T02:20:27Z"
                },
                "message": "[FLINK-22523][table-planner-blink] Window TVF should throw helpful exception when specifying offset parameter (#15803)",
                "tree": {
                    "sha": "0e372ac5b7b358da84649544e1a7af1c4a8f414d",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/0e372ac5b7b358da84649544e1a7af1c4a8f414d"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/1088b8726732d5121a40a88f38e2fe0bcefffb37",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEE4sRUF77VwQQVTzQQhbrLWu+uMgIFAmCZ6esACgkQhbrLWu+u\nMgJdYw//TwlfOCSoe7qsUG4WEZ/LGHNn1ahvx18oRKwOaFSHL9pcGC/RE5und5Pg\n/9TvUl1yZVc9oE5b/yC/8hRs9YEVc39D7vdSN3zE64uGGPgzZP+AZxw//Jy0vFXN\naju3XrSyTaeG8zXKzgrQkiVylfhz2hiR09aQmCAPuiVBOkAGgtZy5TCEQ9iIZ8gj\npj/WP3/88CSs2sbv9iGc1ZnzaVwm7lZ1K0ey7y8xAYzgG3YJO5mZqB8sGi/zIDwW\n4CK4IWFySGttTIOO3cZ3ASk6fDqaIfHzEznLHHRo9e707a+uVr6NS4sdVftHOe3F\n325M8CR0/VgL/YvNsQP6Nwh2Z6OMHvn1Jq5JKE6HudRH4obUzhbdNGgtj0JByfwD\n9S58kFOzhceGDsiob+KvYqMXrs7I7CHgzF+L28yOc9koC0/D13AD9IN0RDXgNxtZ\n7C9kYPxrkmQex+o3wWvrmOn8455cflMkKdiz2Eie1Nm5nS0VukjO6wysmLU4djzA\npPznuB+rfua0uLnHtOCZbIdnQ0x8YTqf5BhcEkXYcKeRY9fUiy6cWFmvqItgGf3f\nT6L7b3nwsw3KAjpIsqt7uw04360UUCncNMK73XuIxGkbyBXbfBYrhBD25sk4ZrFx\nCGb21cAt3A+uYmtWNYLPjz+MtQyuz2dB4TUprZYHMaaztvOuk5Q=\n=c9H7\n-----END PGP SIGNATURE-----",
                    "payload": "tree 0e372ac5b7b358da84649544e1a7af1c4a8f414d\nparent ce7c78ca72ce86df0b4a28fbd3233b89da3238e1\nauthor Jark Wu <jark@apache.org> 1620699598 +0800\ncommitter Jark Wu <jark@apache.org> 1620699627 +0800\n\n[FLINK-22523][table-planner-blink] Window TVF should throw helpful exception when specifying offset parameter (#15803)\n\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/1088b8726732d5121a40a88f38e2fe0bcefffb37",
            "html_url": "https://github.com/apache/flink/commit/1088b8726732d5121a40a88f38e2fe0bcefffb37",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/1088b8726732d5121a40a88f38e2fe0bcefffb37/comments",
            "author": {
                "login": "wuchong",
                "id": 5378924,
                "node_id": "MDQ6VXNlcjUzNzg5MjQ=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5378924?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/wuchong",
                "html_url": "https://github.com/wuchong",
                "followers_url": "https://api.github.com/users/wuchong/followers",
                "following_url": "https://api.github.com/users/wuchong/following{/other_user}",
                "gists_url": "https://api.github.com/users/wuchong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/wuchong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/wuchong/subscriptions",
                "organizations_url": "https://api.github.com/users/wuchong/orgs",
                "repos_url": "https://api.github.com/users/wuchong/repos",
                "events_url": "https://api.github.com/users/wuchong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/wuchong/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "wuchong",
                "id": 5378924,
                "node_id": "MDQ6VXNlcjUzNzg5MjQ=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5378924?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/wuchong",
                "html_url": "https://github.com/wuchong",
                "followers_url": "https://api.github.com/users/wuchong/followers",
                "following_url": "https://api.github.com/users/wuchong/following{/other_user}",
                "gists_url": "https://api.github.com/users/wuchong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/wuchong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/wuchong/subscriptions",
                "organizations_url": "https://api.github.com/users/wuchong/orgs",
                "repos_url": "https://api.github.com/users/wuchong/repos",
                "events_url": "https://api.github.com/users/wuchong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/wuchong/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "ce7c78ca72ce86df0b4a28fbd3233b89da3238e1",
                "url": "https://api.github.com/repos/apache/flink/commits/ce7c78ca72ce86df0b4a28fbd3233b89da3238e1",
                "html_url": "https://github.com/apache/flink/commit/ce7c78ca72ce86df0b4a28fbd3233b89da3238e1"
            }]
        },
        {
            "sha": "b5f375dee021fb7a1294908e6a70553adfb3a81a",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6YjVmMzc1ZGVlMDIxZmI3YTEyOTQ5MDhlNmE3MDU1M2FkZmIzYTgxYQ==",
            "commit": {
                "author": {
                    "name": "Leonard Xu",
                    "email": "xbjtdcq@163.com",
                    "date": "2021-05-11T04:23:04Z"
                },
                "committer": {
                    "name": "GitHub",
                    "email": "noreply@github.com",
                    "date": "2021-05-11T04:23:04Z"
                },
                "message": "[FLINK-22525][table-api] Fix gmt format in Flink from GMT-8:00 to GMT-08:00 (#15874)",
                "tree": {
                    "sha": "82d3a5a20fc5f9b7adcf9f6569f1465d1071adaa",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/82d3a5a20fc5f9b7adcf9f6569f1465d1071adaa"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/b5f375dee021fb7a1294908e6a70553adfb3a81a",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJgmgaoCRBK7hj4Ov3rIwAAIXoIAGOXgjJtImncvzMO2zW8I+vP\nuWhCQEIEr5F6ScGkbvxH2pOSpVQ/9M7YKjAmplKrEfrhPvQzpKZSIIk0W7THWZh8\ndoaoMHgruFTyHM8GG7WM/3gNeBexZZXLFwz3bkI1IcYZAbi4ijCnZPbLgVa4ff5z\nCP1+TeH1hNRAn4zkgohUmuaR7N1jmf9gWnmCens2ao9o2c4mfl9W9rdyJSX42tO9\nRXU6N6FNRCzZKTVnpXvwTTqaDrv5HGf9jrQxM6+4XVro29QJQYqwzD/Q9YnpHBCi\nB7ZoiecyDpiKzHnNqMFRi89PfkAQT1DFTOlMVGIHbznyOEPFqNfQA3oZMnmye/E=\n=K/cS\n-----END PGP SIGNATURE-----\n",
                    "payload": "tree 82d3a5a20fc5f9b7adcf9f6569f1465d1071adaa\nparent 1088b8726732d5121a40a88f38e2fe0bcefffb37\nauthor Leonard Xu <xbjtdcq@163.com> 1620706984 +0800\ncommitter GitHub <noreply@github.com> 1620706984 +0800\n\n[FLINK-22525][table-api] Fix gmt format in Flink from GMT-8:00 to GMT-08:00 (#15874)\n\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/b5f375dee021fb7a1294908e6a70553adfb3a81a",
            "html_url": "https://github.com/apache/flink/commit/b5f375dee021fb7a1294908e6a70553adfb3a81a",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/b5f375dee021fb7a1294908e6a70553adfb3a81a/comments",
            "author": {
                "login": "leonardBang",
                "id": 5163645,
                "node_id": "MDQ6VXNlcjUxNjM2NDU=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5163645?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/leonardBang",
                "html_url": "https://github.com/leonardBang",
                "followers_url": "https://api.github.com/users/leonardBang/followers",
                "following_url": "https://api.github.com/users/leonardBang/following{/other_user}",
                "gists_url": "https://api.github.com/users/leonardBang/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/leonardBang/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/leonardBang/subscriptions",
                "organizations_url": "https://api.github.com/users/leonardBang/orgs",
                "repos_url": "https://api.github.com/users/leonardBang/repos",
                "events_url": "https://api.github.com/users/leonardBang/events{/privacy}",
                "received_events_url": "https://api.github.com/users/leonardBang/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "web-flow",
                "id": 19864447,
                "node_id": "MDQ6VXNlcjE5ODY0NDQ3",
                "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/web-flow",
                "html_url": "https://github.com/web-flow",
                "followers_url": "https://api.github.com/users/web-flow/followers",
                "following_url": "https://api.github.com/users/web-flow/following{/other_user}",
                "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions",
                "organizations_url": "https://api.github.com/users/web-flow/orgs",
                "repos_url": "https://api.github.com/users/web-flow/repos",
                "events_url": "https://api.github.com/users/web-flow/events{/privacy}",
                "received_events_url": "https://api.github.com/users/web-flow/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "1088b8726732d5121a40a88f38e2fe0bcefffb37",
                "url": "https://api.github.com/repos/apache/flink/commits/1088b8726732d5121a40a88f38e2fe0bcefffb37",
                "html_url": "https://github.com/apache/flink/commit/1088b8726732d5121a40a88f38e2fe0bcefffb37"
            }]
        },
        {
            "sha": "2502e40d56bbcda330ca60477c3fc965bd53d15a",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MjUwMmU0MGQ1NmJiY2RhMzMwY2E2MDQ3N2MzZmM5NjViZDUzZDE1YQ==",
            "commit": {
                "author": {
                    "name": "Matthias Pohl",
                    "email": "matthias@ververica.com",
                    "date": "2021-05-07T11:42:44Z"
                },
                "committer": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-05-11T08:23:32Z"
                },
                "message": "[hotfix][test] Adds -e flag to interpret newline in the right way",
                "tree": {
                    "sha": "532e8ce98246679cdb9c58fd87c8a2987c5895a4",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/532e8ce98246679cdb9c58fd87c8a2987c5895a4"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/2502e40d56bbcda330ca60477c3fc965bd53d15a",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/2502e40d56bbcda330ca60477c3fc965bd53d15a",
            "html_url": "https://github.com/apache/flink/commit/2502e40d56bbcda330ca60477c3fc965bd53d15a",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/2502e40d56bbcda330ca60477c3fc965bd53d15a/comments",
            "author": {
                "login": "XComp",
                "id": 1101012,
                "node_id": "MDQ6VXNlcjExMDEwMTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1101012?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/XComp",
                "html_url": "https://github.com/XComp",
                "followers_url": "https://api.github.com/users/XComp/followers",
                "following_url": "https://api.github.com/users/XComp/following{/other_user}",
                "gists_url": "https://api.github.com/users/XComp/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/XComp/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/XComp/subscriptions",
                "organizations_url": "https://api.github.com/users/XComp/orgs",
                "repos_url": "https://api.github.com/users/XComp/repos",
                "events_url": "https://api.github.com/users/XComp/events{/privacy}",
                "received_events_url": "https://api.github.com/users/XComp/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "b5f375dee021fb7a1294908e6a70553adfb3a81a",
                "url": "https://api.github.com/repos/apache/flink/commits/b5f375dee021fb7a1294908e6a70553adfb3a81a",
                "html_url": "https://github.com/apache/flink/commit/b5f375dee021fb7a1294908e6a70553adfb3a81a"
            }]
        },
        {
            "sha": "b5a9336b9b93920708a6ca4126d4035bb165bab5",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6YjVhOTMzNmI5YjkzOTIwNzA4YTZjYTQxMjZkNDAzNWJiMTY1YmFiNQ==",
            "commit": {
                "author": {
                    "name": "Matthias Pohl",
                    "email": "matthias@ververica.com",
                    "date": "2021-05-07T12:53:07Z"
                },
                "committer": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-05-11T08:23:32Z"
                },
                "message": "[FLINK-22566][test] Adds log extraction for the worker nodes\n\nWe struggled to get the logs of the node manager which made it hard to\ninvestigate FLINK-22566 where there was a lag between setting up the YARN\ncontainers and starting the TaskExecutor. Hopefully, the nodemanager logs\nlocated on the worker nodes will help next time to investigate something like\nthat.",
                "tree": {
                    "sha": "c6b2e77f8a7cff844146b66c0664d8834e7b5e94",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/c6b2e77f8a7cff844146b66c0664d8834e7b5e94"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/b5a9336b9b93920708a6ca4126d4035bb165bab5",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/b5a9336b9b93920708a6ca4126d4035bb165bab5",
            "html_url": "https://github.com/apache/flink/commit/b5a9336b9b93920708a6ca4126d4035bb165bab5",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/b5a9336b9b93920708a6ca4126d4035bb165bab5/comments",
            "author": {
                "login": "XComp",
                "id": 1101012,
                "node_id": "MDQ6VXNlcjExMDEwMTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1101012?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/XComp",
                "html_url": "https://github.com/XComp",
                "followers_url": "https://api.github.com/users/XComp/followers",
                "following_url": "https://api.github.com/users/XComp/following{/other_user}",
                "gists_url": "https://api.github.com/users/XComp/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/XComp/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/XComp/subscriptions",
                "organizations_url": "https://api.github.com/users/XComp/orgs",
                "repos_url": "https://api.github.com/users/XComp/repos",
                "events_url": "https://api.github.com/users/XComp/events{/privacy}",
                "received_events_url": "https://api.github.com/users/XComp/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "2502e40d56bbcda330ca60477c3fc965bd53d15a",
                "url": "https://api.github.com/repos/apache/flink/commits/2502e40d56bbcda330ca60477c3fc965bd53d15a",
                "html_url": "https://github.com/apache/flink/commit/2502e40d56bbcda330ca60477c3fc965bd53d15a"
            }]
        },
        {
            "sha": "0765f2f9411bea4e0014096e333ab76a0d7aa788",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MDc2NWYyZjk0MTFiZWE0ZTAwMTQwOTZlMzMzYWI3NmEwZDdhYTc4OA==",
            "commit": {
                "author": {
                    "name": "Senhong Liu",
                    "email": "amazingliux@gmail.com",
                    "date": "2021-05-11T10:19:06Z"
                },
                "committer": {
                    "name": "Jark Wu",
                    "email": "jark@apache.org",
                    "date": "2021-05-11T10:19:59Z"
                },
                "message": "[FLINK-22364][doc] Translate the page of \"Data Sources\" to Chinese. (#15763)",
                "tree": {
                    "sha": "7961365fe3c66a47f78aa1d0ebbcccd7ab7f4f4a",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/7961365fe3c66a47f78aa1d0ebbcccd7ab7f4f4a"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/0765f2f9411bea4e0014096e333ab76a0d7aa788",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEE4sRUF77VwQQVTzQQhbrLWu+uMgIFAmCaWk8ACgkQhbrLWu+u\nMgJYyw//e7NSGi7d+4V3qbIKY4ngRZgMp/6hz0mz25vQFhACjfLmGl5EEpq74/gD\nhMtL7uBjpIZ/7MfZQlwCyiw3DJUzig2K6QFplecU2M/lAth3hg8fniUyMUbs5n/b\nHpCwEvDUX6dQC6kdaJ685j61DmglavIIbDO8BwHrgux59wT7+NDlo97xkCzIgf6h\nYh2q9B7UbU5YRa5cflTnUZ1AnE9VZM7cHoIII09Mk5jPiRS3xbIKxPfrP9V0SJA3\ncIwyAETFQQRTMw150nHeiXe6OFsf3xvwt1EWVWeyZUxHglslbniN7vbrfUqf3klN\nhsTTCozfEppccLyIeGTRBVs5UHXovnCOZXvxitFGTHy7cMnBmaSbsTUw1l2ophQb\ncunXpShaC4OIFlv42xYhjfVja2VZvIHZM0l03YC+j5D7D2IMNsHaREcKhNCyYxCd\nAA+pCNPEWNp6lc7SJtIVCnuTL1g+tYlqMtBtBhtM2+ZHFbpZ3CwZkti7E3HiX3p+\nJQesfVaRq6u/Zr1xKnwTOw5DTQl7G+Jher96uYiKHebaaOAR092DnOpvp35nMmJl\niLaJ1YvQOWhNGeglqTdSK7QASFJyZcvYCAT24L4Pe6DG4zN3Fwfkq1zEtqNAtAPj\nZ0jmY7ujL26Dkf6UruDYOrYW6LEfdyGVYBvBlQ0Qj9wOnh3c5Wk=\n=OzvI\n-----END PGP SIGNATURE-----",
                    "payload": "tree 7961365fe3c66a47f78aa1d0ebbcccd7ab7f4f4a\nparent b5a9336b9b93920708a6ca4126d4035bb165bab5\nauthor Senhong Liu <amazingliux@gmail.com> 1620728346 +0800\ncommitter Jark Wu <jark@apache.org> 1620728399 +0800\n\n[FLINK-22364][doc] Translate the page of \"Data Sources\" to Chinese. (#15763)\n\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/0765f2f9411bea4e0014096e333ab76a0d7aa788",
            "html_url": "https://github.com/apache/flink/commit/0765f2f9411bea4e0014096e333ab76a0d7aa788",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/0765f2f9411bea4e0014096e333ab76a0d7aa788/comments",
            "author": {
                "login": "Senhongl",
                "id": 45899749,
                "node_id": "MDQ6VXNlcjQ1ODk5NzQ5",
                "avatar_url": "https://avatars.githubusercontent.com/u/45899749?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/Senhongl",
                "html_url": "https://github.com/Senhongl",
                "followers_url": "https://api.github.com/users/Senhongl/followers",
                "following_url": "https://api.github.com/users/Senhongl/following{/other_user}",
                "gists_url": "https://api.github.com/users/Senhongl/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/Senhongl/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/Senhongl/subscriptions",
                "organizations_url": "https://api.github.com/users/Senhongl/orgs",
                "repos_url": "https://api.github.com/users/Senhongl/repos",
                "events_url": "https://api.github.com/users/Senhongl/events{/privacy}",
                "received_events_url": "https://api.github.com/users/Senhongl/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "wuchong",
                "id": 5378924,
                "node_id": "MDQ6VXNlcjUzNzg5MjQ=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5378924?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/wuchong",
                "html_url": "https://github.com/wuchong",
                "followers_url": "https://api.github.com/users/wuchong/followers",
                "following_url": "https://api.github.com/users/wuchong/following{/other_user}",
                "gists_url": "https://api.github.com/users/wuchong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/wuchong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/wuchong/subscriptions",
                "organizations_url": "https://api.github.com/users/wuchong/orgs",
                "repos_url": "https://api.github.com/users/wuchong/repos",
                "events_url": "https://api.github.com/users/wuchong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/wuchong/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "b5a9336b9b93920708a6ca4126d4035bb165bab5",
                "url": "https://api.github.com/repos/apache/flink/commits/b5a9336b9b93920708a6ca4126d4035bb165bab5",
                "html_url": "https://github.com/apache/flink/commit/b5a9336b9b93920708a6ca4126d4035bb165bab5"
            }]
        },
        {
            "sha": "207d0fdb4b0b3a3780dbffbb5bb9d43b8f8f1fd4",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MjA3ZDBmZGI0YjBiM2EzNzgwZGJmZmJiNWJiOWQ0M2I4ZjhmMWZkNA==",
            "commit": {
                "author": {
                    "name": "wangyang0918",
                    "email": "danrtsey.wy@alibaba-inc.com",
                    "date": "2021-05-07T08:22:24Z"
                },
                "committer": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-05-11T12:07:58Z"
                },
                "message": "[hotfix][e2e] Output and collect the logs for Kubernetes IT cases",
                "tree": {
                    "sha": "0d6fd22d63e0546f1412a609876bd4843622632d",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/0d6fd22d63e0546f1412a609876bd4843622632d"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/207d0fdb4b0b3a3780dbffbb5bb9d43b8f8f1fd4",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEEuUmfpp7/Xe7rw8H1un5Bh8b3PYIFAmCac54ACgkQun5Bh8b3\nPYIo9Q//Xv1exX5cLhMU5/TfIrOfKcQ3MjCa3KXAK2LRjYwxl6txL8oRmi2YThzH\nETG1eZdOX0GUl9ZiYiFK0j24Tq4q/kg7G+hei3Gb2Zf2OJbzbGajbY4a+bv0rOmH\nUPzV9+x0yNStAnbtg9nv+nqlWREQwLBck8qhZrfXAzwpZtZLBNNdVT3hm5yKGEMm\ne3jN86Vst68YJeo0UI3+9qnp9nhLVvWkE23fqQnh6EqNdEhEziHba/T5JNVoOL9z\n7YpwKpE762We47KsMj/ZDfOIgeadnZkIYI93a6homfI4499RfBoMfX7kBjsFk9lN\n937ot/b6RklMHCo/QmXqd6JCz9SGV72WVPb79OWk/jee73bGz+SSeCZ5JRlE0sDI\niSktY8Sak19wSSOVtJEbJrTzKnQa1BEHp39R83Hatk1sY6MgyDHdFGjafWcRUDGH\nVjU9SxJnRHWyssFcrYdcb3Qn5oowQjt/G6clOT561PEHhyiFUePwVnLR8l6FjF6b\n1p+TsFcUwacvg1JxCYXlhUsugpNIDcL8CKf8wQdcEpalVjR7YZUO97toyMknTzx/\nOg4/TDh5kLbYzQXZkyuS7RJbU6kVra4wL1YW5zKPrngyWLMIsZ8KMK1ecASmZ9Fl\nOUBCPkIq8uyIBrLUbnQc2+bPRHiUhtZcmQL5DTKRzRIARRDL2iM=\n=DGEq\n-----END PGP SIGNATURE-----",
                    "payload": "tree 0d6fd22d63e0546f1412a609876bd4843622632d\nparent 0765f2f9411bea4e0014096e333ab76a0d7aa788\nauthor wangyang0918 <danrtsey.wy@alibaba-inc.com> 1620375744 +0800\ncommitter Till Rohrmann <trohrmann@apache.org> 1620734878 +0200\n\n[hotfix][e2e] Output and collect the logs for Kubernetes IT cases\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/207d0fdb4b0b3a3780dbffbb5bb9d43b8f8f1fd4",
            "html_url": "https://github.com/apache/flink/commit/207d0fdb4b0b3a3780dbffbb5bb9d43b8f8f1fd4",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/207d0fdb4b0b3a3780dbffbb5bb9d43b8f8f1fd4/comments",
            "author": {
                "login": "wangyang0918",
                "id": 15904523,
                "node_id": "MDQ6VXNlcjE1OTA0NTIz",
                "avatar_url": "https://avatars.githubusercontent.com/u/15904523?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/wangyang0918",
                "html_url": "https://github.com/wangyang0918",
                "followers_url": "https://api.github.com/users/wangyang0918/followers",
                "following_url": "https://api.github.com/users/wangyang0918/following{/other_user}",
                "gists_url": "https://api.github.com/users/wangyang0918/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/wangyang0918/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/wangyang0918/subscriptions",
                "organizations_url": "https://api.github.com/users/wangyang0918/orgs",
                "repos_url": "https://api.github.com/users/wangyang0918/repos",
                "events_url": "https://api.github.com/users/wangyang0918/events{/privacy}",
                "received_events_url": "https://api.github.com/users/wangyang0918/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "0765f2f9411bea4e0014096e333ab76a0d7aa788",
                "url": "https://api.github.com/repos/apache/flink/commits/0765f2f9411bea4e0014096e333ab76a0d7aa788",
                "html_url": "https://github.com/apache/flink/commit/0765f2f9411bea4e0014096e333ab76a0d7aa788"
            }]
        },
        {
            "sha": "e9c7f3f1e2facdeb6b10d161e437c7171fa88696",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZTljN2YzZjFlMmZhY2RlYjZiMTBkMTYxZTQzN2M3MTcxZmE4ODY5Ng==",
            "commit": {
                "author": {
                    "name": "wangyang0918",
                    "email": "danrtsey.wy@alibaba-inc.com",
                    "date": "2020-11-10T05:58:14Z"
                },
                "committer": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-05-11T12:07:59Z"
                },
                "message": "[FLINK-17857][test] Make K8s e2e tests could run on Mac\n\nThis closes #15889.",
                "tree": {
                    "sha": "b06cc8d9cca432512796b1c941b503f914c958b0",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/b06cc8d9cca432512796b1c941b503f914c958b0"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/e9c7f3f1e2facdeb6b10d161e437c7171fa88696",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEEuUmfpp7/Xe7rw8H1un5Bh8b3PYIFAmCac7AACgkQun5Bh8b3\nPYIrhw//RVtFY+YA1jlNoEexq67pSERKRudmz/KU1iScLBRAXWByOaovIfE6MlOj\nOmXvDwelXrSwZwzcQZ3JIF5yqabA9qq9FDjy/gebFAdjJA9udRAqUo0bCrHx9FJs\nMrNB/2YTqvEp6y3bTATEC3Ulv9AzkZX0JRHKtcN+H5aQ28wxeyoS37Q2rSP+yvJz\nvT1rK0Sm2d5ie51TbbvdWU9CXCkPKSU0OtwTPH6nnaA90Wx9FwFR1RNuuDfmevMF\nhrhwHh7VAkM8h9Ih14aHAAEGMcNO4GrjLFZeocPRK9WwydX0gYgnfvP9xqbZLxSe\nZotLbLud5gREWuNr4G5NEMWWf0pTb+Wj6IlgQkMvtntr80WkOVh+KP79Qxcz6cR8\nsU7OWhsv0M2ZG0duBs3NjnEP/EjJyaDl2yvbdgZh5NtzLAC1/V31zdpqNch9sNrR\nH23T4Z70ZqzkaCdWE3ZF/VPmVT/rNME0E3bTheYkC7OFMv3VGcSwxHBqSH7CBnZL\ni4IsPZ0Rfp6Jh0K+O6k3OHrjZIJDg7G82S22YbLApAqZO3KCClEgsY9Hab9nVyUn\nBH1taTFS4i7Q+jGwpkVKMkpM96i5tSXFtdz4Wt6/lq5rV8xWOjmsimfKYdPseOJc\nxsfs5dy5YYUm7zunpg1g1gym9WO3GitS4xIq6jBgwZ9RG5KdTsE=\n=J2jC\n-----END PGP SIGNATURE-----",
                    "payload": "tree b06cc8d9cca432512796b1c941b503f914c958b0\nparent 207d0fdb4b0b3a3780dbffbb5bb9d43b8f8f1fd4\nauthor wangyang0918 <danrtsey.wy@alibaba-inc.com> 1604987894 +0800\ncommitter Till Rohrmann <trohrmann@apache.org> 1620734879 +0200\n\n[FLINK-17857][test] Make K8s e2e tests could run on Mac\n\nThis closes #15889.\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/e9c7f3f1e2facdeb6b10d161e437c7171fa88696",
            "html_url": "https://github.com/apache/flink/commit/e9c7f3f1e2facdeb6b10d161e437c7171fa88696",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/e9c7f3f1e2facdeb6b10d161e437c7171fa88696/comments",
            "author": {
                "login": "wangyang0918",
                "id": 15904523,
                "node_id": "MDQ6VXNlcjE1OTA0NTIz",
                "avatar_url": "https://avatars.githubusercontent.com/u/15904523?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/wangyang0918",
                "html_url": "https://github.com/wangyang0918",
                "followers_url": "https://api.github.com/users/wangyang0918/followers",
                "following_url": "https://api.github.com/users/wangyang0918/following{/other_user}",
                "gists_url": "https://api.github.com/users/wangyang0918/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/wangyang0918/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/wangyang0918/subscriptions",
                "organizations_url": "https://api.github.com/users/wangyang0918/orgs",
                "repos_url": "https://api.github.com/users/wangyang0918/repos",
                "events_url": "https://api.github.com/users/wangyang0918/events{/privacy}",
                "received_events_url": "https://api.github.com/users/wangyang0918/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "207d0fdb4b0b3a3780dbffbb5bb9d43b8f8f1fd4",
                "url": "https://api.github.com/repos/apache/flink/commits/207d0fdb4b0b3a3780dbffbb5bb9d43b8f8f1fd4",
                "html_url": "https://github.com/apache/flink/commit/207d0fdb4b0b3a3780dbffbb5bb9d43b8f8f1fd4"
            }]
        },
        {
            "sha": "21866fd1b0af732289ea22336c45e1eefcec009e",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MjE4NjZmZDFiMGFmNzMyMjg5ZWEyMjMzNmM0NWUxZWVmY2VjMDA5ZQ==",
            "commit": {
                "author": {
                    "name": "aidenma",
                    "email": "aidenma@tencent.com",
                    "date": "2021-05-11T13:14:36Z"
                },
                "committer": {
                    "name": "Rui Li",
                    "email": "lirui@apache.org",
                    "date": "2021-05-12T09:00:48Z"
                },
                "message": "[FLINK-22408][sql-parser] Fix SqlDropPartitions unparse Error\n\nThis closes #15894",
                "tree": {
                    "sha": "67c7cfc993ee73933ea079d7ed41d95a38c430b6",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/67c7cfc993ee73933ea079d7ed41d95a38c430b6"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/21866fd1b0af732289ea22336c45e1eefcec009e",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/21866fd1b0af732289ea22336c45e1eefcec009e",
            "html_url": "https://github.com/apache/flink/commit/21866fd1b0af732289ea22336c45e1eefcec009e",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/21866fd1b0af732289ea22336c45e1eefcec009e/comments",
            "author": {
                "login": "aidenma-develop",
                "id": 41923627,
                "node_id": "MDQ6VXNlcjQxOTIzNjI3",
                "avatar_url": "https://avatars.githubusercontent.com/u/41923627?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/aidenma-develop",
                "html_url": "https://github.com/aidenma-develop",
                "followers_url": "https://api.github.com/users/aidenma-develop/followers",
                "following_url": "https://api.github.com/users/aidenma-develop/following{/other_user}",
                "gists_url": "https://api.github.com/users/aidenma-develop/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/aidenma-develop/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/aidenma-develop/subscriptions",
                "organizations_url": "https://api.github.com/users/aidenma-develop/orgs",
                "repos_url": "https://api.github.com/users/aidenma-develop/repos",
                "events_url": "https://api.github.com/users/aidenma-develop/events{/privacy}",
                "received_events_url": "https://api.github.com/users/aidenma-develop/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "lirui-apache",
                "id": 5210788,
                "node_id": "MDQ6VXNlcjUyMTA3ODg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5210788?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/lirui-apache",
                "html_url": "https://github.com/lirui-apache",
                "followers_url": "https://api.github.com/users/lirui-apache/followers",
                "following_url": "https://api.github.com/users/lirui-apache/following{/other_user}",
                "gists_url": "https://api.github.com/users/lirui-apache/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/lirui-apache/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/lirui-apache/subscriptions",
                "organizations_url": "https://api.github.com/users/lirui-apache/orgs",
                "repos_url": "https://api.github.com/users/lirui-apache/repos",
                "events_url": "https://api.github.com/users/lirui-apache/events{/privacy}",
                "received_events_url": "https://api.github.com/users/lirui-apache/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "e9c7f3f1e2facdeb6b10d161e437c7171fa88696",
                "url": "https://api.github.com/repos/apache/flink/commits/e9c7f3f1e2facdeb6b10d161e437c7171fa88696",
                "html_url": "https://github.com/apache/flink/commit/e9c7f3f1e2facdeb6b10d161e437c7171fa88696"
            }]
        },
        {
            "sha": "64af77b8e239c9f0442d1200f1d36147633bbe5c",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NjRhZjc3YjhlMjM5YzlmMDQ0MmQxMjAwZjFkMzYxNDc2MzNiYmU1Yw==",
            "commit": {
                "author": {
                    "name": "Yuan Mei",
                    "email": "yuanmei.work@gmail.com",
                    "date": "2021-05-10T05:46:43Z"
                },
                "committer": {
                    "name": "Dawid Wysakowicz",
                    "email": "dwysakowicz@apache.org",
                    "date": "2021-05-12T12:09:18Z"
                },
                "message": "[FLINK-21469][runtime] Implement advanceToEndOfEventTime for MultipleInputStreamTask\n\nFor stop with savepoint, StreamTask#advanceToEndOfEventTime() is called (in source tasks)\nto advance to the max watermark. This PR implments advanceToEndOfEventTime for\nMultipleInputStreamTask chained sources.\n\nThis closes #15872",
                "tree": {
                    "sha": "7d0f2525c7ea89afcb518276f4c85c0773355782",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/7d0f2525c7ea89afcb518276f4c85c0773355782"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/64af77b8e239c9f0442d1200f1d36147633bbe5c",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEE6pOkNbTiybTJ9TP2MdLdEL/BWi0FAmCbxX0ACgkQMdLdEL/B\nWi0sWw/+MbH2cmchaFc9h415CMICCNG2Zu99aZdAZCfpx2527+kEQKeL2KuNc318\nEC8wsVptwhaDRsWyd+UmUcp9NWHFmuhWU/iPwyeKjqXMIHl2pli63srQCAUCcBo/\nXAnk66nfC9ujlsoSnNsWuk31Gqs73uaY2g6TZyeWvdznQT133Y8Lo+7uZP6bMz+H\n9KfhwWsEFFE1ekrHxJSmxGRJFxP26prohiXwX7wpk1uNq6LOJLPOS/d4AvjeHco5\nNBWg6Hb0R51iDyvBjljkJbr9gt3eeB6plrRt7unzUWTPrJopD8dOT1jBTuBbIZ2N\nUFDB5p8aORJQ+bEX2shyXVvUaHgB94/vbERdBjdAxwrarKcsEjv5dPJAqCMGUWKf\negi6N1CQFSljYhtpAf+l5TQYIb9TB0R++qtAYcAxfgdQWurr/SKE6l3oyvmVGQrG\nKR+8H2jeVyXS7Z4ynDHyFItIIQGg7tICFAuG/5X4Dkfx9P7YFfchY65XcFgna4fG\n4xF6ccp5KyEZuOOEaxGc7D2ajLgBixPLR9cyk4ZQLEAYfDzuxbnDfXxIoMIQrnZZ\n+1OHRoxKpOW9MBgZbMWwFkX0M8n5p838YNfYGy93epCghc/OwBD/x/LxRBkFZkXU\nL5WEg3c3tv/h+WqZUcCIztwLvJEV3fsKpCBErfms9lbjMZH0vnI=\n=O91a\n-----END PGP SIGNATURE-----",
                    "payload": "tree 7d0f2525c7ea89afcb518276f4c85c0773355782\nparent 21866fd1b0af732289ea22336c45e1eefcec009e\nauthor Yuan Mei <yuanmei.work@gmail.com> 1620625603 +0800\ncommitter Dawid Wysakowicz <dwysakowicz@apache.org> 1620821358 +0200\n\n[FLINK-21469][runtime] Implement advanceToEndOfEventTime for MultipleInputStreamTask\n\nFor stop with savepoint, StreamTask#advanceToEndOfEventTime() is called (in source tasks)\nto advance to the max watermark. This PR implments advanceToEndOfEventTime for\nMultipleInputStreamTask chained sources.\n\nThis closes #15872\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/64af77b8e239c9f0442d1200f1d36147633bbe5c",
            "html_url": "https://github.com/apache/flink/commit/64af77b8e239c9f0442d1200f1d36147633bbe5c",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/64af77b8e239c9f0442d1200f1d36147633bbe5c/comments",
            "author": {
                "login": "curcur",
                "id": 11065508,
                "node_id": "MDQ6VXNlcjExMDY1NTA4",
                "avatar_url": "https://avatars.githubusercontent.com/u/11065508?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/curcur",
                "html_url": "https://github.com/curcur",
                "followers_url": "https://api.github.com/users/curcur/followers",
                "following_url": "https://api.github.com/users/curcur/following{/other_user}",
                "gists_url": "https://api.github.com/users/curcur/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/curcur/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/curcur/subscriptions",
                "organizations_url": "https://api.github.com/users/curcur/orgs",
                "repos_url": "https://api.github.com/users/curcur/repos",
                "events_url": "https://api.github.com/users/curcur/events{/privacy}",
                "received_events_url": "https://api.github.com/users/curcur/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "dawidwys",
                "id": 6242259,
                "node_id": "MDQ6VXNlcjYyNDIyNTk=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6242259?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dawidwys",
                "html_url": "https://github.com/dawidwys",
                "followers_url": "https://api.github.com/users/dawidwys/followers",
                "following_url": "https://api.github.com/users/dawidwys/following{/other_user}",
                "gists_url": "https://api.github.com/users/dawidwys/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dawidwys/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dawidwys/subscriptions",
                "organizations_url": "https://api.github.com/users/dawidwys/orgs",
                "repos_url": "https://api.github.com/users/dawidwys/repos",
                "events_url": "https://api.github.com/users/dawidwys/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dawidwys/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "21866fd1b0af732289ea22336c45e1eefcec009e",
                "url": "https://api.github.com/repos/apache/flink/commits/21866fd1b0af732289ea22336c45e1eefcec009e",
                "html_url": "https://github.com/apache/flink/commit/21866fd1b0af732289ea22336c45e1eefcec009e"
            }]
        },
        {
            "sha": "acf84a93739de363943be5d95efb8b9d93e4e553",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6YWNmODRhOTM3MzlkZTM2Mzk0M2JlNWQ5NWVmYjhiOWQ5M2U0ZTU1Mw==",
            "commit": {
                "author": {
                    "name": "HuangXiao",
                    "email": "hx36w35@163.com",
                    "date": "2021-05-08T07:48:39Z"
                },
                "committer": {
                    "name": "Seth Wiesman",
                    "email": "sjwiesman@gmail.com",
                    "date": "2021-05-12T13:55:00Z"
                },
                "message": "[hotfix][docs] Fix all broken images\n\nCo-authored-by: Xintong Song <6509172+xintongsong@users.noreply.github.com>\n\nThis closes #15865",
                "tree": {
                    "sha": "33d1d8e3a5dd3aa7a1048b5d21fe317bc2b056f7",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/33d1d8e3a5dd3aa7a1048b5d21fe317bc2b056f7"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/acf84a93739de363943be5d95efb8b9d93e4e553",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/acf84a93739de363943be5d95efb8b9d93e4e553",
            "html_url": "https://github.com/apache/flink/commit/acf84a93739de363943be5d95efb8b9d93e4e553",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/acf84a93739de363943be5d95efb8b9d93e4e553/comments",
            "author": {
                "login": "Shawn-Hx",
                "id": 18097476,
                "node_id": "MDQ6VXNlcjE4MDk3NDc2",
                "avatar_url": "https://avatars.githubusercontent.com/u/18097476?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/Shawn-Hx",
                "html_url": "https://github.com/Shawn-Hx",
                "followers_url": "https://api.github.com/users/Shawn-Hx/followers",
                "following_url": "https://api.github.com/users/Shawn-Hx/following{/other_user}",
                "gists_url": "https://api.github.com/users/Shawn-Hx/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/Shawn-Hx/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/Shawn-Hx/subscriptions",
                "organizations_url": "https://api.github.com/users/Shawn-Hx/orgs",
                "repos_url": "https://api.github.com/users/Shawn-Hx/repos",
                "events_url": "https://api.github.com/users/Shawn-Hx/events{/privacy}",
                "received_events_url": "https://api.github.com/users/Shawn-Hx/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "sjwiesman",
                "id": 1891970,
                "node_id": "MDQ6VXNlcjE4OTE5NzA=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1891970?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/sjwiesman",
                "html_url": "https://github.com/sjwiesman",
                "followers_url": "https://api.github.com/users/sjwiesman/followers",
                "following_url": "https://api.github.com/users/sjwiesman/following{/other_user}",
                "gists_url": "https://api.github.com/users/sjwiesman/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/sjwiesman/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/sjwiesman/subscriptions",
                "organizations_url": "https://api.github.com/users/sjwiesman/orgs",
                "repos_url": "https://api.github.com/users/sjwiesman/repos",
                "events_url": "https://api.github.com/users/sjwiesman/events{/privacy}",
                "received_events_url": "https://api.github.com/users/sjwiesman/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "64af77b8e239c9f0442d1200f1d36147633bbe5c",
                "url": "https://api.github.com/repos/apache/flink/commits/64af77b8e239c9f0442d1200f1d36147633bbe5c",
                "html_url": "https://github.com/apache/flink/commit/64af77b8e239c9f0442d1200f1d36147633bbe5c"
            }]
        },
        {
            "sha": "a4153f50d72a41a06c0f3e690c7d8a753fbe2872",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6YTQxNTNmNTBkNzJhNDFhMDZjMGYzZTY5MGM3ZDhhNzUzZmJlMjg3Mg==",
            "commit": {
                "author": {
                    "name": "Kevin Bohinski",
                    "email": "kbohinski@users.noreply.github.com",
                    "date": "2021-05-10T17:47:17Z"
                },
                "committer": {
                    "name": "Seth Wiesman",
                    "email": "sjwiesman@gmail.com",
                    "date": "2021-05-12T14:06:51Z"
                },
                "message": "[hotfix][docs] Fix typo in k8s docs\n\nThis closes #15886",
                "tree": {
                    "sha": "7bc436f34dcd13eac57b81bd5f68eda6f4f81d29",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/7bc436f34dcd13eac57b81bd5f68eda6f4f81d29"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/a4153f50d72a41a06c0f3e690c7d8a753fbe2872",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/a4153f50d72a41a06c0f3e690c7d8a753fbe2872",
            "html_url": "https://github.com/apache/flink/commit/a4153f50d72a41a06c0f3e690c7d8a753fbe2872",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/a4153f50d72a41a06c0f3e690c7d8a753fbe2872/comments",
            "author": {
                "login": "kbohinski",
                "id": 6530081,
                "node_id": "MDQ6VXNlcjY1MzAwODE=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6530081?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/kbohinski",
                "html_url": "https://github.com/kbohinski",
                "followers_url": "https://api.github.com/users/kbohinski/followers",
                "following_url": "https://api.github.com/users/kbohinski/following{/other_user}",
                "gists_url": "https://api.github.com/users/kbohinski/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/kbohinski/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/kbohinski/subscriptions",
                "organizations_url": "https://api.github.com/users/kbohinski/orgs",
                "repos_url": "https://api.github.com/users/kbohinski/repos",
                "events_url": "https://api.github.com/users/kbohinski/events{/privacy}",
                "received_events_url": "https://api.github.com/users/kbohinski/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "sjwiesman",
                "id": 1891970,
                "node_id": "MDQ6VXNlcjE4OTE5NzA=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1891970?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/sjwiesman",
                "html_url": "https://github.com/sjwiesman",
                "followers_url": "https://api.github.com/users/sjwiesman/followers",
                "following_url": "https://api.github.com/users/sjwiesman/following{/other_user}",
                "gists_url": "https://api.github.com/users/sjwiesman/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/sjwiesman/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/sjwiesman/subscriptions",
                "organizations_url": "https://api.github.com/users/sjwiesman/orgs",
                "repos_url": "https://api.github.com/users/sjwiesman/repos",
                "events_url": "https://api.github.com/users/sjwiesman/events{/privacy}",
                "received_events_url": "https://api.github.com/users/sjwiesman/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "acf84a93739de363943be5d95efb8b9d93e4e553",
                "url": "https://api.github.com/repos/apache/flink/commits/acf84a93739de363943be5d95efb8b9d93e4e553",
                "html_url": "https://github.com/apache/flink/commit/acf84a93739de363943be5d95efb8b9d93e4e553"
            }]
        },
        {
            "sha": "c32022bd1b0de8c4d14168558add86aeb0c62d6e",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6YzMyMDIyYmQxYjBkZThjNGQxNDE2ODU1OGFkZDg2YWViMGM2MmQ2ZQ==",
            "commit": {
                "author": {
                    "name": "yangqu",
                    "email": "quyanghaoren@126.com",
                    "date": "2021-05-11T09:53:23Z"
                },
                "committer": {
                    "name": "Seth Wiesman",
                    "email": "sjwiesman@gmail.com",
                    "date": "2021-05-12T14:11:16Z"
                },
                "message": "[FLINK-22628][docs] Update state_processor_api.md\n\nThis closes #15892",
                "tree": {
                    "sha": "6e14a8c99205a1b8cc97096a5f1d67e964941503",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/6e14a8c99205a1b8cc97096a5f1d67e964941503"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/c32022bd1b0de8c4d14168558add86aeb0c62d6e",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/c32022bd1b0de8c4d14168558add86aeb0c62d6e",
            "html_url": "https://github.com/apache/flink/commit/c32022bd1b0de8c4d14168558add86aeb0c62d6e",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/c32022bd1b0de8c4d14168558add86aeb0c62d6e/comments",
            "author": {
                "login": "yangqu",
                "id": 7777647,
                "node_id": "MDQ6VXNlcjc3Nzc2NDc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/7777647?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/yangqu",
                "html_url": "https://github.com/yangqu",
                "followers_url": "https://api.github.com/users/yangqu/followers",
                "following_url": "https://api.github.com/users/yangqu/following{/other_user}",
                "gists_url": "https://api.github.com/users/yangqu/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/yangqu/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/yangqu/subscriptions",
                "organizations_url": "https://api.github.com/users/yangqu/orgs",
                "repos_url": "https://api.github.com/users/yangqu/repos",
                "events_url": "https://api.github.com/users/yangqu/events{/privacy}",
                "received_events_url": "https://api.github.com/users/yangqu/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "sjwiesman",
                "id": 1891970,
                "node_id": "MDQ6VXNlcjE4OTE5NzA=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1891970?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/sjwiesman",
                "html_url": "https://github.com/sjwiesman",
                "followers_url": "https://api.github.com/users/sjwiesman/followers",
                "following_url": "https://api.github.com/users/sjwiesman/following{/other_user}",
                "gists_url": "https://api.github.com/users/sjwiesman/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/sjwiesman/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/sjwiesman/subscriptions",
                "organizations_url": "https://api.github.com/users/sjwiesman/orgs",
                "repos_url": "https://api.github.com/users/sjwiesman/repos",
                "events_url": "https://api.github.com/users/sjwiesman/events{/privacy}",
                "received_events_url": "https://api.github.com/users/sjwiesman/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "a4153f50d72a41a06c0f3e690c7d8a753fbe2872",
                "url": "https://api.github.com/repos/apache/flink/commits/a4153f50d72a41a06c0f3e690c7d8a753fbe2872",
                "html_url": "https://github.com/apache/flink/commit/a4153f50d72a41a06c0f3e690c7d8a753fbe2872"
            }]
        },
        {
            "sha": "cfdf0013a640bac2be13285f8a1492b5d4781f6c",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6Y2ZkZjAwMTNhNjQwYmFjMmJlMTMyODVmOGExNDkyYjVkNDc4MWY2Yw==",
            "commit": {
                "author": {
                    "name": "Yao Zhang",
                    "email": "xzhangyao@126.com",
                    "date": "2021-05-11T01:55:53Z"
                },
                "committer": {
                    "name": "Xintong Song",
                    "email": "tonysong820@gmail.com",
                    "date": "2021-05-13T09:42:08Z"
                },
                "message": "[FLINK-22618][runtime] Fix incorrect free resource metrics of task managers\n\nThis closes #15887",
                "tree": {
                    "sha": "33222e852126c1a12bc5aab59067eabe6347f8e0",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/33222e852126c1a12bc5aab59067eabe6347f8e0"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/cfdf0013a640bac2be13285f8a1492b5d4781f6c",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCgAdFiEEGsvLF58sbVnbyFd20SHP9Sk+Y18FAmCc9HAACgkQ0SHP9Sk+\nY19GRg/+P75VhRB+utwr+uFBusm6MTKmZXkhPFERs51UXhrgKw1dptEYCuq03gSK\nBzMU1ttYcqMa2kxT8C8URDiU4QLycBqhR8TweBtrUXmjwtmwenw8UVh6Hu2LqhXo\nkLkLSo+WcECWHL/MUPkznWPvth2JVrHCUm8Jl56ZBkJ3U6hc6sVsAfzYgGmksYNu\nVJ2cUXzj4IbP1JgJKNTnQHp9Zf8peqxn2ehq+Y198CF4k8qhZ4pnv5IgdyQ8HvYQ\n+CH3Tr8SDnhaDyy0i7ReysvJUE7ex+3uZsyUOE+IjYTS+uIDDfrOGNIDk/oyMMVN\nbUoJuGGWkAKKlhruXtB50qUP4nGl443Lqk2AJOHw7rI9BqPDJ4BJ+IFVCrwf5oTZ\njfvNZMHqXFTz163MVaMQ14xk+gh8Ql9DEKJQ4aAgLRTiMFFpTMM/wp9no9TLdkUM\ns1+eirb5S8KGQ2Ch2qGyV2ebCb5gu+q9nwDp87axaN+NV8T3bde1s3mZ9uCj+LRh\n457TcGJPmRpaGaufeOmMTS2hYpQHTkrhzFjzDm+TkcMu2qLDTL9k2WyqSzgNrJ0N\na4OYQqUeBhlnW2fSRyd7iloTZZax2IAnaQQqUUrbmSOQnIPliK5LjCeETYKV2kn8\nLQKyh2zzMHLflQidWzRSuy3NewnK7n/801jwPHAbHGk8G9VrK64=\n=DgSR\n-----END PGP SIGNATURE-----",
                    "payload": "tree 33222e852126c1a12bc5aab59067eabe6347f8e0\nparent c32022bd1b0de8c4d14168558add86aeb0c62d6e\nauthor Yao Zhang <xzhangyao@126.com> 1620698153 +0800\ncommitter Xintong Song <tonysong820@gmail.com> 1620898928 +0800\n\n[FLINK-22618][runtime] Fix incorrect free resource metrics of task managers\n\nThis closes #15887\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/cfdf0013a640bac2be13285f8a1492b5d4781f6c",
            "html_url": "https://github.com/apache/flink/commit/cfdf0013a640bac2be13285f8a1492b5d4781f6c",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/cfdf0013a640bac2be13285f8a1492b5d4781f6c/comments",
            "author": {
                "login": "paul8263",
                "id": 7007327,
                "node_id": "MDQ6VXNlcjcwMDczMjc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/7007327?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/paul8263",
                "html_url": "https://github.com/paul8263",
                "followers_url": "https://api.github.com/users/paul8263/followers",
                "following_url": "https://api.github.com/users/paul8263/following{/other_user}",
                "gists_url": "https://api.github.com/users/paul8263/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/paul8263/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/paul8263/subscriptions",
                "organizations_url": "https://api.github.com/users/paul8263/orgs",
                "repos_url": "https://api.github.com/users/paul8263/repos",
                "events_url": "https://api.github.com/users/paul8263/events{/privacy}",
                "received_events_url": "https://api.github.com/users/paul8263/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "xintongsong",
                "id": 6509172,
                "node_id": "MDQ6VXNlcjY1MDkxNzI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6509172?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/xintongsong",
                "html_url": "https://github.com/xintongsong",
                "followers_url": "https://api.github.com/users/xintongsong/followers",
                "following_url": "https://api.github.com/users/xintongsong/following{/other_user}",
                "gists_url": "https://api.github.com/users/xintongsong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/xintongsong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/xintongsong/subscriptions",
                "organizations_url": "https://api.github.com/users/xintongsong/orgs",
                "repos_url": "https://api.github.com/users/xintongsong/repos",
                "events_url": "https://api.github.com/users/xintongsong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/xintongsong/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "c32022bd1b0de8c4d14168558add86aeb0c62d6e",
                "url": "https://api.github.com/repos/apache/flink/commits/c32022bd1b0de8c4d14168558add86aeb0c62d6e",
                "html_url": "https://github.com/apache/flink/commit/c32022bd1b0de8c4d14168558add86aeb0c62d6e"
            }]
        },
        {
            "sha": "51680fadfd3fe6cfe63e6c89000a9b3fdaae0353",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NTE2ODBmYWRmZDNmZTZjZmU2M2U2Yzg5MDAwYTliM2ZkYWFlMDM1Mw==",
            "commit": {
                "author": {
                    "name": "Robert Metzger",
                    "email": "rmetzger@apache.org",
                    "date": "2021-05-10T13:46:21Z"
                },
                "committer": {
                    "name": "Robert Metzger",
                    "email": "rmetzger@apache.org",
                    "date": "2021-05-13T14:49:08Z"
                },
                "message": "[hotfix] Add missing TestLogger to Kinesis tests",
                "tree": {
                    "sha": "4630eae3dbe15e7f5daf61293fc7225eaa39e9f6",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/4630eae3dbe15e7f5daf61293fc7225eaa39e9f6"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/51680fadfd3fe6cfe63e6c89000a9b3fdaae0353",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/51680fadfd3fe6cfe63e6c89000a9b3fdaae0353",
            "html_url": "https://github.com/apache/flink/commit/51680fadfd3fe6cfe63e6c89000a9b3fdaae0353",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/51680fadfd3fe6cfe63e6c89000a9b3fdaae0353/comments",
            "author": {
                "login": "rmetzger",
                "id": 89049,
                "node_id": "MDQ6VXNlcjg5MDQ5",
                "avatar_url": "https://avatars.githubusercontent.com/u/89049?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rmetzger",
                "html_url": "https://github.com/rmetzger",
                "followers_url": "https://api.github.com/users/rmetzger/followers",
                "following_url": "https://api.github.com/users/rmetzger/following{/other_user}",
                "gists_url": "https://api.github.com/users/rmetzger/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rmetzger/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rmetzger/subscriptions",
                "organizations_url": "https://api.github.com/users/rmetzger/orgs",
                "repos_url": "https://api.github.com/users/rmetzger/repos",
                "events_url": "https://api.github.com/users/rmetzger/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rmetzger/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "rmetzger",
                "id": 89049,
                "node_id": "MDQ6VXNlcjg5MDQ5",
                "avatar_url": "https://avatars.githubusercontent.com/u/89049?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rmetzger",
                "html_url": "https://github.com/rmetzger",
                "followers_url": "https://api.github.com/users/rmetzger/followers",
                "following_url": "https://api.github.com/users/rmetzger/following{/other_user}",
                "gists_url": "https://api.github.com/users/rmetzger/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rmetzger/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rmetzger/subscriptions",
                "organizations_url": "https://api.github.com/users/rmetzger/orgs",
                "repos_url": "https://api.github.com/users/rmetzger/repos",
                "events_url": "https://api.github.com/users/rmetzger/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rmetzger/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "cfdf0013a640bac2be13285f8a1492b5d4781f6c",
                "url": "https://api.github.com/repos/apache/flink/commits/cfdf0013a640bac2be13285f8a1492b5d4781f6c",
                "html_url": "https://github.com/apache/flink/commit/cfdf0013a640bac2be13285f8a1492b5d4781f6c"
            }]
        },
        {
            "sha": "25489aa0cc536f1551a0a887bdfc690824a24bd9",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MjU0ODlhYTBjYzUzNmYxNTUxYTBhODg3YmRmYzY5MDgyNGEyNGJkOQ==",
            "commit": {
                "author": {
                    "name": "Robert Metzger",
                    "email": "rmetzger@apache.org",
                    "date": "2021-05-07T06:35:04Z"
                },
                "committer": {
                    "name": "Robert Metzger",
                    "email": "rmetzger@apache.org",
                    "date": "2021-05-13T14:49:08Z"
                },
                "message": "[FLINK-22574] Adaptive Scheduler: Fix cancellation while in Restarting state.\n\nThe Canceling state of Adaptive Scheduler was expecting the ExecutionGraph to be in state RUNNING when entering the state.\nHowever, the Restarting state is cancelling the ExecutionGraph already, thus the ExectionGraph can be in state CANCELING or CANCELED when entering the Canceling state.\n\nCalling the ExecutionGraph.cancel() method in the Canceling state while being in ExecutionGraph.state = CANCELED || CANCELLED is not a problem.\n\nThe change is guarded by a new ITCase, as this issue affects the interplay between different AS states.",
                "tree": {
                    "sha": "48af8a60034a0aae85ffaa9722dcab41bb125a86",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/48af8a60034a0aae85ffaa9722dcab41bb125a86"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/25489aa0cc536f1551a0a887bdfc690824a24bd9",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/25489aa0cc536f1551a0a887bdfc690824a24bd9",
            "html_url": "https://github.com/apache/flink/commit/25489aa0cc536f1551a0a887bdfc690824a24bd9",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/25489aa0cc536f1551a0a887bdfc690824a24bd9/comments",
            "author": {
                "login": "rmetzger",
                "id": 89049,
                "node_id": "MDQ6VXNlcjg5MDQ5",
                "avatar_url": "https://avatars.githubusercontent.com/u/89049?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rmetzger",
                "html_url": "https://github.com/rmetzger",
                "followers_url": "https://api.github.com/users/rmetzger/followers",
                "following_url": "https://api.github.com/users/rmetzger/following{/other_user}",
                "gists_url": "https://api.github.com/users/rmetzger/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rmetzger/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rmetzger/subscriptions",
                "organizations_url": "https://api.github.com/users/rmetzger/orgs",
                "repos_url": "https://api.github.com/users/rmetzger/repos",
                "events_url": "https://api.github.com/users/rmetzger/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rmetzger/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "rmetzger",
                "id": 89049,
                "node_id": "MDQ6VXNlcjg5MDQ5",
                "avatar_url": "https://avatars.githubusercontent.com/u/89049?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rmetzger",
                "html_url": "https://github.com/rmetzger",
                "followers_url": "https://api.github.com/users/rmetzger/followers",
                "following_url": "https://api.github.com/users/rmetzger/following{/other_user}",
                "gists_url": "https://api.github.com/users/rmetzger/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rmetzger/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rmetzger/subscriptions",
                "organizations_url": "https://api.github.com/users/rmetzger/orgs",
                "repos_url": "https://api.github.com/users/rmetzger/repos",
                "events_url": "https://api.github.com/users/rmetzger/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rmetzger/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "51680fadfd3fe6cfe63e6c89000a9b3fdaae0353",
                "url": "https://api.github.com/repos/apache/flink/commits/51680fadfd3fe6cfe63e6c89000a9b3fdaae0353",
                "html_url": "https://github.com/apache/flink/commit/51680fadfd3fe6cfe63e6c89000a9b3fdaae0353"
            }]
        },
        {
            "sha": "6bf648aecf31d4253ecaf64bc6df16401397cbeb",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NmJmNjQ4YWVjZjMxZDQyNTNlY2FmNjRiYzZkZjE2NDAxMzk3Y2JlYg==",
            "commit": {
                "author": {
                    "name": "Ingo Bürk",
                    "email": "ingo.buerk@tngtech.com",
                    "date": "2021-05-11T06:00:58Z"
                },
                "committer": {
                    "name": "Timo Walther",
                    "email": "twalthr@apache.org",
                    "date": "2021-05-14T13:40:13Z"
                },
                "message": "[FLINK-22475][table-common] Document usage of '#' placeholder in option keys",
                "tree": {
                    "sha": "ef30224674f9cd2e94d65ffe38654343336869f6",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/ef30224674f9cd2e94d65ffe38654343336869f6"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/6bf648aecf31d4253ecaf64bc6df16401397cbeb",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/6bf648aecf31d4253ecaf64bc6df16401397cbeb",
            "html_url": "https://github.com/apache/flink/commit/6bf648aecf31d4253ecaf64bc6df16401397cbeb",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/6bf648aecf31d4253ecaf64bc6df16401397cbeb/comments",
            "author": {
                "login": "Airblader",
                "id": 2392216,
                "node_id": "MDQ6VXNlcjIzOTIyMTY=",
                "avatar_url": "https://avatars.githubusercontent.com/u/2392216?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/Airblader",
                "html_url": "https://github.com/Airblader",
                "followers_url": "https://api.github.com/users/Airblader/followers",
                "following_url": "https://api.github.com/users/Airblader/following{/other_user}",
                "gists_url": "https://api.github.com/users/Airblader/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/Airblader/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/Airblader/subscriptions",
                "organizations_url": "https://api.github.com/users/Airblader/orgs",
                "repos_url": "https://api.github.com/users/Airblader/repos",
                "events_url": "https://api.github.com/users/Airblader/events{/privacy}",
                "received_events_url": "https://api.github.com/users/Airblader/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "twalthr",
                "id": 5746567,
                "node_id": "MDQ6VXNlcjU3NDY1Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5746567?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/twalthr",
                "html_url": "https://github.com/twalthr",
                "followers_url": "https://api.github.com/users/twalthr/followers",
                "following_url": "https://api.github.com/users/twalthr/following{/other_user}",
                "gists_url": "https://api.github.com/users/twalthr/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/twalthr/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/twalthr/subscriptions",
                "organizations_url": "https://api.github.com/users/twalthr/orgs",
                "repos_url": "https://api.github.com/users/twalthr/repos",
                "events_url": "https://api.github.com/users/twalthr/events{/privacy}",
                "received_events_url": "https://api.github.com/users/twalthr/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "25489aa0cc536f1551a0a887bdfc690824a24bd9",
                "url": "https://api.github.com/repos/apache/flink/commits/25489aa0cc536f1551a0a887bdfc690824a24bd9",
                "html_url": "https://github.com/apache/flink/commit/25489aa0cc536f1551a0a887bdfc690824a24bd9"
            }]
        },
        {
            "sha": "dd1c1bc19169a53755be96c5cf1e5e80c76a9145",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZGQxYzFiYzE5MTY5YTUzNzU1YmU5NmM1Y2YxZTVlODBjNzZhOTE0NQ==",
            "commit": {
                "author": {
                    "name": "Ingo Bürk",
                    "email": "ingo.buerk@tngtech.com",
                    "date": "2021-05-11T13:48:06Z"
                },
                "committer": {
                    "name": "Timo Walther",
                    "email": "twalthr@apache.org",
                    "date": "2021-05-14T13:40:13Z"
                },
                "message": "[FLINK-22475][table-common] Exclude options with '#' placeholder from validation of required options",
                "tree": {
                    "sha": "ffe181e81a8395f483b3c7f69c6169e9adab0c03",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/ffe181e81a8395f483b3c7f69c6169e9adab0c03"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/dd1c1bc19169a53755be96c5cf1e5e80c76a9145",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/dd1c1bc19169a53755be96c5cf1e5e80c76a9145",
            "html_url": "https://github.com/apache/flink/commit/dd1c1bc19169a53755be96c5cf1e5e80c76a9145",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/dd1c1bc19169a53755be96c5cf1e5e80c76a9145/comments",
            "author": {
                "login": "Airblader",
                "id": 2392216,
                "node_id": "MDQ6VXNlcjIzOTIyMTY=",
                "avatar_url": "https://avatars.githubusercontent.com/u/2392216?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/Airblader",
                "html_url": "https://github.com/Airblader",
                "followers_url": "https://api.github.com/users/Airblader/followers",
                "following_url": "https://api.github.com/users/Airblader/following{/other_user}",
                "gists_url": "https://api.github.com/users/Airblader/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/Airblader/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/Airblader/subscriptions",
                "organizations_url": "https://api.github.com/users/Airblader/orgs",
                "repos_url": "https://api.github.com/users/Airblader/repos",
                "events_url": "https://api.github.com/users/Airblader/events{/privacy}",
                "received_events_url": "https://api.github.com/users/Airblader/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "twalthr",
                "id": 5746567,
                "node_id": "MDQ6VXNlcjU3NDY1Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5746567?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/twalthr",
                "html_url": "https://github.com/twalthr",
                "followers_url": "https://api.github.com/users/twalthr/followers",
                "following_url": "https://api.github.com/users/twalthr/following{/other_user}",
                "gists_url": "https://api.github.com/users/twalthr/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/twalthr/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/twalthr/subscriptions",
                "organizations_url": "https://api.github.com/users/twalthr/orgs",
                "repos_url": "https://api.github.com/users/twalthr/repos",
                "events_url": "https://api.github.com/users/twalthr/events{/privacy}",
                "received_events_url": "https://api.github.com/users/twalthr/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "6bf648aecf31d4253ecaf64bc6df16401397cbeb",
                "url": "https://api.github.com/repos/apache/flink/commits/6bf648aecf31d4253ecaf64bc6df16401397cbeb",
                "html_url": "https://github.com/apache/flink/commit/6bf648aecf31d4253ecaf64bc6df16401397cbeb"
            }]
        },
        {
            "sha": "4f6e0dd5741cb13e38b9ede7183805290e0d22ce",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NGY2ZTBkZDU3NDFjYjEzZTM4YjllZGU3MTgzODA1MjkwZTBkMjJjZQ==",
            "commit": {
                "author": {
                    "name": "Ingo Bürk",
                    "email": "ingo.buerk@tngtech.com",
                    "date": "2021-05-11T15:20:57Z"
                },
                "committer": {
                    "name": "Timo Walther",
                    "email": "twalthr@apache.org",
                    "date": "2021-05-14T13:40:13Z"
                },
                "message": "[FLINK-22475][table-api-java-bridge] Add placeholder options for datagen connector\n\nThis closes #15896.",
                "tree": {
                    "sha": "596f9911bef53c7f30b29a78e239aecf565d531a",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/596f9911bef53c7f30b29a78e239aecf565d531a"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/4f6e0dd5741cb13e38b9ede7183805290e0d22ce",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/4f6e0dd5741cb13e38b9ede7183805290e0d22ce",
            "html_url": "https://github.com/apache/flink/commit/4f6e0dd5741cb13e38b9ede7183805290e0d22ce",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/4f6e0dd5741cb13e38b9ede7183805290e0d22ce/comments",
            "author": {
                "login": "Airblader",
                "id": 2392216,
                "node_id": "MDQ6VXNlcjIzOTIyMTY=",
                "avatar_url": "https://avatars.githubusercontent.com/u/2392216?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/Airblader",
                "html_url": "https://github.com/Airblader",
                "followers_url": "https://api.github.com/users/Airblader/followers",
                "following_url": "https://api.github.com/users/Airblader/following{/other_user}",
                "gists_url": "https://api.github.com/users/Airblader/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/Airblader/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/Airblader/subscriptions",
                "organizations_url": "https://api.github.com/users/Airblader/orgs",
                "repos_url": "https://api.github.com/users/Airblader/repos",
                "events_url": "https://api.github.com/users/Airblader/events{/privacy}",
                "received_events_url": "https://api.github.com/users/Airblader/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "twalthr",
                "id": 5746567,
                "node_id": "MDQ6VXNlcjU3NDY1Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5746567?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/twalthr",
                "html_url": "https://github.com/twalthr",
                "followers_url": "https://api.github.com/users/twalthr/followers",
                "following_url": "https://api.github.com/users/twalthr/following{/other_user}",
                "gists_url": "https://api.github.com/users/twalthr/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/twalthr/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/twalthr/subscriptions",
                "organizations_url": "https://api.github.com/users/twalthr/orgs",
                "repos_url": "https://api.github.com/users/twalthr/repos",
                "events_url": "https://api.github.com/users/twalthr/events{/privacy}",
                "received_events_url": "https://api.github.com/users/twalthr/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "dd1c1bc19169a53755be96c5cf1e5e80c76a9145",
                "url": "https://api.github.com/repos/apache/flink/commits/dd1c1bc19169a53755be96c5cf1e5e80c76a9145",
                "html_url": "https://github.com/apache/flink/commit/dd1c1bc19169a53755be96c5cf1e5e80c76a9145"
            }]
        },
        {
            "sha": "7253525f6d43a54bff7336768506974a60aa6754",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NzI1MzUyNWY2ZDQzYTU0YmZmNzMzNjc2ODUwNjk3NGE2MGFhNjc1NA==",
            "commit": {
                "author": {
                    "name": "huangxingbo",
                    "email": "hxbks2ks@gmail.com",
                    "date": "2021-04-28T12:39:34Z"
                },
                "committer": {
                    "name": "huangxingbo",
                    "email": "hxbks2ks@gmail.com",
                    "date": "2021-05-15T07:36:33Z"
                },
                "message": "[FLINK-22511][python] Fix the bug of non-composite result type in Python TableAggregateFunction\n\nThis closes #15796.",
                "tree": {
                    "sha": "1dadb115f2e38ca02ee8791e84f3255e2e8e81f8",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/1dadb115f2e38ca02ee8791e84f3255e2e8e81f8"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/7253525f6d43a54bff7336768506974a60aa6754",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/7253525f6d43a54bff7336768506974a60aa6754",
            "html_url": "https://github.com/apache/flink/commit/7253525f6d43a54bff7336768506974a60aa6754",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/7253525f6d43a54bff7336768506974a60aa6754/comments",
            "author": {
                "login": "HuangXingBo",
                "id": 8536293,
                "node_id": "MDQ6VXNlcjg1MzYyOTM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8536293?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/HuangXingBo",
                "html_url": "https://github.com/HuangXingBo",
                "followers_url": "https://api.github.com/users/HuangXingBo/followers",
                "following_url": "https://api.github.com/users/HuangXingBo/following{/other_user}",
                "gists_url": "https://api.github.com/users/HuangXingBo/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/HuangXingBo/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/HuangXingBo/subscriptions",
                "organizations_url": "https://api.github.com/users/HuangXingBo/orgs",
                "repos_url": "https://api.github.com/users/HuangXingBo/repos",
                "events_url": "https://api.github.com/users/HuangXingBo/events{/privacy}",
                "received_events_url": "https://api.github.com/users/HuangXingBo/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "HuangXingBo",
                "id": 8536293,
                "node_id": "MDQ6VXNlcjg1MzYyOTM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8536293?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/HuangXingBo",
                "html_url": "https://github.com/HuangXingBo",
                "followers_url": "https://api.github.com/users/HuangXingBo/followers",
                "following_url": "https://api.github.com/users/HuangXingBo/following{/other_user}",
                "gists_url": "https://api.github.com/users/HuangXingBo/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/HuangXingBo/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/HuangXingBo/subscriptions",
                "organizations_url": "https://api.github.com/users/HuangXingBo/orgs",
                "repos_url": "https://api.github.com/users/HuangXingBo/repos",
                "events_url": "https://api.github.com/users/HuangXingBo/events{/privacy}",
                "received_events_url": "https://api.github.com/users/HuangXingBo/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "4f6e0dd5741cb13e38b9ede7183805290e0d22ce",
                "url": "https://api.github.com/repos/apache/flink/commits/4f6e0dd5741cb13e38b9ede7183805290e0d22ce",
                "html_url": "https://github.com/apache/flink/commit/4f6e0dd5741cb13e38b9ede7183805290e0d22ce"
            }]
        },
        {
            "sha": "6f4a49ce7c79a8f820c22bd797c6db13f5d0d177",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NmY0YTQ5Y2U3Yzc5YThmODIwYzIyYmQ3OTdjNmRiMTNmNWQwZDE3Nw==",
            "commit": {
                "author": {
                    "name": "Terry Wang",
                    "email": "zjuwangg@foxmail.com",
                    "date": "2021-05-17T02:31:29Z"
                },
                "committer": {
                    "name": "godfreyhe",
                    "email": "godfreyhe@163.com",
                    "date": "2021-05-17T02:35:46Z"
                },
                "message": "[FLINK-22654][sql-parser] Fix SqlCreateTable#toString()/unparse() lose CONSTRAINTS and watermarks\n\nThis closes #15918\n\n(cherry picked from commit cb4b4d37870fba22af122d1c31e49ce7f3ed096c)",
                "tree": {
                    "sha": "8c0263b2c91a0a4c5e2b01722400a36931c2eee9",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/8c0263b2c91a0a4c5e2b01722400a36931c2eee9"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/6f4a49ce7c79a8f820c22bd797c6db13f5d0d177",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/6f4a49ce7c79a8f820c22bd797c6db13f5d0d177",
            "html_url": "https://github.com/apache/flink/commit/6f4a49ce7c79a8f820c22bd797c6db13f5d0d177",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/6f4a49ce7c79a8f820c22bd797c6db13f5d0d177/comments",
            "author": {
                "login": "zjuwangg",
                "id": 8543127,
                "node_id": "MDQ6VXNlcjg1NDMxMjc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8543127?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zjuwangg",
                "html_url": "https://github.com/zjuwangg",
                "followers_url": "https://api.github.com/users/zjuwangg/followers",
                "following_url": "https://api.github.com/users/zjuwangg/following{/other_user}",
                "gists_url": "https://api.github.com/users/zjuwangg/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zjuwangg/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zjuwangg/subscriptions",
                "organizations_url": "https://api.github.com/users/zjuwangg/orgs",
                "repos_url": "https://api.github.com/users/zjuwangg/repos",
                "events_url": "https://api.github.com/users/zjuwangg/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zjuwangg/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "godfreyhe",
                "id": 8777671,
                "node_id": "MDQ6VXNlcjg3Nzc2NzE=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8777671?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/godfreyhe",
                "html_url": "https://github.com/godfreyhe",
                "followers_url": "https://api.github.com/users/godfreyhe/followers",
                "following_url": "https://api.github.com/users/godfreyhe/following{/other_user}",
                "gists_url": "https://api.github.com/users/godfreyhe/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/godfreyhe/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/godfreyhe/subscriptions",
                "organizations_url": "https://api.github.com/users/godfreyhe/orgs",
                "repos_url": "https://api.github.com/users/godfreyhe/repos",
                "events_url": "https://api.github.com/users/godfreyhe/events{/privacy}",
                "received_events_url": "https://api.github.com/users/godfreyhe/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "7253525f6d43a54bff7336768506974a60aa6754",
                "url": "https://api.github.com/repos/apache/flink/commits/7253525f6d43a54bff7336768506974a60aa6754",
                "html_url": "https://github.com/apache/flink/commit/7253525f6d43a54bff7336768506974a60aa6754"
            }]
        },
        {
            "sha": "9b2f97d07dfa39c58572655f0a30d76ad9156546",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6OWIyZjk3ZDA3ZGZhMzljNTg1NzI2NTVmMGEzMGQ3NmFkOTE1NjU0Ng==",
            "commit": {
                "author": {
                    "name": "SteNicholas",
                    "email": "programgeek@163.com",
                    "date": "2021-05-13T12:25:53Z"
                },
                "committer": {
                    "name": "Xintong Song",
                    "email": "tonysong820@gmail.com",
                    "date": "2021-05-17T03:15:50Z"
                },
                "message": "[FLINK-22592][runtime] numBuffersInLocal is always zero when using unaligned checkpoints\n\nThis closes #15915",
                "tree": {
                    "sha": "168cde354865b653d9826fcc6b04c18d21c51749",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/168cde354865b653d9826fcc6b04c18d21c51749"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/9b2f97d07dfa39c58572655f0a30d76ad9156546",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCgAdFiEEGsvLF58sbVnbyFd20SHP9Sk+Y18FAmCh3+YACgkQ0SHP9Sk+\nY1+FLRAAhAWCQUajzVpizKIeaqCkys0kG+mwZUzMD5IbcITgkJtLi8mH03R6BJ3n\nMYLFzcgYDJ6eoHEkNhcinJdtXXFdd/Mcnuh/8p8vKlfyBYrZ0+Z/U95+oit+EV9L\nGrxrrFpa1n8oyGuuXV6nfoSL11IkqGv04rTwLb78r8T1vwOwyrdsiOAVzelgBGWz\nTTqDGY6T1tk19V9zJWEx7rxLzrq8laJ7EtZljr/Qt2G+G/XiPuszZWX7E71cl6Ob\nhXMZXtGPevgk1bPXWxVSJBLKUPq2guM+jtcjTznSYKFfUzFR7fYa+KsXI6cDn1a/\n+K1w65w8wxYGw5cC1nAns+1ByLQnUsux9PFgPE4gTRibT10SJXpGugm9223VX+MI\n6jds6U4Hrz04GuwgLHS3XDIOB51EyFkTpMaBVE9S57a5qOp2O3do2O0TX2R2Ioac\n0r5kb9IER6RawvcyBnlXwx3pR9VrPmt/GuLyFJjicB/L+HWzf/ezY+HtNjmgRfxQ\nbxwOxoLsUdzL3VWOGMCN7XsuhKjPfSGHYU5GerZGgFGwEyTGmNOYsvtn5rEHkqYx\nph31s8Zkezz1KGEyiguGJSiscBfIPFtOa+mc6wwoXYhlQbuWysakqyaNr+zmhGpP\nsr7aNG0lJrdMxG9zMCBkal2Bk8fDscagCbNe3v7R8JcQUm9XFVQ=\n=VHfn\n-----END PGP SIGNATURE-----",
                    "payload": "tree 168cde354865b653d9826fcc6b04c18d21c51749\nparent 6f4a49ce7c79a8f820c22bd797c6db13f5d0d177\nauthor SteNicholas <programgeek@163.com> 1620908753 +0800\ncommitter Xintong Song <tonysong820@gmail.com> 1621221350 +0800\n\n[FLINK-22592][runtime] numBuffersInLocal is always zero when using unaligned checkpoints\n\nThis closes #15915\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/9b2f97d07dfa39c58572655f0a30d76ad9156546",
            "html_url": "https://github.com/apache/flink/commit/9b2f97d07dfa39c58572655f0a30d76ad9156546",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/9b2f97d07dfa39c58572655f0a30d76ad9156546/comments",
            "author": {
                "login": "SteNicholas",
                "id": 10048174,
                "node_id": "MDQ6VXNlcjEwMDQ4MTc0",
                "avatar_url": "https://avatars.githubusercontent.com/u/10048174?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/SteNicholas",
                "html_url": "https://github.com/SteNicholas",
                "followers_url": "https://api.github.com/users/SteNicholas/followers",
                "following_url": "https://api.github.com/users/SteNicholas/following{/other_user}",
                "gists_url": "https://api.github.com/users/SteNicholas/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/SteNicholas/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/SteNicholas/subscriptions",
                "organizations_url": "https://api.github.com/users/SteNicholas/orgs",
                "repos_url": "https://api.github.com/users/SteNicholas/repos",
                "events_url": "https://api.github.com/users/SteNicholas/events{/privacy}",
                "received_events_url": "https://api.github.com/users/SteNicholas/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "xintongsong",
                "id": 6509172,
                "node_id": "MDQ6VXNlcjY1MDkxNzI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6509172?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/xintongsong",
                "html_url": "https://github.com/xintongsong",
                "followers_url": "https://api.github.com/users/xintongsong/followers",
                "following_url": "https://api.github.com/users/xintongsong/following{/other_user}",
                "gists_url": "https://api.github.com/users/xintongsong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/xintongsong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/xintongsong/subscriptions",
                "organizations_url": "https://api.github.com/users/xintongsong/orgs",
                "repos_url": "https://api.github.com/users/xintongsong/repos",
                "events_url": "https://api.github.com/users/xintongsong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/xintongsong/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "6f4a49ce7c79a8f820c22bd797c6db13f5d0d177",
                "url": "https://api.github.com/repos/apache/flink/commits/6f4a49ce7c79a8f820c22bd797c6db13f5d0d177",
                "html_url": "https://github.com/apache/flink/commit/6f4a49ce7c79a8f820c22bd797c6db13f5d0d177"
            }]
        },
        {
            "sha": "32f41f861ef082cc1154937124f66ff0c03dc32c",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MzJmNDFmODYxZWYwODJjYzExNTQ5MzcxMjRmNjZmZjBjMDNkYzMyYw==",
            "commit": {
                "author": {
                    "name": "Roman Khachatryan",
                    "email": "khachatryan.roman@gmail.com",
                    "date": "2021-05-05T16:59:14Z"
                },
                "committer": {
                    "name": "Roman",
                    "email": "khachatryan.roman@gmail.com",
                    "date": "2021-05-17T13:13:31Z"
                },
                "message": "[FLINK-22502][checkpointing] Don't tolerate checkpoint retrieval failures on recovery\n\nIgnoring such failures and running with an incomplete\nset of checkpoints can lead to consistency violation.\n\nInstead, transient failures should be mitigated by\nautomatic job restart.",
                "tree": {
                    "sha": "3b150b5c8882f22d954b8da5915872eb2383b08a",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/3b150b5c8882f22d954b8da5915872eb2383b08a"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/32f41f861ef082cc1154937124f66ff0c03dc32c",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/32f41f861ef082cc1154937124f66ff0c03dc32c",
            "html_url": "https://github.com/apache/flink/commit/32f41f861ef082cc1154937124f66ff0c03dc32c",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/32f41f861ef082cc1154937124f66ff0c03dc32c/comments",
            "author": {
                "login": "rkhachatryan",
                "id": 3939322,
                "node_id": "MDQ6VXNlcjM5MzkzMjI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3939322?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rkhachatryan",
                "html_url": "https://github.com/rkhachatryan",
                "followers_url": "https://api.github.com/users/rkhachatryan/followers",
                "following_url": "https://api.github.com/users/rkhachatryan/following{/other_user}",
                "gists_url": "https://api.github.com/users/rkhachatryan/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rkhachatryan/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rkhachatryan/subscriptions",
                "organizations_url": "https://api.github.com/users/rkhachatryan/orgs",
                "repos_url": "https://api.github.com/users/rkhachatryan/repos",
                "events_url": "https://api.github.com/users/rkhachatryan/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rkhachatryan/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "rkhachatryan",
                "id": 3939322,
                "node_id": "MDQ6VXNlcjM5MzkzMjI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3939322?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rkhachatryan",
                "html_url": "https://github.com/rkhachatryan",
                "followers_url": "https://api.github.com/users/rkhachatryan/followers",
                "following_url": "https://api.github.com/users/rkhachatryan/following{/other_user}",
                "gists_url": "https://api.github.com/users/rkhachatryan/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rkhachatryan/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rkhachatryan/subscriptions",
                "organizations_url": "https://api.github.com/users/rkhachatryan/orgs",
                "repos_url": "https://api.github.com/users/rkhachatryan/repos",
                "events_url": "https://api.github.com/users/rkhachatryan/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rkhachatryan/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "9b2f97d07dfa39c58572655f0a30d76ad9156546",
                "url": "https://api.github.com/repos/apache/flink/commits/9b2f97d07dfa39c58572655f0a30d76ad9156546",
                "html_url": "https://github.com/apache/flink/commit/9b2f97d07dfa39c58572655f0a30d76ad9156546"
            }]
        },
        {
            "sha": "6bf53142f5a0d7445cb3468ee5b7e72809343e03",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NmJmNTMxNDJmNWEwZDc0NDVjYjM0NjhlZTViN2U3MjgwOTM0M2UwMw==",
            "commit": {
                "author": {
                    "name": "Timo Walther",
                    "email": "twalthr@apache.org",
                    "date": "2021-05-17T07:15:49Z"
                },
                "committer": {
                    "name": "Timo Walther",
                    "email": "twalthr@apache.org",
                    "date": "2021-05-17T14:27:21Z"
                },
                "message": "[FLINK-22666][table] Make structured type's fields more lenient during casting\n\nCompare children individually for anonymous structured types. This\nfixes issues with primitive fields and Scala case classes.\n\nThis closes #15935.",
                "tree": {
                    "sha": "4c94ea0f5ce4b1366bc1b1a7feae7dbaf1da31a5",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/4c94ea0f5ce4b1366bc1b1a7feae7dbaf1da31a5"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/6bf53142f5a0d7445cb3468ee5b7e72809343e03",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/6bf53142f5a0d7445cb3468ee5b7e72809343e03",
            "html_url": "https://github.com/apache/flink/commit/6bf53142f5a0d7445cb3468ee5b7e72809343e03",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/6bf53142f5a0d7445cb3468ee5b7e72809343e03/comments",
            "author": {
                "login": "twalthr",
                "id": 5746567,
                "node_id": "MDQ6VXNlcjU3NDY1Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5746567?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/twalthr",
                "html_url": "https://github.com/twalthr",
                "followers_url": "https://api.github.com/users/twalthr/followers",
                "following_url": "https://api.github.com/users/twalthr/following{/other_user}",
                "gists_url": "https://api.github.com/users/twalthr/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/twalthr/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/twalthr/subscriptions",
                "organizations_url": "https://api.github.com/users/twalthr/orgs",
                "repos_url": "https://api.github.com/users/twalthr/repos",
                "events_url": "https://api.github.com/users/twalthr/events{/privacy}",
                "received_events_url": "https://api.github.com/users/twalthr/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "twalthr",
                "id": 5746567,
                "node_id": "MDQ6VXNlcjU3NDY1Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5746567?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/twalthr",
                "html_url": "https://github.com/twalthr",
                "followers_url": "https://api.github.com/users/twalthr/followers",
                "following_url": "https://api.github.com/users/twalthr/following{/other_user}",
                "gists_url": "https://api.github.com/users/twalthr/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/twalthr/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/twalthr/subscriptions",
                "organizations_url": "https://api.github.com/users/twalthr/orgs",
                "repos_url": "https://api.github.com/users/twalthr/repos",
                "events_url": "https://api.github.com/users/twalthr/events{/privacy}",
                "received_events_url": "https://api.github.com/users/twalthr/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "32f41f861ef082cc1154937124f66ff0c03dc32c",
                "url": "https://api.github.com/repos/apache/flink/commits/32f41f861ef082cc1154937124f66ff0c03dc32c",
                "html_url": "https://github.com/apache/flink/commit/32f41f861ef082cc1154937124f66ff0c03dc32c"
            }]
        },
        {
            "sha": "3f59de843063c01fa917cc94bd74cf15fbb91b7d",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6M2Y1OWRlODQzMDYzYzAxZmE5MTdjYzk0YmQ3NGNmMTVmYmI5MWI3ZA==",
            "commit": {
                "author": {
                    "name": "Timo Walther",
                    "email": "twalthr@apache.org",
                    "date": "2021-05-17T09:01:50Z"
                },
                "committer": {
                    "name": "Timo Walther",
                    "email": "twalthr@apache.org",
                    "date": "2021-05-17T14:27:21Z"
                },
                "message": "[hotfix][table-planner-blink] Give more helpful exception for codegen structured types",
                "tree": {
                    "sha": "ec53beb028705eabd2800e6aa30e55647d4ca187",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/ec53beb028705eabd2800e6aa30e55647d4ca187"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/3f59de843063c01fa917cc94bd74cf15fbb91b7d",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/3f59de843063c01fa917cc94bd74cf15fbb91b7d",
            "html_url": "https://github.com/apache/flink/commit/3f59de843063c01fa917cc94bd74cf15fbb91b7d",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/3f59de843063c01fa917cc94bd74cf15fbb91b7d/comments",
            "author": {
                "login": "twalthr",
                "id": 5746567,
                "node_id": "MDQ6VXNlcjU3NDY1Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5746567?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/twalthr",
                "html_url": "https://github.com/twalthr",
                "followers_url": "https://api.github.com/users/twalthr/followers",
                "following_url": "https://api.github.com/users/twalthr/following{/other_user}",
                "gists_url": "https://api.github.com/users/twalthr/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/twalthr/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/twalthr/subscriptions",
                "organizations_url": "https://api.github.com/users/twalthr/orgs",
                "repos_url": "https://api.github.com/users/twalthr/repos",
                "events_url": "https://api.github.com/users/twalthr/events{/privacy}",
                "received_events_url": "https://api.github.com/users/twalthr/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "twalthr",
                "id": 5746567,
                "node_id": "MDQ6VXNlcjU3NDY1Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5746567?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/twalthr",
                "html_url": "https://github.com/twalthr",
                "followers_url": "https://api.github.com/users/twalthr/followers",
                "following_url": "https://api.github.com/users/twalthr/following{/other_user}",
                "gists_url": "https://api.github.com/users/twalthr/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/twalthr/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/twalthr/subscriptions",
                "organizations_url": "https://api.github.com/users/twalthr/orgs",
                "repos_url": "https://api.github.com/users/twalthr/repos",
                "events_url": "https://api.github.com/users/twalthr/events{/privacy}",
                "received_events_url": "https://api.github.com/users/twalthr/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "6bf53142f5a0d7445cb3468ee5b7e72809343e03",
                "url": "https://api.github.com/repos/apache/flink/commits/6bf53142f5a0d7445cb3468ee5b7e72809343e03",
                "html_url": "https://github.com/apache/flink/commit/6bf53142f5a0d7445cb3468ee5b7e72809343e03"
            }]
        },
        {
            "sha": "57bc204c5757b47a30dddd6c12029416b94e1331",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NTdiYzIwNGM1NzU3YjQ3YTMwZGRkZDZjMTIwMjk0MTZiOTRlMTMzMQ==",
            "commit": {
                "author": {
                    "name": "Yi Tang",
                    "email": "ssnailtang@gmail.com",
                    "date": "2021-04-12T04:59:40Z"
                },
                "committer": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-05-18T07:17:21Z"
                },
                "message": "[FLINK-20695][ha] Clean ha data for job if globally terminated\n\nAt the moment Flink only cleans up the ha data (e.g. K8s ConfigMaps, or\nZookeeper nodes) while shutting down the cluster. This is not enough for\na long running session cluster to which you submit multiple jobs. In\nthis commit, we clean up the data for the particular job if it reaches a\nglobally terminal state.\n\nThis closes #15909.",
                "tree": {
                    "sha": "d2a052934f04ea8e4a8ea2e185e046a1441637b8",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/d2a052934f04ea8e4a8ea2e185e046a1441637b8"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/57bc204c5757b47a30dddd6c12029416b94e1331",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEEuUmfpp7/Xe7rw8H1un5Bh8b3PYIFAmCjag8ACgkQun5Bh8b3\nPYJFiA/+KBAMkGzmj/78l22FTG5h45qWE+eF7Be4WH1945D9aMZhihWOROu82tUY\nLlSGpCiSv+MTGsEhKkVfIcVedTHjGeF82Afzc5Ibkh5p2+1gUIuam8W2qwL3DY5W\nZC6eIZBQDkb8J6qtCAyhGCqsO7wu7orXJhbUC7ujErsiC+sRMn93bDQ7y9/CLaeJ\nuzu8hZwoKNF7NfZs9Ztle/Tfpt8pDtHvSvJ+j0WZKUQiEnKd5BPhxip8ld3W5Zeu\n79w6eslNba+VSoPFyRy5sZP7J7H3yQKT8CF7TG0yKmG86H/yYAo7s9A0nKXNQ/eY\nYO6qt6YiX9mEhmTjeWBQsvg0hys3dwuTk3Stosw+awkgPrGCIZUJK359tZJugowm\n77a29RsiCHMTaknL9zBn9+2Wqc4KQgjJKCnTBsXl5YyJvlAzEDb6gG5jScknOcj/\nbZ4zBupUk6oA2n0/QFn6GeXx4L2xX/F+HIYVR5spPLlRWrCOcM7Ziu8GeB7ZR78X\nYSZsr/5fDK3VUApEptY64p5ypke1ZT7P+s7G5FIsN0y1OcTSlnO9qHgcih8C1d5V\nkExYccu3nI8SwvWjN2+ELpkf298ziG9bl3MFP1DWkS47YRL/7d/0wRjfhJeYb7cZ\nC8ezdPhhKZPo2vKaujPH2WpYUpVA4guAmWtrRX2sQQrzBKQnTNw=\n=Hxf2\n-----END PGP SIGNATURE-----",
                    "payload": "tree d2a052934f04ea8e4a8ea2e185e046a1441637b8\nparent 3f59de843063c01fa917cc94bd74cf15fbb91b7d\nauthor Yi Tang <ssnailtang@gmail.com> 1618203580 +0800\ncommitter Till Rohrmann <trohrmann@apache.org> 1621322241 +0200\n\n[FLINK-20695][ha] Clean ha data for job if globally terminated\n\nAt the moment Flink only cleans up the ha data (e.g. K8s ConfigMaps, or\nZookeeper nodes) while shutting down the cluster. This is not enough for\na long running session cluster to which you submit multiple jobs. In\nthis commit, we clean up the data for the particular job if it reaches a\nglobally terminal state.\n\nThis closes #15909.\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/57bc204c5757b47a30dddd6c12029416b94e1331",
            "html_url": "https://github.com/apache/flink/commit/57bc204c5757b47a30dddd6c12029416b94e1331",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/57bc204c5757b47a30dddd6c12029416b94e1331/comments",
            "author": {
                "login": "yittg",
                "id": 4429171,
                "node_id": "MDQ6VXNlcjQ0MjkxNzE=",
                "avatar_url": "https://avatars.githubusercontent.com/u/4429171?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/yittg",
                "html_url": "https://github.com/yittg",
                "followers_url": "https://api.github.com/users/yittg/followers",
                "following_url": "https://api.github.com/users/yittg/following{/other_user}",
                "gists_url": "https://api.github.com/users/yittg/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/yittg/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/yittg/subscriptions",
                "organizations_url": "https://api.github.com/users/yittg/orgs",
                "repos_url": "https://api.github.com/users/yittg/repos",
                "events_url": "https://api.github.com/users/yittg/events{/privacy}",
                "received_events_url": "https://api.github.com/users/yittg/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "3f59de843063c01fa917cc94bd74cf15fbb91b7d",
                "url": "https://api.github.com/repos/apache/flink/commits/3f59de843063c01fa917cc94bd74cf15fbb91b7d",
                "html_url": "https://github.com/apache/flink/commit/3f59de843063c01fa917cc94bd74cf15fbb91b7d"
            }]
        },
        {
            "sha": "a24b0d86d7d55da1e6190ee377ac22c808584525",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6YTI0YjBkODZkN2Q1NWRhMWU2MTkwZWUzNzdhYzIyYzgwODU4NDUyNQ==",
            "commit": {
                "author": {
                    "name": "Matthias Pohl",
                    "email": "matthias@ververica.com",
                    "date": "2021-05-03T07:40:12Z"
                },
                "committer": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-05-18T09:02:40Z"
                },
                "message": "[FLINK-22494][kubernetes] Introduces PossibleInconsistentStateException\n\nWe experienced cases where the ConfigMap was updated but the corresponding HTTP\nrequest failed due to connectivity issues. PossibleInconsistentStateException\nis used to reflect cases where it's not clear whether the data was actually\nwritten or not.",
                "tree": {
                    "sha": "731c7e35d3242ca3cca4dc62506409474da07ff2",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/731c7e35d3242ca3cca4dc62506409474da07ff2"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/a24b0d86d7d55da1e6190ee377ac22c808584525",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEEuUmfpp7/Xe7rw8H1un5Bh8b3PYIFAmCjgrAACgkQun5Bh8b3\nPYJ3BRAAj+W+HLfpdsa/C8HMzyf8yvp6RkGP8Pvv7NQb/VefH6esYYTpRbw533Tz\n1gkeEEB+oZAsNZkmaZEv9OB7KaNCjIPdBggcoIG0LbQIWic4Sk5jBFaAhl/8FBfw\nci/H+flPvC3s/FmSPFBlnN05ThTo2Biob7OoHMfisFewqf7SibHCc8BzzOSZ5wJs\n45yYIl/Dape7wdHXN7SKPVQ9vqrWENBOo6AlLaEcl0Xvs2t1D5pTMEsAOHW5hZC+\nSHQMshPBQSDCglQOEuj/Cc0MLiw0wdvhlqx7dbAC4XMzppo15I5UTUzyckYOPSgz\nziElfa7lUzNd8fm/3mgZ7+x5mBQEj00S7rFjKIKAi2Pe2wAZkh85DBLGpUhAt289\nDnKo7FVPH1HuBcKjwqY8ouIUrxEbend68kJXdmchYIHhvYOhXdI6kREbGCP1xupX\np9kXqKrjTvmAY2fKwWHzl7Nrd4LMv1EHw8YPqsegbVBzi4MLSmkgD7jkD1LTXOOx\nJFjTB/bR/Pvvc4DRkUdrQTZbLNmMVnjNdkPDedpctDsjydW3Af3LrubeK42+93K0\n+vwXEDmKRsFt5Qu6zyyNKf/ckGemYSAjErBUoYRx/HcoZpCYhmG3ld0eGupGJ9QT\npkJ1dUG+hgeoWtAIvb9nJdCsj5bJDOgGrswTPmkP8D96uholKgk=\n=WsvO\n-----END PGP SIGNATURE-----",
                    "payload": "tree 731c7e35d3242ca3cca4dc62506409474da07ff2\nparent 57bc204c5757b47a30dddd6c12029416b94e1331\nauthor Matthias Pohl <matthias@ververica.com> 1620027612 +0200\ncommitter Till Rohrmann <trohrmann@apache.org> 1621328560 +0200\n\n[FLINK-22494][kubernetes] Introduces PossibleInconsistentStateException\n\nWe experienced cases where the ConfigMap was updated but the corresponding HTTP\nrequest failed due to connectivity issues. PossibleInconsistentStateException\nis used to reflect cases where it's not clear whether the data was actually\nwritten or not.\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/a24b0d86d7d55da1e6190ee377ac22c808584525",
            "html_url": "https://github.com/apache/flink/commit/a24b0d86d7d55da1e6190ee377ac22c808584525",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/a24b0d86d7d55da1e6190ee377ac22c808584525/comments",
            "author": {
                "login": "XComp",
                "id": 1101012,
                "node_id": "MDQ6VXNlcjExMDEwMTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1101012?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/XComp",
                "html_url": "https://github.com/XComp",
                "followers_url": "https://api.github.com/users/XComp/followers",
                "following_url": "https://api.github.com/users/XComp/following{/other_user}",
                "gists_url": "https://api.github.com/users/XComp/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/XComp/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/XComp/subscriptions",
                "organizations_url": "https://api.github.com/users/XComp/orgs",
                "repos_url": "https://api.github.com/users/XComp/repos",
                "events_url": "https://api.github.com/users/XComp/events{/privacy}",
                "received_events_url": "https://api.github.com/users/XComp/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "57bc204c5757b47a30dddd6c12029416b94e1331",
                "url": "https://api.github.com/repos/apache/flink/commits/57bc204c5757b47a30dddd6c12029416b94e1331",
                "html_url": "https://github.com/apache/flink/commit/57bc204c5757b47a30dddd6c12029416b94e1331"
            }]
        },
        {
            "sha": "6ce9cc900ccab09519dfd758cbd48bbd90f33c15",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NmNlOWNjOTAwY2NhYjA5NTE5ZGZkNzU4Y2JkNDhiYmQ5MGYzM2MxNQ==",
            "commit": {
                "author": {
                    "name": "Matthias Pohl",
                    "email": "matthias@ververica.com",
                    "date": "2021-05-04T11:08:07Z"
                },
                "committer": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-05-18T09:02:40Z"
                },
                "message": "[FLINK-22494][ha] Refactors TestingLongStateHandleHelper to operate on references\n\nThe previous implementation stored the state in the StateHandle. This causes\nproblems when deserializing the state creating a new instance that does not\npoint to the actual state but is a copy of this state.\n\nThis refactoring introduces LongStateHandle handling the actual state and\nLongRetrievableStateHandle referencing this handle.",
                "tree": {
                    "sha": "4128296ae8b277956a53e96927a19fd95d85f1ed",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/4128296ae8b277956a53e96927a19fd95d85f1ed"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/6ce9cc900ccab09519dfd758cbd48bbd90f33c15",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEEuUmfpp7/Xe7rw8H1un5Bh8b3PYIFAmCjgrAACgkQun5Bh8b3\nPYIgJQ/8Dy+XkYMeUwzyRBGRidSqeGPg67iFGfPZt2+HB15kgjj2PqXx2pfnnsCc\nNYl8Z8nHH/JUQ+TEqPXx5dYpQHqsaIWqpprTdm+a8rvmh4reDWpLzIrSeg4ZBbk9\nDKAk0p46irJpCXKwZjEPRtJ9AKPePtaaVzdmd6f6l6XkSZNpoOBRevFJ7+xJosJN\ncaAmib9YnmUjbbbeM3AlceLbLAdKFHMh4rhkG/fHnRzDrREnU5sTgLGpWlxbwyAa\nKayI4yp9aO2nNMfwuKUj69aQpA2KefF7kQh5xF7gcYc3wmybA+UNwvOkpF49V1dJ\nCE83Ct+ySTaOKec0gTqVafeLGHyvomQrIHPahOdHlSa2OVCwciCFO/jzGbbaaZxk\nPIG9/IFNviK4dWFNdalZDku3OXZb1XLM6PFwWbW3pCXnM8YEUxu3m/62f1SR/x+H\n+EWKEvFkCCbvby0mzAucli6ZV6B98wqn3xahtusQYlJU7P7YjgE60v8HU0R/Yt2T\nm536kiYig0TWIWsNkjojs2/BXMHjY38hAyVAgqiAax/gW++mrxpf+cbNxaLxpppd\nnSakPf0B3UaT5Odi4tnHVg+KnzFezPWhveARBJnUbkjA9Nq0wmCGoGQQdIsxVf0f\neg0jl6mk/4V3Oh7jKro+tLtHBcndAhEzhu3wwM5KcFj51Lg5EEs=\n=qWPZ\n-----END PGP SIGNATURE-----",
                    "payload": "tree 4128296ae8b277956a53e96927a19fd95d85f1ed\nparent a24b0d86d7d55da1e6190ee377ac22c808584525\nauthor Matthias Pohl <matthias@ververica.com> 1620126487 +0200\ncommitter Till Rohrmann <trohrmann@apache.org> 1621328560 +0200\n\n[FLINK-22494][ha] Refactors TestingLongStateHandleHelper to operate on references\n\nThe previous implementation stored the state in the StateHandle. This causes\nproblems when deserializing the state creating a new instance that does not\npoint to the actual state but is a copy of this state.\n\nThis refactoring introduces LongStateHandle handling the actual state and\nLongRetrievableStateHandle referencing this handle.\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/6ce9cc900ccab09519dfd758cbd48bbd90f33c15",
            "html_url": "https://github.com/apache/flink/commit/6ce9cc900ccab09519dfd758cbd48bbd90f33c15",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/6ce9cc900ccab09519dfd758cbd48bbd90f33c15/comments",
            "author": {
                "login": "XComp",
                "id": 1101012,
                "node_id": "MDQ6VXNlcjExMDEwMTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1101012?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/XComp",
                "html_url": "https://github.com/XComp",
                "followers_url": "https://api.github.com/users/XComp/followers",
                "following_url": "https://api.github.com/users/XComp/following{/other_user}",
                "gists_url": "https://api.github.com/users/XComp/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/XComp/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/XComp/subscriptions",
                "organizations_url": "https://api.github.com/users/XComp/orgs",
                "repos_url": "https://api.github.com/users/XComp/repos",
                "events_url": "https://api.github.com/users/XComp/events{/privacy}",
                "received_events_url": "https://api.github.com/users/XComp/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "a24b0d86d7d55da1e6190ee377ac22c808584525",
                "url": "https://api.github.com/repos/apache/flink/commits/a24b0d86d7d55da1e6190ee377ac22c808584525",
                "html_url": "https://github.com/apache/flink/commit/a24b0d86d7d55da1e6190ee377ac22c808584525"
            }]
        },
        {
            "sha": "b5c49ef484ec4cde63206d89e2b7e317a76280fc",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6YjVjNDllZjQ4NGVjNGNkZTYzMjA2ZDg5ZTJiN2UzMTdhNzYyODBmYw==",
            "commit": {
                "author": {
                    "name": "Matthias Pohl",
                    "email": "matthias@ververica.com",
                    "date": "2021-05-04T07:41:38Z"
                },
                "committer": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-05-18T09:02:40Z"
                },
                "message": "[FLINK-22494][ha] Introduces PossibleInconsistentState to StateHandleStore",
                "tree": {
                    "sha": "6caebcaa1b7edaf48e68bb6d867668240ff1e2ea",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/6caebcaa1b7edaf48e68bb6d867668240ff1e2ea"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/b5c49ef484ec4cde63206d89e2b7e317a76280fc",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEEuUmfpp7/Xe7rw8H1un5Bh8b3PYIFAmCjgrAACgkQun5Bh8b3\nPYKrqg//UD728Tg9JZg18+E6lI98/0UVigRF4GSeKCgO5gZ3rtTGgCiClJEXHZQX\n1ChuAkrv3FbNLnAsp4FUdmKMGMZsp+KjIIXo/X0vVQ4ID98MJk1d/vgxwtpbkzqn\nDVhtAmC47kKOWTkhcSEuwEtRCpsemGJs2Nqeakhuk8a0324exI+FCOhJLtpAXCMM\nXg6r1sHyqrXoaGkESdDifp6Aqr/R6qpXPSijOTjrFvrvzdHf664v7XCcqCxY47/y\nHDkkXIgyRin1XwHcEgy0nKQ+jw8dkoQU8rlAM8qUHBuRLNNlswvH17l/Y/OQn8vG\npeT3x4FVDo283U+apKeoutMreyTN5Y0wIq3BkAk6V+aeUBWI1Z0pqgMsGyx+gveT\nv1N8rV1ITjrkhNOlJ5GXO/zEwdqpizETX8dRHem9gMYpja/d8OvAlMR9tXGwGSuW\nha+F9zUb0aGyxhFoMyfWmeKhErSQERID0tHTz3sqBQbeMrP4pw59Am9ru+i/UWQI\n0Vvf/8ss6HiDMspP52i62a+H4IxoVMrcjQHEDhbp1Ge9dJru4y4NiwFxSsIMfnUJ\nTsRKQrdb9hXcmOKFJbj74zQUvdBvn0w9zeTh986xO8xE6yuL42wr+pupfBE+hJ1j\noepJkgxf6hfYUoMfCOw07NM5J0wnAU679f81cONDS/48i2EPFtM=\n=j4EM\n-----END PGP SIGNATURE-----",
                    "payload": "tree 6caebcaa1b7edaf48e68bb6d867668240ff1e2ea\nparent 6ce9cc900ccab09519dfd758cbd48bbd90f33c15\nauthor Matthias Pohl <matthias@ververica.com> 1620114098 +0200\ncommitter Till Rohrmann <trohrmann@apache.org> 1621328560 +0200\n\n[FLINK-22494][ha] Introduces PossibleInconsistentState to StateHandleStore\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/b5c49ef484ec4cde63206d89e2b7e317a76280fc",
            "html_url": "https://github.com/apache/flink/commit/b5c49ef484ec4cde63206d89e2b7e317a76280fc",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/b5c49ef484ec4cde63206d89e2b7e317a76280fc/comments",
            "author": {
                "login": "XComp",
                "id": 1101012,
                "node_id": "MDQ6VXNlcjExMDEwMTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1101012?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/XComp",
                "html_url": "https://github.com/XComp",
                "followers_url": "https://api.github.com/users/XComp/followers",
                "following_url": "https://api.github.com/users/XComp/following{/other_user}",
                "gists_url": "https://api.github.com/users/XComp/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/XComp/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/XComp/subscriptions",
                "organizations_url": "https://api.github.com/users/XComp/orgs",
                "repos_url": "https://api.github.com/users/XComp/repos",
                "events_url": "https://api.github.com/users/XComp/events{/privacy}",
                "received_events_url": "https://api.github.com/users/XComp/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "6ce9cc900ccab09519dfd758cbd48bbd90f33c15",
                "url": "https://api.github.com/repos/apache/flink/commits/6ce9cc900ccab09519dfd758cbd48bbd90f33c15",
                "html_url": "https://github.com/apache/flink/commit/6ce9cc900ccab09519dfd758cbd48bbd90f33c15"
            }]
        },
        {
            "sha": "a6c13e79b646ce88e5498b3885e9f7d8040dc85c",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6YTZjMTNlNzliNjQ2Y2U4OGU1NDk4YjM4ODVlOWY3ZDgwNDBkYzg1Yw==",
            "commit": {
                "author": {
                    "name": "Matthias Pohl",
                    "email": "matthias@ververica.com",
                    "date": "2021-05-04T15:37:35Z"
                },
                "committer": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-05-18T09:02:40Z"
                },
                "message": "[FLINK-22494][runtime] Refactors CheckpointsCleaner to handle also discardOnFailedStoring",
                "tree": {
                    "sha": "4dbce1c2129f1b8009e53b1b349e67ac316665ec",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/4dbce1c2129f1b8009e53b1b349e67ac316665ec"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/a6c13e79b646ce88e5498b3885e9f7d8040dc85c",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEEuUmfpp7/Xe7rw8H1un5Bh8b3PYIFAmCjgrAACgkQun5Bh8b3\nPYK8+xAAgJWujoIQ3DbLyiRMNO2N6e+SXkb+s8/B1OScgTt7ktXrGEn2VELeXbls\nMm1z7GNiB/mn96yosZwgtQlTdlVeetxtZA+GSXrx8Jr77OytOiQwyVNFTrcyky9f\nXT7GPqioyoasEcp1KXsvQlbrvvVnxze1x8qjd0sApsxKFEUvyjDnMVfjii2yrfHQ\navnL8ObcDQST9vkFXbdMRCzhFlAtGFAXsKLt3HD2YsgixfBIkwSvNmsveQBJ7si7\nE3mGKhDR0jaBsS3quC3c3NNRu5+1UVOrZfTRDJJKdChuwNaYtxRepAWAEbKvCBAy\nihpFftSA0yZaEKpLjv9244g69+VmzSDqOzsEEJUD5hHjx6oNepm86sEyRESkpyJK\ngj7Y5QL5gTflKHEWb11MImb/BVHsOQxG0EAL620qmvLE8HJ4SRx+OneZdfIBTnUp\ntYNvHCCu7mOI2yZT4Q+tJK1BUlF4Pqu4j+YfjforDKnPDJwqCiTNsXU1G8zcfwcB\n+HtkJx5TZ4wqaH/WIBkmzGw5Dsft6LLEdog/wpUgheyzdo8k3Tpas7d8uByR43u9\nMtEbjkjzIfvnLdKRPy31UfCcoJ8oEb4P38ApP6+yaqX3kYrV7nK9hgtsOoIDkZHJ\nAbQq+/ZdDBIF0EceURqGPW3NT9H1I4xRAIcykBuGtIvyTnGA0qY=\n=UQsC\n-----END PGP SIGNATURE-----",
                    "payload": "tree 4dbce1c2129f1b8009e53b1b349e67ac316665ec\nparent b5c49ef484ec4cde63206d89e2b7e317a76280fc\nauthor Matthias Pohl <matthias@ververica.com> 1620142655 +0200\ncommitter Till Rohrmann <trohrmann@apache.org> 1621328560 +0200\n\n[FLINK-22494][runtime] Refactors CheckpointsCleaner to handle also discardOnFailedStoring\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/a6c13e79b646ce88e5498b3885e9f7d8040dc85c",
            "html_url": "https://github.com/apache/flink/commit/a6c13e79b646ce88e5498b3885e9f7d8040dc85c",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/a6c13e79b646ce88e5498b3885e9f7d8040dc85c/comments",
            "author": {
                "login": "XComp",
                "id": 1101012,
                "node_id": "MDQ6VXNlcjExMDEwMTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1101012?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/XComp",
                "html_url": "https://github.com/XComp",
                "followers_url": "https://api.github.com/users/XComp/followers",
                "following_url": "https://api.github.com/users/XComp/following{/other_user}",
                "gists_url": "https://api.github.com/users/XComp/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/XComp/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/XComp/subscriptions",
                "organizations_url": "https://api.github.com/users/XComp/orgs",
                "repos_url": "https://api.github.com/users/XComp/repos",
                "events_url": "https://api.github.com/users/XComp/events{/privacy}",
                "received_events_url": "https://api.github.com/users/XComp/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "b5c49ef484ec4cde63206d89e2b7e317a76280fc",
                "url": "https://api.github.com/repos/apache/flink/commits/b5c49ef484ec4cde63206d89e2b7e317a76280fc",
                "html_url": "https://github.com/apache/flink/commit/b5c49ef484ec4cde63206d89e2b7e317a76280fc"
            }]
        },
        {
            "sha": "13bc663802020c898a838525f91a181537d96127",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MTNiYzY2MzgwMjAyMGM4OThhODM4NTI1ZjkxYTE4MTUzN2Q5NjEyNw==",
            "commit": {
                "author": {
                    "name": "Matthias Pohl",
                    "email": "matthias@ververica.com",
                    "date": "2021-05-04T13:32:36Z"
                },
                "committer": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-05-18T09:02:43Z"
                },
                "message": "[FLINK-22494][runtime] Adds PossibleInconsistentStateException handling to CheckpointCoordinator\n\nThis closes #15908.",
                "tree": {
                    "sha": "4221465d05b0803eed6ae7c552f5b6484e9e3766",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/4221465d05b0803eed6ae7c552f5b6484e9e3766"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/13bc663802020c898a838525f91a181537d96127",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEEuUmfpp7/Xe7rw8H1un5Bh8b3PYIFAmCjgrkACgkQun5Bh8b3\nPYJ7JQ//XhsyvAdo6+GIWsxCbxmnQOdYihkh8/+SJ6ll1R9wmVwaumizigHcHSLi\n9MDl8GZedSq+S0QqIyIqEQnQCGON45Xn8wnJSgWsaT/OKK6h03PRsJmgZNvzJ2G/\nJ21VeU+jpVmka4s04633AZpM1tBnXvt/CF569q0ahPZX6IU++bfgsUQdU04Su7v4\ntOTVqG0rQID6hvuKt9/5LpB15M7X9QH+JO0WA0LKAwPm1jSMOMSbkJVD83BBPIg6\nUDcTjVLlGqWQE0deyqsUIArXX6fXIG6YTt56m7xG3n0TIaktKcf6H6l9MQGoXRtm\nEYdE5twa+hwvhIho4vPE5ZqjFoLl8Kk2zgX4fdHl9/yk9myRIcygNR5TtCO336Um\n9yYa6R7khCr2JPdD0L7jEfRSneWdaZex4iZTxA2hQp6iZtgy3P0JZHaUQODbZnQV\nSSN8nGVnCKjKd7mIbQYdEyFxooRNxZLLFkbVHsICXpq7xEvIt+yOCK7mIkTGvosQ\nibdB37ed3yRv4y2ERqLRA7nfELJhfZYKiR2g2Fi6SU+7Yk0oqbfc6YFIbAeHzHbh\n0eb/Dll7zewiBdOexP+uRL1TgnPAnODJFEK03DQGXnUZp2fxYv+WEuMadJjsPu/e\njHpmUKB7h+iLWpclS7o1JYlbkiwGxsZl9sonmvNU6yuHRetlUt0=\n=DkVA\n-----END PGP SIGNATURE-----",
                    "payload": "tree 4221465d05b0803eed6ae7c552f5b6484e9e3766\nparent a6c13e79b646ce88e5498b3885e9f7d8040dc85c\nauthor Matthias Pohl <matthias@ververica.com> 1620135156 +0200\ncommitter Till Rohrmann <trohrmann@apache.org> 1621328563 +0200\n\n[FLINK-22494][runtime] Adds PossibleInconsistentStateException handling to CheckpointCoordinator\n\nThis closes #15908.\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/13bc663802020c898a838525f91a181537d96127",
            "html_url": "https://github.com/apache/flink/commit/13bc663802020c898a838525f91a181537d96127",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/13bc663802020c898a838525f91a181537d96127/comments",
            "author": {
                "login": "XComp",
                "id": 1101012,
                "node_id": "MDQ6VXNlcjExMDEwMTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1101012?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/XComp",
                "html_url": "https://github.com/XComp",
                "followers_url": "https://api.github.com/users/XComp/followers",
                "following_url": "https://api.github.com/users/XComp/following{/other_user}",
                "gists_url": "https://api.github.com/users/XComp/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/XComp/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/XComp/subscriptions",
                "organizations_url": "https://api.github.com/users/XComp/orgs",
                "repos_url": "https://api.github.com/users/XComp/repos",
                "events_url": "https://api.github.com/users/XComp/events{/privacy}",
                "received_events_url": "https://api.github.com/users/XComp/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "a6c13e79b646ce88e5498b3885e9f7d8040dc85c",
                "url": "https://api.github.com/repos/apache/flink/commits/a6c13e79b646ce88e5498b3885e9f7d8040dc85c",
                "html_url": "https://github.com/apache/flink/commit/a6c13e79b646ce88e5498b3885e9f7d8040dc85c"
            }]
        },
        {
            "sha": "1c7adac48440e6a14bae3ab26770bfaf3da2dc35",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MWM3YWRhYzQ4NDQwZTZhMTRiYWUzYWIyNjc3MGJmYWYzZGEyZGMzNQ==",
            "commit": {
                "author": {
                    "name": "wangyang0918",
                    "email": "danrtsey.wy@alibaba-inc.com",
                    "date": "2021-05-08T03:54:13Z"
                },
                "committer": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-05-18T13:41:05Z"
                },
                "message": "[FLINK-19545][e2e] Add e2e test for native Kubernetes HA\n\nThe HA e2e test will start a Flink application first and wait for three successful checkpoints. Then kill the JobManager. A new JobManager should be launched and recover the job from latest successful checkpoint. Finally, cancel the job and all the K8s resources should be cleaned up automatically.\n\nThis closes #14172.",
                "tree": {
                    "sha": "f3b65f228cc7e246224e88651f2bf2c18680bdc8",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/f3b65f228cc7e246224e88651f2bf2c18680bdc8"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/1c7adac48440e6a14bae3ab26770bfaf3da2dc35",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEEuUmfpp7/Xe7rw8H1un5Bh8b3PYIFAmCjw/EACgkQun5Bh8b3\nPYLCMg/+LPQ9ZKOyHoeucFBJKDTMRyCEDEmw2jY1yzpK/pIXCykS1f6WcG3jSqCy\nqu8jBeG+JpdB4jiYmqHMOJDTYyA1ItPuhGvKdNhvGAZyAOa8qa3SpeoTw3LuYmlP\nJcb2WSCf7nDYHhNluL+mCm0Pm1SMmOWaj6NOIbPUb8C15Xfo+UC5SW4yt4ofTqnr\n9TYFFAhDddyS0SLRWxRuhpYGVatPcDNgyxyKFbnbV5Zj/d/tRXm7VbDnlCTIctXm\nogaHMQF0lg/5cz3iaaKd5beRjBVCtLMb0tD7Hz4K7AM3XeJIfaY191sYl6jTfw/y\nsJPDg56IYNaqZ7ps83c4Cvtf0tQKqWexQJVuPeq6b8i3yHCjfRcOYM7XC7y7N5EQ\nnqY+TYXuwkZRVnvRmY/xUU25hp6+Kbg6DV5e30G7YDJj2Gjpv+g+AOQnuCMpdI+z\nYQsetoOoL2JzVMOPIRCccbkW7BydNGgqRNgx37NZUdNQLTfsAFJkVg6LsbGre4vF\nf2E03YGempUE1NUqP9u2G5gkUriGlKWUqmlwt+nDcZlVwqty+aI+C2JN5XySpl9A\nhri6QPHCDKrYc6y2Zif+stFUilWeN8/JwQh4eELnsNPGd0zNqN9hufzVwEsVVysD\nXONqjw9k8T6EUhXIL+1C+rnaxzHLCSuzJAzOHLf+ZEi9LKdNFiQ=\n=K+5K\n-----END PGP SIGNATURE-----",
                    "payload": "tree f3b65f228cc7e246224e88651f2bf2c18680bdc8\nparent 13bc663802020c898a838525f91a181537d96127\nauthor wangyang0918 <danrtsey.wy@alibaba-inc.com> 1620446053 +0800\ncommitter Till Rohrmann <trohrmann@apache.org> 1621345265 +0200\n\n[FLINK-19545][e2e] Add e2e test for native Kubernetes HA\n\nThe HA e2e test will start a Flink application first and wait for three successful checkpoints. Then kill the JobManager. A new JobManager should be launched and recover the job from latest successful checkpoint. Finally, cancel the job and all the K8s resources should be cleaned up automatically.\n\nThis closes #14172.\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/1c7adac48440e6a14bae3ab26770bfaf3da2dc35",
            "html_url": "https://github.com/apache/flink/commit/1c7adac48440e6a14bae3ab26770bfaf3da2dc35",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/1c7adac48440e6a14bae3ab26770bfaf3da2dc35/comments",
            "author": {
                "login": "wangyang0918",
                "id": 15904523,
                "node_id": "MDQ6VXNlcjE1OTA0NTIz",
                "avatar_url": "https://avatars.githubusercontent.com/u/15904523?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/wangyang0918",
                "html_url": "https://github.com/wangyang0918",
                "followers_url": "https://api.github.com/users/wangyang0918/followers",
                "following_url": "https://api.github.com/users/wangyang0918/following{/other_user}",
                "gists_url": "https://api.github.com/users/wangyang0918/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/wangyang0918/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/wangyang0918/subscriptions",
                "organizations_url": "https://api.github.com/users/wangyang0918/orgs",
                "repos_url": "https://api.github.com/users/wangyang0918/repos",
                "events_url": "https://api.github.com/users/wangyang0918/events{/privacy}",
                "received_events_url": "https://api.github.com/users/wangyang0918/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "13bc663802020c898a838525f91a181537d96127",
                "url": "https://api.github.com/repos/apache/flink/commits/13bc663802020c898a838525f91a181537d96127",
                "html_url": "https://github.com/apache/flink/commit/13bc663802020c898a838525f91a181537d96127"
            }]
        },
        {
            "sha": "e624d210b33ca69352f77b16d48acda5494a612a",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZTYyNGQyMTBiMzNjYTY5MzUyZjc3YjE2ZDQ4YWNkYTU0OTRhNjEyYQ==",
            "commit": {
                "author": {
                    "name": "Roman Khachatryan",
                    "email": "khachatryan.roman@gmail.com",
                    "date": "2021-04-15T10:58:14Z"
                },
                "committer": {
                    "name": "Roman",
                    "email": "khachatryan.roman@gmail.com",
                    "date": "2021-05-19T12:27:54Z"
                },
                "message": "[hotfix][runtime] Log checkpoint processing delay if above threshold",
                "tree": {
                    "sha": "6b58a66e10cc0673ac644327fba23f6bb9c9d4a7",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/6b58a66e10cc0673ac644327fba23f6bb9c9d4a7"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/e624d210b33ca69352f77b16d48acda5494a612a",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/e624d210b33ca69352f77b16d48acda5494a612a",
            "html_url": "https://github.com/apache/flink/commit/e624d210b33ca69352f77b16d48acda5494a612a",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/e624d210b33ca69352f77b16d48acda5494a612a/comments",
            "author": {
                "login": "rkhachatryan",
                "id": 3939322,
                "node_id": "MDQ6VXNlcjM5MzkzMjI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3939322?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rkhachatryan",
                "html_url": "https://github.com/rkhachatryan",
                "followers_url": "https://api.github.com/users/rkhachatryan/followers",
                "following_url": "https://api.github.com/users/rkhachatryan/following{/other_user}",
                "gists_url": "https://api.github.com/users/rkhachatryan/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rkhachatryan/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rkhachatryan/subscriptions",
                "organizations_url": "https://api.github.com/users/rkhachatryan/orgs",
                "repos_url": "https://api.github.com/users/rkhachatryan/repos",
                "events_url": "https://api.github.com/users/rkhachatryan/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rkhachatryan/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "rkhachatryan",
                "id": 3939322,
                "node_id": "MDQ6VXNlcjM5MzkzMjI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3939322?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rkhachatryan",
                "html_url": "https://github.com/rkhachatryan",
                "followers_url": "https://api.github.com/users/rkhachatryan/followers",
                "following_url": "https://api.github.com/users/rkhachatryan/following{/other_user}",
                "gists_url": "https://api.github.com/users/rkhachatryan/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rkhachatryan/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rkhachatryan/subscriptions",
                "organizations_url": "https://api.github.com/users/rkhachatryan/orgs",
                "repos_url": "https://api.github.com/users/rkhachatryan/repos",
                "events_url": "https://api.github.com/users/rkhachatryan/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rkhachatryan/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "1c7adac48440e6a14bae3ab26770bfaf3da2dc35",
                "url": "https://api.github.com/repos/apache/flink/commits/1c7adac48440e6a14bae3ab26770bfaf3da2dc35",
                "html_url": "https://github.com/apache/flink/commit/1c7adac48440e6a14bae3ab26770bfaf3da2dc35"
            }]
        },
        {
            "sha": "2f1e7928258876970ac9859e7afe070c9f03fa96",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MmYxZTc5MjgyNTg4NzY5NzBhYzk4NTllN2FmZTA3MGM5ZjAzZmE5Ng==",
            "commit": {
                "author": {
                    "name": "Roman Khachatryan",
                    "email": "khachatryan.roman@gmail.com",
                    "date": "2021-04-15T11:05:21Z"
                },
                "committer": {
                    "name": "Roman",
                    "email": "khachatryan.roman@gmail.com",
                    "date": "2021-05-19T12:27:54Z"
                },
                "message": "[FLINK-21329][tests] Increase timeout and delay in local test_local_recovery_and_scheduling.sh\n\nBack-pressure is likely to occur without injection delay at the source\nwhich may lead to delaying checkpoint triggering at the sources\nwhich may lead to a timeout.\n\nTo prevent this, test timeout is increased from 10m to 15m\nand injection delay of 100ms is added.",
                "tree": {
                    "sha": "0e4f08dbaa9c183777f1174f92f5da5565badcd4",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/0e4f08dbaa9c183777f1174f92f5da5565badcd4"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/2f1e7928258876970ac9859e7afe070c9f03fa96",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/2f1e7928258876970ac9859e7afe070c9f03fa96",
            "html_url": "https://github.com/apache/flink/commit/2f1e7928258876970ac9859e7afe070c9f03fa96",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/2f1e7928258876970ac9859e7afe070c9f03fa96/comments",
            "author": {
                "login": "rkhachatryan",
                "id": 3939322,
                "node_id": "MDQ6VXNlcjM5MzkzMjI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3939322?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rkhachatryan",
                "html_url": "https://github.com/rkhachatryan",
                "followers_url": "https://api.github.com/users/rkhachatryan/followers",
                "following_url": "https://api.github.com/users/rkhachatryan/following{/other_user}",
                "gists_url": "https://api.github.com/users/rkhachatryan/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rkhachatryan/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rkhachatryan/subscriptions",
                "organizations_url": "https://api.github.com/users/rkhachatryan/orgs",
                "repos_url": "https://api.github.com/users/rkhachatryan/repos",
                "events_url": "https://api.github.com/users/rkhachatryan/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rkhachatryan/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "rkhachatryan",
                "id": 3939322,
                "node_id": "MDQ6VXNlcjM5MzkzMjI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3939322?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rkhachatryan",
                "html_url": "https://github.com/rkhachatryan",
                "followers_url": "https://api.github.com/users/rkhachatryan/followers",
                "following_url": "https://api.github.com/users/rkhachatryan/following{/other_user}",
                "gists_url": "https://api.github.com/users/rkhachatryan/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rkhachatryan/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rkhachatryan/subscriptions",
                "organizations_url": "https://api.github.com/users/rkhachatryan/orgs",
                "repos_url": "https://api.github.com/users/rkhachatryan/repos",
                "events_url": "https://api.github.com/users/rkhachatryan/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rkhachatryan/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "e624d210b33ca69352f77b16d48acda5494a612a",
                "url": "https://api.github.com/repos/apache/flink/commits/e624d210b33ca69352f77b16d48acda5494a612a",
                "html_url": "https://github.com/apache/flink/commit/e624d210b33ca69352f77b16d48acda5494a612a"
            }]
        },
        {
            "sha": "d7c5f89a857e0b204e774fb7f3917f2782045d4e",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZDdjNWY4OWE4NTdlMGIyMDRlNzc0ZmI3ZjM5MTdmMjc4MjA0NWQ0ZQ==",
            "commit": {
                "author": {
                    "name": "Timo Walther",
                    "email": "twalthr@apache.org",
                    "date": "2021-05-19T12:25:27Z"
                },
                "committer": {
                    "name": "Timo Walther",
                    "email": "twalthr@apache.org",
                    "date": "2021-05-19T12:30:22Z"
                },
                "message": "[hotfix][docs] Update SQL grammar for WITH and sub queries",
                "tree": {
                    "sha": "4f164fa582a7259525b5e1d56bc1ae26d44ad141",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/4f164fa582a7259525b5e1d56bc1ae26d44ad141"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/d7c5f89a857e0b204e774fb7f3917f2782045d4e",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/d7c5f89a857e0b204e774fb7f3917f2782045d4e",
            "html_url": "https://github.com/apache/flink/commit/d7c5f89a857e0b204e774fb7f3917f2782045d4e",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/d7c5f89a857e0b204e774fb7f3917f2782045d4e/comments",
            "author": {
                "login": "twalthr",
                "id": 5746567,
                "node_id": "MDQ6VXNlcjU3NDY1Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5746567?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/twalthr",
                "html_url": "https://github.com/twalthr",
                "followers_url": "https://api.github.com/users/twalthr/followers",
                "following_url": "https://api.github.com/users/twalthr/following{/other_user}",
                "gists_url": "https://api.github.com/users/twalthr/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/twalthr/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/twalthr/subscriptions",
                "organizations_url": "https://api.github.com/users/twalthr/orgs",
                "repos_url": "https://api.github.com/users/twalthr/repos",
                "events_url": "https://api.github.com/users/twalthr/events{/privacy}",
                "received_events_url": "https://api.github.com/users/twalthr/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "twalthr",
                "id": 5746567,
                "node_id": "MDQ6VXNlcjU3NDY1Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5746567?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/twalthr",
                "html_url": "https://github.com/twalthr",
                "followers_url": "https://api.github.com/users/twalthr/followers",
                "following_url": "https://api.github.com/users/twalthr/following{/other_user}",
                "gists_url": "https://api.github.com/users/twalthr/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/twalthr/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/twalthr/subscriptions",
                "organizations_url": "https://api.github.com/users/twalthr/orgs",
                "repos_url": "https://api.github.com/users/twalthr/repos",
                "events_url": "https://api.github.com/users/twalthr/events{/privacy}",
                "received_events_url": "https://api.github.com/users/twalthr/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "2f1e7928258876970ac9859e7afe070c9f03fa96",
                "url": "https://api.github.com/repos/apache/flink/commits/2f1e7928258876970ac9859e7afe070c9f03fa96",
                "html_url": "https://github.com/apache/flink/commit/2f1e7928258876970ac9859e7afe070c9f03fa96"
            }]
        },
        {
            "sha": "ac19f763b97e07486a1ad498d72a6409e8352d27",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6YWMxOWY3NjNiOTdlMDc0ODZhMWFkNDk4ZDcyYTY0MDllODM1MmQyNw==",
            "commit": {
                "author": {
                    "name": "Timo Walther",
                    "email": "twalthr@apache.org",
                    "date": "2021-05-19T15:26:31Z"
                },
                "committer": {
                    "name": "Timo Walther",
                    "email": "twalthr@apache.org",
                    "date": "2021-05-19T15:29:12Z"
                },
                "message": "[FLINK-22699][table-common] Declare ConstantArgumentCount as @PublicEvolving",
                "tree": {
                    "sha": "b9ffaf0a5308d749440d7ecbd6de4558fe57d9bb",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/b9ffaf0a5308d749440d7ecbd6de4558fe57d9bb"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/ac19f763b97e07486a1ad498d72a6409e8352d27",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/ac19f763b97e07486a1ad498d72a6409e8352d27",
            "html_url": "https://github.com/apache/flink/commit/ac19f763b97e07486a1ad498d72a6409e8352d27",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/ac19f763b97e07486a1ad498d72a6409e8352d27/comments",
            "author": {
                "login": "twalthr",
                "id": 5746567,
                "node_id": "MDQ6VXNlcjU3NDY1Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5746567?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/twalthr",
                "html_url": "https://github.com/twalthr",
                "followers_url": "https://api.github.com/users/twalthr/followers",
                "following_url": "https://api.github.com/users/twalthr/following{/other_user}",
                "gists_url": "https://api.github.com/users/twalthr/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/twalthr/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/twalthr/subscriptions",
                "organizations_url": "https://api.github.com/users/twalthr/orgs",
                "repos_url": "https://api.github.com/users/twalthr/repos",
                "events_url": "https://api.github.com/users/twalthr/events{/privacy}",
                "received_events_url": "https://api.github.com/users/twalthr/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "twalthr",
                "id": 5746567,
                "node_id": "MDQ6VXNlcjU3NDY1Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5746567?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/twalthr",
                "html_url": "https://github.com/twalthr",
                "followers_url": "https://api.github.com/users/twalthr/followers",
                "following_url": "https://api.github.com/users/twalthr/following{/other_user}",
                "gists_url": "https://api.github.com/users/twalthr/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/twalthr/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/twalthr/subscriptions",
                "organizations_url": "https://api.github.com/users/twalthr/orgs",
                "repos_url": "https://api.github.com/users/twalthr/repos",
                "events_url": "https://api.github.com/users/twalthr/events{/privacy}",
                "received_events_url": "https://api.github.com/users/twalthr/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "d7c5f89a857e0b204e774fb7f3917f2782045d4e",
                "url": "https://api.github.com/repos/apache/flink/commits/d7c5f89a857e0b204e774fb7f3917f2782045d4e",
                "html_url": "https://github.com/apache/flink/commit/d7c5f89a857e0b204e774fb7f3917f2782045d4e"
            }]
        },
        {
            "sha": "7390981e088e618af91a4493d720a36572e8672c",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NzM5MDk4MWUwODhlNjE4YWY5MWE0NDkzZDcyMGEzNjU3MmU4NjcyYw==",
            "commit": {
                "author": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-05-19T08:27:46Z"
                },
                "committer": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-05-20T08:16:33Z"
                },
                "message": "[FLINK-22704][tests] Harden ZooKeeperHaServicesTest.testCleanupJobData\n\nThis commit hardens the ZooKeeperHaServicesTest.testCleanupJobData by making sure that all\nzNodes have been created before checking for their existence. This is done by waiting for\nthe leader information for the ResourceManager and the JobMaster.\n\nThis closes #15955.",
                "tree": {
                    "sha": "4f49419d2fe69c5f9e965ca976686bbf30d63c2a",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/4f49419d2fe69c5f9e965ca976686bbf30d63c2a"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/7390981e088e618af91a4493d720a36572e8672c",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEEuUmfpp7/Xe7rw8H1un5Bh8b3PYIFAmCmGukACgkQun5Bh8b3\nPYK48A/7BOgWDeBlhFJH5rkHWsqfNecAowYyiDUXrJN/MTwcvAJ1zW5yQ3VXLhQr\nCZ/MrSALGLw46RL4CSjSjfr5Kj6CVtdhkNIUawTo/8pV3qYrGp+rVSPkaP6oQgT9\n6epbuTMFxV+kpUMsxL7Wwd2fduHwPvvYNb7e91hc5514dMGaCE29ewYzTLHP3QOb\nXwwe7hm//woSnI1y8Jaqr/uP89fN06D5j27++8BhAUuEPli+QBfPO3BZnz7twmOy\nCFcZLlwGanNBC0UvuuKUKJEjIqzAqiYtIG+wy+/yvJaVRN8n0fr4iKJl7pGxxcMu\n7G/i/6Xb/NAy5ErC++OpG5Nlk3YFr2jELEvj+0HJP2S9fz4Y9+SLGenvwTR6t3bd\nD+dTygbTZvZjQFNajCtgI6KDFQz7QPqNBd5eTXMfovLojMqqb3jvfhVkeAIbJntH\n2XfJWyBnqcuQUWDZjqrYv7L9rIoY/BPPjtBQj29E84Fi+HUA45Z0AaSraUlslW4T\ngQuGelJzeqaCc82C1Xc1OzveJB4ziWXZdWYdIVDfQDtYxri0Y5miogts+KmYv8Ux\nRmlvbk35+iZK3jh3yJD4jP9T1ZpO21Bufwb5QkFC3QVTE1ZghgoFs5m7PAv/YJ2u\n1vG2/Kw91WmhpprCRtPSP04liF9G8uhWcpX8Z3v8pjvVgeCixUc=\n=XJw5\n-----END PGP SIGNATURE-----",
                    "payload": "tree 4f49419d2fe69c5f9e965ca976686bbf30d63c2a\nparent ac19f763b97e07486a1ad498d72a6409e8352d27\nauthor Till Rohrmann <trohrmann@apache.org> 1621412866 +0200\ncommitter Till Rohrmann <trohrmann@apache.org> 1621498593 +0200\n\n[FLINK-22704][tests] Harden ZooKeeperHaServicesTest.testCleanupJobData\n\nThis commit hardens the ZooKeeperHaServicesTest.testCleanupJobData by making sure that all\nzNodes have been created before checking for their existence. This is done by waiting for\nthe leader information for the ResourceManager and the JobMaster.\n\nThis closes #15955.\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/7390981e088e618af91a4493d720a36572e8672c",
            "html_url": "https://github.com/apache/flink/commit/7390981e088e618af91a4493d720a36572e8672c",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/7390981e088e618af91a4493d720a36572e8672c/comments",
            "author": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "ac19f763b97e07486a1ad498d72a6409e8352d27",
                "url": "https://api.github.com/repos/apache/flink/commits/ac19f763b97e07486a1ad498d72a6409e8352d27",
                "html_url": "https://github.com/apache/flink/commit/ac19f763b97e07486a1ad498d72a6409e8352d27"
            }]
        },
        {
            "sha": "c88c0c98198b061e351d7574a5c5b891ba38116b",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6Yzg4YzBjOTgxOThiMDYxZTM1MWQ3NTc0YTVjNWI4OTFiYTM4MTE2Yg==",
            "commit": {
                "author": {
                    "name": "Rui Li",
                    "email": "lirui@apache.org",
                    "date": "2021-05-14T08:02:18Z"
                },
                "committer": {
                    "name": "Rui Li",
                    "email": "lirui@apache.org",
                    "date": "2021-05-20T08:17:33Z"
                },
                "message": "[FLINK-22661][hive] HiveInputFormatPartitionReader can return invalid data",
                "tree": {
                    "sha": "722c748ee0c2c46e991af869d56bef369901dc6a",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/722c748ee0c2c46e991af869d56bef369901dc6a"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/c88c0c98198b061e351d7574a5c5b891ba38116b",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/c88c0c98198b061e351d7574a5c5b891ba38116b",
            "html_url": "https://github.com/apache/flink/commit/c88c0c98198b061e351d7574a5c5b891ba38116b",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/c88c0c98198b061e351d7574a5c5b891ba38116b/comments",
            "author": {
                "login": "lirui-apache",
                "id": 5210788,
                "node_id": "MDQ6VXNlcjUyMTA3ODg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5210788?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/lirui-apache",
                "html_url": "https://github.com/lirui-apache",
                "followers_url": "https://api.github.com/users/lirui-apache/followers",
                "following_url": "https://api.github.com/users/lirui-apache/following{/other_user}",
                "gists_url": "https://api.github.com/users/lirui-apache/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/lirui-apache/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/lirui-apache/subscriptions",
                "organizations_url": "https://api.github.com/users/lirui-apache/orgs",
                "repos_url": "https://api.github.com/users/lirui-apache/repos",
                "events_url": "https://api.github.com/users/lirui-apache/events{/privacy}",
                "received_events_url": "https://api.github.com/users/lirui-apache/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "lirui-apache",
                "id": 5210788,
                "node_id": "MDQ6VXNlcjUyMTA3ODg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5210788?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/lirui-apache",
                "html_url": "https://github.com/lirui-apache",
                "followers_url": "https://api.github.com/users/lirui-apache/followers",
                "following_url": "https://api.github.com/users/lirui-apache/following{/other_user}",
                "gists_url": "https://api.github.com/users/lirui-apache/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/lirui-apache/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/lirui-apache/subscriptions",
                "organizations_url": "https://api.github.com/users/lirui-apache/orgs",
                "repos_url": "https://api.github.com/users/lirui-apache/repos",
                "events_url": "https://api.github.com/users/lirui-apache/events{/privacy}",
                "received_events_url": "https://api.github.com/users/lirui-apache/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "7390981e088e618af91a4493d720a36572e8672c",
                "url": "https://api.github.com/repos/apache/flink/commits/7390981e088e618af91a4493d720a36572e8672c",
                "html_url": "https://github.com/apache/flink/commit/7390981e088e618af91a4493d720a36572e8672c"
            }]
        },
        {
            "sha": "d1dd346aa0ce7c6300e4e392384b8ac40be0c13c",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZDFkZDM0NmFhMGNlN2M2MzAwZTRlMzkyMzg0YjhhYzQwYmUwYzEzYw==",
            "commit": {
                "author": {
                    "name": "FuyaoLi2017",
                    "email": "30902086+FuyaoLi2017@users.noreply.github.com",
                    "date": "2021-05-20T08:53:38Z"
                },
                "committer": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-05-20T08:55:04Z"
                },
                "message": "[FLINK-22706][legal] Update NOTICE regarding docs/ contents",
                "tree": {
                    "sha": "ad3e9b0010d1b7bbc648d2b4e6164ca96b67aa8f",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/ad3e9b0010d1b7bbc648d2b4e6164ca96b67aa8f"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/d1dd346aa0ce7c6300e4e392384b8ac40be0c13c",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/d1dd346aa0ce7c6300e4e392384b8ac40be0c13c",
            "html_url": "https://github.com/apache/flink/commit/d1dd346aa0ce7c6300e4e392384b8ac40be0c13c",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/d1dd346aa0ce7c6300e4e392384b8ac40be0c13c/comments",
            "author": {
                "login": "FuyaoLi2017",
                "id": 30902086,
                "node_id": "MDQ6VXNlcjMwOTAyMDg2",
                "avatar_url": "https://avatars.githubusercontent.com/u/30902086?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/FuyaoLi2017",
                "html_url": "https://github.com/FuyaoLi2017",
                "followers_url": "https://api.github.com/users/FuyaoLi2017/followers",
                "following_url": "https://api.github.com/users/FuyaoLi2017/following{/other_user}",
                "gists_url": "https://api.github.com/users/FuyaoLi2017/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/FuyaoLi2017/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/FuyaoLi2017/subscriptions",
                "organizations_url": "https://api.github.com/users/FuyaoLi2017/orgs",
                "repos_url": "https://api.github.com/users/FuyaoLi2017/repos",
                "events_url": "https://api.github.com/users/FuyaoLi2017/events{/privacy}",
                "received_events_url": "https://api.github.com/users/FuyaoLi2017/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "c88c0c98198b061e351d7574a5c5b891ba38116b",
                "url": "https://api.github.com/repos/apache/flink/commits/c88c0c98198b061e351d7574a5c5b891ba38116b",
                "html_url": "https://github.com/apache/flink/commit/c88c0c98198b061e351d7574a5c5b891ba38116b"
            }]
        },
        {
            "sha": "040bd81a28adaeee70f6d878045632b8b3588fa9",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MDQwYmQ4MWEyOGFkYWVlZTcwZjZkODc4MDQ1NjMyYjhiMzU4OGZhOQ==",
            "commit": {
                "author": {
                    "name": "Robert Metzger",
                    "email": "rmetzger@apache.org",
                    "date": "2021-05-06T11:32:12Z"
                },
                "committer": {
                    "name": "Robert Metzger",
                    "email": "rmetzger@apache.org",
                    "date": "2021-05-20T13:36:49Z"
                },
                "message": "[FLINK-22266] Fix stop-with-savepoint operation in AdaptiveScheduler\n\nThis closes #15884",
                "tree": {
                    "sha": "e4883343d7f6a6c292c77d0ac8d6cedf186fa203",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/e4883343d7f6a6c292c77d0ac8d6cedf186fa203"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/040bd81a28adaeee70f6d878045632b8b3588fa9",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/040bd81a28adaeee70f6d878045632b8b3588fa9",
            "html_url": "https://github.com/apache/flink/commit/040bd81a28adaeee70f6d878045632b8b3588fa9",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/040bd81a28adaeee70f6d878045632b8b3588fa9/comments",
            "author": {
                "login": "rmetzger",
                "id": 89049,
                "node_id": "MDQ6VXNlcjg5MDQ5",
                "avatar_url": "https://avatars.githubusercontent.com/u/89049?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rmetzger",
                "html_url": "https://github.com/rmetzger",
                "followers_url": "https://api.github.com/users/rmetzger/followers",
                "following_url": "https://api.github.com/users/rmetzger/following{/other_user}",
                "gists_url": "https://api.github.com/users/rmetzger/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rmetzger/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rmetzger/subscriptions",
                "organizations_url": "https://api.github.com/users/rmetzger/orgs",
                "repos_url": "https://api.github.com/users/rmetzger/repos",
                "events_url": "https://api.github.com/users/rmetzger/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rmetzger/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "rmetzger",
                "id": 89049,
                "node_id": "MDQ6VXNlcjg5MDQ5",
                "avatar_url": "https://avatars.githubusercontent.com/u/89049?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rmetzger",
                "html_url": "https://github.com/rmetzger",
                "followers_url": "https://api.github.com/users/rmetzger/followers",
                "following_url": "https://api.github.com/users/rmetzger/following{/other_user}",
                "gists_url": "https://api.github.com/users/rmetzger/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rmetzger/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rmetzger/subscriptions",
                "organizations_url": "https://api.github.com/users/rmetzger/orgs",
                "repos_url": "https://api.github.com/users/rmetzger/repos",
                "events_url": "https://api.github.com/users/rmetzger/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rmetzger/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "d1dd346aa0ce7c6300e4e392384b8ac40be0c13c",
                "url": "https://api.github.com/repos/apache/flink/commits/d1dd346aa0ce7c6300e4e392384b8ac40be0c13c",
                "html_url": "https://github.com/apache/flink/commit/d1dd346aa0ce7c6300e4e392384b8ac40be0c13c"
            }]
        },
        {
            "sha": "e4c626dc6eee910de31f0ed7aadd1ca25917703d",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZTRjNjI2ZGM2ZWVlOTEwZGUzMWYwZWQ3YWFkZDFjYTI1OTE3NzAzZA==",
            "commit": {
                "author": {
                    "name": "Roman Khachatryan",
                    "email": "khachatryan.roman@gmail.com",
                    "date": "2021-05-19T16:58:34Z"
                },
                "committer": {
                    "name": "Roman",
                    "email": "khachatryan.roman@gmail.com",
                    "date": "2021-05-20T13:39:47Z"
                },
                "message": "[FLINK-22692][tests] Disable CheckpointStoreITCase with adaptive scheduler\n\nAdaptive scheduler doesn't currently retry after failures on recovery.",
                "tree": {
                    "sha": "04ed27af6ed5fd31e4d0407dea8fbff02d56c34d",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/04ed27af6ed5fd31e4d0407dea8fbff02d56c34d"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/e4c626dc6eee910de31f0ed7aadd1ca25917703d",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/e4c626dc6eee910de31f0ed7aadd1ca25917703d",
            "html_url": "https://github.com/apache/flink/commit/e4c626dc6eee910de31f0ed7aadd1ca25917703d",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/e4c626dc6eee910de31f0ed7aadd1ca25917703d/comments",
            "author": {
                "login": "rkhachatryan",
                "id": 3939322,
                "node_id": "MDQ6VXNlcjM5MzkzMjI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3939322?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rkhachatryan",
                "html_url": "https://github.com/rkhachatryan",
                "followers_url": "https://api.github.com/users/rkhachatryan/followers",
                "following_url": "https://api.github.com/users/rkhachatryan/following{/other_user}",
                "gists_url": "https://api.github.com/users/rkhachatryan/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rkhachatryan/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rkhachatryan/subscriptions",
                "organizations_url": "https://api.github.com/users/rkhachatryan/orgs",
                "repos_url": "https://api.github.com/users/rkhachatryan/repos",
                "events_url": "https://api.github.com/users/rkhachatryan/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rkhachatryan/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "rkhachatryan",
                "id": 3939322,
                "node_id": "MDQ6VXNlcjM5MzkzMjI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3939322?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rkhachatryan",
                "html_url": "https://github.com/rkhachatryan",
                "followers_url": "https://api.github.com/users/rkhachatryan/followers",
                "following_url": "https://api.github.com/users/rkhachatryan/following{/other_user}",
                "gists_url": "https://api.github.com/users/rkhachatryan/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rkhachatryan/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rkhachatryan/subscriptions",
                "organizations_url": "https://api.github.com/users/rkhachatryan/orgs",
                "repos_url": "https://api.github.com/users/rkhachatryan/repos",
                "events_url": "https://api.github.com/users/rkhachatryan/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rkhachatryan/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "040bd81a28adaeee70f6d878045632b8b3588fa9",
                "url": "https://api.github.com/repos/apache/flink/commits/040bd81a28adaeee70f6d878045632b8b3588fa9",
                "html_url": "https://github.com/apache/flink/commit/040bd81a28adaeee70f6d878045632b8b3588fa9"
            }]
        },
        {
            "sha": "d6ef576a308fe8aa204ca9636af3e2d4ec231da3",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZDZlZjU3NmEzMDhmZThhYTIwNGNhOTYzNmFmM2UyZDRlYzIzMWRhMw==",
            "commit": {
                "author": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-05-20T08:32:57Z"
                },
                "committer": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-05-20T15:52:23Z"
                },
                "message": "[FLINK-22721][ha] Add default implementation for HighAvailabilityServices.cleanupJobData\n\nIn order to not break the HighAvailabilityServices interface, this commit adds a default\nimplementation for the HighAavilabilityServices.cleanupJobData method which does nothing.\nUsers of this interface are recommended to override this method and add a specific\nimplementation in order to clean up job specific HA services after a job completion.\n\nThis closes #15970.",
                "tree": {
                    "sha": "e35925262a023d623f87e2bc12f655fc4ebb844e",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/e35925262a023d623f87e2bc12f655fc4ebb844e"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/d6ef576a308fe8aa204ca9636af3e2d4ec231da3",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEEuUmfpp7/Xe7rw8H1un5Bh8b3PYIFAmCmhb4ACgkQun5Bh8b3\nPYJtcg//a0M8Qv6K7ozlbSQ50T2ean+ljY7klQH+yojOO5WoboRdpA3e0pSvlaKe\nbZK0ntQTtT5LE0u0+rJaXhhsS6yce2MdAIw8IIvI1t9aJ9AoK3W4qabogozxKTq8\nvaEmMAcTUgxXcAYPr9oufY0Mop9g0acn/oddVDOx1xkTbtkiqVXqKBytNBM4+Gma\nfoAW0ueqlSzJ0LDBtl7TdiKLUXmiuC0V6UfoFPHSkQlwIyDjy57o4WNXU6hgWCmI\nozCHoQovTvk2pxr099tLJVNC4AiduT6A8BV8ecPxFJgvS3j6F3oSE6IruQX5BzeW\nUuwq/6ZgpisY7CIRbugyRcIqecU6T1MTxTgOp15/fo+hIfXf92/fUuE7YxOhHfhm\nAqtx4+jZO3Mb9TcecpRnqDLuZbToaQNW3oWspN1JtyCah6HRVij2T5EORmSccQVR\nA35s5DMy3J43pnTVvYs9sroq4w0wjJXe4Y36N261I4HlWqGNpaOQ1wCbMgRfUuzg\nWCPQQ4RVNuzG5oqOHGQzPkZ5ijdRfIJaGNBEUDTsYqyiYZpwNR1cnX5Xg3DzClzr\nHqC7v6qeAGcdlpezT0GKdh5GOcu7v36f2Wm9WrMTlrrgBcLdI3PFJ8QUlQrqFFog\nO0aHJNGVrnHBLFx+of8wJfqjqBQsaJC5sF/VgY5pAZ25Clz6Nok=\n=lGZW\n-----END PGP SIGNATURE-----",
                    "payload": "tree e35925262a023d623f87e2bc12f655fc4ebb844e\nparent e4c626dc6eee910de31f0ed7aadd1ca25917703d\nauthor Till Rohrmann <trohrmann@apache.org> 1621499577 +0200\ncommitter Till Rohrmann <trohrmann@apache.org> 1621525943 +0200\n\n[FLINK-22721][ha] Add default implementation for HighAvailabilityServices.cleanupJobData\n\nIn order to not break the HighAvailabilityServices interface, this commit adds a default\nimplementation for the HighAavilabilityServices.cleanupJobData method which does nothing.\nUsers of this interface are recommended to override this method and add a specific\nimplementation in order to clean up job specific HA services after a job completion.\n\nThis closes #15970.\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/d6ef576a308fe8aa204ca9636af3e2d4ec231da3",
            "html_url": "https://github.com/apache/flink/commit/d6ef576a308fe8aa204ca9636af3e2d4ec231da3",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/d6ef576a308fe8aa204ca9636af3e2d4ec231da3/comments",
            "author": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "e4c626dc6eee910de31f0ed7aadd1ca25917703d",
                "url": "https://api.github.com/repos/apache/flink/commits/e4c626dc6eee910de31f0ed7aadd1ca25917703d",
                "html_url": "https://github.com/apache/flink/commit/e4c626dc6eee910de31f0ed7aadd1ca25917703d"
            }]
        },
        {
            "sha": "1fffd9d9d7435872f5b10975a9cbf390fd126536",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MWZmZmQ5ZDlkNzQzNTg3MmY1YjEwOTc1YTljYmYzOTBmZDEyNjUzNg==",
            "commit": {
                "author": {
                    "name": "Dawid Wysakowicz",
                    "email": "dwysakowicz@apache.org",
                    "date": "2021-05-19T07:21:11Z"
                },
                "committer": {
                    "name": "Dawid Wysakowicz",
                    "email": "dwysakowicz@apache.org",
                    "date": "2021-05-21T08:51:00Z"
                },
                "message": "[FLINK-22708][config] Propagate savepoint settings from StreamExecutionEnvironment to StreamGraph",
                "tree": {
                    "sha": "7c67b956e902b07fb440d4f2449f2d59da4fcb26",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/7c67b956e902b07fb440d4f2449f2d59da4fcb26"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/1fffd9d9d7435872f5b10975a9cbf390fd126536",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEE6pOkNbTiybTJ9TP2MdLdEL/BWi0FAmCndHQACgkQMdLdEL/B\nWi3x4A//dha0q1ZJILyBSfllDduKzidRy5/Nxf/E0gk6OnoexqE5ZRTTl9BXAWoz\ntgRQbnu6gM0vua1WHKXJ6u0ZqOG0ntO9esYEdJ8TujxQGYxE9LFlfx27mnp6/6u9\nri5Hez63B94t8orpUodWDyEODUKpEgricElcTb9qBvCPHcDlLsNeNAOLcYiJMEtk\ndSFV8/ZbNGTi2x3RdXlNJHMnZLViubKWGgEX3jx8WLzZQHl+CLh+wppIWvulHELa\ndzVgMqGGWNkgPYIkcwk/O8u6TbuH2Tun2cwL5KKjGgGhq0crg7zmCdd3s17VK2Dr\npn3LEptGiSE+Rtc/SPTNjMmF4YypmoRKpqVRaNqCgBw3O0Z+hz48GLWB4+6IomnS\nIQ94dR5cVHDBGw8upVqmuiJcHJUolyLSADUsYarzOd0JcGq5/An7omEXpJbbfEF9\nWzv7fS1GZ+QlucnXTwqD0qohFekSyqokkoap2YJTYwR6ezfxVFMxANgbXHtwunbs\nMVBBlu3RXOigs+7VtFJO9gn+SD735vC9PQGthcTs/rNc8bu6k4LVLTXF3MTkR88m\neE5CpiOB3c5d0ZnZiGchuZd2L0mnkE/rvY4VY8kie04L7d8b7pvQg/N/ytqpdgP+\nlHmDnKQ3fpeJdYQfRfR0xvzdeYC2/+GBe5GIgz0pqw8n+jAzGj4=\n=K/Yv\n-----END PGP SIGNATURE-----",
                    "payload": "tree 7c67b956e902b07fb440d4f2449f2d59da4fcb26\nparent d6ef576a308fe8aa204ca9636af3e2d4ec231da3\nauthor Dawid Wysakowicz <dwysakowicz@apache.org> 1621408871 +0200\ncommitter Dawid Wysakowicz <dwysakowicz@apache.org> 1621587060 +0200\n\n[FLINK-22708][config] Propagate savepoint settings from StreamExecutionEnvironment to StreamGraph\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/1fffd9d9d7435872f5b10975a9cbf390fd126536",
            "html_url": "https://github.com/apache/flink/commit/1fffd9d9d7435872f5b10975a9cbf390fd126536",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/1fffd9d9d7435872f5b10975a9cbf390fd126536/comments",
            "author": {
                "login": "dawidwys",
                "id": 6242259,
                "node_id": "MDQ6VXNlcjYyNDIyNTk=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6242259?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dawidwys",
                "html_url": "https://github.com/dawidwys",
                "followers_url": "https://api.github.com/users/dawidwys/followers",
                "following_url": "https://api.github.com/users/dawidwys/following{/other_user}",
                "gists_url": "https://api.github.com/users/dawidwys/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dawidwys/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dawidwys/subscriptions",
                "organizations_url": "https://api.github.com/users/dawidwys/orgs",
                "repos_url": "https://api.github.com/users/dawidwys/repos",
                "events_url": "https://api.github.com/users/dawidwys/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dawidwys/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "dawidwys",
                "id": 6242259,
                "node_id": "MDQ6VXNlcjYyNDIyNTk=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6242259?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dawidwys",
                "html_url": "https://github.com/dawidwys",
                "followers_url": "https://api.github.com/users/dawidwys/followers",
                "following_url": "https://api.github.com/users/dawidwys/following{/other_user}",
                "gists_url": "https://api.github.com/users/dawidwys/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dawidwys/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dawidwys/subscriptions",
                "organizations_url": "https://api.github.com/users/dawidwys/orgs",
                "repos_url": "https://api.github.com/users/dawidwys/repos",
                "events_url": "https://api.github.com/users/dawidwys/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dawidwys/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "d6ef576a308fe8aa204ca9636af3e2d4ec231da3",
                "url": "https://api.github.com/repos/apache/flink/commits/d6ef576a308fe8aa204ca9636af3e2d4ec231da3",
                "html_url": "https://github.com/apache/flink/commit/d6ef576a308fe8aa204ca9636af3e2d4ec231da3"
            }]
        },
        {
            "sha": "e70fe71f48e453bb84d808761c01ca27abbd7c48",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZTcwZmU3MWY0OGU0NTNiYjg0ZDgwODc2MWMwMWNhMjdhYmJkN2M0OA==",
            "commit": {
                "author": {
                    "name": "Dawid Wysakowicz",
                    "email": "dwysakowicz@apache.org",
                    "date": "2021-05-10T14:53:58Z"
                },
                "committer": {
                    "name": "Dawid Wysakowicz",
                    "email": "dwysakowicz@apache.org",
                    "date": "2021-05-21T10:44:57Z"
                },
                "message": "[FLINK-22638] Keep channels blocked on alignment timeout\n\nThis commit keeps channels blocked in case an alignment timeout occurs.\nThat way we prioritize the channels that we have not received the\nbarrier yet. This solution is based on the assumption that all upstream\noperators are working with aligned checkpoints and we do not mind\ndelaying the subsequent checkpoints on the blocked channels.\n\nThis closes #15897",
                "tree": {
                    "sha": "a7a7f69e45b0a37693f2e2c2a39cf4b674570342",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/a7a7f69e45b0a37693f2e2c2a39cf4b674570342"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/e70fe71f48e453bb84d808761c01ca27abbd7c48",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEE6pOkNbTiybTJ9TP2MdLdEL/BWi0FAmCnjykACgkQMdLdEL/B\nWi369A/5AclkDjGtn9GME5eaCAn6D1v3la+uOLDGKqmblDCoSiAUQvIG756rynD3\naE/lQXlXdWt/3+dXN9EYu1tqveAGnDusSMz33+g8OTwuZm1CQ1u1X2B4kPW/jKI5\nrzLZ+GKq3JLw7FOSnezubMQQe2EVPHklhRrEMA6EpofmxkmwkMs2TNFkRCj3AcvR\npYIx7Yzifx5is5MfKGDTtTPtlfeIJnut5jHbR+uiZVAAAb2lZZgdEzrdfgMS+FcU\n72w55IwE+6SZxLrvWnN2uqhstt0suMZQRIH3hX/D0jFPebiK9D68ho4ZH/wOD0Kf\npCaKxU9PDtfh/45y+dGk52mzTuZNV21e8CCwCf+z6+af5PmLkGvL/eKrIyX4F457\nvCbLDzLoWdLxphVv4zgwP9zc4v2yWZL5DUyiaxUOD6i7p4HPqtVBA6a0smDZZXDQ\n8AuKgKNdKhS6KUKrU5YU2YzM3JQVy+cBiNSDb9lrYU1jupryiLzGqmK8zGgnoDDH\nDDpxbp4GQJ3acXN4uKi/4S6ax20O097ydRhGfhifKb83iqJ314z37EwExT7RLrGp\nZeRDbGmQYefqcR5cMswayhXJ/M7OZEVNmQVM3i0oJbchPXKTB82jUcpqBH614oW0\nR56n1OwetPqHxKLAWKB6JaMS0aMiXxNPIcWddiSoJ9Gfi5WmPic=\n=NnEu\n-----END PGP SIGNATURE-----",
                    "payload": "tree a7a7f69e45b0a37693f2e2c2a39cf4b674570342\nparent 1fffd9d9d7435872f5b10975a9cbf390fd126536\nauthor Dawid Wysakowicz <dwysakowicz@apache.org> 1620658438 +0200\ncommitter Dawid Wysakowicz <dwysakowicz@apache.org> 1621593897 +0200\n\n[FLINK-22638] Keep channels blocked on alignment timeout\n\nThis commit keeps channels blocked in case an alignment timeout occurs.\nThat way we prioritize the channels that we have not received the\nbarrier yet. This solution is based on the assumption that all upstream\noperators are working with aligned checkpoints and we do not mind\ndelaying the subsequent checkpoints on the blocked channels.\n\nThis closes #15897\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/e70fe71f48e453bb84d808761c01ca27abbd7c48",
            "html_url": "https://github.com/apache/flink/commit/e70fe71f48e453bb84d808761c01ca27abbd7c48",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/e70fe71f48e453bb84d808761c01ca27abbd7c48/comments",
            "author": {
                "login": "dawidwys",
                "id": 6242259,
                "node_id": "MDQ6VXNlcjYyNDIyNTk=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6242259?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dawidwys",
                "html_url": "https://github.com/dawidwys",
                "followers_url": "https://api.github.com/users/dawidwys/followers",
                "following_url": "https://api.github.com/users/dawidwys/following{/other_user}",
                "gists_url": "https://api.github.com/users/dawidwys/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dawidwys/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dawidwys/subscriptions",
                "organizations_url": "https://api.github.com/users/dawidwys/orgs",
                "repos_url": "https://api.github.com/users/dawidwys/repos",
                "events_url": "https://api.github.com/users/dawidwys/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dawidwys/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "dawidwys",
                "id": 6242259,
                "node_id": "MDQ6VXNlcjYyNDIyNTk=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6242259?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dawidwys",
                "html_url": "https://github.com/dawidwys",
                "followers_url": "https://api.github.com/users/dawidwys/followers",
                "following_url": "https://api.github.com/users/dawidwys/following{/other_user}",
                "gists_url": "https://api.github.com/users/dawidwys/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dawidwys/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dawidwys/subscriptions",
                "organizations_url": "https://api.github.com/users/dawidwys/orgs",
                "repos_url": "https://api.github.com/users/dawidwys/repos",
                "events_url": "https://api.github.com/users/dawidwys/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dawidwys/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "1fffd9d9d7435872f5b10975a9cbf390fd126536",
                "url": "https://api.github.com/repos/apache/flink/commits/1fffd9d9d7435872f5b10975a9cbf390fd126536",
                "html_url": "https://github.com/apache/flink/commit/1fffd9d9d7435872f5b10975a9cbf390fd126536"
            }]
        },
        {
            "sha": "256cf8d634917ce6b71ede67c8f5bdea54768002",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MjU2Y2Y4ZDYzNDkxN2NlNmI3MWVkZTY3YzhmNWJkZWE1NDc2ODAwMg==",
            "commit": {
                "author": {
                    "name": "Dian Fu",
                    "email": "dianfu@apache.org",
                    "date": "2021-05-21T05:51:22Z"
                },
                "committer": {
                    "name": "Dian Fu",
                    "email": "dianfu@apache.org",
                    "date": "2021-05-21T11:07:54Z"
                },
                "message": "[FLINK-22733][python] DataStream.union should handle properly for KeyedStream in Python DataStream API\n\nThis closes #15981.",
                "tree": {
                    "sha": "fb9b23e2594b052dc7f2381af2582ae062595503",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/fb9b23e2594b052dc7f2381af2582ae062595503"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/256cf8d634917ce6b71ede67c8f5bdea54768002",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/256cf8d634917ce6b71ede67c8f5bdea54768002",
            "html_url": "https://github.com/apache/flink/commit/256cf8d634917ce6b71ede67c8f5bdea54768002",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/256cf8d634917ce6b71ede67c8f5bdea54768002/comments",
            "author": {
                "login": "dianfu",
                "id": 5466492,
                "node_id": "MDQ6VXNlcjU0NjY0OTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5466492?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dianfu",
                "html_url": "https://github.com/dianfu",
                "followers_url": "https://api.github.com/users/dianfu/followers",
                "following_url": "https://api.github.com/users/dianfu/following{/other_user}",
                "gists_url": "https://api.github.com/users/dianfu/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dianfu/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dianfu/subscriptions",
                "organizations_url": "https://api.github.com/users/dianfu/orgs",
                "repos_url": "https://api.github.com/users/dianfu/repos",
                "events_url": "https://api.github.com/users/dianfu/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dianfu/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "dianfu",
                "id": 5466492,
                "node_id": "MDQ6VXNlcjU0NjY0OTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5466492?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dianfu",
                "html_url": "https://github.com/dianfu",
                "followers_url": "https://api.github.com/users/dianfu/followers",
                "following_url": "https://api.github.com/users/dianfu/following{/other_user}",
                "gists_url": "https://api.github.com/users/dianfu/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dianfu/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dianfu/subscriptions",
                "organizations_url": "https://api.github.com/users/dianfu/orgs",
                "repos_url": "https://api.github.com/users/dianfu/repos",
                "events_url": "https://api.github.com/users/dianfu/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dianfu/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "e70fe71f48e453bb84d808761c01ca27abbd7c48",
                "url": "https://api.github.com/repos/apache/flink/commits/e70fe71f48e453bb84d808761c01ca27abbd7c48",
                "html_url": "https://github.com/apache/flink/commit/e70fe71f48e453bb84d808761c01ca27abbd7c48"
            }]
        },
        {
            "sha": "1aeb7e3fab771d8ecfbd0efbdc5a60f4dea41b51",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MWFlYjdlM2ZhYjc3MWQ4ZWNmYmQwZWZiZGM1YTYwZjRkZWE0MWI1MQ==",
            "commit": {
                "author": {
                    "name": "Matthias Pohl",
                    "email": "matthias@ververica.com",
                    "date": "2021-05-21T11:57:45Z"
                },
                "committer": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-05-21T11:58:34Z"
                },
                "message": "[FLINK-22688][coordination] Eases assertion on ExceptionHistoryEntry",
                "tree": {
                    "sha": "092d89591dac6a32030302d8cf48796933b8b6ae",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/092d89591dac6a32030302d8cf48796933b8b6ae"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/1aeb7e3fab771d8ecfbd0efbdc5a60f4dea41b51",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/1aeb7e3fab771d8ecfbd0efbdc5a60f4dea41b51",
            "html_url": "https://github.com/apache/flink/commit/1aeb7e3fab771d8ecfbd0efbdc5a60f4dea41b51",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/1aeb7e3fab771d8ecfbd0efbdc5a60f4dea41b51/comments",
            "author": {
                "login": "XComp",
                "id": 1101012,
                "node_id": "MDQ6VXNlcjExMDEwMTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1101012?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/XComp",
                "html_url": "https://github.com/XComp",
                "followers_url": "https://api.github.com/users/XComp/followers",
                "following_url": "https://api.github.com/users/XComp/following{/other_user}",
                "gists_url": "https://api.github.com/users/XComp/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/XComp/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/XComp/subscriptions",
                "organizations_url": "https://api.github.com/users/XComp/orgs",
                "repos_url": "https://api.github.com/users/XComp/repos",
                "events_url": "https://api.github.com/users/XComp/events{/privacy}",
                "received_events_url": "https://api.github.com/users/XComp/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "256cf8d634917ce6b71ede67c8f5bdea54768002",
                "url": "https://api.github.com/repos/apache/flink/commits/256cf8d634917ce6b71ede67c8f5bdea54768002",
                "html_url": "https://github.com/apache/flink/commit/256cf8d634917ce6b71ede67c8f5bdea54768002"
            }]
        },
        {
            "sha": "cfdb34a5caa44d448005c01ca93dde2f020911ae",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6Y2ZkYjM0YTVjYWE0NGQ0NDgwMDVjMDFjYTkzZGRlMmYwMjA5MTFhZQ==",
            "commit": {
                "author": {
                    "name": "Fabian Paul",
                    "email": "fabianpaul@ververica.com",
                    "date": "2021-04-26T12:42:44Z"
                },
                "committer": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-05-21T12:24:44Z"
                },
                "message": "[FLINK-22434] Store suspended execution graphs on termination to keep them accessible\n\nBefore this change as soon as a cluster termination was initiated every\njob was suspended and not accessible anymore until recovery. By storing\nthe execution graph they will appear as SUSPENDED they are now\naccessible until the cluster is fully shutdown.",
                "tree": {
                    "sha": "f3af4e009e4ef902b4698cc0d2004c645465ecb4",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/f3af4e009e4ef902b4698cc0d2004c645465ecb4"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/cfdb34a5caa44d448005c01ca93dde2f020911ae",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEEuUmfpp7/Xe7rw8H1un5Bh8b3PYIFAmCnpowACgkQun5Bh8b3\nPYLpvA/9Ejk/jgVfjL+nU7y8MjNcgmeCbvdVRy4S9G2iJI7vcfSmOo5Sqte2hMPy\nmtWEWGrDDekmRFd0dgGU5USR3x8PZrOuK+r53muRoeY5FCnpUaDuStb8KfnyaY2K\nPJyImbKWdGp2AANHO6YIinMPbmMkIoWs08L5m/wCB+cHTAgYbXdup/YRlijiO5Ph\nzeNvAFCanukIs6uZjS0isIRTbYyhWG0CZU3eyPL/HLQ1PK9kC2wX0ykMzJODU7gG\nbJClCfmvxj2FVvMb+lm+DfpU6ouxnH8qetAQte9tg4MTOphwowp/o0xYX00bp3PP\nAIrUxwit36NRc087kdyadW2zKog3DddaLizpujbliktMXFXj+rVMrwaHjS9bYLyj\nrMbI6pMBthdWMggB6NfIAvrVyvBSUBfMtRoe3cGVuJFx4Cn1wSbsjAg987X9joGf\n2bh72vi0eRvTvTij1qKhP1C+eO/xlMW54UM3SfFn1tqe2F5Hspn5hLejewTORAvN\nHjfD9jgwWMllvX/X+ZpyFSIpun+R9Xkqn4jVZeJu1eAAoqzdbJIHk6SpIqbgU843\nV0GqPc7V/ifIlAfmvwmyaCMZIb9E1byVvWORABav63ZxfpJZe+dwjkAJ+jxuN3vv\nInzBgzLIDVa/Ch1Dss1yn79uiAUkB+GHdpFGd60mu3wmFK+l/vo=\n=x+Sc\n-----END PGP SIGNATURE-----",
                    "payload": "tree f3af4e009e4ef902b4698cc0d2004c645465ecb4\nparent 1aeb7e3fab771d8ecfbd0efbdc5a60f4dea41b51\nauthor Fabian Paul <fabianpaul@ververica.com> 1619440964 +0200\ncommitter Till Rohrmann <trohrmann@apache.org> 1621599884 +0200\n\n[FLINK-22434] Store suspended execution graphs on termination to keep them accessible\n\nBefore this change as soon as a cluster termination was initiated every\njob was suspended and not accessible anymore until recovery. By storing\nthe execution graph they will appear as SUSPENDED they are now\naccessible until the cluster is fully shutdown.\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/cfdb34a5caa44d448005c01ca93dde2f020911ae",
            "html_url": "https://github.com/apache/flink/commit/cfdb34a5caa44d448005c01ca93dde2f020911ae",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/cfdb34a5caa44d448005c01ca93dde2f020911ae/comments",
            "author": {
                "login": "fapaul",
                "id": 7405553,
                "node_id": "MDQ6VXNlcjc0MDU1NTM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/7405553?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/fapaul",
                "html_url": "https://github.com/fapaul",
                "followers_url": "https://api.github.com/users/fapaul/followers",
                "following_url": "https://api.github.com/users/fapaul/following{/other_user}",
                "gists_url": "https://api.github.com/users/fapaul/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/fapaul/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/fapaul/subscriptions",
                "organizations_url": "https://api.github.com/users/fapaul/orgs",
                "repos_url": "https://api.github.com/users/fapaul/repos",
                "events_url": "https://api.github.com/users/fapaul/events{/privacy}",
                "received_events_url": "https://api.github.com/users/fapaul/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "1aeb7e3fab771d8ecfbd0efbdc5a60f4dea41b51",
                "url": "https://api.github.com/repos/apache/flink/commits/1aeb7e3fab771d8ecfbd0efbdc5a60f4dea41b51",
                "html_url": "https://github.com/apache/flink/commit/1aeb7e3fab771d8ecfbd0efbdc5a60f4dea41b51"
            }]
        },
        {
            "sha": "cd449e0378e41197ff1ee1f0784cefa3efdb579b",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6Y2Q0NDllMDM3OGU0MTE5N2ZmMWVlMWYwNzg0Y2VmYTNlZmRiNTc5Yg==",
            "commit": {
                "author": {
                    "name": "Fabian Paul",
                    "email": "fabianpaul@ververica.com",
                    "date": "2021-05-12T11:50:22Z"
                },
                "committer": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-05-21T12:24:46Z"
                },
                "message": "[FLINK-22434] Retry in clusterclient if job state is unknown\n\nSince the dispatcher now exposed the SUSPENDED job state it\nneeds to be handled in the ClusterClient. We decided to not\nexpose this state because it would be an unexpected change\nfor users relying on the old behavior.\nIn summary, the RestClusterClient will retry to receive a\ndifferent state for jobs in SUSPENDED state.\n\nThis closes #15964.",
                "tree": {
                    "sha": "339b4652bdc68ad574ce9ee739e5852b64690dad",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/339b4652bdc68ad574ce9ee739e5852b64690dad"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/cd449e0378e41197ff1ee1f0784cefa3efdb579b",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEEuUmfpp7/Xe7rw8H1un5Bh8b3PYIFAmCnppUACgkQun5Bh8b3\nPYLlKg//THY8X1i0DLrRcVo2zXCec+hwlq1Bwh0Zn6+3KeZsTC39RFz5c+qWg/tL\noxENiB7XB94u+5pDOf+r+0yVpZppSx72TxB9xVUntex4OYhlhGEkp4Voch+cUi9o\nwAV9QtH9U96uoilR/zQClVZZ0PBZzOz7HpbAkJbkpsV34uDGo9qJcU3pT2AqmSg7\nOviYosMx+HAb60XvVaoDhjFdJ0HnJReFDFAXyO9ZpB61HadoTYZ2V0m+Uzus/xx9\nuoThRkWzKAxXsAa3RWYFqec/e7UDwG87g5mQVygEjeYSnjVp2k8/ndq8McPRFJBJ\nzV+2lzLtM+IiKzeOv8ER+1J78BjpjTyAY0Vc2nsnxPEef3Wqf4zbOAehA+tqSKef\nDNMd1PiklSDGuWAuxwPVW37glnQ97OuAjBR6+VN5hCAVM/ngxM5AKqScBzq3ovEQ\ncpMOldAdxT5jcSoaEpuNj6q64uN8q5cOfXwEhbajC0qvzNOwBQrIghCjD2clxbBY\ngXQ2P4C7Rq4nrsthEkXtgOKzDX4WJC7+Spld2Frsow2/PPp4ISdvCVAnoLP3nV/A\notDm9mJ5KbkGXkqWud+t4eMQ+SDgKPvypTFQIjcDgtXNGamRLCPHB6O9uTnTR1cW\nTygDYiW82dxnHTAypnchB3D0UHXZ044KTBUR4VjRttf91LNLMmM=\n=zgHq\n-----END PGP SIGNATURE-----",
                    "payload": "tree 339b4652bdc68ad574ce9ee739e5852b64690dad\nparent cfdb34a5caa44d448005c01ca93dde2f020911ae\nauthor Fabian Paul <fabianpaul@ververica.com> 1620820222 +0200\ncommitter Till Rohrmann <trohrmann@apache.org> 1621599886 +0200\n\n[FLINK-22434] Retry in clusterclient if job state is unknown\n\nSince the dispatcher now exposed the SUSPENDED job state it\nneeds to be handled in the ClusterClient. We decided to not\nexpose this state because it would be an unexpected change\nfor users relying on the old behavior.\nIn summary, the RestClusterClient will retry to receive a\ndifferent state for jobs in SUSPENDED state.\n\nThis closes #15964.\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/cd449e0378e41197ff1ee1f0784cefa3efdb579b",
            "html_url": "https://github.com/apache/flink/commit/cd449e0378e41197ff1ee1f0784cefa3efdb579b",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/cd449e0378e41197ff1ee1f0784cefa3efdb579b/comments",
            "author": {
                "login": "fapaul",
                "id": 7405553,
                "node_id": "MDQ6VXNlcjc0MDU1NTM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/7405553?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/fapaul",
                "html_url": "https://github.com/fapaul",
                "followers_url": "https://api.github.com/users/fapaul/followers",
                "following_url": "https://api.github.com/users/fapaul/following{/other_user}",
                "gists_url": "https://api.github.com/users/fapaul/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/fapaul/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/fapaul/subscriptions",
                "organizations_url": "https://api.github.com/users/fapaul/orgs",
                "repos_url": "https://api.github.com/users/fapaul/repos",
                "events_url": "https://api.github.com/users/fapaul/events{/privacy}",
                "received_events_url": "https://api.github.com/users/fapaul/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "cfdb34a5caa44d448005c01ca93dde2f020911ae",
                "url": "https://api.github.com/repos/apache/flink/commits/cfdb34a5caa44d448005c01ca93dde2f020911ae",
                "html_url": "https://github.com/apache/flink/commit/cfdb34a5caa44d448005c01ca93dde2f020911ae"
            }]
        },
        {
            "sha": "2245a016ddfeab8d268058267419b951d3663302",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MjI0NWEwMTZkZGZlYWI4ZDI2ODA1ODI2NzQxOWI5NTFkMzY2MzMwMg==",
            "commit": {
                "author": {
                    "name": "Dian Fu",
                    "email": "dianfu@apache.org",
                    "date": "2021-05-24T04:07:44Z"
                },
                "committer": {
                    "name": "Dian Fu",
                    "email": "dianfu@apache.org",
                    "date": "2021-05-24T04:08:33Z"
                },
                "message": "[hotfix][python][docs] Add documentation about how to set config options in Python DataStream API program",
                "tree": {
                    "sha": "e105d37cf39b2387aa6fb7273aaa0fcbad22ac28",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/e105d37cf39b2387aa6fb7273aaa0fcbad22ac28"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/2245a016ddfeab8d268058267419b951d3663302",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/2245a016ddfeab8d268058267419b951d3663302",
            "html_url": "https://github.com/apache/flink/commit/2245a016ddfeab8d268058267419b951d3663302",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/2245a016ddfeab8d268058267419b951d3663302/comments",
            "author": {
                "login": "dianfu",
                "id": 5466492,
                "node_id": "MDQ6VXNlcjU0NjY0OTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5466492?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dianfu",
                "html_url": "https://github.com/dianfu",
                "followers_url": "https://api.github.com/users/dianfu/followers",
                "following_url": "https://api.github.com/users/dianfu/following{/other_user}",
                "gists_url": "https://api.github.com/users/dianfu/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dianfu/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dianfu/subscriptions",
                "organizations_url": "https://api.github.com/users/dianfu/orgs",
                "repos_url": "https://api.github.com/users/dianfu/repos",
                "events_url": "https://api.github.com/users/dianfu/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dianfu/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "dianfu",
                "id": 5466492,
                "node_id": "MDQ6VXNlcjU0NjY0OTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5466492?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dianfu",
                "html_url": "https://github.com/dianfu",
                "followers_url": "https://api.github.com/users/dianfu/followers",
                "following_url": "https://api.github.com/users/dianfu/following{/other_user}",
                "gists_url": "https://api.github.com/users/dianfu/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dianfu/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dianfu/subscriptions",
                "organizations_url": "https://api.github.com/users/dianfu/orgs",
                "repos_url": "https://api.github.com/users/dianfu/repos",
                "events_url": "https://api.github.com/users/dianfu/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dianfu/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "cd449e0378e41197ff1ee1f0784cefa3efdb579b",
                "url": "https://api.github.com/repos/apache/flink/commits/cd449e0378e41197ff1ee1f0784cefa3efdb579b",
                "html_url": "https://github.com/apache/flink/commit/cd449e0378e41197ff1ee1f0784cefa3efdb579b"
            }]
        },
        {
            "sha": "31ee0cb0c4425c4101fe398325d86a0251c49971",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MzFlZTBjYjBjNDQyNWM0MTAxZmUzOTgzMjVkODZhMDI1MWM0OTk3MQ==",
            "commit": {
                "author": {
                    "name": "Rainie Li",
                    "email": "rainieli@pinterest.com",
                    "date": "2021-05-24T08:11:23Z"
                },
                "committer": {
                    "name": "Yun Tang",
                    "email": "tangyun@apache.org",
                    "date": "2021-05-24T08:12:15Z"
                },
                "message": "[FLINK-22659][docs] Add execution.checkpointing.interval to docs of checkpoint configuration\n\nThis closes #15979.",
                "tree": {
                    "sha": "d29c977dffdacd0d93a053e234739181a84a8d8f",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/d29c977dffdacd0d93a053e234739181a84a8d8f"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/31ee0cb0c4425c4101fe398325d86a0251c49971",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/31ee0cb0c4425c4101fe398325d86a0251c49971",
            "html_url": "https://github.com/apache/flink/commit/31ee0cb0c4425c4101fe398325d86a0251c49971",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/31ee0cb0c4425c4101fe398325d86a0251c49971/comments",
            "author": {
                "login": "lixmgl",
                "id": 7441350,
                "node_id": "MDQ6VXNlcjc0NDEzNTA=",
                "avatar_url": "https://avatars.githubusercontent.com/u/7441350?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/lixmgl",
                "html_url": "https://github.com/lixmgl",
                "followers_url": "https://api.github.com/users/lixmgl/followers",
                "following_url": "https://api.github.com/users/lixmgl/following{/other_user}",
                "gists_url": "https://api.github.com/users/lixmgl/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/lixmgl/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/lixmgl/subscriptions",
                "organizations_url": "https://api.github.com/users/lixmgl/orgs",
                "repos_url": "https://api.github.com/users/lixmgl/repos",
                "events_url": "https://api.github.com/users/lixmgl/events{/privacy}",
                "received_events_url": "https://api.github.com/users/lixmgl/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "Myasuka",
                "id": 1709104,
                "node_id": "MDQ6VXNlcjE3MDkxMDQ=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1709104?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/Myasuka",
                "html_url": "https://github.com/Myasuka",
                "followers_url": "https://api.github.com/users/Myasuka/followers",
                "following_url": "https://api.github.com/users/Myasuka/following{/other_user}",
                "gists_url": "https://api.github.com/users/Myasuka/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/Myasuka/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/Myasuka/subscriptions",
                "organizations_url": "https://api.github.com/users/Myasuka/orgs",
                "repos_url": "https://api.github.com/users/Myasuka/repos",
                "events_url": "https://api.github.com/users/Myasuka/events{/privacy}",
                "received_events_url": "https://api.github.com/users/Myasuka/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "2245a016ddfeab8d268058267419b951d3663302",
                "url": "https://api.github.com/repos/apache/flink/commits/2245a016ddfeab8d268058267419b951d3663302",
                "html_url": "https://github.com/apache/flink/commit/2245a016ddfeab8d268058267419b951d3663302"
            }]
        },
        {
            "sha": "c03197f0b43f822bb8c0064b41cc550116cd1e39",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6YzAzMTk3ZjBiNDNmODIyYmI4YzAwNjRiNDFjYzU1MDExNmNkMWUzOQ==",
            "commit": {
                "author": {
                    "name": "Timo Walther",
                    "email": "twalthr@apache.org",
                    "date": "2021-05-21T12:55:39Z"
                },
                "committer": {
                    "name": "Timo Walther",
                    "email": "twalthr@apache.org",
                    "date": "2021-05-25T16:43:06Z"
                },
                "message": "[FLINK-22747] Upgrade to commons-io 2.8.0\n\nThis closes #15989.",
                "tree": {
                    "sha": "39ead71c328177e6de71bb18ac03af6450d7b7af",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/39ead71c328177e6de71bb18ac03af6450d7b7af"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/c03197f0b43f822bb8c0064b41cc550116cd1e39",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/c03197f0b43f822bb8c0064b41cc550116cd1e39",
            "html_url": "https://github.com/apache/flink/commit/c03197f0b43f822bb8c0064b41cc550116cd1e39",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/c03197f0b43f822bb8c0064b41cc550116cd1e39/comments",
            "author": {
                "login": "twalthr",
                "id": 5746567,
                "node_id": "MDQ6VXNlcjU3NDY1Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5746567?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/twalthr",
                "html_url": "https://github.com/twalthr",
                "followers_url": "https://api.github.com/users/twalthr/followers",
                "following_url": "https://api.github.com/users/twalthr/following{/other_user}",
                "gists_url": "https://api.github.com/users/twalthr/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/twalthr/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/twalthr/subscriptions",
                "organizations_url": "https://api.github.com/users/twalthr/orgs",
                "repos_url": "https://api.github.com/users/twalthr/repos",
                "events_url": "https://api.github.com/users/twalthr/events{/privacy}",
                "received_events_url": "https://api.github.com/users/twalthr/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "twalthr",
                "id": 5746567,
                "node_id": "MDQ6VXNlcjU3NDY1Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5746567?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/twalthr",
                "html_url": "https://github.com/twalthr",
                "followers_url": "https://api.github.com/users/twalthr/followers",
                "following_url": "https://api.github.com/users/twalthr/following{/other_user}",
                "gists_url": "https://api.github.com/users/twalthr/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/twalthr/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/twalthr/subscriptions",
                "organizations_url": "https://api.github.com/users/twalthr/orgs",
                "repos_url": "https://api.github.com/users/twalthr/repos",
                "events_url": "https://api.github.com/users/twalthr/events{/privacy}",
                "received_events_url": "https://api.github.com/users/twalthr/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "31ee0cb0c4425c4101fe398325d86a0251c49971",
                "url": "https://api.github.com/repos/apache/flink/commits/31ee0cb0c4425c4101fe398325d86a0251c49971",
                "html_url": "https://github.com/apache/flink/commit/31ee0cb0c4425c4101fe398325d86a0251c49971"
            }]
        },
        {
            "sha": "5363432300e4c102a73ac1365fee198d21289790",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NTM2MzQzMjMwMGU0YzEwMmE3M2FjMTM2NWZlZTE5OGQyMTI4OTc5MA==",
            "commit": {
                "author": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-05-25T20:26:26Z"
                },
                "committer": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-05-25T20:34:05Z"
                },
                "message": "[FLINK-22725][coordination] SlotManagers unregister metrics in suspend()",
                "tree": {
                    "sha": "b0863aed846beb95fd0c7174751a4a2792953c07",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/b0863aed846beb95fd0c7174751a4a2792953c07"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/5363432300e4c102a73ac1365fee198d21289790",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/5363432300e4c102a73ac1365fee198d21289790",
            "html_url": "https://github.com/apache/flink/commit/5363432300e4c102a73ac1365fee198d21289790",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/5363432300e4c102a73ac1365fee198d21289790/comments",
            "author": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "c03197f0b43f822bb8c0064b41cc550116cd1e39",
                "url": "https://api.github.com/repos/apache/flink/commits/c03197f0b43f822bb8c0064b41cc550116cd1e39",
                "html_url": "https://github.com/apache/flink/commit/c03197f0b43f822bb8c0064b41cc550116cd1e39"
            }]
        },
        {
            "sha": "fae3e70532056465be3a2376a47ba20b5f80b13b",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZmFlM2U3MDUzMjA1NjQ2NWJlM2EyMzc2YTQ3YmEyMGI1ZjgwYjEzYg==",
            "commit": {
                "author": {
                    "name": "Jark Wu",
                    "email": "jark@apache.org",
                    "date": "2021-05-21T04:27:44Z"
                },
                "committer": {
                    "name": "Jark Wu",
                    "email": "jark@apache.org",
                    "date": "2021-05-26T04:14:20Z"
                },
                "message": "[FLINK-22203][table-runtime-blink] Fix ConcurrentModificationException for testing values sink functions (#15978)",
                "tree": {
                    "sha": "b3a5a50dea14abc51eba1789c7fbcc13de2ba6ec",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/b3a5a50dea14abc51eba1789c7fbcc13de2ba6ec"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/fae3e70532056465be3a2376a47ba20b5f80b13b",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEE4sRUF77VwQQVTzQQhbrLWu+uMgIFAmCtyxwACgkQhbrLWu+u\nMgKyMQ/+OayymDdZEiuO37Rz0f6gIunajjzX0hmHBvxro1KPotJVlaKtqcgWRaTQ\nKtUQspKm5r0Me1e2RqIbz7DUi9imnpTfa8mc09JHThHG/OCADKees9Hn1u3YPCSs\nz2s+v5O4KmGgLmncDChyRfEFBIZqVP7TmrVWt3lALdfAWWZ6uxxcYkXT3GeU7zV6\nK+oe+dewYIlLD5Zg0iW958jjh4dTu0JxbvoiSsVUqT0x37L0rO2z/S3anklOXDxm\njML/4HrC/IEdI51+HMl8+uo6piVx4CGeiwK5FBnVOe5Mvfs1rbPYwpDMLZRiFuum\n+OS5kldQXkUhYF4/TvCCwBxmxM4JTaSMZP2hPWXlj1mOjilJ9+XPcwu/XLdfJ63i\nbgBLCjfmsNhu6EerT2KJaVxDoSS2LnkqYfOLEQNoiaj0FO/FUANabwXz9uXYY1dN\nMBy0Ra+vXQ9rSYfMJLLNrNmwl4EhnhOsVorJFM8pMxlpbsQLGDGTZtfHuNxngGDk\nl7M2OuZQ+dRQ/nPl68Lh1ffy/HAprxzjR4CgsO9otPJEk2jU82lc3ExS+/gDmd8G\nniChwE15+siyX8svtIATSgE6Aa8/uldVqBTQGIo/RLGSIFEj1O5vJPHTX/0XDvV6\nlDQcPCphUujvcG8n3FG/o9Y9SE4JhcUZkheH+zxX6Mr6HxWXprs=\n=yu9H\n-----END PGP SIGNATURE-----",
                    "payload": "tree b3a5a50dea14abc51eba1789c7fbcc13de2ba6ec\nparent 5363432300e4c102a73ac1365fee198d21289790\nauthor Jark Wu <jark@apache.org> 1621571264 +0800\ncommitter Jark Wu <jark@apache.org> 1622002460 +0800\n\n[FLINK-22203][table-runtime-blink] Fix ConcurrentModificationException for testing values sink functions (#15978)\n\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/fae3e70532056465be3a2376a47ba20b5f80b13b",
            "html_url": "https://github.com/apache/flink/commit/fae3e70532056465be3a2376a47ba20b5f80b13b",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/fae3e70532056465be3a2376a47ba20b5f80b13b/comments",
            "author": {
                "login": "wuchong",
                "id": 5378924,
                "node_id": "MDQ6VXNlcjUzNzg5MjQ=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5378924?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/wuchong",
                "html_url": "https://github.com/wuchong",
                "followers_url": "https://api.github.com/users/wuchong/followers",
                "following_url": "https://api.github.com/users/wuchong/following{/other_user}",
                "gists_url": "https://api.github.com/users/wuchong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/wuchong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/wuchong/subscriptions",
                "organizations_url": "https://api.github.com/users/wuchong/orgs",
                "repos_url": "https://api.github.com/users/wuchong/repos",
                "events_url": "https://api.github.com/users/wuchong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/wuchong/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "wuchong",
                "id": 5378924,
                "node_id": "MDQ6VXNlcjUzNzg5MjQ=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5378924?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/wuchong",
                "html_url": "https://github.com/wuchong",
                "followers_url": "https://api.github.com/users/wuchong/followers",
                "following_url": "https://api.github.com/users/wuchong/following{/other_user}",
                "gists_url": "https://api.github.com/users/wuchong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/wuchong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/wuchong/subscriptions",
                "organizations_url": "https://api.github.com/users/wuchong/orgs",
                "repos_url": "https://api.github.com/users/wuchong/repos",
                "events_url": "https://api.github.com/users/wuchong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/wuchong/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "5363432300e4c102a73ac1365fee198d21289790",
                "url": "https://api.github.com/repos/apache/flink/commits/5363432300e4c102a73ac1365fee198d21289790",
                "html_url": "https://github.com/apache/flink/commit/5363432300e4c102a73ac1365fee198d21289790"
            }]
        },
        {
            "sha": "b18ec48695ad73c8e7565b513be94e259ee91baa",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6YjE4ZWM0ODY5NWFkNzNjOGU3NTY1YjUxM2JlOTRlMjU5ZWU5MWJhYQ==",
            "commit": {
                "author": {
                    "name": "Arvid Heise",
                    "email": "arvid@ververica.com",
                    "date": "2021-05-25T16:21:49Z"
                },
                "committer": {
                    "name": "Arvid Heise",
                    "email": "AHeise@users.noreply.github.com",
                    "date": "2021-05-26T14:50:08Z"
                },
                "message": "[FLINK-22613][tests] Fix FlinkKinesisITCase.testStopWithSavepoint.\n\nThe test relies on a few elements remaining pending after stop-with-savepoint, however that can only be guaranteed heuristically: We cannot block task thread or else the respective savepoint will not succeed but we also cannot add infinite input as it's an IT test against Kinesis. Here, the fix is to add much more elements to Kinesis stream. An optimized sendMessage on the test client ensures timely setup.",
                "tree": {
                    "sha": "c6d3364a4baa9eca868e048719e1601e57e032bf",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/c6d3364a4baa9eca868e048719e1601e57e032bf"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/b18ec48695ad73c8e7565b513be94e259ee91baa",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/b18ec48695ad73c8e7565b513be94e259ee91baa",
            "html_url": "https://github.com/apache/flink/commit/b18ec48695ad73c8e7565b513be94e259ee91baa",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/b18ec48695ad73c8e7565b513be94e259ee91baa/comments",
            "author": {
                "login": "AHeise",
                "id": 4559103,
                "node_id": "MDQ6VXNlcjQ1NTkxMDM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/4559103?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/AHeise",
                "html_url": "https://github.com/AHeise",
                "followers_url": "https://api.github.com/users/AHeise/followers",
                "following_url": "https://api.github.com/users/AHeise/following{/other_user}",
                "gists_url": "https://api.github.com/users/AHeise/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/AHeise/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/AHeise/subscriptions",
                "organizations_url": "https://api.github.com/users/AHeise/orgs",
                "repos_url": "https://api.github.com/users/AHeise/repos",
                "events_url": "https://api.github.com/users/AHeise/events{/privacy}",
                "received_events_url": "https://api.github.com/users/AHeise/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "AHeise",
                "id": 4559103,
                "node_id": "MDQ6VXNlcjQ1NTkxMDM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/4559103?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/AHeise",
                "html_url": "https://github.com/AHeise",
                "followers_url": "https://api.github.com/users/AHeise/followers",
                "following_url": "https://api.github.com/users/AHeise/following{/other_user}",
                "gists_url": "https://api.github.com/users/AHeise/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/AHeise/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/AHeise/subscriptions",
                "organizations_url": "https://api.github.com/users/AHeise/orgs",
                "repos_url": "https://api.github.com/users/AHeise/repos",
                "events_url": "https://api.github.com/users/AHeise/events{/privacy}",
                "received_events_url": "https://api.github.com/users/AHeise/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "fae3e70532056465be3a2376a47ba20b5f80b13b",
                "url": "https://api.github.com/repos/apache/flink/commits/fae3e70532056465be3a2376a47ba20b5f80b13b",
                "html_url": "https://github.com/apache/flink/commit/fae3e70532056465be3a2376a47ba20b5f80b13b"
            }]
        },
        {
            "sha": "7d97a004e698779d8799e0dc0b48e0faec538285",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6N2Q5N2EwMDRlNjk4Nzc5ZDg3OTllMGRjMGI0OGUwZmFlYzUzODI4NQ==",
            "commit": {
                "author": {
                    "name": "Stefan Gloutnikov",
                    "email": "stefan@gloutnikov.com",
                    "date": "2021-05-26T02:47:55Z"
                },
                "committer": {
                    "name": "Seth Wiesman",
                    "email": "sjwiesman@gmail.com",
                    "date": "2021-05-26T16:40:59Z"
                },
                "message": "[FLINK-22777][docs] Restored full Datastream API fraud detection example in Try Flink section\n\nThis closes #16003",
                "tree": {
                    "sha": "c921d3df1f9e0849e12d01403cec6d6a7b0fbbaa",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/c921d3df1f9e0849e12d01403cec6d6a7b0fbbaa"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/7d97a004e698779d8799e0dc0b48e0faec538285",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/7d97a004e698779d8799e0dc0b48e0faec538285",
            "html_url": "https://github.com/apache/flink/commit/7d97a004e698779d8799e0dc0b48e0faec538285",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/7d97a004e698779d8799e0dc0b48e0faec538285/comments",
            "author": {
                "login": "sgloutnikov",
                "id": 2321958,
                "node_id": "MDQ6VXNlcjIzMjE5NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/2321958?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/sgloutnikov",
                "html_url": "https://github.com/sgloutnikov",
                "followers_url": "https://api.github.com/users/sgloutnikov/followers",
                "following_url": "https://api.github.com/users/sgloutnikov/following{/other_user}",
                "gists_url": "https://api.github.com/users/sgloutnikov/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/sgloutnikov/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/sgloutnikov/subscriptions",
                "organizations_url": "https://api.github.com/users/sgloutnikov/orgs",
                "repos_url": "https://api.github.com/users/sgloutnikov/repos",
                "events_url": "https://api.github.com/users/sgloutnikov/events{/privacy}",
                "received_events_url": "https://api.github.com/users/sgloutnikov/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "sjwiesman",
                "id": 1891970,
                "node_id": "MDQ6VXNlcjE4OTE5NzA=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1891970?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/sjwiesman",
                "html_url": "https://github.com/sjwiesman",
                "followers_url": "https://api.github.com/users/sjwiesman/followers",
                "following_url": "https://api.github.com/users/sjwiesman/following{/other_user}",
                "gists_url": "https://api.github.com/users/sjwiesman/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/sjwiesman/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/sjwiesman/subscriptions",
                "organizations_url": "https://api.github.com/users/sjwiesman/orgs",
                "repos_url": "https://api.github.com/users/sjwiesman/repos",
                "events_url": "https://api.github.com/users/sjwiesman/events{/privacy}",
                "received_events_url": "https://api.github.com/users/sjwiesman/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "b18ec48695ad73c8e7565b513be94e259ee91baa",
                "url": "https://api.github.com/repos/apache/flink/commits/b18ec48695ad73c8e7565b513be94e259ee91baa",
                "html_url": "https://github.com/apache/flink/commit/b18ec48695ad73c8e7565b513be94e259ee91baa"
            }]
        },
        {
            "sha": "878dfe961528d2093990d02dd6e2c291c7012f90",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ODc4ZGZlOTYxNTI4ZDIwOTM5OTBkMDJkZDZlMmMyOTFjNzAxMmY5MA==",
            "commit": {
                "author": {
                    "name": "Timo Walther",
                    "email": "twalthr@apache.org",
                    "date": "2021-05-25T13:00:51Z"
                },
                "committer": {
                    "name": "Timo Walther",
                    "email": "twalthr@apache.org",
                    "date": "2021-05-26T20:29:52Z"
                },
                "message": "[FLINK-22774][sql-connector-kinesis] Update Kinesis SQL connector's Guava to 27.0-jre\n\nAvoids that security tools complain about an outdated Guava version in the Kinesis\nSQL connector.\n\nThis closes #16005.",
                "tree": {
                    "sha": "bee0efa005eff6dd0e317fe04578d14969a9bcf6",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/bee0efa005eff6dd0e317fe04578d14969a9bcf6"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/878dfe961528d2093990d02dd6e2c291c7012f90",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/878dfe961528d2093990d02dd6e2c291c7012f90",
            "html_url": "https://github.com/apache/flink/commit/878dfe961528d2093990d02dd6e2c291c7012f90",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/878dfe961528d2093990d02dd6e2c291c7012f90/comments",
            "author": {
                "login": "twalthr",
                "id": 5746567,
                "node_id": "MDQ6VXNlcjU3NDY1Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5746567?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/twalthr",
                "html_url": "https://github.com/twalthr",
                "followers_url": "https://api.github.com/users/twalthr/followers",
                "following_url": "https://api.github.com/users/twalthr/following{/other_user}",
                "gists_url": "https://api.github.com/users/twalthr/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/twalthr/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/twalthr/subscriptions",
                "organizations_url": "https://api.github.com/users/twalthr/orgs",
                "repos_url": "https://api.github.com/users/twalthr/repos",
                "events_url": "https://api.github.com/users/twalthr/events{/privacy}",
                "received_events_url": "https://api.github.com/users/twalthr/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "twalthr",
                "id": 5746567,
                "node_id": "MDQ6VXNlcjU3NDY1Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5746567?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/twalthr",
                "html_url": "https://github.com/twalthr",
                "followers_url": "https://api.github.com/users/twalthr/followers",
                "following_url": "https://api.github.com/users/twalthr/following{/other_user}",
                "gists_url": "https://api.github.com/users/twalthr/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/twalthr/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/twalthr/subscriptions",
                "organizations_url": "https://api.github.com/users/twalthr/orgs",
                "repos_url": "https://api.github.com/users/twalthr/repos",
                "events_url": "https://api.github.com/users/twalthr/events{/privacy}",
                "received_events_url": "https://api.github.com/users/twalthr/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "7d97a004e698779d8799e0dc0b48e0faec538285",
                "url": "https://api.github.com/repos/apache/flink/commits/7d97a004e698779d8799e0dc0b48e0faec538285",
                "html_url": "https://github.com/apache/flink/commit/7d97a004e698779d8799e0dc0b48e0faec538285"
            }]
        },
        {
            "sha": "520aa94fbb887437ca8750a19475a942dd554763",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NTIwYWE5NGZiYjg4NzQzN2NhODc1MGExOTQ3NWE5NDJkZDU1NDc2Mw==",
            "commit": {
                "author": {
                    "name": "Authuir",
                    "email": "authuir@authuir.com",
                    "date": "2021-05-22T18:21:41Z"
                },
                "committer": {
                    "name": "Seth Wiesman",
                    "email": "sjwiesman@gmail.com",
                    "date": "2021-05-27T14:27:51Z"
                },
                "message": "[FLINK-22746][docs] Links to connectors in docs are broken\n\nThis closes #15990",
                "tree": {
                    "sha": "b159b452923054fbb9fee82fae5551cb0ded3930",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/b159b452923054fbb9fee82fae5551cb0ded3930"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/520aa94fbb887437ca8750a19475a942dd554763",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/520aa94fbb887437ca8750a19475a942dd554763",
            "html_url": "https://github.com/apache/flink/commit/520aa94fbb887437ca8750a19475a942dd554763",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/520aa94fbb887437ca8750a19475a942dd554763/comments",
            "author": {
                "login": "authuir",
                "id": 9346867,
                "node_id": "MDQ6VXNlcjkzNDY4Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/9346867?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/authuir",
                "html_url": "https://github.com/authuir",
                "followers_url": "https://api.github.com/users/authuir/followers",
                "following_url": "https://api.github.com/users/authuir/following{/other_user}",
                "gists_url": "https://api.github.com/users/authuir/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/authuir/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/authuir/subscriptions",
                "organizations_url": "https://api.github.com/users/authuir/orgs",
                "repos_url": "https://api.github.com/users/authuir/repos",
                "events_url": "https://api.github.com/users/authuir/events{/privacy}",
                "received_events_url": "https://api.github.com/users/authuir/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "sjwiesman",
                "id": 1891970,
                "node_id": "MDQ6VXNlcjE4OTE5NzA=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1891970?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/sjwiesman",
                "html_url": "https://github.com/sjwiesman",
                "followers_url": "https://api.github.com/users/sjwiesman/followers",
                "following_url": "https://api.github.com/users/sjwiesman/following{/other_user}",
                "gists_url": "https://api.github.com/users/sjwiesman/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/sjwiesman/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/sjwiesman/subscriptions",
                "organizations_url": "https://api.github.com/users/sjwiesman/orgs",
                "repos_url": "https://api.github.com/users/sjwiesman/repos",
                "events_url": "https://api.github.com/users/sjwiesman/events{/privacy}",
                "received_events_url": "https://api.github.com/users/sjwiesman/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "878dfe961528d2093990d02dd6e2c291c7012f90",
                "url": "https://api.github.com/repos/apache/flink/commits/878dfe961528d2093990d02dd6e2c291c7012f90",
                "html_url": "https://github.com/apache/flink/commit/878dfe961528d2093990d02dd6e2c291c7012f90"
            }]
        },
        {
            "sha": "5a873bc4c61ce17ef991e2202d1f1bf665f67edf",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NWE4NzNiYzRjNjFjZTE3ZWY5OTFlMjIwMmQxZjFiZjY2NWY2N2VkZg==",
            "commit": {
                "author": {
                    "name": "WilliamSong11",
                    "email": "1063877656@qq.com",
                    "date": "2021-05-27T13:38:58Z"
                },
                "committer": {
                    "name": "Dian Fu",
                    "email": "dianfu@apache.org",
                    "date": "2021-05-28T03:38:32Z"
                },
                "message": "[FLINK-20140][python][docs] Add documentation for TableResult.collect for Python Table API.\n\nThis closes #16014.",
                "tree": {
                    "sha": "199dfb6d2134a3e64754b37fc34516cecbcb1f28",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/199dfb6d2134a3e64754b37fc34516cecbcb1f28"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/5a873bc4c61ce17ef991e2202d1f1bf665f67edf",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/5a873bc4c61ce17ef991e2202d1f1bf665f67edf",
            "html_url": "https://github.com/apache/flink/commit/5a873bc4c61ce17ef991e2202d1f1bf665f67edf",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/5a873bc4c61ce17ef991e2202d1f1bf665f67edf/comments",
            "author": {
                "login": "WilliamSong112",
                "id": 13831999,
                "node_id": "MDQ6VXNlcjEzODMxOTk5",
                "avatar_url": "https://avatars.githubusercontent.com/u/13831999?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/WilliamSong112",
                "html_url": "https://github.com/WilliamSong112",
                "followers_url": "https://api.github.com/users/WilliamSong112/followers",
                "following_url": "https://api.github.com/users/WilliamSong112/following{/other_user}",
                "gists_url": "https://api.github.com/users/WilliamSong112/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/WilliamSong112/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/WilliamSong112/subscriptions",
                "organizations_url": "https://api.github.com/users/WilliamSong112/orgs",
                "repos_url": "https://api.github.com/users/WilliamSong112/repos",
                "events_url": "https://api.github.com/users/WilliamSong112/events{/privacy}",
                "received_events_url": "https://api.github.com/users/WilliamSong112/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "dianfu",
                "id": 5466492,
                "node_id": "MDQ6VXNlcjU0NjY0OTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5466492?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dianfu",
                "html_url": "https://github.com/dianfu",
                "followers_url": "https://api.github.com/users/dianfu/followers",
                "following_url": "https://api.github.com/users/dianfu/following{/other_user}",
                "gists_url": "https://api.github.com/users/dianfu/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dianfu/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dianfu/subscriptions",
                "organizations_url": "https://api.github.com/users/dianfu/orgs",
                "repos_url": "https://api.github.com/users/dianfu/repos",
                "events_url": "https://api.github.com/users/dianfu/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dianfu/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "520aa94fbb887437ca8750a19475a942dd554763",
                "url": "https://api.github.com/repos/apache/flink/commits/520aa94fbb887437ca8750a19475a942dd554763",
                "html_url": "https://github.com/apache/flink/commit/520aa94fbb887437ca8750a19475a942dd554763"
            }]
        },
        {
            "sha": "a873ef925a3807292a7463cf66be0abad11a52db",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6YTg3M2VmOTI1YTM4MDcyOTJhNzQ2M2NmNjZiZTBhYmFkMTFhNTJkYg==",
            "commit": {
                "author": {
                    "name": "莫辞",
                    "email": "luoyuxia.luoyuxia@alibaba-inc.com",
                    "date": "2021-05-25T07:38:15Z"
                },
                "committer": {
                    "name": "Rui Li",
                    "email": "lirui@apache.org",
                    "date": "2021-05-28T04:41:19Z"
                },
                "message": "[FLINK-22760][Connectors/Hive] Fix issue of HiveParser::setCurrentTimestamp fails with hive-3.1.2\n\nThis closes #15995",
                "tree": {
                    "sha": "c65207aacf0d3a36fa61d1ff7d6372b146bd7ede",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/c65207aacf0d3a36fa61d1ff7d6372b146bd7ede"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/a873ef925a3807292a7463cf66be0abad11a52db",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/a873ef925a3807292a7463cf66be0abad11a52db",
            "html_url": "https://github.com/apache/flink/commit/a873ef925a3807292a7463cf66be0abad11a52db",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/a873ef925a3807292a7463cf66be0abad11a52db/comments",
            "author": {
                "login": "luoyuxia",
                "id": 20389154,
                "node_id": "MDQ6VXNlcjIwMzg5MTU0",
                "avatar_url": "https://avatars.githubusercontent.com/u/20389154?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/luoyuxia",
                "html_url": "https://github.com/luoyuxia",
                "followers_url": "https://api.github.com/users/luoyuxia/followers",
                "following_url": "https://api.github.com/users/luoyuxia/following{/other_user}",
                "gists_url": "https://api.github.com/users/luoyuxia/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/luoyuxia/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/luoyuxia/subscriptions",
                "organizations_url": "https://api.github.com/users/luoyuxia/orgs",
                "repos_url": "https://api.github.com/users/luoyuxia/repos",
                "events_url": "https://api.github.com/users/luoyuxia/events{/privacy}",
                "received_events_url": "https://api.github.com/users/luoyuxia/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "lirui-apache",
                "id": 5210788,
                "node_id": "MDQ6VXNlcjUyMTA3ODg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5210788?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/lirui-apache",
                "html_url": "https://github.com/lirui-apache",
                "followers_url": "https://api.github.com/users/lirui-apache/followers",
                "following_url": "https://api.github.com/users/lirui-apache/following{/other_user}",
                "gists_url": "https://api.github.com/users/lirui-apache/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/lirui-apache/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/lirui-apache/subscriptions",
                "organizations_url": "https://api.github.com/users/lirui-apache/orgs",
                "repos_url": "https://api.github.com/users/lirui-apache/repos",
                "events_url": "https://api.github.com/users/lirui-apache/events{/privacy}",
                "received_events_url": "https://api.github.com/users/lirui-apache/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "5a873bc4c61ce17ef991e2202d1f1bf665f67edf",
                "url": "https://api.github.com/repos/apache/flink/commits/5a873bc4c61ce17ef991e2202d1f1bf665f67edf",
                "html_url": "https://github.com/apache/flink/commit/5a873bc4c61ce17ef991e2202d1f1bf665f67edf"
            }]
        },
        {
            "sha": "8d62fe8e5130575f92c6d3c7b5411fce9752e9f7",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6OGQ2MmZlOGU1MTMwNTc1ZjkyYzZkM2M3YjU0MTFmY2U5NzUyZTlmNw==",
            "commit": {
                "author": {
                    "name": "JasonLee",
                    "email": "40521353+JasonLeeCoding@users.noreply.github.com",
                    "date": "2021-05-28T09:37:42Z"
                },
                "committer": {
                    "name": "Jark Wu",
                    "email": "jark@apache.org",
                    "date": "2021-05-28T09:38:40Z"
                },
                "message": "[FLINK-22655][sql-client] Fix \"-i init.sql\" doesn't work when first line is a comment\n\nThis closes #15980",
                "tree": {
                    "sha": "d466be45bedf6e90a9a2eba1cd84be7c4bf8866b",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/d466be45bedf6e90a9a2eba1cd84be7c4bf8866b"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/8d62fe8e5130575f92c6d3c7b5411fce9752e9f7",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEE4sRUF77VwQQVTzQQhbrLWu+uMgIFAmCwuiAACgkQhbrLWu+u\nMgL0EhAAnI/pYx2sYoO6KSNzWMi+CphKNvYYkNip51bXurJVfpPrDPNiTOPxoqw3\nV11Y2yKX8jDLH2WLoo36kHZfgtQvKx3xEJyqA8LpTHe5V6f75TLdB8whYw0iJSPL\nSNtAXkc3Qac5kcwWJgHQCmOR5jkHm5Q4kcCGHslvlHWpjTR4B+MhjkLrIPDT38d8\nYQ+hNkelvbGd4baCsMNUr5eSv/zISpdFOFOCBk4m0DiicBn/3183n171MjM5ln6g\nm9eTFlzojMy4rV5KJIzWZUKVVW/U45aMoCzaZGL9+Fq2yP2Tw4TE8RoodB0q15rA\nt3CAu2DNAJKx5fbGEXh2DVqgEu+zcd6edC6IykinO2xyJ16rPuZAOXeuRlbaisL7\neih3zlLNPh/0ZglkpXV2oXeNdTPvw9f4MLnoeP4ny1Ab5gJbfEDgznPJRvH/seMu\nLs3AdvhdAlAm/MtPabA+jb+rHH32WM2ccIsDqIV12hl49fn1BjQU6Bmg4INAR5Pc\nyP7mYRhtg/DnQXxhwscP7pSiKSzxdOBJTz6azWugdbVk6Z6qavKs+/kYbnEymzgD\ndoS6g8BNrX5OIJ25fCTLBcGCz0qrBcYA9GUyacSHynM5q9OrW+yfW0C9kTlBNHLQ\nTrWs6Hk0u8bEHzSZmpM0xvrDcTqBmfhkD/Gs9Xo5UWWp1ueFvxM=\n=GqTh\n-----END PGP SIGNATURE-----",
                    "payload": "tree d466be45bedf6e90a9a2eba1cd84be7c4bf8866b\nparent a873ef925a3807292a7463cf66be0abad11a52db\nauthor JasonLee <40521353+JasonLeeCoding@users.noreply.github.com> 1622194662 +0800\ncommitter Jark Wu <jark@apache.org> 1622194720 +0800\n\n[FLINK-22655][sql-client] Fix \"-i init.sql\" doesn't work when first line is a comment\n\nThis closes #15980"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/8d62fe8e5130575f92c6d3c7b5411fce9752e9f7",
            "html_url": "https://github.com/apache/flink/commit/8d62fe8e5130575f92c6d3c7b5411fce9752e9f7",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/8d62fe8e5130575f92c6d3c7b5411fce9752e9f7/comments",
            "author": {
                "login": "JasonLeeCoding",
                "id": 40521353,
                "node_id": "MDQ6VXNlcjQwNTIxMzUz",
                "avatar_url": "https://avatars.githubusercontent.com/u/40521353?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/JasonLeeCoding",
                "html_url": "https://github.com/JasonLeeCoding",
                "followers_url": "https://api.github.com/users/JasonLeeCoding/followers",
                "following_url": "https://api.github.com/users/JasonLeeCoding/following{/other_user}",
                "gists_url": "https://api.github.com/users/JasonLeeCoding/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/JasonLeeCoding/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/JasonLeeCoding/subscriptions",
                "organizations_url": "https://api.github.com/users/JasonLeeCoding/orgs",
                "repos_url": "https://api.github.com/users/JasonLeeCoding/repos",
                "events_url": "https://api.github.com/users/JasonLeeCoding/events{/privacy}",
                "received_events_url": "https://api.github.com/users/JasonLeeCoding/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "wuchong",
                "id": 5378924,
                "node_id": "MDQ6VXNlcjUzNzg5MjQ=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5378924?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/wuchong",
                "html_url": "https://github.com/wuchong",
                "followers_url": "https://api.github.com/users/wuchong/followers",
                "following_url": "https://api.github.com/users/wuchong/following{/other_user}",
                "gists_url": "https://api.github.com/users/wuchong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/wuchong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/wuchong/subscriptions",
                "organizations_url": "https://api.github.com/users/wuchong/orgs",
                "repos_url": "https://api.github.com/users/wuchong/repos",
                "events_url": "https://api.github.com/users/wuchong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/wuchong/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "a873ef925a3807292a7463cf66be0abad11a52db",
                "url": "https://api.github.com/repos/apache/flink/commits/a873ef925a3807292a7463cf66be0abad11a52db",
                "html_url": "https://github.com/apache/flink/commit/a873ef925a3807292a7463cf66be0abad11a52db"
            }]
        },
        {
            "sha": "df2d08837d89e94066393942f5147b6a0ffead22",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZGYyZDA4ODM3ZDg5ZTk0MDY2MzkzOTQyZjUxNDdiNmEwZmZlYWQyMg==",
            "commit": {
                "author": {
                    "name": "Ingo Bürk",
                    "email": "ingo.buerk@tngtech.com",
                    "date": "2021-05-27T05:48:48Z"
                },
                "committer": {
                    "name": "Timo Walther",
                    "email": "twalthr@apache.org",
                    "date": "2021-05-28T10:37:41Z"
                },
                "message": "[FLINK-22770][sql-parser][planner-blink] Expose SET/RESET\n\nThis adds the SET and RESET DCL statements directly into the parser and\nexposes them as their respective (pre-existing) operations.\n\nA major difference to the current SET/RESET supported in the SQL Client\nis that we now require quoting of both key and value for consistency with\noptions elsewhere in Flink SQL. To avoid a breaking change, the SQL Client\nspecific implementation is kept for now which takes precedence.",
                "tree": {
                    "sha": "4670b4ab0f986fc757b8179028a403828079a25f",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/4670b4ab0f986fc757b8179028a403828079a25f"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/df2d08837d89e94066393942f5147b6a0ffead22",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/df2d08837d89e94066393942f5147b6a0ffead22",
            "html_url": "https://github.com/apache/flink/commit/df2d08837d89e94066393942f5147b6a0ffead22",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/df2d08837d89e94066393942f5147b6a0ffead22/comments",
            "author": {
                "login": "Airblader",
                "id": 2392216,
                "node_id": "MDQ6VXNlcjIzOTIyMTY=",
                "avatar_url": "https://avatars.githubusercontent.com/u/2392216?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/Airblader",
                "html_url": "https://github.com/Airblader",
                "followers_url": "https://api.github.com/users/Airblader/followers",
                "following_url": "https://api.github.com/users/Airblader/following{/other_user}",
                "gists_url": "https://api.github.com/users/Airblader/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/Airblader/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/Airblader/subscriptions",
                "organizations_url": "https://api.github.com/users/Airblader/orgs",
                "repos_url": "https://api.github.com/users/Airblader/repos",
                "events_url": "https://api.github.com/users/Airblader/events{/privacy}",
                "received_events_url": "https://api.github.com/users/Airblader/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "twalthr",
                "id": 5746567,
                "node_id": "MDQ6VXNlcjU3NDY1Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5746567?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/twalthr",
                "html_url": "https://github.com/twalthr",
                "followers_url": "https://api.github.com/users/twalthr/followers",
                "following_url": "https://api.github.com/users/twalthr/following{/other_user}",
                "gists_url": "https://api.github.com/users/twalthr/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/twalthr/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/twalthr/subscriptions",
                "organizations_url": "https://api.github.com/users/twalthr/orgs",
                "repos_url": "https://api.github.com/users/twalthr/repos",
                "events_url": "https://api.github.com/users/twalthr/events{/privacy}",
                "received_events_url": "https://api.github.com/users/twalthr/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "8d62fe8e5130575f92c6d3c7b5411fce9752e9f7",
                "url": "https://api.github.com/repos/apache/flink/commits/8d62fe8e5130575f92c6d3c7b5411fce9752e9f7",
                "html_url": "https://github.com/apache/flink/commit/8d62fe8e5130575f92c6d3c7b5411fce9752e9f7"
            }]
        },
        {
            "sha": "320ed880513377acc622daf7764a9be70e7704f0",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MzIwZWQ4ODA1MTMzNzdhY2M2MjJkYWY3NzY0YTliZTcwZTc3MDRmMA==",
            "commit": {
                "author": {
                    "name": "Ingo Bürk",
                    "email": "ingo.buerk@tngtech.com",
                    "date": "2021-05-26T09:18:56Z"
                },
                "committer": {
                    "name": "Timo Walther",
                    "email": "twalthr@apache.org",
                    "date": "2021-05-28T10:37:41Z"
                },
                "message": "[FLINK-22770][docs] Update usage of SET in docs to use quotes",
                "tree": {
                    "sha": "2ec08b76572cbf5a97ae834e37fcd1d7ed637acb",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/2ec08b76572cbf5a97ae834e37fcd1d7ed637acb"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/320ed880513377acc622daf7764a9be70e7704f0",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/320ed880513377acc622daf7764a9be70e7704f0",
            "html_url": "https://github.com/apache/flink/commit/320ed880513377acc622daf7764a9be70e7704f0",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/320ed880513377acc622daf7764a9be70e7704f0/comments",
            "author": {
                "login": "Airblader",
                "id": 2392216,
                "node_id": "MDQ6VXNlcjIzOTIyMTY=",
                "avatar_url": "https://avatars.githubusercontent.com/u/2392216?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/Airblader",
                "html_url": "https://github.com/Airblader",
                "followers_url": "https://api.github.com/users/Airblader/followers",
                "following_url": "https://api.github.com/users/Airblader/following{/other_user}",
                "gists_url": "https://api.github.com/users/Airblader/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/Airblader/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/Airblader/subscriptions",
                "organizations_url": "https://api.github.com/users/Airblader/orgs",
                "repos_url": "https://api.github.com/users/Airblader/repos",
                "events_url": "https://api.github.com/users/Airblader/events{/privacy}",
                "received_events_url": "https://api.github.com/users/Airblader/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "twalthr",
                "id": 5746567,
                "node_id": "MDQ6VXNlcjU3NDY1Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5746567?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/twalthr",
                "html_url": "https://github.com/twalthr",
                "followers_url": "https://api.github.com/users/twalthr/followers",
                "following_url": "https://api.github.com/users/twalthr/following{/other_user}",
                "gists_url": "https://api.github.com/users/twalthr/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/twalthr/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/twalthr/subscriptions",
                "organizations_url": "https://api.github.com/users/twalthr/orgs",
                "repos_url": "https://api.github.com/users/twalthr/repos",
                "events_url": "https://api.github.com/users/twalthr/events{/privacy}",
                "received_events_url": "https://api.github.com/users/twalthr/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "df2d08837d89e94066393942f5147b6a0ffead22",
                "url": "https://api.github.com/repos/apache/flink/commits/df2d08837d89e94066393942f5147b6a0ffead22",
                "html_url": "https://github.com/apache/flink/commit/df2d08837d89e94066393942f5147b6a0ffead22"
            }]
        },
        {
            "sha": "1f9a658a345bc6ab6d43bb843b5bc44500289afe",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MWY5YTY1OGEzNDViYzZhYjZkNDNiYjg0M2I1YmM0NDUwMDI4OWFmZQ==",
            "commit": {
                "author": {
                    "name": "Dawid Wysakowicz",
                    "email": "dwysakowicz@apache.org",
                    "date": "2021-05-28T15:55:18Z"
                },
                "committer": {
                    "name": "Dawid Wysakowicz",
                    "email": "dwysakowicz@apache.org",
                    "date": "2021-05-28T15:55:18Z"
                },
                "message": "Update japicmp configuration for 1.13.1",
                "tree": {
                    "sha": "b5e87f6afee53e0303e4739eefde33112724db86",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/b5e87f6afee53e0303e4739eefde33112724db86"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/1f9a658a345bc6ab6d43bb843b5bc44500289afe",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEE6pOkNbTiybTJ9TP2MdLdEL/BWi0FAmCxEmYACgkQMdLdEL/B\nWi30aRAAjT3RJpedG3UAkMwGqIgNHboTl9GX9o7viq9Z6H6FJa6LqGDGFIh/RujS\nooMouzD4SZIT5Gvg+WR9Lu0NV2cWuR5AnNTm0qeCXNFoIfihMdiz6HZFAXeT2KkE\n3GdEX/ORtWqEaZ4ZsY+BT0pjAtltUYDxr/53sJz7zmcqeuIoUraqJ4/Mzt+4cONv\nu62buljaq+cBnwpQxHFE42pGLVWQvj4clJ4ZW0yiXWGrex7jrDYvMgmFviNpvxOv\nzsqW/ppb1EmrNdm8AVfebZAQ9F8AHvyqm11rtkFIoGS9z3uQiymJ9i7kO5rtcLcT\nXiddt7V0eQ6qjX6d8qpJSRtpnlWjsUGOaRUvsBSutOzObuNyr1bWGjmIp0FsTH+3\ndew4AVQkwFJd6ynGQHg/MpOw+TMQVrJx5zup1zg8Z0LYs7Csxxu2mfR5C5hJKHBJ\ndWmZrWdAnx5rKpOj7vI8oUTdRD/LRre8oAxTNb6lp9gbHezzqax5nWxoJOp5coS2\nS5PZH+c+mYJu+k1erPfqcBM0hl2dOrkS3R6pjIPe5UaNovuyBtDt4Jh/tKWfHFpa\nE0KtxCgYiw2wRaDYwq2Qrbss9hVYCs0Hua9TE69khW69Re29cXTRuqCcy8Q0D3KN\nJmt5Xnr/rmu4BDtLlhiFgbmuz78rcrslqaOf16mUOahkBCTWW/E=\n=svgG\n-----END PGP SIGNATURE-----",
                    "payload": "tree b5e87f6afee53e0303e4739eefde33112724db86\nparent 320ed880513377acc622daf7764a9be70e7704f0\nauthor Dawid Wysakowicz <dwysakowicz@apache.org> 1622217318 +0200\ncommitter Dawid Wysakowicz <dwysakowicz@apache.org> 1622217318 +0200\n\nUpdate japicmp configuration for 1.13.1\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/1f9a658a345bc6ab6d43bb843b5bc44500289afe",
            "html_url": "https://github.com/apache/flink/commit/1f9a658a345bc6ab6d43bb843b5bc44500289afe",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/1f9a658a345bc6ab6d43bb843b5bc44500289afe/comments",
            "author": {
                "login": "dawidwys",
                "id": 6242259,
                "node_id": "MDQ6VXNlcjYyNDIyNTk=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6242259?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dawidwys",
                "html_url": "https://github.com/dawidwys",
                "followers_url": "https://api.github.com/users/dawidwys/followers",
                "following_url": "https://api.github.com/users/dawidwys/following{/other_user}",
                "gists_url": "https://api.github.com/users/dawidwys/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dawidwys/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dawidwys/subscriptions",
                "organizations_url": "https://api.github.com/users/dawidwys/orgs",
                "repos_url": "https://api.github.com/users/dawidwys/repos",
                "events_url": "https://api.github.com/users/dawidwys/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dawidwys/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "dawidwys",
                "id": 6242259,
                "node_id": "MDQ6VXNlcjYyNDIyNTk=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6242259?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dawidwys",
                "html_url": "https://github.com/dawidwys",
                "followers_url": "https://api.github.com/users/dawidwys/followers",
                "following_url": "https://api.github.com/users/dawidwys/following{/other_user}",
                "gists_url": "https://api.github.com/users/dawidwys/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dawidwys/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dawidwys/subscriptions",
                "organizations_url": "https://api.github.com/users/dawidwys/orgs",
                "repos_url": "https://api.github.com/users/dawidwys/repos",
                "events_url": "https://api.github.com/users/dawidwys/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dawidwys/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "320ed880513377acc622daf7764a9be70e7704f0",
                "url": "https://api.github.com/repos/apache/flink/commits/320ed880513377acc622daf7764a9be70e7704f0",
                "html_url": "https://github.com/apache/flink/commit/320ed880513377acc622daf7764a9be70e7704f0"
            }]
        },
        {
            "sha": "1518f96310c97209de139af5727741f7115f1db0",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MTUxOGY5NjMxMGM5NzIwOWRlMTM5YWY1NzI3NzQxZjcxMTVmMWRiMA==",
            "commit": {
                "author": {
                    "name": "Yun Tang",
                    "email": "myasuka@live.com",
                    "date": "2021-05-24T09:26:09Z"
                },
                "committer": {
                    "name": "Yun Tang",
                    "email": "tangyun@apache.org",
                    "date": "2021-05-31T02:47:11Z"
                },
                "message": "[FLINK-22759][docs] Correct the applicability of some RocksDB related options as per operator",
                "tree": {
                    "sha": "8313c73ab1e154bcc7df571e1c5069328b03f415",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/8313c73ab1e154bcc7df571e1c5069328b03f415"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/1518f96310c97209de139af5727741f7115f1db0",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/1518f96310c97209de139af5727741f7115f1db0",
            "html_url": "https://github.com/apache/flink/commit/1518f96310c97209de139af5727741f7115f1db0",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/1518f96310c97209de139af5727741f7115f1db0/comments",
            "author": {
                "login": "Myasuka",
                "id": 1709104,
                "node_id": "MDQ6VXNlcjE3MDkxMDQ=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1709104?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/Myasuka",
                "html_url": "https://github.com/Myasuka",
                "followers_url": "https://api.github.com/users/Myasuka/followers",
                "following_url": "https://api.github.com/users/Myasuka/following{/other_user}",
                "gists_url": "https://api.github.com/users/Myasuka/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/Myasuka/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/Myasuka/subscriptions",
                "organizations_url": "https://api.github.com/users/Myasuka/orgs",
                "repos_url": "https://api.github.com/users/Myasuka/repos",
                "events_url": "https://api.github.com/users/Myasuka/events{/privacy}",
                "received_events_url": "https://api.github.com/users/Myasuka/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "Myasuka",
                "id": 1709104,
                "node_id": "MDQ6VXNlcjE3MDkxMDQ=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1709104?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/Myasuka",
                "html_url": "https://github.com/Myasuka",
                "followers_url": "https://api.github.com/users/Myasuka/followers",
                "following_url": "https://api.github.com/users/Myasuka/following{/other_user}",
                "gists_url": "https://api.github.com/users/Myasuka/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/Myasuka/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/Myasuka/subscriptions",
                "organizations_url": "https://api.github.com/users/Myasuka/orgs",
                "repos_url": "https://api.github.com/users/Myasuka/repos",
                "events_url": "https://api.github.com/users/Myasuka/events{/privacy}",
                "received_events_url": "https://api.github.com/users/Myasuka/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "1f9a658a345bc6ab6d43bb843b5bc44500289afe",
                "url": "https://api.github.com/repos/apache/flink/commits/1f9a658a345bc6ab6d43bb843b5bc44500289afe",
                "html_url": "https://github.com/apache/flink/commit/1f9a658a345bc6ab6d43bb843b5bc44500289afe"
            }]
        },
        {
            "sha": "617fd071cf1bc7b3e38ae1b998c6578a0bfb66fe",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NjE3ZmQwNzFjZjFiYzdiM2UzOGFlMWI5OThjNjU3OGEwYmZiNjZmZQ==",
            "commit": {
                "author": {
                    "name": "Timo Walther",
                    "email": "twalthr@apache.org",
                    "date": "2021-05-31T10:17:13Z"
                },
                "committer": {
                    "name": "Timo Walther",
                    "email": "twalthr@apache.org",
                    "date": "2021-05-31T10:22:53Z"
                },
                "message": "[hotfix][docs] Improve soft deprecation message for DataSet users",
                "tree": {
                    "sha": "e5d119f4170d878d7367a8db3d42d28c25de3561",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/e5d119f4170d878d7367a8db3d42d28c25de3561"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/617fd071cf1bc7b3e38ae1b998c6578a0bfb66fe",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/617fd071cf1bc7b3e38ae1b998c6578a0bfb66fe",
            "html_url": "https://github.com/apache/flink/commit/617fd071cf1bc7b3e38ae1b998c6578a0bfb66fe",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/617fd071cf1bc7b3e38ae1b998c6578a0bfb66fe/comments",
            "author": {
                "login": "twalthr",
                "id": 5746567,
                "node_id": "MDQ6VXNlcjU3NDY1Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5746567?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/twalthr",
                "html_url": "https://github.com/twalthr",
                "followers_url": "https://api.github.com/users/twalthr/followers",
                "following_url": "https://api.github.com/users/twalthr/following{/other_user}",
                "gists_url": "https://api.github.com/users/twalthr/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/twalthr/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/twalthr/subscriptions",
                "organizations_url": "https://api.github.com/users/twalthr/orgs",
                "repos_url": "https://api.github.com/users/twalthr/repos",
                "events_url": "https://api.github.com/users/twalthr/events{/privacy}",
                "received_events_url": "https://api.github.com/users/twalthr/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "twalthr",
                "id": 5746567,
                "node_id": "MDQ6VXNlcjU3NDY1Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5746567?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/twalthr",
                "html_url": "https://github.com/twalthr",
                "followers_url": "https://api.github.com/users/twalthr/followers",
                "following_url": "https://api.github.com/users/twalthr/following{/other_user}",
                "gists_url": "https://api.github.com/users/twalthr/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/twalthr/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/twalthr/subscriptions",
                "organizations_url": "https://api.github.com/users/twalthr/orgs",
                "repos_url": "https://api.github.com/users/twalthr/repos",
                "events_url": "https://api.github.com/users/twalthr/events{/privacy}",
                "received_events_url": "https://api.github.com/users/twalthr/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "1518f96310c97209de139af5727741f7115f1db0",
                "url": "https://api.github.com/repos/apache/flink/commits/1518f96310c97209de139af5727741f7115f1db0",
                "html_url": "https://github.com/apache/flink/commit/1518f96310c97209de139af5727741f7115f1db0"
            }]
        },
        {
            "sha": "dab3cf240ada16aa754f7855dff4a364abf91e5f",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZGFiM2NmMjQwYWRhMTZhYTc1NGY3ODU1ZGZmNGEzNjRhYmY5MWU1Zg==",
            "commit": {
                "author": {
                    "name": "paul8263",
                    "email": "xzhangyao@126.com",
                    "date": "2021-06-01T04:09:05Z"
                },
                "committer": {
                    "name": "Jark Wu",
                    "email": "jark@apache.org",
                    "date": "2021-06-01T04:11:02Z"
                },
                "message": "[FLINK-22689][doc] Fix Row-Based Operations Example in Table API documentation (#16036)",
                "tree": {
                    "sha": "904ce4e1cfdecfe1fd99efa7c0dc0014d96b3d80",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/904ce4e1cfdecfe1fd99efa7c0dc0014d96b3d80"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/dab3cf240ada16aa754f7855dff4a364abf91e5f",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEE4sRUF77VwQQVTzQQhbrLWu+uMgIFAmC1s1YACgkQhbrLWu+u\nMgLEVQ/9F71B0HAH7f235Bb4aOOeaRxNWT+2RFJHtAxNqWTorePljUbdapEXC1Ki\n8+baQEFSnJntm7vZwLMOgP1muHhoHCpWcqtd5n+g48HAn8OjlB+vipQv2h/3x+AN\nKPel+w7RJp6XnTRr2GEx3YyvgVFzGLXB1aZCnxOvgz53lshCfXVZLw2D0jX++bdc\n0wurpbOSJF971ooyWjb0JqcoS5ZVy1qt8au4IiSHUH/Y2mo9YHstRnomaIpj9rrw\nIknRbcoVo7Kzn29OzvDBdrNozTCxkgItL1PsEm1tlcEp5qREWlHQ3ztrtmirV75i\nUR1DxeI3/HNXGTV9k5Lm9EhwHnaUAT5LB8IkU3+bTNET2UrT+s74qqQzJ/OR0kpe\nFBTCopfruueyOZg7AreATSBjHlv+uV0Th6kbcVuvlFpSm5kXzeDHyfRdMPNuQ4Fq\nh4ROMR9gRPBkGgLWuzGLEULo1CTXocWYJLArCXypZcqS4fooS4ws5EVale1V7hG9\nqBXCjKZbcNBXk2oPzazNbRiDqYt4aOV81PvdRwoCK9OPoUMXlniA0kLYAMYTMYHY\nBAKlfvRg54A9Li0f7JlB2p+w1jlnlT03DBxlIClUg8Uo3ZWPNrGQfBceMVsfRByY\nFL3JKalfdInO/jww2A5EPP/MvVk+nxb7LeZJHPuO2bkcIuVTdak=\n=V9ya\n-----END PGP SIGNATURE-----",
                    "payload": "tree 904ce4e1cfdecfe1fd99efa7c0dc0014d96b3d80\nparent 617fd071cf1bc7b3e38ae1b998c6578a0bfb66fe\nauthor paul8263 <xzhangyao@126.com> 1622520545 +0800\ncommitter Jark Wu <jark@apache.org> 1622520662 +0800\n\n[FLINK-22689][doc] Fix Row-Based Operations Example in Table API documentation (#16036)\n\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/dab3cf240ada16aa754f7855dff4a364abf91e5f",
            "html_url": "https://github.com/apache/flink/commit/dab3cf240ada16aa754f7855dff4a364abf91e5f",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/dab3cf240ada16aa754f7855dff4a364abf91e5f/comments",
            "author": {
                "login": "paul8263",
                "id": 7007327,
                "node_id": "MDQ6VXNlcjcwMDczMjc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/7007327?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/paul8263",
                "html_url": "https://github.com/paul8263",
                "followers_url": "https://api.github.com/users/paul8263/followers",
                "following_url": "https://api.github.com/users/paul8263/following{/other_user}",
                "gists_url": "https://api.github.com/users/paul8263/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/paul8263/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/paul8263/subscriptions",
                "organizations_url": "https://api.github.com/users/paul8263/orgs",
                "repos_url": "https://api.github.com/users/paul8263/repos",
                "events_url": "https://api.github.com/users/paul8263/events{/privacy}",
                "received_events_url": "https://api.github.com/users/paul8263/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "wuchong",
                "id": 5378924,
                "node_id": "MDQ6VXNlcjUzNzg5MjQ=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5378924?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/wuchong",
                "html_url": "https://github.com/wuchong",
                "followers_url": "https://api.github.com/users/wuchong/followers",
                "following_url": "https://api.github.com/users/wuchong/following{/other_user}",
                "gists_url": "https://api.github.com/users/wuchong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/wuchong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/wuchong/subscriptions",
                "organizations_url": "https://api.github.com/users/wuchong/orgs",
                "repos_url": "https://api.github.com/users/wuchong/repos",
                "events_url": "https://api.github.com/users/wuchong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/wuchong/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "617fd071cf1bc7b3e38ae1b998c6578a0bfb66fe",
                "url": "https://api.github.com/repos/apache/flink/commits/617fd071cf1bc7b3e38ae1b998c6578a0bfb66fe",
                "html_url": "https://github.com/apache/flink/commit/617fd071cf1bc7b3e38ae1b998c6578a0bfb66fe"
            }]
        },
        {
            "sha": "5332c9898a1c891c2f97867304f912ae8d339c60",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NTMzMmM5ODk4YTFjODkxYzJmOTc4NjczMDRmOTEyYWU4ZDMzOWM2MA==",
            "commit": {
                "author": {
                    "name": "Tony Wei",
                    "email": "tony19920430@gmail.com",
                    "date": "2021-05-28T07:15:24Z"
                },
                "committer": {
                    "name": "Xintong Song",
                    "email": "tonysong820@gmail.com",
                    "date": "2021-06-01T05:57:34Z"
                },
                "message": "[FLINK-22796][doc] Update mem_setup_tm documentation\n\nThis closes #16016",
                "tree": {
                    "sha": "9a794fef2a7dd027960670d635434396b810596d",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/9a794fef2a7dd027960670d635434396b810596d"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/5332c9898a1c891c2f97867304f912ae8d339c60",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCgAdFiEEGsvLF58sbVnbyFd20SHP9Sk+Y18FAmC1zE4ACgkQ0SHP9Sk+\nY19tjg//QscHLeSv6AHE9S2WGzQ+yieK8N3FiVKR1JpxSpFiIpdLV3nCtATiTfqf\n4Noq9D0kCJSbMO5PwQI5Jq1jEfHtWACp/P3fN6sWB3b4TlZigMRx1h6xRDVZOjVU\nm72El+Ep+iutii/vhq88G+5GoozWWrlkqqu6/fJu8jALKpvnUN+z2+Xv5VvGLQjW\nP5VqYBKfVSUyZPVjNTZiiz3lSHK9Os3XwPTA98mwoOLQH77180uA91z6Tqg5ihzD\noVrniYPvAdt8u1YVxVWdEFWNMDiyFYwJNNWjzR1Py5wknHIgWKGEP9OzGcxFbyAB\nySivSp3OmduGhtS4kJElbqEixFVOmwRcf7K1XuQTXxgSMEuBWB+EZ2nj8Iz/+6Zp\nLbpsOamRLjkv85qoWg0CsofnqzEJ/W1FKYjuHKA1h7QWGg1Nb1GRNcnhQFtX12IB\n5yGzLMbT9RJ26V7YDWt3/k5M3KPawsyacxi5dJHGs+sAWJtu+6Qkh3YIry8TIlVz\nLY5pS6Q47pbfoUQ5vbAXPRI9F2+gjyFHobv/Aa4isoZL99O9yuX4rygdCADnlEN5\nyrYkPpPXkC+acYkGJOrZ7vX1Acmj1QpVX7sw0pq7p4A1/ucWylrbvpwgcbCkxi+Y\nESSUTd5A1YJtRFDKmB33zDT8zY89QTQdEOQzS+SgqGLbWFhxJIc=\n=FPpP\n-----END PGP SIGNATURE-----",
                    "payload": "tree 9a794fef2a7dd027960670d635434396b810596d\nparent dab3cf240ada16aa754f7855dff4a364abf91e5f\nauthor Tony Wei <tony19920430@gmail.com> 1622186124 +0800\ncommitter Xintong Song <tonysong820@gmail.com> 1622527054 +0800\n\n[FLINK-22796][doc] Update mem_setup_tm documentation\n\nThis closes #16016\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/5332c9898a1c891c2f97867304f912ae8d339c60",
            "html_url": "https://github.com/apache/flink/commit/5332c9898a1c891c2f97867304f912ae8d339c60",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/5332c9898a1c891c2f97867304f912ae8d339c60/comments",
            "author": {
                "login": "tony810430",
                "id": 14329393,
                "node_id": "MDQ6VXNlcjE0MzI5Mzkz",
                "avatar_url": "https://avatars.githubusercontent.com/u/14329393?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tony810430",
                "html_url": "https://github.com/tony810430",
                "followers_url": "https://api.github.com/users/tony810430/followers",
                "following_url": "https://api.github.com/users/tony810430/following{/other_user}",
                "gists_url": "https://api.github.com/users/tony810430/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tony810430/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tony810430/subscriptions",
                "organizations_url": "https://api.github.com/users/tony810430/orgs",
                "repos_url": "https://api.github.com/users/tony810430/repos",
                "events_url": "https://api.github.com/users/tony810430/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tony810430/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "xintongsong",
                "id": 6509172,
                "node_id": "MDQ6VXNlcjY1MDkxNzI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6509172?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/xintongsong",
                "html_url": "https://github.com/xintongsong",
                "followers_url": "https://api.github.com/users/xintongsong/followers",
                "following_url": "https://api.github.com/users/xintongsong/following{/other_user}",
                "gists_url": "https://api.github.com/users/xintongsong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/xintongsong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/xintongsong/subscriptions",
                "organizations_url": "https://api.github.com/users/xintongsong/orgs",
                "repos_url": "https://api.github.com/users/xintongsong/repos",
                "events_url": "https://api.github.com/users/xintongsong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/xintongsong/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "dab3cf240ada16aa754f7855dff4a364abf91e5f",
                "url": "https://api.github.com/repos/apache/flink/commits/dab3cf240ada16aa754f7855dff4a364abf91e5f",
                "html_url": "https://github.com/apache/flink/commit/dab3cf240ada16aa754f7855dff4a364abf91e5f"
            }]
        },
        {
            "sha": "feac87eb5a2ab66c04182e9b0d866571678a3535",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZmVhYzg3ZWI1YTJhYjY2YzA0MTgyZTliMGQ4NjY1NzE2NzhhMzUzNQ==",
            "commit": {
                "author": {
                    "name": "Robert Metzger",
                    "email": "rmetzger@apache.org",
                    "date": "2021-05-25T11:10:55Z"
                },
                "committer": {
                    "name": "Robert Metzger",
                    "email": "rmetzger@apache.org",
                    "date": "2021-06-01T11:53:58Z"
                },
                "message": "[FLINK-22464][runtime][tests] Disable a test failing with AdaptiveScheduler tracked in FLINK-22464",
                "tree": {
                    "sha": "11b85d294933314568da13cd110bd5abcdc2fe5a",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/11b85d294933314568da13cd110bd5abcdc2fe5a"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/feac87eb5a2ab66c04182e9b0d866571678a3535",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/feac87eb5a2ab66c04182e9b0d866571678a3535",
            "html_url": "https://github.com/apache/flink/commit/feac87eb5a2ab66c04182e9b0d866571678a3535",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/feac87eb5a2ab66c04182e9b0d866571678a3535/comments",
            "author": {
                "login": "rmetzger",
                "id": 89049,
                "node_id": "MDQ6VXNlcjg5MDQ5",
                "avatar_url": "https://avatars.githubusercontent.com/u/89049?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rmetzger",
                "html_url": "https://github.com/rmetzger",
                "followers_url": "https://api.github.com/users/rmetzger/followers",
                "following_url": "https://api.github.com/users/rmetzger/following{/other_user}",
                "gists_url": "https://api.github.com/users/rmetzger/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rmetzger/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rmetzger/subscriptions",
                "organizations_url": "https://api.github.com/users/rmetzger/orgs",
                "repos_url": "https://api.github.com/users/rmetzger/repos",
                "events_url": "https://api.github.com/users/rmetzger/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rmetzger/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "rmetzger",
                "id": 89049,
                "node_id": "MDQ6VXNlcjg5MDQ5",
                "avatar_url": "https://avatars.githubusercontent.com/u/89049?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rmetzger",
                "html_url": "https://github.com/rmetzger",
                "followers_url": "https://api.github.com/users/rmetzger/followers",
                "following_url": "https://api.github.com/users/rmetzger/following{/other_user}",
                "gists_url": "https://api.github.com/users/rmetzger/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rmetzger/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rmetzger/subscriptions",
                "organizations_url": "https://api.github.com/users/rmetzger/orgs",
                "repos_url": "https://api.github.com/users/rmetzger/repos",
                "events_url": "https://api.github.com/users/rmetzger/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rmetzger/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "5332c9898a1c891c2f97867304f912ae8d339c60",
                "url": "https://api.github.com/repos/apache/flink/commits/5332c9898a1c891c2f97867304f912ae8d339c60",
                "html_url": "https://github.com/apache/flink/commit/5332c9898a1c891c2f97867304f912ae8d339c60"
            }]
        },
        {
            "sha": "d4f5d4a02a6b90fd0d35e8f5c6eb0a48acea52b1",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZDRmNWQ0YTAyYTZiOTBmZDBkMzVlOGY1YzZlYjBhNDhhY2VhNTJiMQ==",
            "commit": {
                "author": {
                    "name": "Piotr Nowojski",
                    "email": "piotr.nowojski@gmail.com",
                    "date": "2021-05-31T15:37:55Z"
                },
                "committer": {
                    "name": "Piotr Nowojski",
                    "email": "piotr.nowojski@gmail.com",
                    "date": "2021-06-01T12:29:31Z"
                },
                "message": "[FLINK-22814][metrics] Calculate checkpointStartDelay for FLIP-27 sources",
                "tree": {
                    "sha": "503aad6b7723aa221e15b580ff5ed7834a5504e3",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/503aad6b7723aa221e15b580ff5ed7834a5504e3"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/d4f5d4a02a6b90fd0d35e8f5c6eb0a48acea52b1",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/d4f5d4a02a6b90fd0d35e8f5c6eb0a48acea52b1",
            "html_url": "https://github.com/apache/flink/commit/d4f5d4a02a6b90fd0d35e8f5c6eb0a48acea52b1",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/d4f5d4a02a6b90fd0d35e8f5c6eb0a48acea52b1/comments",
            "author": {
                "login": "pnowojski",
                "id": 8957547,
                "node_id": "MDQ6VXNlcjg5NTc1NDc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8957547?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/pnowojski",
                "html_url": "https://github.com/pnowojski",
                "followers_url": "https://api.github.com/users/pnowojski/followers",
                "following_url": "https://api.github.com/users/pnowojski/following{/other_user}",
                "gists_url": "https://api.github.com/users/pnowojski/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/pnowojski/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/pnowojski/subscriptions",
                "organizations_url": "https://api.github.com/users/pnowojski/orgs",
                "repos_url": "https://api.github.com/users/pnowojski/repos",
                "events_url": "https://api.github.com/users/pnowojski/events{/privacy}",
                "received_events_url": "https://api.github.com/users/pnowojski/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "pnowojski",
                "id": 8957547,
                "node_id": "MDQ6VXNlcjg5NTc1NDc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8957547?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/pnowojski",
                "html_url": "https://github.com/pnowojski",
                "followers_url": "https://api.github.com/users/pnowojski/followers",
                "following_url": "https://api.github.com/users/pnowojski/following{/other_user}",
                "gists_url": "https://api.github.com/users/pnowojski/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/pnowojski/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/pnowojski/subscriptions",
                "organizations_url": "https://api.github.com/users/pnowojski/orgs",
                "repos_url": "https://api.github.com/users/pnowojski/repos",
                "events_url": "https://api.github.com/users/pnowojski/events{/privacy}",
                "received_events_url": "https://api.github.com/users/pnowojski/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "feac87eb5a2ab66c04182e9b0d866571678a3535",
                "url": "https://api.github.com/repos/apache/flink/commits/feac87eb5a2ab66c04182e9b0d866571678a3535",
                "html_url": "https://github.com/apache/flink/commit/feac87eb5a2ab66c04182e9b0d866571678a3535"
            }]
        },
        {
            "sha": "4cfaac4d8ccc0623aba5bff9a95c4ebf09dff7fb",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NGNmYWFjNGQ4Y2NjMDYyM2FiYTViZmY5YTk1YzRlYmYwOWRmZjdmYg==",
            "commit": {
                "author": {
                    "name": "Etienne Chauchot",
                    "email": "echauchot@apache.org",
                    "date": "2021-05-31T14:44:05Z"
                },
                "committer": {
                    "name": "Arvid Heise",
                    "email": "AHeise@users.noreply.github.com",
                    "date": "2021-06-02T07:45:39Z"
                },
                "message": "[FLINK-21393] [formats] Move avro conversion methods from AvroRowSerializationSchema to a new AvroConversions utility",
                "tree": {
                    "sha": "bbcc5f6fd1f3fa2c5e12e191e39eef055e91e198",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/bbcc5f6fd1f3fa2c5e12e191e39eef055e91e198"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/4cfaac4d8ccc0623aba5bff9a95c4ebf09dff7fb",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/4cfaac4d8ccc0623aba5bff9a95c4ebf09dff7fb",
            "html_url": "https://github.com/apache/flink/commit/4cfaac4d8ccc0623aba5bff9a95c4ebf09dff7fb",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/4cfaac4d8ccc0623aba5bff9a95c4ebf09dff7fb/comments",
            "author": {
                "login": "echauchot",
                "id": 8821084,
                "node_id": "MDQ6VXNlcjg4MjEwODQ=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8821084?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/echauchot",
                "html_url": "https://github.com/echauchot",
                "followers_url": "https://api.github.com/users/echauchot/followers",
                "following_url": "https://api.github.com/users/echauchot/following{/other_user}",
                "gists_url": "https://api.github.com/users/echauchot/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/echauchot/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/echauchot/subscriptions",
                "organizations_url": "https://api.github.com/users/echauchot/orgs",
                "repos_url": "https://api.github.com/users/echauchot/repos",
                "events_url": "https://api.github.com/users/echauchot/events{/privacy}",
                "received_events_url": "https://api.github.com/users/echauchot/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "AHeise",
                "id": 4559103,
                "node_id": "MDQ6VXNlcjQ1NTkxMDM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/4559103?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/AHeise",
                "html_url": "https://github.com/AHeise",
                "followers_url": "https://api.github.com/users/AHeise/followers",
                "following_url": "https://api.github.com/users/AHeise/following{/other_user}",
                "gists_url": "https://api.github.com/users/AHeise/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/AHeise/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/AHeise/subscriptions",
                "organizations_url": "https://api.github.com/users/AHeise/orgs",
                "repos_url": "https://api.github.com/users/AHeise/repos",
                "events_url": "https://api.github.com/users/AHeise/events{/privacy}",
                "received_events_url": "https://api.github.com/users/AHeise/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "d4f5d4a02a6b90fd0d35e8f5c6eb0a48acea52b1",
                "url": "https://api.github.com/repos/apache/flink/commits/d4f5d4a02a6b90fd0d35e8f5c6eb0a48acea52b1",
                "html_url": "https://github.com/apache/flink/commit/d4f5d4a02a6b90fd0d35e8f5c6eb0a48acea52b1"
            }]
        },
        {
            "sha": "143a7e1ed6bbb5e9d10e79404540ba48ce3e20be",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MTQzYTdlMWVkNmJiYjVlOWQxMGU3OTQwNDU0MGJhNDhjZTNlMjBiZQ==",
            "commit": {
                "author": {
                    "name": "Etienne Chauchot",
                    "email": "echauchot@apache.org",
                    "date": "2021-05-31T14:45:27Z"
                },
                "committer": {
                    "name": "Arvid Heise",
                    "email": "AHeise@users.noreply.github.com",
                    "date": "2021-06-02T07:45:39Z"
                },
                "message": "[FLINK-21393] [formats] Add ParquetAvroInputFormat",
                "tree": {
                    "sha": "c2cc73e16bb7a59d4ab7411c1e695a2e3b18dca6",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/c2cc73e16bb7a59d4ab7411c1e695a2e3b18dca6"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/143a7e1ed6bbb5e9d10e79404540ba48ce3e20be",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/143a7e1ed6bbb5e9d10e79404540ba48ce3e20be",
            "html_url": "https://github.com/apache/flink/commit/143a7e1ed6bbb5e9d10e79404540ba48ce3e20be",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/143a7e1ed6bbb5e9d10e79404540ba48ce3e20be/comments",
            "author": {
                "login": "echauchot",
                "id": 8821084,
                "node_id": "MDQ6VXNlcjg4MjEwODQ=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8821084?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/echauchot",
                "html_url": "https://github.com/echauchot",
                "followers_url": "https://api.github.com/users/echauchot/followers",
                "following_url": "https://api.github.com/users/echauchot/following{/other_user}",
                "gists_url": "https://api.github.com/users/echauchot/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/echauchot/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/echauchot/subscriptions",
                "organizations_url": "https://api.github.com/users/echauchot/orgs",
                "repos_url": "https://api.github.com/users/echauchot/repos",
                "events_url": "https://api.github.com/users/echauchot/events{/privacy}",
                "received_events_url": "https://api.github.com/users/echauchot/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "AHeise",
                "id": 4559103,
                "node_id": "MDQ6VXNlcjQ1NTkxMDM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/4559103?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/AHeise",
                "html_url": "https://github.com/AHeise",
                "followers_url": "https://api.github.com/users/AHeise/followers",
                "following_url": "https://api.github.com/users/AHeise/following{/other_user}",
                "gists_url": "https://api.github.com/users/AHeise/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/AHeise/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/AHeise/subscriptions",
                "organizations_url": "https://api.github.com/users/AHeise/orgs",
                "repos_url": "https://api.github.com/users/AHeise/repos",
                "events_url": "https://api.github.com/users/AHeise/events{/privacy}",
                "received_events_url": "https://api.github.com/users/AHeise/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "4cfaac4d8ccc0623aba5bff9a95c4ebf09dff7fb",
                "url": "https://api.github.com/repos/apache/flink/commits/4cfaac4d8ccc0623aba5bff9a95c4ebf09dff7fb",
                "html_url": "https://github.com/apache/flink/commit/4cfaac4d8ccc0623aba5bff9a95c4ebf09dff7fb"
            }]
        },
        {
            "sha": "df0ae16bbd3ecb59203d30fe88571ead598788b4",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZGYwYWUxNmJiZDNlY2I1OTIwM2QzMGZlODg1NzFlYWQ1OTg3ODhiNA==",
            "commit": {
                "author": {
                    "name": "Zhiwen Sun",
                    "email": "pensz01@gmail.com",
                    "date": "2021-06-03T03:45:57Z"
                },
                "committer": {
                    "name": "Jark Wu",
                    "email": "jark@apache.org",
                    "date": "2021-06-03T03:47:58Z"
                },
                "message": "[FLINK-22786][sql-client] sql-client can not create history file when under soft link path (#16029)",
                "tree": {
                    "sha": "454a0ca9b11aec8f2e1b7ca2ea8c8d5266e482c9",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/454a0ca9b11aec8f2e1b7ca2ea8c8d5266e482c9"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/df0ae16bbd3ecb59203d30fe88571ead598788b4",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEE4sRUF77VwQQVTzQQhbrLWu+uMgIFAmC4UO4ACgkQhbrLWu+u\nMgIpZRAAoiFOAdXVIq7GlW1VvaY9G3pafGzcW+xzu2gq7tpd9TidM6ToKJ6hOUSg\nt5kO7vlp/rZIZgFYHR9XSVXLwDL7DV1dFJKaek1+itIV+rDRlx7y5+XOgjSP0adl\nZanhXtmoXIaG1ZphO8jW+rQ+9hanNCEq1yDVEk8vzFEdnFgiuBJonOdZ44eGim0T\n/SGJByQ0/7ea6XGbdvPw3rIvZ+BmEkkSilyufCA3s6ooI9uICrQvC42BP5nXFCoh\nMNcB4qALMMohdAvcVIxDL8G9bc4+7QqM8y8XhTN2v101V4ELmqV623FeOzy/JYec\nFiHApqpQdPR1BtZic+ECmaqHirGP3en6OqYU50JXJsFmnCqhRWl3gIDDYpAFxoOj\nX5OWqiBBSga+IbUFzV0PPZENcs2NtlpMssFfnKj6cTxYSm/tvu+bPmTrRm1wVL1M\n/vjYXlE9IVOSVgsq3JDcPsWc2llShkJa8Jl14PwcppOduSgjg+QMQmBYVhFOXM6P\nkc6u7ZSoDgaGei1/ein2zmj7zi0cRqgSHr5ZzRjqNN+gXvW0wmpTslMaSAvacJuE\n1yMD/2zzA3TG/3y2r0JWYA4qXG6rN+x+1GsIp/4W9kpgfubirIort6UVql4LaUvh\n8+0u9NFDRxlQjzXMHCEmUgIObqLF3N0S7iMuOGOtrJ94ObjHFHU=\n=wU64\n-----END PGP SIGNATURE-----",
                    "payload": "tree 454a0ca9b11aec8f2e1b7ca2ea8c8d5266e482c9\nparent 143a7e1ed6bbb5e9d10e79404540ba48ce3e20be\nauthor Zhiwen Sun <pensz01@gmail.com> 1622691957 +0800\ncommitter Jark Wu <jark@apache.org> 1622692078 +0800\n\n[FLINK-22786][sql-client] sql-client can not create history file when under soft link path (#16029)\n\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/df0ae16bbd3ecb59203d30fe88571ead598788b4",
            "html_url": "https://github.com/apache/flink/commit/df0ae16bbd3ecb59203d30fe88571ead598788b4",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/df0ae16bbd3ecb59203d30fe88571ead598788b4/comments",
            "author": {
                "login": "pensz",
                "id": 899302,
                "node_id": "MDQ6VXNlcjg5OTMwMg==",
                "avatar_url": "https://avatars.githubusercontent.com/u/899302?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/pensz",
                "html_url": "https://github.com/pensz",
                "followers_url": "https://api.github.com/users/pensz/followers",
                "following_url": "https://api.github.com/users/pensz/following{/other_user}",
                "gists_url": "https://api.github.com/users/pensz/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/pensz/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/pensz/subscriptions",
                "organizations_url": "https://api.github.com/users/pensz/orgs",
                "repos_url": "https://api.github.com/users/pensz/repos",
                "events_url": "https://api.github.com/users/pensz/events{/privacy}",
                "received_events_url": "https://api.github.com/users/pensz/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "wuchong",
                "id": 5378924,
                "node_id": "MDQ6VXNlcjUzNzg5MjQ=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5378924?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/wuchong",
                "html_url": "https://github.com/wuchong",
                "followers_url": "https://api.github.com/users/wuchong/followers",
                "following_url": "https://api.github.com/users/wuchong/following{/other_user}",
                "gists_url": "https://api.github.com/users/wuchong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/wuchong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/wuchong/subscriptions",
                "organizations_url": "https://api.github.com/users/wuchong/orgs",
                "repos_url": "https://api.github.com/users/wuchong/repos",
                "events_url": "https://api.github.com/users/wuchong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/wuchong/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "143a7e1ed6bbb5e9d10e79404540ba48ce3e20be",
                "url": "https://api.github.com/repos/apache/flink/commits/143a7e1ed6bbb5e9d10e79404540ba48ce3e20be",
                "html_url": "https://github.com/apache/flink/commit/143a7e1ed6bbb5e9d10e79404540ba48ce3e20be"
            }]
        },
        {
            "sha": "2ea2f9f3bc21cfdaeec732d0c692eafa68665b2c",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MmVhMmY5ZjNiYzIxY2ZkYWVlYzczMmQwYzY5MmVhZmE2ODY2NWIyYw==",
            "commit": {
                "author": {
                    "name": "Yangze Guo",
                    "email": "karmagyz@gmail.com",
                    "date": "2021-05-17T10:02:18Z"
                },
                "committer": {
                    "name": "Xintong Song",
                    "email": "tonysong820@gmail.com",
                    "date": "2021-06-03T07:19:38Z"
                },
                "message": "[FLINK-22683][runtime] Fix the null or incorrect value of total Flink/process memory in creating TaskExecutorMemoryConfiguration\n\nThis closes #15936",
                "tree": {
                    "sha": "776eb8326042c953a37e58ddcef9dc1fe880dd5b",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/776eb8326042c953a37e58ddcef9dc1fe880dd5b"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/2ea2f9f3bc21cfdaeec732d0c692eafa68665b2c",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCgAdFiEEGsvLF58sbVnbyFd20SHP9Sk+Y18FAmC4gooACgkQ0SHP9Sk+\nY1+DqRAAvoTwN3FzURrWBckI7Bq5tqUjjcEy7Y18uJBHhKK0ygyto9FEYRR0ysJ/\nKzHcBZ39BZS3ldm/MZ1BJLU88t1zFut0gpZ02QsnKD/XChsO0RjN1krqxzKFXmkQ\n/TNVJQfy/jA8oOHQDvbLGMRZ4fxCjm+py8f4kWTo7cMiMrc7WDV0JxLehIViDaUG\nLxQGZRerxi+1HHXlWzySVn4ywJo+wWYlWJossHTP4hvpCsFyahbaYiCNoNY74Tam\nfTyv8tEB85khSQb3F4kC9grJ/KrVUsgn1JCyykfT/bo1AnLaB5UAR75hFKgHCyQv\nKEMcLQ8u1W63bxK+sCAA5gUErzL6FbAPnYioqEtLO6ra9uDglcySEZZ3bVZq32av\ncn1bMHeAfCz165lJ6BT4E00AhXZIC7Tc3UnvH4OolYbsmjPBjqcp/ehXYbp4ZJmE\nHSsx52Eb+26KnZJv2guN40m/1rVSfoCo9e0Lbr3otKxBR41UUrD6PVlLFzIKRg4O\nbHQRW6FYwb9bW9CRtwzFcrVvU3X7qYIk5Ybdm30O0/3iY5vra3ZglkstMuCC6ZVK\ncB8SStPnp/bA/7+P3szribfg68/cu7A15Pd90+ly/0Y4uzs75UhR1tgrboFFIwBB\nkWdi9sqbQjPJj0cVe/7YE4+jQBTDVmPnYbgpDF7bjovlH3rHbkQ=\n=a0Fo\n-----END PGP SIGNATURE-----",
                    "payload": "tree 776eb8326042c953a37e58ddcef9dc1fe880dd5b\nparent df0ae16bbd3ecb59203d30fe88571ead598788b4\nauthor Yangze Guo <karmagyz@gmail.com> 1621245738 +0800\ncommitter Xintong Song <tonysong820@gmail.com> 1622704778 +0800\n\n[FLINK-22683][runtime] Fix the null or incorrect value of total Flink/process memory in creating TaskExecutorMemoryConfiguration\n\nThis closes #15936\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/2ea2f9f3bc21cfdaeec732d0c692eafa68665b2c",
            "html_url": "https://github.com/apache/flink/commit/2ea2f9f3bc21cfdaeec732d0c692eafa68665b2c",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/2ea2f9f3bc21cfdaeec732d0c692eafa68665b2c/comments",
            "author": {
                "login": "KarmaGYZ",
                "id": 8684799,
                "node_id": "MDQ6VXNlcjg2ODQ3OTk=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8684799?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/KarmaGYZ",
                "html_url": "https://github.com/KarmaGYZ",
                "followers_url": "https://api.github.com/users/KarmaGYZ/followers",
                "following_url": "https://api.github.com/users/KarmaGYZ/following{/other_user}",
                "gists_url": "https://api.github.com/users/KarmaGYZ/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/KarmaGYZ/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/KarmaGYZ/subscriptions",
                "organizations_url": "https://api.github.com/users/KarmaGYZ/orgs",
                "repos_url": "https://api.github.com/users/KarmaGYZ/repos",
                "events_url": "https://api.github.com/users/KarmaGYZ/events{/privacy}",
                "received_events_url": "https://api.github.com/users/KarmaGYZ/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "xintongsong",
                "id": 6509172,
                "node_id": "MDQ6VXNlcjY1MDkxNzI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6509172?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/xintongsong",
                "html_url": "https://github.com/xintongsong",
                "followers_url": "https://api.github.com/users/xintongsong/followers",
                "following_url": "https://api.github.com/users/xintongsong/following{/other_user}",
                "gists_url": "https://api.github.com/users/xintongsong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/xintongsong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/xintongsong/subscriptions",
                "organizations_url": "https://api.github.com/users/xintongsong/orgs",
                "repos_url": "https://api.github.com/users/xintongsong/repos",
                "events_url": "https://api.github.com/users/xintongsong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/xintongsong/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "df0ae16bbd3ecb59203d30fe88571ead598788b4",
                "url": "https://api.github.com/repos/apache/flink/commits/df0ae16bbd3ecb59203d30fe88571ead598788b4",
                "html_url": "https://github.com/apache/flink/commit/df0ae16bbd3ecb59203d30fe88571ead598788b4"
            }]
        },
        {
            "sha": "f82ffc337f7c028adade17e55f9fda57e7b48863",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZjgyZmZjMzM3ZjdjMDI4YWRhZGUxN2U1NWY5ZmRhNTdlN2I0ODg2Mw==",
            "commit": {
                "author": {
                    "name": "Fabian Paul",
                    "email": "fabianpaul@ververica.com",
                    "date": "2021-06-02T14:18:31Z"
                },
                "committer": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-06-03T07:29:28Z"
                },
                "message": "[FLINK-22820] Allow storing SUSPENDED jobs in FileExecutionGraphInfoStore",
                "tree": {
                    "sha": "0cb6cc139ea8a991327fa91cb0914570d99a8fc9",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/0cb6cc139ea8a991327fa91cb0914570d99a8fc9"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/f82ffc337f7c028adade17e55f9fda57e7b48863",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/f82ffc337f7c028adade17e55f9fda57e7b48863",
            "html_url": "https://github.com/apache/flink/commit/f82ffc337f7c028adade17e55f9fda57e7b48863",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/f82ffc337f7c028adade17e55f9fda57e7b48863/comments",
            "author": {
                "login": "fapaul",
                "id": 7405553,
                "node_id": "MDQ6VXNlcjc0MDU1NTM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/7405553?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/fapaul",
                "html_url": "https://github.com/fapaul",
                "followers_url": "https://api.github.com/users/fapaul/followers",
                "following_url": "https://api.github.com/users/fapaul/following{/other_user}",
                "gists_url": "https://api.github.com/users/fapaul/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/fapaul/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/fapaul/subscriptions",
                "organizations_url": "https://api.github.com/users/fapaul/orgs",
                "repos_url": "https://api.github.com/users/fapaul/repos",
                "events_url": "https://api.github.com/users/fapaul/events{/privacy}",
                "received_events_url": "https://api.github.com/users/fapaul/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "2ea2f9f3bc21cfdaeec732d0c692eafa68665b2c",
                "url": "https://api.github.com/repos/apache/flink/commits/2ea2f9f3bc21cfdaeec732d0c692eafa68665b2c",
                "html_url": "https://github.com/apache/flink/commit/2ea2f9f3bc21cfdaeec732d0c692eafa68665b2c"
            }]
        },
        {
            "sha": "c4227cc2237373592cbfe4357a9a9223c516ae66",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6YzQyMjdjYzIyMzczNzM1OTJjYmZlNDM1N2E5YTkyMjNjNTE2YWU2Ng==",
            "commit": {
                "author": {
                    "name": "Dawid Wysakowicz",
                    "email": "dwysakowicz@apache.org",
                    "date": "2021-05-28T07:39:09Z"
                },
                "committer": {
                    "name": "Dawid Wysakowicz",
                    "email": "dwysakowicz@apache.org",
                    "date": "2021-06-03T07:37:02Z"
                },
                "message": "[FLINK-22815][checkpointing] Disable unaligned checkpoints for broadcast partitioning\n\nBroadcast partitioning can not work with unaligned checkpointing. There\nis no guarantees that records are consumed at the same rate in all\nchannels. This can result in some tasks applying state changes\ncorresponding to a certain broadcasted event while others don't. In turn\nupon restore it may lead to an unconsistent state.",
                "tree": {
                    "sha": "12096817005192a2e82a7c9fe51ca39f0b4adb78",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/12096817005192a2e82a7c9fe51ca39f0b4adb78"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/c4227cc2237373592cbfe4357a9a9223c516ae66",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEE6pOkNbTiybTJ9TP2MdLdEL/BWi0FAmC4hp4ACgkQMdLdEL/B\nWi18GQ/8Ck5iVH19LDr02OvV0mT5ke1hInUZ9qzhBh6TmblZMdKmk9F/bCbEO20W\nwr1tvRpHYFq0L0h+9xkgTalXYr8+Rb2AedYcnl6t9BuxTQhkETfPLOLYZX9FFtgj\nveCR2hL6iPK/uKxhMgaBiw6dNZvphfbxxAOpaqCzZCRtWqWTFVujA8HeyDMN6PUX\nfAncYnb6S/8vI2LSx8JSYmTac0VzgQch+fwJyVTDaqDvXxH2pm+/Guxk2yO2B/yd\nzWsi6ueRMIHmJjSFpOirDncw6aXMXVbYF013JBamuvFFPADrU3N74h75pg3GSdfc\nhAsQCDrhPxVdyU9mhQ2x9NBVkRQ+SF5TIFVnIx31GjM8mW/c6lFldwi9nbFNulkc\n1QRwBh06AfmHXMjdJoTMmldD+oXj2cT8u5EIvMhPnBP2zXIVDIZBHkzULuShQS4g\nA86NYElVprlYjqvsz0OQ8CftSDhutVjd+9PGxtPbfsVOJlfuX42v1vwU88QAF8fX\n1bJO0+U9eC8zuFeSMdSiJbaxJqZPCwEVW1r+R49i2eyna9LndLwskYz1HJa95q+4\nsyzZ6W0z8XTTx3uBSWbQcLg/6+KEw1YsU7QNg7SFMRzzum+n0EyQqOJyzVICxCN6\nO2/etr6WXth6tLw+Ks1b+vDuoYjOnWMyI7gB8lJwbIj/mskQNXs=\n=l43A\n-----END PGP SIGNATURE-----",
                    "payload": "tree 12096817005192a2e82a7c9fe51ca39f0b4adb78\nparent f82ffc337f7c028adade17e55f9fda57e7b48863\nauthor Dawid Wysakowicz <dwysakowicz@apache.org> 1622187549 +0200\ncommitter Dawid Wysakowicz <dwysakowicz@apache.org> 1622705822 +0200\n\n[FLINK-22815][checkpointing] Disable unaligned checkpoints for broadcast partitioning\n\nBroadcast partitioning can not work with unaligned checkpointing. There\nis no guarantees that records are consumed at the same rate in all\nchannels. This can result in some tasks applying state changes\ncorresponding to a certain broadcasted event while others don't. In turn\nupon restore it may lead to an unconsistent state.\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/c4227cc2237373592cbfe4357a9a9223c516ae66",
            "html_url": "https://github.com/apache/flink/commit/c4227cc2237373592cbfe4357a9a9223c516ae66",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/c4227cc2237373592cbfe4357a9a9223c516ae66/comments",
            "author": {
                "login": "dawidwys",
                "id": 6242259,
                "node_id": "MDQ6VXNlcjYyNDIyNTk=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6242259?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dawidwys",
                "html_url": "https://github.com/dawidwys",
                "followers_url": "https://api.github.com/users/dawidwys/followers",
                "following_url": "https://api.github.com/users/dawidwys/following{/other_user}",
                "gists_url": "https://api.github.com/users/dawidwys/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dawidwys/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dawidwys/subscriptions",
                "organizations_url": "https://api.github.com/users/dawidwys/orgs",
                "repos_url": "https://api.github.com/users/dawidwys/repos",
                "events_url": "https://api.github.com/users/dawidwys/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dawidwys/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "dawidwys",
                "id": 6242259,
                "node_id": "MDQ6VXNlcjYyNDIyNTk=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6242259?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dawidwys",
                "html_url": "https://github.com/dawidwys",
                "followers_url": "https://api.github.com/users/dawidwys/followers",
                "following_url": "https://api.github.com/users/dawidwys/following{/other_user}",
                "gists_url": "https://api.github.com/users/dawidwys/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dawidwys/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dawidwys/subscriptions",
                "organizations_url": "https://api.github.com/users/dawidwys/orgs",
                "repos_url": "https://api.github.com/users/dawidwys/repos",
                "events_url": "https://api.github.com/users/dawidwys/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dawidwys/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "f82ffc337f7c028adade17e55f9fda57e7b48863",
                "url": "https://api.github.com/repos/apache/flink/commits/f82ffc337f7c028adade17e55f9fda57e7b48863",
                "html_url": "https://github.com/apache/flink/commit/f82ffc337f7c028adade17e55f9fda57e7b48863"
            }]
        },
        {
            "sha": "fec1ccea059d53ad70a3f905a20815d069c665a6",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZmVjMWNjZWEwNTlkNTNhZDcwYTNmOTA1YTIwODE1ZDA2OWM2NjVhNg==",
            "commit": {
                "author": {
                    "name": "Dawid Wysakowicz",
                    "email": "dwysakowicz@apache.org",
                    "date": "2021-05-28T09:07:51Z"
                },
                "committer": {
                    "name": "Dawid Wysakowicz",
                    "email": "dwysakowicz@apache.org",
                    "date": "2021-06-03T07:37:02Z"
                },
                "message": "[FLINK-22815][checkpointing] Remove SubtaskStateMapper.DISCARD_EXTRA_STATE which does\nnot work\n\nThe mapping implemented via DISCARD_EXTRA_STATE is not supported on the\nnetwork level. At the same time there is no use for that mapping. It's\nbetter to remove the mapper for now, so that it is not used by mistake.",
                "tree": {
                    "sha": "58e11a033d3ad0a700f2c3dd5ccdacce9efd1cbb",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/58e11a033d3ad0a700f2c3dd5ccdacce9efd1cbb"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/fec1ccea059d53ad70a3f905a20815d069c665a6",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEE6pOkNbTiybTJ9TP2MdLdEL/BWi0FAmC4hp4ACgkQMdLdEL/B\nWi3lURAAo3feTWhOGL3VPSvVWL/iY9BpTTo4ELXHkN7cejYtder9+j+pFG9QRrry\noLZeuA/Adb+Wxh0PovDJ5Pp21RHaGsZWEyz1v64UzjkLSTVjHvuPDUDUPj9pJgca\nqmNKeUYFPXwl8iE+eb0FU8IcSpGOMur/mFisN5nYfxf6wk/F0gn3RX5gP5ZGXK7/\ncJrcPygA2DztzaAvI3ldGq9xBcAPRpTu45OBGJYimIQUsw0yCylLNEcJIQ5oZ01n\nV8Q34SkjhhT7/rgDjFJJTGFURCfmVzKRmNLOVC+e2atXPD1hPiq/s799Y4R4Sx/0\ndjzZ0L+187o2iwH01BpVmzXU02pStvtKtFqSNHEwjUJkocFaHxGIu81UO7lxkAEa\nP8SwHcbm44uujN/3/VZMrZq/r5eKOzl/q8BIW0XSP+sBCSeDhHROGQsViwvI/wcA\nXMhAI6SGM+UBAz1wtaBwptpqjvj8iUZ7fhZbmOA1/gSmUeQGFcSWyyi2xZ8ss7pR\nJi5zSqyQqj1b1I9vjwdJnAbaaVEqxbWzgoaQ8o2EAX8KHYCYXultA853ygkpjPtH\nJ7+8Quo3kJaN50bLJGpMSMz+2D9f/sYJZ79VDBXegZ885zrZ+nevifx1L+v2OIxG\nrtZbP/n3Zck+1MjU6BF+iifHZTGXx/mfJ8yMUw6CoR5m4dtPfTY=\n=fIGt\n-----END PGP SIGNATURE-----",
                    "payload": "tree 58e11a033d3ad0a700f2c3dd5ccdacce9efd1cbb\nparent c4227cc2237373592cbfe4357a9a9223c516ae66\nauthor Dawid Wysakowicz <dwysakowicz@apache.org> 1622192871 +0200\ncommitter Dawid Wysakowicz <dwysakowicz@apache.org> 1622705822 +0200\n\n[FLINK-22815][checkpointing] Remove SubtaskStateMapper.DISCARD_EXTRA_STATE which does\nnot work\n\nThe mapping implemented via DISCARD_EXTRA_STATE is not supported on the\nnetwork level. At the same time there is no use for that mapping. It's\nbetter to remove the mapper for now, so that it is not used by mistake.\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/fec1ccea059d53ad70a3f905a20815d069c665a6",
            "html_url": "https://github.com/apache/flink/commit/fec1ccea059d53ad70a3f905a20815d069c665a6",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/fec1ccea059d53ad70a3f905a20815d069c665a6/comments",
            "author": {
                "login": "dawidwys",
                "id": 6242259,
                "node_id": "MDQ6VXNlcjYyNDIyNTk=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6242259?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dawidwys",
                "html_url": "https://github.com/dawidwys",
                "followers_url": "https://api.github.com/users/dawidwys/followers",
                "following_url": "https://api.github.com/users/dawidwys/following{/other_user}",
                "gists_url": "https://api.github.com/users/dawidwys/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dawidwys/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dawidwys/subscriptions",
                "organizations_url": "https://api.github.com/users/dawidwys/orgs",
                "repos_url": "https://api.github.com/users/dawidwys/repos",
                "events_url": "https://api.github.com/users/dawidwys/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dawidwys/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "dawidwys",
                "id": 6242259,
                "node_id": "MDQ6VXNlcjYyNDIyNTk=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6242259?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dawidwys",
                "html_url": "https://github.com/dawidwys",
                "followers_url": "https://api.github.com/users/dawidwys/followers",
                "following_url": "https://api.github.com/users/dawidwys/following{/other_user}",
                "gists_url": "https://api.github.com/users/dawidwys/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dawidwys/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dawidwys/subscriptions",
                "organizations_url": "https://api.github.com/users/dawidwys/orgs",
                "repos_url": "https://api.github.com/users/dawidwys/repos",
                "events_url": "https://api.github.com/users/dawidwys/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dawidwys/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "c4227cc2237373592cbfe4357a9a9223c516ae66",
                "url": "https://api.github.com/repos/apache/flink/commits/c4227cc2237373592cbfe4357a9a9223c516ae66",
                "html_url": "https://github.com/apache/flink/commit/c4227cc2237373592cbfe4357a9a9223c516ae66"
            }]
        },
        {
            "sha": "8004830b1997f9111e9b1c1fa8a56b8ff3b37c91",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ODAwNDgzMGIxOTk3ZjkxMTFlOWIxYzFmYThhNTZiOGZmM2IzN2M5MQ==",
            "commit": {
                "author": {
                    "name": "Dawid Wysakowicz",
                    "email": "dwysakowicz@apache.org",
                    "date": "2021-05-28T08:24:06Z"
                },
                "committer": {
                    "name": "Dawid Wysakowicz",
                    "email": "dwysakowicz@apache.org",
                    "date": "2021-06-03T07:37:02Z"
                },
                "message": "[hotfix] Disable TRACE network logging in UnalignedCheckpointTestBase",
                "tree": {
                    "sha": "97abda4d4a16213a8c3039498dda0482c5c24a83",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/97abda4d4a16213a8c3039498dda0482c5c24a83"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/8004830b1997f9111e9b1c1fa8a56b8ff3b37c91",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEE6pOkNbTiybTJ9TP2MdLdEL/BWi0FAmC4hp4ACgkQMdLdEL/B\nWi3baBAAs1QaSOH69x3R7+r5ABZ95UXbt57q/GIks7aM3B3HtnGClre79yTX+4un\ndthiB64ajj/SY6QQgUIQ62Vyc91JaF+olEveHSZJ1sv4gUkWJx/P1wRFu+awdKMv\n5FcDzQTfrw/O/pNnBvBcW4rO4mDojhhuJDg1rsCvuktICqWvKof5FuugQnZ+UfrS\n9vrswBBDrWs9MzYFG1yI70M7xda1GeijIGg1/qx972teV/Es+hCMIsPFbL6jaJvH\ngh4kKRRkMwed6RvaBUC9c2dqOrrHa2WjK1LcWxZ6Xs/0kd0V381BzyzD00Ph7Eei\nQTDs3WdXSqkY8DdjSc4uenwp7TmcIToCjo3ukIrhNcmI9w3e+VyYDqxBtDFlVPSC\nMGhMYGGFaVrRJ93rWkCdM8ZXmcYXgutIuo390WEAWT6GJwxxIi2Ba5EyUB+Va66j\nGLq57U73xShTR6iu/hIrtnsOjFgpzZsUcnzuEvfTK6xE+nTa3ERwd8b9WmTymhO9\nkiCLWCXh2WOXidiF3RUp7I7PWcF4wbMnOEebv8MLwNbDHsY1g7PGi/rAUJ/+CNC8\nY0Y+5NU0VGZI6KGk+jiz5aOoZ9OHWi1G0VVFbGGi2eaixhdqckyED4pZtTbY/UWS\nUOlbiPAH/Z183ZCPP0a6kFjYvD3399BJtAHxvclNEuGGCvqASS8=\n=o5Ks\n-----END PGP SIGNATURE-----",
                    "payload": "tree 97abda4d4a16213a8c3039498dda0482c5c24a83\nparent fec1ccea059d53ad70a3f905a20815d069c665a6\nauthor Dawid Wysakowicz <dwysakowicz@apache.org> 1622190246 +0200\ncommitter Dawid Wysakowicz <dwysakowicz@apache.org> 1622705822 +0200\n\n[hotfix] Disable TRACE network logging in UnalignedCheckpointTestBase\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/8004830b1997f9111e9b1c1fa8a56b8ff3b37c91",
            "html_url": "https://github.com/apache/flink/commit/8004830b1997f9111e9b1c1fa8a56b8ff3b37c91",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/8004830b1997f9111e9b1c1fa8a56b8ff3b37c91/comments",
            "author": {
                "login": "dawidwys",
                "id": 6242259,
                "node_id": "MDQ6VXNlcjYyNDIyNTk=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6242259?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dawidwys",
                "html_url": "https://github.com/dawidwys",
                "followers_url": "https://api.github.com/users/dawidwys/followers",
                "following_url": "https://api.github.com/users/dawidwys/following{/other_user}",
                "gists_url": "https://api.github.com/users/dawidwys/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dawidwys/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dawidwys/subscriptions",
                "organizations_url": "https://api.github.com/users/dawidwys/orgs",
                "repos_url": "https://api.github.com/users/dawidwys/repos",
                "events_url": "https://api.github.com/users/dawidwys/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dawidwys/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "dawidwys",
                "id": 6242259,
                "node_id": "MDQ6VXNlcjYyNDIyNTk=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6242259?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dawidwys",
                "html_url": "https://github.com/dawidwys",
                "followers_url": "https://api.github.com/users/dawidwys/followers",
                "following_url": "https://api.github.com/users/dawidwys/following{/other_user}",
                "gists_url": "https://api.github.com/users/dawidwys/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dawidwys/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dawidwys/subscriptions",
                "organizations_url": "https://api.github.com/users/dawidwys/orgs",
                "repos_url": "https://api.github.com/users/dawidwys/repos",
                "events_url": "https://api.github.com/users/dawidwys/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dawidwys/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "fec1ccea059d53ad70a3f905a20815d069c665a6",
                "url": "https://api.github.com/repos/apache/flink/commits/fec1ccea059d53ad70a3f905a20815d069c665a6",
                "html_url": "https://github.com/apache/flink/commit/fec1ccea059d53ad70a3f905a20815d069c665a6"
            }]
        },
        {
            "sha": "8327f4486841cd1d6beb05418e6d4206a6f4858b",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ODMyN2Y0NDg2ODQxY2QxZDZiZWIwNTQxOGU2ZDQyMDZhNmY0ODU4Yg==",
            "commit": {
                "author": {
                    "name": "Dawid Wysakowicz",
                    "email": "dwysakowicz@apache.org",
                    "date": "2021-05-20T06:58:00Z"
                },
                "committer": {
                    "name": "Dawid Wysakowicz",
                    "email": "dwysakowicz@apache.org",
                    "date": "2021-06-03T07:37:02Z"
                },
                "message": "[FLINK-22686][checkpointing] Incompatible subtask mappings while resuming from unaligned checkpoints\n\nIn the initial implementation of rescaling channel data we assumed that\nthe subtasks indices are the same for all input gates. This assumptions\ndoes not hold when there are different partitioners. It can happen e.g.\nin case of a broadcast with a keyed input.\n\nThe commit tracks the subtask indices separately for each partition and\ninput gate.\n\nThis closes #16019",
                "tree": {
                    "sha": "ae6764a58135c04322eedcbc18c38d3548d1f00a",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/ae6764a58135c04322eedcbc18c38d3548d1f00a"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/8327f4486841cd1d6beb05418e6d4206a6f4858b",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEE6pOkNbTiybTJ9TP2MdLdEL/BWi0FAmC4hp4ACgkQMdLdEL/B\nWi3iPg/+NUOtE0IkWMxbM9nGx2vtDvslcRLtluYKxVKKQgsqh0pviI5i+yOToDyi\nbbXDVv2S2txmhtUMHyt9bMk1mpdJ5XAu6oS+eRy91p2nrHSX1iSlX0HARevxdZLE\nwbPnQb/cbooHE+Ag43TCs6hwcGol1LD/3PNOo61m8cA7HtObmxL6jfD0yU1U1Cww\nTNYWqqJ0J4jBMo0IxzwaQXpEpuilzU6iEaBQKKzkTr6ZLAVPZbQJgFaqN/rImZmx\nfkEVDSyr92KFWyHx/Rpw6Rtmlmbw+6ybHUZWmmVwqzvEQTIHTUnyjSFiqcQ0fsN5\nUflZkrWP3cIRjVXDKDJcezHTQschHE9Bh7uTy+JZgmngO1XLSrYmKxUktY31Fb6U\npTuZRLGKXbI6ncgR+5rOniBdrnk/y0WxogigkCBQfmcs1kCyCKcnMsrHkiS74epr\n74NiUAr1oO9FmZkWDOpXrWUDQrVp61v/AvogDV9nCl0NnD49ghRJWUuSw7rI7nk4\nBNLvCgtz6xjF3VA3qiIQ169CMlKK+S3BrUZ5ynyRA352tTD61xiTDVyT+gkQcmqS\n3m28y5F+/+X+Q2v/pzuVa8KnXb8hdSubtZE45f6CCxv2Thy1ZKUOFY/R+SIi1Yo1\n4xcFFx/mtP+2+Gg71RyA2Yh7X1fChWZFmWoMWOfgmrteMEms3mI=\n=qrLf\n-----END PGP SIGNATURE-----",
                    "payload": "tree ae6764a58135c04322eedcbc18c38d3548d1f00a\nparent 8004830b1997f9111e9b1c1fa8a56b8ff3b37c91\nauthor Dawid Wysakowicz <dwysakowicz@apache.org> 1621493880 +0200\ncommitter Dawid Wysakowicz <dwysakowicz@apache.org> 1622705822 +0200\n\n[FLINK-22686][checkpointing] Incompatible subtask mappings while resuming from unaligned checkpoints\n\nIn the initial implementation of rescaling channel data we assumed that\nthe subtasks indices are the same for all input gates. This assumptions\ndoes not hold when there are different partitioners. It can happen e.g.\nin case of a broadcast with a keyed input.\n\nThe commit tracks the subtask indices separately for each partition and\ninput gate.\n\nThis closes #16019\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/8327f4486841cd1d6beb05418e6d4206a6f4858b",
            "html_url": "https://github.com/apache/flink/commit/8327f4486841cd1d6beb05418e6d4206a6f4858b",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/8327f4486841cd1d6beb05418e6d4206a6f4858b/comments",
            "author": {
                "login": "dawidwys",
                "id": 6242259,
                "node_id": "MDQ6VXNlcjYyNDIyNTk=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6242259?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dawidwys",
                "html_url": "https://github.com/dawidwys",
                "followers_url": "https://api.github.com/users/dawidwys/followers",
                "following_url": "https://api.github.com/users/dawidwys/following{/other_user}",
                "gists_url": "https://api.github.com/users/dawidwys/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dawidwys/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dawidwys/subscriptions",
                "organizations_url": "https://api.github.com/users/dawidwys/orgs",
                "repos_url": "https://api.github.com/users/dawidwys/repos",
                "events_url": "https://api.github.com/users/dawidwys/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dawidwys/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "dawidwys",
                "id": 6242259,
                "node_id": "MDQ6VXNlcjYyNDIyNTk=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6242259?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dawidwys",
                "html_url": "https://github.com/dawidwys",
                "followers_url": "https://api.github.com/users/dawidwys/followers",
                "following_url": "https://api.github.com/users/dawidwys/following{/other_user}",
                "gists_url": "https://api.github.com/users/dawidwys/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dawidwys/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dawidwys/subscriptions",
                "organizations_url": "https://api.github.com/users/dawidwys/orgs",
                "repos_url": "https://api.github.com/users/dawidwys/repos",
                "events_url": "https://api.github.com/users/dawidwys/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dawidwys/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "8004830b1997f9111e9b1c1fa8a56b8ff3b37c91",
                "url": "https://api.github.com/repos/apache/flink/commits/8004830b1997f9111e9b1c1fa8a56b8ff3b37c91",
                "html_url": "https://github.com/apache/flink/commit/8004830b1997f9111e9b1c1fa8a56b8ff3b37c91"
            }]
        },
        {
            "sha": "43da9f5394e1054a984f56a416566d140b752412",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NDNkYTlmNTM5NGUxMDU0YTk4NGY1NmE0MTY1NjZkMTQwYjc1MjQxMg==",
            "commit": {
                "author": {
                    "name": "Jark Wu",
                    "email": "jark@apache.org",
                    "date": "2021-06-03T11:16:42Z"
                },
                "committer": {
                    "name": "GitHub",
                    "email": "noreply@github.com",
                    "date": "2021-06-03T11:16:42Z"
                },
                "message": "[FLINK-22795][sql-client] Throw better exception when executing remote SQL file in SQL Client\n\nThis closes #16059",
                "tree": {
                    "sha": "e6e29cfd000e274b6b15bd005d4367906fa0cb66",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/e6e29cfd000e274b6b15bd005d4367906fa0cb66"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/43da9f5394e1054a984f56a416566d140b752412",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJguLoaCRBK7hj4Ov3rIwAAq70IAJjimfR/6hciNaXEPCKnRB2T\nq1Kwy7K7u+qdLKmmMbKuLcxnyjBKYHsR4D+sRHfvBTQma8jie4hbsE28rhZtTUTR\nC9ZiFjDNT5Lc8e1FivZpB3s6Bn4pvlEPXwKveQLiK534272+AhrcH8Aj6lW9N2/s\nD8TvlbJ69MwSewJpfNMEHU1hUXDE4jIzmswfYAFSF5S62Q2Nab8wQUjkRKsuB6jk\n7251rapfRroQvGc0HrCfqikh8X/p1RKE8lp+5TPFi0qVt7zAvcATjz2xv0rma7bG\nVfNLmknDvkCzYOT890hkp/N2dum6u3K/V8TyLtk8Z7qJhrZ/u4omrtfY8O1PXF0=\n=3ITo\n-----END PGP SIGNATURE-----\n",
                    "payload": "tree e6e29cfd000e274b6b15bd005d4367906fa0cb66\nparent 8327f4486841cd1d6beb05418e6d4206a6f4858b\nauthor Jark Wu <jark@apache.org> 1622719002 +0800\ncommitter GitHub <noreply@github.com> 1622719002 +0800\n\n[FLINK-22795][sql-client] Throw better exception when executing remote SQL file in SQL Client\n\nThis closes #16059"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/43da9f5394e1054a984f56a416566d140b752412",
            "html_url": "https://github.com/apache/flink/commit/43da9f5394e1054a984f56a416566d140b752412",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/43da9f5394e1054a984f56a416566d140b752412/comments",
            "author": {
                "login": "wuchong",
                "id": 5378924,
                "node_id": "MDQ6VXNlcjUzNzg5MjQ=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5378924?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/wuchong",
                "html_url": "https://github.com/wuchong",
                "followers_url": "https://api.github.com/users/wuchong/followers",
                "following_url": "https://api.github.com/users/wuchong/following{/other_user}",
                "gists_url": "https://api.github.com/users/wuchong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/wuchong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/wuchong/subscriptions",
                "organizations_url": "https://api.github.com/users/wuchong/orgs",
                "repos_url": "https://api.github.com/users/wuchong/repos",
                "events_url": "https://api.github.com/users/wuchong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/wuchong/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "web-flow",
                "id": 19864447,
                "node_id": "MDQ6VXNlcjE5ODY0NDQ3",
                "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/web-flow",
                "html_url": "https://github.com/web-flow",
                "followers_url": "https://api.github.com/users/web-flow/followers",
                "following_url": "https://api.github.com/users/web-flow/following{/other_user}",
                "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions",
                "organizations_url": "https://api.github.com/users/web-flow/orgs",
                "repos_url": "https://api.github.com/users/web-flow/repos",
                "events_url": "https://api.github.com/users/web-flow/events{/privacy}",
                "received_events_url": "https://api.github.com/users/web-flow/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "8327f4486841cd1d6beb05418e6d4206a6f4858b",
                "url": "https://api.github.com/repos/apache/flink/commits/8327f4486841cd1d6beb05418e6d4206a6f4858b",
                "html_url": "https://github.com/apache/flink/commit/8327f4486841cd1d6beb05418e6d4206a6f4858b"
            }]
        },
        {
            "sha": "70765dafb2af5a1ed2ff6ca6864e40ea71290006",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NzA3NjVkYWZiMmFmNWExZWQyZmY2Y2E2ODY0ZTQwZWE3MTI5MDAwNg==",
            "commit": {
                "author": {
                    "name": "hameizi",
                    "email": "1249369293@qq.com",
                    "date": "2021-06-04T02:59:20Z"
                },
                "committer": {
                    "name": "Rui Li",
                    "email": "lirui@apache.org",
                    "date": "2021-06-04T08:57:55Z"
                },
                "message": "[FLINK-22272][hive] HiveCatalog should allow getting generic table with empty schema\n\nThis closes #15638",
                "tree": {
                    "sha": "556df7bccd8c67896778d960847c1b6cb5a60fcc",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/556df7bccd8c67896778d960847c1b6cb5a60fcc"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/70765dafb2af5a1ed2ff6ca6864e40ea71290006",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/70765dafb2af5a1ed2ff6ca6864e40ea71290006",
            "html_url": "https://github.com/apache/flink/commit/70765dafb2af5a1ed2ff6ca6864e40ea71290006",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/70765dafb2af5a1ed2ff6ca6864e40ea71290006/comments",
            "author": {
                "login": "hameizi",
                "id": 18445460,
                "node_id": "MDQ6VXNlcjE4NDQ1NDYw",
                "avatar_url": "https://avatars.githubusercontent.com/u/18445460?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/hameizi",
                "html_url": "https://github.com/hameizi",
                "followers_url": "https://api.github.com/users/hameizi/followers",
                "following_url": "https://api.github.com/users/hameizi/following{/other_user}",
                "gists_url": "https://api.github.com/users/hameizi/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/hameizi/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/hameizi/subscriptions",
                "organizations_url": "https://api.github.com/users/hameizi/orgs",
                "repos_url": "https://api.github.com/users/hameizi/repos",
                "events_url": "https://api.github.com/users/hameizi/events{/privacy}",
                "received_events_url": "https://api.github.com/users/hameizi/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "lirui-apache",
                "id": 5210788,
                "node_id": "MDQ6VXNlcjUyMTA3ODg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5210788?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/lirui-apache",
                "html_url": "https://github.com/lirui-apache",
                "followers_url": "https://api.github.com/users/lirui-apache/followers",
                "following_url": "https://api.github.com/users/lirui-apache/following{/other_user}",
                "gists_url": "https://api.github.com/users/lirui-apache/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/lirui-apache/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/lirui-apache/subscriptions",
                "organizations_url": "https://api.github.com/users/lirui-apache/orgs",
                "repos_url": "https://api.github.com/users/lirui-apache/repos",
                "events_url": "https://api.github.com/users/lirui-apache/events{/privacy}",
                "received_events_url": "https://api.github.com/users/lirui-apache/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "43da9f5394e1054a984f56a416566d140b752412",
                "url": "https://api.github.com/repos/apache/flink/commits/43da9f5394e1054a984f56a416566d140b752412",
                "html_url": "https://github.com/apache/flink/commit/43da9f5394e1054a984f56a416566d140b752412"
            }]
        },
        {
            "sha": "6f774c9db8c33c86ce81cccd68beb7a2e096c177",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NmY3NzRjOWRiOGMzM2M4NmNlODFjY2NkNjhiZWI3YTJlMDk2YzE3Nw==",
            "commit": {
                "author": {
                    "name": "Thesharing",
                    "email": "cyprestar@outlook.com",
                    "date": "2021-06-03T12:09:11Z"
                },
                "committer": {
                    "name": "Zhu Zhu",
                    "email": "reedpor@gmail.com",
                    "date": "2021-06-04T09:26:12Z"
                },
                "message": "[FLINK-22863][runtime] Fix ArrayIndexOutOfBoundsException when building rescale edges in EdgeManagerBuildUtil\n\nThis closes #16071",
                "tree": {
                    "sha": "ea8d8d8ddde667b749bfe8716a4df96685911eec",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/ea8d8d8ddde667b749bfe8716a4df96685911eec"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/6f774c9db8c33c86ce81cccd68beb7a2e096c177",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/6f774c9db8c33c86ce81cccd68beb7a2e096c177",
            "html_url": "https://github.com/apache/flink/commit/6f774c9db8c33c86ce81cccd68beb7a2e096c177",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/6f774c9db8c33c86ce81cccd68beb7a2e096c177/comments",
            "author": {
                "login": "Thesharing",
                "id": 6576831,
                "node_id": "MDQ6VXNlcjY1NzY4MzE=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6576831?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/Thesharing",
                "html_url": "https://github.com/Thesharing",
                "followers_url": "https://api.github.com/users/Thesharing/followers",
                "following_url": "https://api.github.com/users/Thesharing/following{/other_user}",
                "gists_url": "https://api.github.com/users/Thesharing/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/Thesharing/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/Thesharing/subscriptions",
                "organizations_url": "https://api.github.com/users/Thesharing/orgs",
                "repos_url": "https://api.github.com/users/Thesharing/repos",
                "events_url": "https://api.github.com/users/Thesharing/events{/privacy}",
                "received_events_url": "https://api.github.com/users/Thesharing/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "zhuzhurk",
                "id": 5869249,
                "node_id": "MDQ6VXNlcjU4NjkyNDk=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5869249?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zhuzhurk",
                "html_url": "https://github.com/zhuzhurk",
                "followers_url": "https://api.github.com/users/zhuzhurk/followers",
                "following_url": "https://api.github.com/users/zhuzhurk/following{/other_user}",
                "gists_url": "https://api.github.com/users/zhuzhurk/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zhuzhurk/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zhuzhurk/subscriptions",
                "organizations_url": "https://api.github.com/users/zhuzhurk/orgs",
                "repos_url": "https://api.github.com/users/zhuzhurk/repos",
                "events_url": "https://api.github.com/users/zhuzhurk/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zhuzhurk/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "70765dafb2af5a1ed2ff6ca6864e40ea71290006",
                "url": "https://api.github.com/repos/apache/flink/commits/70765dafb2af5a1ed2ff6ca6864e40ea71290006",
                "html_url": "https://github.com/apache/flink/commit/70765dafb2af5a1ed2ff6ca6864e40ea71290006"
            }]
        },
        {
            "sha": "b73f6c40cbdbf8c50ea087644b34f8895cc733aa",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6YjczZjZjNDBjYmRiZjhjNTBlYTA4NzY0NGIzNGY4ODk1Y2M3MzNhYQ==",
            "commit": {
                "author": {
                    "name": "Roc Marshal",
                    "email": "flinker@126.com",
                    "date": "2021-06-03T02:22:53Z"
                },
                "committer": {
                    "name": "Dian Fu",
                    "email": "dianfu@apache.org",
                    "date": "2021-06-07T05:10:56Z"
                },
                "message": "[FLINK-22855][docs-zh] Translate the 'Overview of Python API' page into Chinese.\n\nThis closes #16061.",
                "tree": {
                    "sha": "8b2bd2050ffa6d66e1d0c3d0389b7c4d3540d814",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/8b2bd2050ffa6d66e1d0c3d0389b7c4d3540d814"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/b73f6c40cbdbf8c50ea087644b34f8895cc733aa",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/b73f6c40cbdbf8c50ea087644b34f8895cc733aa",
            "html_url": "https://github.com/apache/flink/commit/b73f6c40cbdbf8c50ea087644b34f8895cc733aa",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/b73f6c40cbdbf8c50ea087644b34f8895cc733aa/comments",
            "author": {
                "login": "RocMarshal",
                "id": 64569824,
                "node_id": "MDQ6VXNlcjY0NTY5ODI0",
                "avatar_url": "https://avatars.githubusercontent.com/u/64569824?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/RocMarshal",
                "html_url": "https://github.com/RocMarshal",
                "followers_url": "https://api.github.com/users/RocMarshal/followers",
                "following_url": "https://api.github.com/users/RocMarshal/following{/other_user}",
                "gists_url": "https://api.github.com/users/RocMarshal/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/RocMarshal/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/RocMarshal/subscriptions",
                "organizations_url": "https://api.github.com/users/RocMarshal/orgs",
                "repos_url": "https://api.github.com/users/RocMarshal/repos",
                "events_url": "https://api.github.com/users/RocMarshal/events{/privacy}",
                "received_events_url": "https://api.github.com/users/RocMarshal/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "dianfu",
                "id": 5466492,
                "node_id": "MDQ6VXNlcjU0NjY0OTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5466492?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dianfu",
                "html_url": "https://github.com/dianfu",
                "followers_url": "https://api.github.com/users/dianfu/followers",
                "following_url": "https://api.github.com/users/dianfu/following{/other_user}",
                "gists_url": "https://api.github.com/users/dianfu/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dianfu/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dianfu/subscriptions",
                "organizations_url": "https://api.github.com/users/dianfu/orgs",
                "repos_url": "https://api.github.com/users/dianfu/repos",
                "events_url": "https://api.github.com/users/dianfu/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dianfu/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "6f774c9db8c33c86ce81cccd68beb7a2e096c177",
                "url": "https://api.github.com/repos/apache/flink/commits/6f774c9db8c33c86ce81cccd68beb7a2e096c177",
                "html_url": "https://github.com/apache/flink/commit/6f774c9db8c33c86ce81cccd68beb7a2e096c177"
            }]
        },
        {
            "sha": "8511ecbc33e613d8554911ba8b943bf7a98ca77c",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ODUxMWVjYmMzM2U2MTNkODU1NDkxMWJhOGI5NDNiZjdhOThjYTc3Yw==",
            "commit": {
                "author": {
                    "name": "Anton Kalashnikov",
                    "email": "kaa.dev@yandex.ru",
                    "date": "2021-05-28T09:51:37Z"
                },
                "committer": {
                    "name": "Piotr Nowojski",
                    "email": "pnowojski@users.noreply.github.com",
                    "date": "2021-06-07T09:01:25Z"
                },
                "message": "[FLINK-22376][runtime] BufferProvider is able to provide pure MemorySegment in order to avoid extracting it from the bufferBuilder\n\n(cherry picked from commit 397468706943aeed4ec2cf72f846e4457e3e1cd4)",
                "tree": {
                    "sha": "8ac7c0527e31b675f492aef004c838836c2080b4",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/8ac7c0527e31b675f492aef004c838836c2080b4"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/8511ecbc33e613d8554911ba8b943bf7a98ca77c",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/8511ecbc33e613d8554911ba8b943bf7a98ca77c",
            "html_url": "https://github.com/apache/flink/commit/8511ecbc33e613d8554911ba8b943bf7a98ca77c",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/8511ecbc33e613d8554911ba8b943bf7a98ca77c/comments",
            "author": {
                "login": "akalash",
                "id": 3996532,
                "node_id": "MDQ6VXNlcjM5OTY1MzI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3996532?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/akalash",
                "html_url": "https://github.com/akalash",
                "followers_url": "https://api.github.com/users/akalash/followers",
                "following_url": "https://api.github.com/users/akalash/following{/other_user}",
                "gists_url": "https://api.github.com/users/akalash/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/akalash/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/akalash/subscriptions",
                "organizations_url": "https://api.github.com/users/akalash/orgs",
                "repos_url": "https://api.github.com/users/akalash/repos",
                "events_url": "https://api.github.com/users/akalash/events{/privacy}",
                "received_events_url": "https://api.github.com/users/akalash/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "pnowojski",
                "id": 8957547,
                "node_id": "MDQ6VXNlcjg5NTc1NDc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8957547?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/pnowojski",
                "html_url": "https://github.com/pnowojski",
                "followers_url": "https://api.github.com/users/pnowojski/followers",
                "following_url": "https://api.github.com/users/pnowojski/following{/other_user}",
                "gists_url": "https://api.github.com/users/pnowojski/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/pnowojski/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/pnowojski/subscriptions",
                "organizations_url": "https://api.github.com/users/pnowojski/orgs",
                "repos_url": "https://api.github.com/users/pnowojski/repos",
                "events_url": "https://api.github.com/users/pnowojski/events{/privacy}",
                "received_events_url": "https://api.github.com/users/pnowojski/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "b73f6c40cbdbf8c50ea087644b34f8895cc733aa",
                "url": "https://api.github.com/repos/apache/flink/commits/b73f6c40cbdbf8c50ea087644b34f8895cc733aa",
                "html_url": "https://github.com/apache/flink/commit/b73f6c40cbdbf8c50ea087644b34f8895cc733aa"
            }]
        },
        {
            "sha": "0bf1fa2cab4e352011966ff191fbabdcef3daaed",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MGJmMWZhMmNhYjRlMzUyMDExOTY2ZmYxOTFmYmFiZGNlZjNkYWFlZA==",
            "commit": {
                "author": {
                    "name": "Anton Kalashnikov",
                    "email": "kaa.dev@yandex.ru",
                    "date": "2021-05-28T09:50:12Z"
                },
                "committer": {
                    "name": "Piotr Nowojski",
                    "email": "pnowojski@users.noreply.github.com",
                    "date": "2021-06-07T09:01:25Z"
                },
                "message": "[FLINK-22376][runtime] Buffer is used inside of BufferBuilder for references counting\n\n(cherry picked from commit 1051ea9c108d4c56623013ddfd2dd866df69eaa7)",
                "tree": {
                    "sha": "bef8971b47cdc18ca86009b98368d63b7b5f3f43",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/bef8971b47cdc18ca86009b98368d63b7b5f3f43"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/0bf1fa2cab4e352011966ff191fbabdcef3daaed",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/0bf1fa2cab4e352011966ff191fbabdcef3daaed",
            "html_url": "https://github.com/apache/flink/commit/0bf1fa2cab4e352011966ff191fbabdcef3daaed",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/0bf1fa2cab4e352011966ff191fbabdcef3daaed/comments",
            "author": {
                "login": "akalash",
                "id": 3996532,
                "node_id": "MDQ6VXNlcjM5OTY1MzI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3996532?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/akalash",
                "html_url": "https://github.com/akalash",
                "followers_url": "https://api.github.com/users/akalash/followers",
                "following_url": "https://api.github.com/users/akalash/following{/other_user}",
                "gists_url": "https://api.github.com/users/akalash/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/akalash/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/akalash/subscriptions",
                "organizations_url": "https://api.github.com/users/akalash/orgs",
                "repos_url": "https://api.github.com/users/akalash/repos",
                "events_url": "https://api.github.com/users/akalash/events{/privacy}",
                "received_events_url": "https://api.github.com/users/akalash/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "pnowojski",
                "id": 8957547,
                "node_id": "MDQ6VXNlcjg5NTc1NDc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8957547?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/pnowojski",
                "html_url": "https://github.com/pnowojski",
                "followers_url": "https://api.github.com/users/pnowojski/followers",
                "following_url": "https://api.github.com/users/pnowojski/following{/other_user}",
                "gists_url": "https://api.github.com/users/pnowojski/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/pnowojski/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/pnowojski/subscriptions",
                "organizations_url": "https://api.github.com/users/pnowojski/orgs",
                "repos_url": "https://api.github.com/users/pnowojski/repos",
                "events_url": "https://api.github.com/users/pnowojski/events{/privacy}",
                "received_events_url": "https://api.github.com/users/pnowojski/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "8511ecbc33e613d8554911ba8b943bf7a98ca77c",
                "url": "https://api.github.com/repos/apache/flink/commits/8511ecbc33e613d8554911ba8b943bf7a98ca77c",
                "html_url": "https://github.com/apache/flink/commit/8511ecbc33e613d8554911ba8b943bf7a98ca77c"
            }]
        },
        {
            "sha": "79a7b6db86e68be4aa265e52210046d3265149ad",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NzlhN2I2ZGI4NmU2OGJlNGFhMjY1ZTUyMjEwMDQ2ZDMyNjUxNDlhZA==",
            "commit": {
                "author": {
                    "name": "Anton Kalashnikov",
                    "email": "kaa.dev@yandex.ru",
                    "date": "2021-06-01T14:08:47Z"
                },
                "committer": {
                    "name": "Piotr Nowojski",
                    "email": "pnowojski@users.noreply.github.com",
                    "date": "2021-06-07T09:01:25Z"
                },
                "message": "[FLINK-22376][runtime] RecoveredChannelStateHandler requires the ownership of the input Buffer\n\n(cherry picked from commit 2293362f0a144f47e182039c26c0d7047f87232a)",
                "tree": {
                    "sha": "f39d42a4a8b4a1e4c5be57a9a5fd201ecad233b2",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/f39d42a4a8b4a1e4c5be57a9a5fd201ecad233b2"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/79a7b6db86e68be4aa265e52210046d3265149ad",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/79a7b6db86e68be4aa265e52210046d3265149ad",
            "html_url": "https://github.com/apache/flink/commit/79a7b6db86e68be4aa265e52210046d3265149ad",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/79a7b6db86e68be4aa265e52210046d3265149ad/comments",
            "author": {
                "login": "akalash",
                "id": 3996532,
                "node_id": "MDQ6VXNlcjM5OTY1MzI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3996532?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/akalash",
                "html_url": "https://github.com/akalash",
                "followers_url": "https://api.github.com/users/akalash/followers",
                "following_url": "https://api.github.com/users/akalash/following{/other_user}",
                "gists_url": "https://api.github.com/users/akalash/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/akalash/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/akalash/subscriptions",
                "organizations_url": "https://api.github.com/users/akalash/orgs",
                "repos_url": "https://api.github.com/users/akalash/repos",
                "events_url": "https://api.github.com/users/akalash/events{/privacy}",
                "received_events_url": "https://api.github.com/users/akalash/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "pnowojski",
                "id": 8957547,
                "node_id": "MDQ6VXNlcjg5NTc1NDc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8957547?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/pnowojski",
                "html_url": "https://github.com/pnowojski",
                "followers_url": "https://api.github.com/users/pnowojski/followers",
                "following_url": "https://api.github.com/users/pnowojski/following{/other_user}",
                "gists_url": "https://api.github.com/users/pnowojski/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/pnowojski/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/pnowojski/subscriptions",
                "organizations_url": "https://api.github.com/users/pnowojski/orgs",
                "repos_url": "https://api.github.com/users/pnowojski/repos",
                "events_url": "https://api.github.com/users/pnowojski/events{/privacy}",
                "received_events_url": "https://api.github.com/users/pnowojski/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "0bf1fa2cab4e352011966ff191fbabdcef3daaed",
                "url": "https://api.github.com/repos/apache/flink/commits/0bf1fa2cab4e352011966ff191fbabdcef3daaed",
                "html_url": "https://github.com/apache/flink/commit/0bf1fa2cab4e352011966ff191fbabdcef3daaed"
            }]
        },
        {
            "sha": "6a2f80605b1cc2545ac1400ae6a131fb7b5093b4",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NmEyZjgwNjA1YjFjYzI1NDVhYzE0MDBhZTZhMTMxZmI3YjUwOTNiNA==",
            "commit": {
                "author": {
                    "name": "Anton Kalashnikov",
                    "email": "kaa.dev@yandex.ru",
                    "date": "2021-06-02T16:39:04Z"
                },
                "committer": {
                    "name": "Piotr Nowojski",
                    "email": "pnowojski@users.noreply.github.com",
                    "date": "2021-06-07T09:01:25Z"
                },
                "message": "[hotfix] Clarification ownerships of the buffer for Remote InputChannel#onBuffer in javadoc\n\n(cherry picked from commit bc8c739320210432128bbb486259b70a7250de9c)",
                "tree": {
                    "sha": "5803ee7f0e5e2afb10ee76669e69e45a27e1e759",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/5803ee7f0e5e2afb10ee76669e69e45a27e1e759"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/6a2f80605b1cc2545ac1400ae6a131fb7b5093b4",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/6a2f80605b1cc2545ac1400ae6a131fb7b5093b4",
            "html_url": "https://github.com/apache/flink/commit/6a2f80605b1cc2545ac1400ae6a131fb7b5093b4",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/6a2f80605b1cc2545ac1400ae6a131fb7b5093b4/comments",
            "author": {
                "login": "akalash",
                "id": 3996532,
                "node_id": "MDQ6VXNlcjM5OTY1MzI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3996532?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/akalash",
                "html_url": "https://github.com/akalash",
                "followers_url": "https://api.github.com/users/akalash/followers",
                "following_url": "https://api.github.com/users/akalash/following{/other_user}",
                "gists_url": "https://api.github.com/users/akalash/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/akalash/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/akalash/subscriptions",
                "organizations_url": "https://api.github.com/users/akalash/orgs",
                "repos_url": "https://api.github.com/users/akalash/repos",
                "events_url": "https://api.github.com/users/akalash/events{/privacy}",
                "received_events_url": "https://api.github.com/users/akalash/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "pnowojski",
                "id": 8957547,
                "node_id": "MDQ6VXNlcjg5NTc1NDc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8957547?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/pnowojski",
                "html_url": "https://github.com/pnowojski",
                "followers_url": "https://api.github.com/users/pnowojski/followers",
                "following_url": "https://api.github.com/users/pnowojski/following{/other_user}",
                "gists_url": "https://api.github.com/users/pnowojski/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/pnowojski/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/pnowojski/subscriptions",
                "organizations_url": "https://api.github.com/users/pnowojski/orgs",
                "repos_url": "https://api.github.com/users/pnowojski/repos",
                "events_url": "https://api.github.com/users/pnowojski/events{/privacy}",
                "received_events_url": "https://api.github.com/users/pnowojski/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "79a7b6db86e68be4aa265e52210046d3265149ad",
                "url": "https://api.github.com/repos/apache/flink/commits/79a7b6db86e68be4aa265e52210046d3265149ad",
                "html_url": "https://github.com/apache/flink/commit/79a7b6db86e68be4aa265e52210046d3265149ad"
            }]
        },
        {
            "sha": "00f02b8a641cdd8c67bb161c70e98451f95f7088",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MDBmMDJiOGE2NDFjZGQ4YzY3YmIxNjFjNzBlOTg0NTFmOTVmNzA4OA==",
            "commit": {
                "author": {
                    "name": "liuyanpunk",
                    "email": "liuyanpunk@hotmail.com",
                    "date": "2021-06-08T03:41:07Z"
                },
                "committer": {
                    "name": "Jark Wu",
                    "email": "jark@apache.org",
                    "date": "2021-06-08T03:42:14Z"
                },
                "message": "[FLINK-22905][docs] Fix missing comma in SQL example in \"Versioned Table\" page \n\nThis closes #16098",
                "tree": {
                    "sha": "80f12f45c40f00856dab70288ad99ebe8e14e903",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/80f12f45c40f00856dab70288ad99ebe8e14e903"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/00f02b8a641cdd8c67bb161c70e98451f95f7088",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEE4sRUF77VwQQVTzQQhbrLWu+uMgIFAmC+5xYACgkQhbrLWu+u\nMgLRRA//Qo+wWHxoJjZSSGHqN+0W49GAScn12IiXvr3/ph7++4RAQMK3dyt6h94X\nXxG+YHdRfVGwbKPp3DK9YotQZOyiMie+N+scD7912eEy75B2A9Ua4L3ctE+JSmbL\nGQ2KHl59GKa+84PU/3Md7k9h1M4zXgn8PjA+71qy9DQnvHWmIUVJa9SWSxNfxeHq\na9y9EhjtyUzf69uP3v1QrR4sC1mnrfT0rVOOBC4T3PfrUkM6iwOSWp7RG45eX8gx\nX6BwXAeRt5Yab6n5+l6F6sTnFKB4Hu/t5ZnaeA2MAhRl3AljyaJO3t2/38Ax8x4R\nwWax3F0jt5QahndB/ILGSzG2sP7zchD0VWD7uecNhsJ8w0RMteikein4gjkmtOiE\nOh5wDhSnvy1/L1L2YzPY2fhcqEOM91zEIeICvFDCBQ/ckMJvGTa67gmDN8/KAlV2\n4Z4/2nP776q06z1DTFOBJSntCuA7u9oDB0ophAZ9Y79bQwqZEVVbXxxGWcun3CUe\n5PNuLMhYKVZ+zpSvNYYGwXcsZ0AVDNZt9LZol46t4hlCJrxe6CV6qigq4RTyUYN3\nyY0CM37gWYvd1ANHAEJMp/PuIJrjv4p5xJFQDC35pMHerCI8H9u26wtDpCxDqCZi\ndPL71xtPy0IFmj/4BlmH+cYlcnRu26AM04R1JfmCk4I+Msak7rk=\n=qs0S\n-----END PGP SIGNATURE-----",
                    "payload": "tree 80f12f45c40f00856dab70288ad99ebe8e14e903\nparent 6a2f80605b1cc2545ac1400ae6a131fb7b5093b4\nauthor liuyanpunk <liuyanpunk@hotmail.com> 1623123667 +0800\ncommitter Jark Wu <jark@apache.org> 1623123734 +0800\n\n[FLINK-22905][docs] Fix missing comma in SQL example in \"Versioned Table\" page \n\nThis closes #16098"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/00f02b8a641cdd8c67bb161c70e98451f95f7088",
            "html_url": "https://github.com/apache/flink/commit/00f02b8a641cdd8c67bb161c70e98451f95f7088",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/00f02b8a641cdd8c67bb161c70e98451f95f7088/comments",
            "author": {
                "login": "liuyanpunk",
                "id": 7599397,
                "node_id": "MDQ6VXNlcjc1OTkzOTc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/7599397?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/liuyanpunk",
                "html_url": "https://github.com/liuyanpunk",
                "followers_url": "https://api.github.com/users/liuyanpunk/followers",
                "following_url": "https://api.github.com/users/liuyanpunk/following{/other_user}",
                "gists_url": "https://api.github.com/users/liuyanpunk/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/liuyanpunk/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/liuyanpunk/subscriptions",
                "organizations_url": "https://api.github.com/users/liuyanpunk/orgs",
                "repos_url": "https://api.github.com/users/liuyanpunk/repos",
                "events_url": "https://api.github.com/users/liuyanpunk/events{/privacy}",
                "received_events_url": "https://api.github.com/users/liuyanpunk/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "wuchong",
                "id": 5378924,
                "node_id": "MDQ6VXNlcjUzNzg5MjQ=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5378924?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/wuchong",
                "html_url": "https://github.com/wuchong",
                "followers_url": "https://api.github.com/users/wuchong/followers",
                "following_url": "https://api.github.com/users/wuchong/following{/other_user}",
                "gists_url": "https://api.github.com/users/wuchong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/wuchong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/wuchong/subscriptions",
                "organizations_url": "https://api.github.com/users/wuchong/orgs",
                "repos_url": "https://api.github.com/users/wuchong/repos",
                "events_url": "https://api.github.com/users/wuchong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/wuchong/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "6a2f80605b1cc2545ac1400ae6a131fb7b5093b4",
                "url": "https://api.github.com/repos/apache/flink/commits/6a2f80605b1cc2545ac1400ae6a131fb7b5093b4",
                "html_url": "https://github.com/apache/flink/commit/6a2f80605b1cc2545ac1400ae6a131fb7b5093b4"
            }]
        },
        {
            "sha": "a1dbcc9b939bbf0b2c53ecf7580882abec62c0d6",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6YTFkYmNjOWI5MzliYmYwYjJjNTNlY2Y3NTgwODgyYWJlYzYyYzBkNg==",
            "commit": {
                "author": {
                    "name": "Rui Li",
                    "email": "lirui@apache.org",
                    "date": "2021-06-07T13:07:40Z"
                },
                "committer": {
                    "name": "Rui Li",
                    "email": "lirui@apache.org",
                    "date": "2021-06-08T05:39:22Z"
                },
                "message": "[FLINK-22890][hive] HiveTestUtils should create partition after the data file is ready\n\nThis closes #16099",
                "tree": {
                    "sha": "21f71fc7f1f1899cb79221b5d739ec9a861dcdc1",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/21f71fc7f1f1899cb79221b5d739ec9a861dcdc1"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/a1dbcc9b939bbf0b2c53ecf7580882abec62c0d6",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/a1dbcc9b939bbf0b2c53ecf7580882abec62c0d6",
            "html_url": "https://github.com/apache/flink/commit/a1dbcc9b939bbf0b2c53ecf7580882abec62c0d6",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/a1dbcc9b939bbf0b2c53ecf7580882abec62c0d6/comments",
            "author": {
                "login": "lirui-apache",
                "id": 5210788,
                "node_id": "MDQ6VXNlcjUyMTA3ODg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5210788?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/lirui-apache",
                "html_url": "https://github.com/lirui-apache",
                "followers_url": "https://api.github.com/users/lirui-apache/followers",
                "following_url": "https://api.github.com/users/lirui-apache/following{/other_user}",
                "gists_url": "https://api.github.com/users/lirui-apache/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/lirui-apache/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/lirui-apache/subscriptions",
                "organizations_url": "https://api.github.com/users/lirui-apache/orgs",
                "repos_url": "https://api.github.com/users/lirui-apache/repos",
                "events_url": "https://api.github.com/users/lirui-apache/events{/privacy}",
                "received_events_url": "https://api.github.com/users/lirui-apache/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "lirui-apache",
                "id": 5210788,
                "node_id": "MDQ6VXNlcjUyMTA3ODg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5210788?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/lirui-apache",
                "html_url": "https://github.com/lirui-apache",
                "followers_url": "https://api.github.com/users/lirui-apache/followers",
                "following_url": "https://api.github.com/users/lirui-apache/following{/other_user}",
                "gists_url": "https://api.github.com/users/lirui-apache/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/lirui-apache/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/lirui-apache/subscriptions",
                "organizations_url": "https://api.github.com/users/lirui-apache/orgs",
                "repos_url": "https://api.github.com/users/lirui-apache/repos",
                "events_url": "https://api.github.com/users/lirui-apache/events{/privacy}",
                "received_events_url": "https://api.github.com/users/lirui-apache/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "00f02b8a641cdd8c67bb161c70e98451f95f7088",
                "url": "https://api.github.com/repos/apache/flink/commits/00f02b8a641cdd8c67bb161c70e98451f95f7088",
                "html_url": "https://github.com/apache/flink/commit/00f02b8a641cdd8c67bb161c70e98451f95f7088"
            }]
        },
        {
            "sha": "ed02b5deca5881ac5572228ddd1cd3e85eadfd32",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZWQwMmI1ZGVjYTU4ODFhYzU1NzIyMjhkZGQxY2QzZTg1ZWFkZmQzMg==",
            "commit": {
                "author": {
                    "name": "Robert Metzger",
                    "email": "rmetzger@apache.org",
                    "date": "2021-06-02T13:10:22Z"
                },
                "committer": {
                    "name": "Robert Metzger",
                    "email": "rmetzger@apache.org",
                    "date": "2021-06-08T09:52:59Z"
                },
                "message": "[FLINK-22856][Azure] Upgrade to ubuntu-20.04",
                "tree": {
                    "sha": "dc411c8f8124e3a67af9c456897131c944921227",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/dc411c8f8124e3a67af9c456897131c944921227"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/ed02b5deca5881ac5572228ddd1cd3e85eadfd32",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/ed02b5deca5881ac5572228ddd1cd3e85eadfd32",
            "html_url": "https://github.com/apache/flink/commit/ed02b5deca5881ac5572228ddd1cd3e85eadfd32",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/ed02b5deca5881ac5572228ddd1cd3e85eadfd32/comments",
            "author": {
                "login": "rmetzger",
                "id": 89049,
                "node_id": "MDQ6VXNlcjg5MDQ5",
                "avatar_url": "https://avatars.githubusercontent.com/u/89049?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rmetzger",
                "html_url": "https://github.com/rmetzger",
                "followers_url": "https://api.github.com/users/rmetzger/followers",
                "following_url": "https://api.github.com/users/rmetzger/following{/other_user}",
                "gists_url": "https://api.github.com/users/rmetzger/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rmetzger/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rmetzger/subscriptions",
                "organizations_url": "https://api.github.com/users/rmetzger/orgs",
                "repos_url": "https://api.github.com/users/rmetzger/repos",
                "events_url": "https://api.github.com/users/rmetzger/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rmetzger/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "rmetzger",
                "id": 89049,
                "node_id": "MDQ6VXNlcjg5MDQ5",
                "avatar_url": "https://avatars.githubusercontent.com/u/89049?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rmetzger",
                "html_url": "https://github.com/rmetzger",
                "followers_url": "https://api.github.com/users/rmetzger/followers",
                "following_url": "https://api.github.com/users/rmetzger/following{/other_user}",
                "gists_url": "https://api.github.com/users/rmetzger/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rmetzger/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rmetzger/subscriptions",
                "organizations_url": "https://api.github.com/users/rmetzger/orgs",
                "repos_url": "https://api.github.com/users/rmetzger/repos",
                "events_url": "https://api.github.com/users/rmetzger/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rmetzger/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "a1dbcc9b939bbf0b2c53ecf7580882abec62c0d6",
                "url": "https://api.github.com/repos/apache/flink/commits/a1dbcc9b939bbf0b2c53ecf7580882abec62c0d6",
                "html_url": "https://github.com/apache/flink/commit/a1dbcc9b939bbf0b2c53ecf7580882abec62c0d6"
            }]
        },
        {
            "sha": "1a55cae23b3c1e943298ca4a93cad2704994e29b",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MWE1NWNhZTIzYjNjMWU5NDMyOThjYTRhOTNjYWQyNzA0OTk0ZTI5Yg==",
            "commit": {
                "author": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-06-08T10:42:18Z"
                },
                "committer": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-06-08T15:52:48Z"
                },
                "message": "[FLINK-22496][tests] Harden ClusterEntrypointTest.testCloseAsyncShouldBeExecutedInShutdownHook\n\nHardens the ClusterEntrypointTest.testCloseAsyncShouldBeExecutedInShutdownHook by increasing the timeout from 3s to 10s.",
                "tree": {
                    "sha": "b0714c8450dbefda5a7630187f57d6ca7124d1b9",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/b0714c8450dbefda5a7630187f57d6ca7124d1b9"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/1a55cae23b3c1e943298ca4a93cad2704994e29b",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEEuUmfpp7/Xe7rw8H1un5Bh8b3PYIFAmC/klAACgkQun5Bh8b3\nPYJNsw/5ARrzgCbCVHWShYIn3VVvkppvp93ARSP/qtbOt911JXKzCmVjyJ13rZ71\nVlc2nLLs2n6Wdp2b8m1WSfAii/qmukcg3DYysrOXE1oObq7kpDRcAI5KPQtRXwfQ\n19s2stJWxC/emjhFemMDMFuoPbk0URpXeY8WagW3QotFiIcWLiNPHg5tFF1PQ5QH\nbPpu4kaXQ5nlGvuv6U8pJ9Xi3OU2xXNSTz95aakOqh1YcqytwyZFxsAq6AOfmX0R\ndOVSgWU8RUKpFytdAOwssMr/+uvUqGKTwqQdhX3GVxBwAzVWQ7L6MtaHm66tWMDc\nrvdoy/IJ3i0m35hTOTEi66+jV1AM3TXsmkXkr9UDQgRrzVlqwtCvpFV38Xsc3bSE\n8VoyDBmlQ3kc5CyHR/0+S8VlVFyOuIo5tznad70fRfevv+p4PgthQ04+qlFD5qcq\nUV+w4+lU8aFnVnY5SlW4REg4P9rTomfNR6TVAl3ca/JsFyxOT1ymHlLHb0vpo+kl\naoMBC0ErdvhK/g8yzL57P5lpAhxUfQUru6vlrLeF9qbsAqxHzDlp08XSLWuccwsj\nuueJ8jnztRukJpAznMWleOhSHTi/wgyC9YCzGXbKRzVYTtIvhBjbZZbgic+g6T6k\nEaDEY/6J58hu6q1ibg/fVbr0aI4FAuNC5remTcIg9L2vnM0O7MQ=\n=G9/q\n-----END PGP SIGNATURE-----",
                    "payload": "tree b0714c8450dbefda5a7630187f57d6ca7124d1b9\nparent ed02b5deca5881ac5572228ddd1cd3e85eadfd32\nauthor Till Rohrmann <trohrmann@apache.org> 1623148938 +0200\ncommitter Till Rohrmann <trohrmann@apache.org> 1623167568 +0200\n\n[FLINK-22496][tests] Harden ClusterEntrypointTest.testCloseAsyncShouldBeExecutedInShutdownHook\n\nHardens the ClusterEntrypointTest.testCloseAsyncShouldBeExecutedInShutdownHook by increasing the timeout from 3s to 10s.\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/1a55cae23b3c1e943298ca4a93cad2704994e29b",
            "html_url": "https://github.com/apache/flink/commit/1a55cae23b3c1e943298ca4a93cad2704994e29b",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/1a55cae23b3c1e943298ca4a93cad2704994e29b/comments",
            "author": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "ed02b5deca5881ac5572228ddd1cd3e85eadfd32",
                "url": "https://api.github.com/repos/apache/flink/commits/ed02b5deca5881ac5572228ddd1cd3e85eadfd32",
                "html_url": "https://github.com/apache/flink/commit/ed02b5deca5881ac5572228ddd1cd3e85eadfd32"
            }]
        },
        {
            "sha": "3660748b252e8de1553305dc326fc38065756951",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MzY2MDc0OGIyNTJlOGRlMTU1MzMwNWRjMzI2ZmMzODA2NTc1Njk1MQ==",
            "commit": {
                "author": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-06-08T10:52:08Z"
                },
                "committer": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-06-08T15:52:48Z"
                },
                "message": "[FLINK-22496][tests] Include log output from started process in ClusterEntrypointTest.testCloseAsyncShouldBeExecutedInShutdownHook\n\nThis closes #16111.",
                "tree": {
                    "sha": "7d60769e947cf43e4cc63b729764c139bb6e1518",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/7d60769e947cf43e4cc63b729764c139bb6e1518"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/3660748b252e8de1553305dc326fc38065756951",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEEuUmfpp7/Xe7rw8H1un5Bh8b3PYIFAmC/klAACgkQun5Bh8b3\nPYLJiw/8CTSOOKCFwqaEgwzshPDSRPF0EZ18l+4bk2KgQM9MktvzFcr8sgnyLicp\nWKmKVRG9mqYCanxObA2bQd+chgqn8FbU37w/dSF45InaF4Z45HT/RNWTVGrGZLiJ\n7C2gw0mhlG7UzfyiXb3loi3BBt3m+QLgGQX1rvt09MwbTxGEzk8EQ4CEFQDNqeYc\nuLUGC8tfZbburY0y7EhUwAHjgrsyB+Vh9jRUxk/YBADPwjuWSZ8WA/SS/8F+7Yps\ngTIj0aF5MAJzlUyRtMTJOWeUmLzYxPWyvHj2FMNPGpomZd7vsVWXebCe2ssfGA8+\nIZhT57P9wkU+YNFyynhsU03EwQKrayUJb4w32ikYAp0Bu6frbC9wq0hiF1UOlEGs\n926P0n3D9+cyZprzcCYzWBTxTiN92jkejTu3Ui3nTafpF8G4Ef1hLgQGUUrzkPXZ\nq2GkJfPCgXpL9v9+4PWbhdRqRmYGWKWNtQ538FbEfUSe83xwDF1QM1bJqsXsckJU\npyPsVUg3sk1Farv6IISFaFjIy4ApHwYfSMBY8aTgTP2ROk3Lcka2RBJ/8NU4hgfQ\ngSqwxixRXQx38YjGiVRe7I19mAVjTacpy2D5GrWb4mZXhlAubcOtmbFsm8qYlyvv\nEVh9uvIsEcdfP4C8i/wbpPc5IAKT6SnsuGLgu/LxFWeSxeJHeuw=\n=wNmJ\n-----END PGP SIGNATURE-----",
                    "payload": "tree 7d60769e947cf43e4cc63b729764c139bb6e1518\nparent 1a55cae23b3c1e943298ca4a93cad2704994e29b\nauthor Till Rohrmann <trohrmann@apache.org> 1623149528 +0200\ncommitter Till Rohrmann <trohrmann@apache.org> 1623167568 +0200\n\n[FLINK-22496][tests] Include log output from started process in ClusterEntrypointTest.testCloseAsyncShouldBeExecutedInShutdownHook\n\nThis closes #16111.\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/3660748b252e8de1553305dc326fc38065756951",
            "html_url": "https://github.com/apache/flink/commit/3660748b252e8de1553305dc326fc38065756951",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/3660748b252e8de1553305dc326fc38065756951/comments",
            "author": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "1a55cae23b3c1e943298ca4a93cad2704994e29b",
                "url": "https://api.github.com/repos/apache/flink/commits/1a55cae23b3c1e943298ca4a93cad2704994e29b",
                "html_url": "https://github.com/apache/flink/commit/1a55cae23b3c1e943298ca4a93cad2704994e29b"
            }]
        },
        {
            "sha": "7b1923dbfb160fb8b97244d4e2dc6fd98a9432ac",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6N2IxOTIzZGJmYjE2MGZiOGI5NzI0NGQ0ZTJkYzZmZDk4YTk0MzJhYw==",
            "commit": {
                "author": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-06-08T10:52:57Z"
                },
                "committer": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-06-08T15:52:49Z"
                },
                "message": "[hotfix] Replace deprecated import org.junit.Assert.assertThat with org.hamcrest.MatcherAssert.assertThat",
                "tree": {
                    "sha": "3f1aa2cbece443698413959d4899436b2b8e7c1f",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/3f1aa2cbece443698413959d4899436b2b8e7c1f"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/7b1923dbfb160fb8b97244d4e2dc6fd98a9432ac",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEEuUmfpp7/Xe7rw8H1un5Bh8b3PYIFAmC/klEACgkQun5Bh8b3\nPYKQ0g/+K7wDXt+4t2vx2nnwcN1r70iWhHuvxA8uQWp9KXg3Y01TyEal/PDTUDex\nEZNZh1gjSgBTrIkm9AKCCCD8ym3wZ07vpq4V21mLCUm6rOZBapA/aRuQOGjDAWl2\nzyrtZU3JOBrvFwortC9h+5VBFcPoykL5tawrC2AH4U0V5Q66yEaSkJnYeG3lDj3a\n3k7p+iWnH3fvg2VS1bg1xcqqW/2gCVcAJIWmm8GYLfnMXdIf86F6RuSxYNzu82et\nYJDVtiA0J+P9MeKEDlFp7mRdhOCtx/gFPZ4UyEy4NEF5CqYcdMzt5SyiR35L8jAJ\nQUeu/Z5claPwO1NeqZ7/+SrAdeKB3ulwbsbuuOTJtW4/h27M4ZzfR4AzMPOMMOI7\nSabOWJG78dGI8jx1Cc4DYlwV4Ac0z8eO/TpKwrfNdq1C8vCjjnfTol8l1p9PnKIm\nOidnC5tcV3LFNgfQyLIsIXerFU7WhmsWi8LPSfjJAyMv95G8i5oaSnnCqqTlokBh\nLQTTtVUnCjc1TD077dCxNT31AcPjw1lyCpw3Zkdt+vV9ACHDaWpCeC/9BcW3MRiB\nm3xzMDtXHtxKD3eqXBB5qT23Z3xN+GFEYSi8hMgMl/XjVCW4YgrhQdPN1YUvF3Y2\nKDBmizUKQ1PUYcq/gmq2ZS/LphU6l8TH3Gz/PRNUYPcm0pH8f6k=\n=asaA\n-----END PGP SIGNATURE-----",
                    "payload": "tree 3f1aa2cbece443698413959d4899436b2b8e7c1f\nparent 3660748b252e8de1553305dc326fc38065756951\nauthor Till Rohrmann <trohrmann@apache.org> 1623149577 +0200\ncommitter Till Rohrmann <trohrmann@apache.org> 1623167569 +0200\n\n[hotfix] Replace deprecated import org.junit.Assert.assertThat with org.hamcrest.MatcherAssert.assertThat\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/7b1923dbfb160fb8b97244d4e2dc6fd98a9432ac",
            "html_url": "https://github.com/apache/flink/commit/7b1923dbfb160fb8b97244d4e2dc6fd98a9432ac",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/7b1923dbfb160fb8b97244d4e2dc6fd98a9432ac/comments",
            "author": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "3660748b252e8de1553305dc326fc38065756951",
                "url": "https://api.github.com/repos/apache/flink/commits/3660748b252e8de1553305dc326fc38065756951",
                "html_url": "https://github.com/apache/flink/commit/3660748b252e8de1553305dc326fc38065756951"
            }]
        },
        {
            "sha": "160cfa41e406bda18e0cb257c5628039d0900e75",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MTYwY2ZhNDFlNDA2YmRhMThlMGNiMjU3YzU2MjgwMzlkMDkwMGU3NQ==",
            "commit": {
                "author": {
                    "name": "Jing Zhang",
                    "email": "beyond1920@126.com",
                    "date": "2021-06-09T04:20:17Z"
                },
                "committer": {
                    "name": "JingsongLi",
                    "email": "lzljs3620320@aliyun.com",
                    "date": "2021-06-09T04:21:15Z"
                },
                "message": "[FLINK-22894][table-runtime] Fix rankEnd validation of WindowRank to support top1\n\nThis closes #16088",
                "tree": {
                    "sha": "e4725f0e85c4f27510589c87c6f5640c122b87cb",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/e4725f0e85c4f27510589c87c6f5640c122b87cb"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/160cfa41e406bda18e0cb257c5628039d0900e75",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/160cfa41e406bda18e0cb257c5628039d0900e75",
            "html_url": "https://github.com/apache/flink/commit/160cfa41e406bda18e0cb257c5628039d0900e75",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/160cfa41e406bda18e0cb257c5628039d0900e75/comments",
            "author": {
                "login": "beyond1920",
                "id": 1525333,
                "node_id": "MDQ6VXNlcjE1MjUzMzM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1525333?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/beyond1920",
                "html_url": "https://github.com/beyond1920",
                "followers_url": "https://api.github.com/users/beyond1920/followers",
                "following_url": "https://api.github.com/users/beyond1920/following{/other_user}",
                "gists_url": "https://api.github.com/users/beyond1920/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/beyond1920/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/beyond1920/subscriptions",
                "organizations_url": "https://api.github.com/users/beyond1920/orgs",
                "repos_url": "https://api.github.com/users/beyond1920/repos",
                "events_url": "https://api.github.com/users/beyond1920/events{/privacy}",
                "received_events_url": "https://api.github.com/users/beyond1920/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "JingsongLi",
                "id": 9601882,
                "node_id": "MDQ6VXNlcjk2MDE4ODI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/9601882?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/JingsongLi",
                "html_url": "https://github.com/JingsongLi",
                "followers_url": "https://api.github.com/users/JingsongLi/followers",
                "following_url": "https://api.github.com/users/JingsongLi/following{/other_user}",
                "gists_url": "https://api.github.com/users/JingsongLi/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/JingsongLi/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/JingsongLi/subscriptions",
                "organizations_url": "https://api.github.com/users/JingsongLi/orgs",
                "repos_url": "https://api.github.com/users/JingsongLi/repos",
                "events_url": "https://api.github.com/users/JingsongLi/events{/privacy}",
                "received_events_url": "https://api.github.com/users/JingsongLi/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "7b1923dbfb160fb8b97244d4e2dc6fd98a9432ac",
                "url": "https://api.github.com/repos/apache/flink/commits/7b1923dbfb160fb8b97244d4e2dc6fd98a9432ac",
                "html_url": "https://github.com/apache/flink/commit/7b1923dbfb160fb8b97244d4e2dc6fd98a9432ac"
            }]
        },
        {
            "sha": "53e3834915744b6d04e13c7b7977b4d960e84f10",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NTNlMzgzNDkxNTc0NGI2ZDA0ZTEzYzdiNzk3N2I0ZDk2MGU4NGYxMA==",
            "commit": {
                "author": {
                    "name": "Rui Li",
                    "email": "lirui@apache.org",
                    "date": "2021-05-21T08:54:10Z"
                },
                "committer": {
                    "name": "Rui Li",
                    "email": "lirui@apache.org",
                    "date": "2021-06-09T04:33:35Z"
                },
                "message": "[FLINK-22726][hive] Support grouping__id in hive prior to 2.3.0\n\nThis closes #15983",
                "tree": {
                    "sha": "9711031dabbe8f8b562a81b8ed0982474f95a4fe",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/9711031dabbe8f8b562a81b8ed0982474f95a4fe"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/53e3834915744b6d04e13c7b7977b4d960e84f10",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/53e3834915744b6d04e13c7b7977b4d960e84f10",
            "html_url": "https://github.com/apache/flink/commit/53e3834915744b6d04e13c7b7977b4d960e84f10",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/53e3834915744b6d04e13c7b7977b4d960e84f10/comments",
            "author": {
                "login": "lirui-apache",
                "id": 5210788,
                "node_id": "MDQ6VXNlcjUyMTA3ODg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5210788?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/lirui-apache",
                "html_url": "https://github.com/lirui-apache",
                "followers_url": "https://api.github.com/users/lirui-apache/followers",
                "following_url": "https://api.github.com/users/lirui-apache/following{/other_user}",
                "gists_url": "https://api.github.com/users/lirui-apache/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/lirui-apache/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/lirui-apache/subscriptions",
                "organizations_url": "https://api.github.com/users/lirui-apache/orgs",
                "repos_url": "https://api.github.com/users/lirui-apache/repos",
                "events_url": "https://api.github.com/users/lirui-apache/events{/privacy}",
                "received_events_url": "https://api.github.com/users/lirui-apache/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "lirui-apache",
                "id": 5210788,
                "node_id": "MDQ6VXNlcjUyMTA3ODg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5210788?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/lirui-apache",
                "html_url": "https://github.com/lirui-apache",
                "followers_url": "https://api.github.com/users/lirui-apache/followers",
                "following_url": "https://api.github.com/users/lirui-apache/following{/other_user}",
                "gists_url": "https://api.github.com/users/lirui-apache/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/lirui-apache/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/lirui-apache/subscriptions",
                "organizations_url": "https://api.github.com/users/lirui-apache/orgs",
                "repos_url": "https://api.github.com/users/lirui-apache/repos",
                "events_url": "https://api.github.com/users/lirui-apache/events{/privacy}",
                "received_events_url": "https://api.github.com/users/lirui-apache/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "160cfa41e406bda18e0cb257c5628039d0900e75",
                "url": "https://api.github.com/repos/apache/flink/commits/160cfa41e406bda18e0cb257c5628039d0900e75",
                "html_url": "https://github.com/apache/flink/commit/160cfa41e406bda18e0cb257c5628039d0900e75"
            }]
        },
        {
            "sha": "19582b9895ac477c0f95bccb0da597329b82628f",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MTk1ODJiOTg5NWFjNDc3YzBmOTViY2NiMGRhNTk3MzI5YjgyNjI4Zg==",
            "commit": {
                "author": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-06-09T06:11:39Z"
                },
                "committer": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-06-09T09:23:48Z"
                },
                "message": "[FLINK-22939][azure] Generalize JDK switch",
                "tree": {
                    "sha": "eb32dd033bae4c6d6e7845f887b1cddaa6415bd3",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/eb32dd033bae4c6d6e7845f887b1cddaa6415bd3"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/19582b9895ac477c0f95bccb0da597329b82628f",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/19582b9895ac477c0f95bccb0da597329b82628f",
            "html_url": "https://github.com/apache/flink/commit/19582b9895ac477c0f95bccb0da597329b82628f",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/19582b9895ac477c0f95bccb0da597329b82628f/comments",
            "author": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "53e3834915744b6d04e13c7b7977b4d960e84f10",
                "url": "https://api.github.com/repos/apache/flink/commits/53e3834915744b6d04e13c7b7977b4d960e84f10",
                "html_url": "https://github.com/apache/flink/commit/53e3834915744b6d04e13c7b7977b4d960e84f10"
            }]
        },
        {
            "sha": "41a21454da1c1ddb38bcd7aaae058b2040257bd4",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NDFhMjE0NTRkYTFjMWRkYjM4YmNkN2FhYWUwNThiMjA0MDI1N2JkNA==",
            "commit": {
                "author": {
                    "name": "Roman Khachatryan",
                    "email": "khachatryan.roman@gmail.com",
                    "date": "2021-06-07T07:55:41Z"
                },
                "committer": {
                    "name": "Roman",
                    "email": "khachatryan.roman@gmail.com",
                    "date": "2021-06-09T10:54:24Z"
                },
                "message": "[FLINK-22889][tests] Ignore JdbcExactlyOnceSinkE2eTest temporarily",
                "tree": {
                    "sha": "4bd0bd23c89ba34d136c36ec22316cd24f70a9c8",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/4bd0bd23c89ba34d136c36ec22316cd24f70a9c8"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/41a21454da1c1ddb38bcd7aaae058b2040257bd4",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/41a21454da1c1ddb38bcd7aaae058b2040257bd4",
            "html_url": "https://github.com/apache/flink/commit/41a21454da1c1ddb38bcd7aaae058b2040257bd4",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/41a21454da1c1ddb38bcd7aaae058b2040257bd4/comments",
            "author": {
                "login": "rkhachatryan",
                "id": 3939322,
                "node_id": "MDQ6VXNlcjM5MzkzMjI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3939322?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rkhachatryan",
                "html_url": "https://github.com/rkhachatryan",
                "followers_url": "https://api.github.com/users/rkhachatryan/followers",
                "following_url": "https://api.github.com/users/rkhachatryan/following{/other_user}",
                "gists_url": "https://api.github.com/users/rkhachatryan/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rkhachatryan/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rkhachatryan/subscriptions",
                "organizations_url": "https://api.github.com/users/rkhachatryan/orgs",
                "repos_url": "https://api.github.com/users/rkhachatryan/repos",
                "events_url": "https://api.github.com/users/rkhachatryan/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rkhachatryan/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "rkhachatryan",
                "id": 3939322,
                "node_id": "MDQ6VXNlcjM5MzkzMjI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3939322?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rkhachatryan",
                "html_url": "https://github.com/rkhachatryan",
                "followers_url": "https://api.github.com/users/rkhachatryan/followers",
                "following_url": "https://api.github.com/users/rkhachatryan/following{/other_user}",
                "gists_url": "https://api.github.com/users/rkhachatryan/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rkhachatryan/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rkhachatryan/subscriptions",
                "organizations_url": "https://api.github.com/users/rkhachatryan/orgs",
                "repos_url": "https://api.github.com/users/rkhachatryan/repos",
                "events_url": "https://api.github.com/users/rkhachatryan/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rkhachatryan/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "19582b9895ac477c0f95bccb0da597329b82628f",
                "url": "https://api.github.com/repos/apache/flink/commits/19582b9895ac477c0f95bccb0da597329b82628f",
                "html_url": "https://github.com/apache/flink/commit/19582b9895ac477c0f95bccb0da597329b82628f"
            }]
        },
        {
            "sha": "9bf3318d492517f5f8a739610050a24c26179a3b",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6OWJmMzMxOGQ0OTI1MTdmNWY4YTczOTYxMDA1MGEyNGMyNjE3OWEzYg==",
            "commit": {
                "author": {
                    "name": "Piotr Nowojski",
                    "email": "piotr.nowojski@gmail.com",
                    "date": "2021-06-02T06:56:10Z"
                },
                "committer": {
                    "name": "Piotr Nowojski",
                    "email": "piotr.nowojski@gmail.com",
                    "date": "2021-06-09T13:20:55Z"
                },
                "message": "[hotfix][task] Rename triggerCheckpoint to better reflect a difference compared to other similarly named methods",
                "tree": {
                    "sha": "ea4e14c39e60002f565fc9b48bf93f40799ff654",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/ea4e14c39e60002f565fc9b48bf93f40799ff654"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/9bf3318d492517f5f8a739610050a24c26179a3b",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/9bf3318d492517f5f8a739610050a24c26179a3b",
            "html_url": "https://github.com/apache/flink/commit/9bf3318d492517f5f8a739610050a24c26179a3b",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/9bf3318d492517f5f8a739610050a24c26179a3b/comments",
            "author": {
                "login": "pnowojski",
                "id": 8957547,
                "node_id": "MDQ6VXNlcjg5NTc1NDc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8957547?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/pnowojski",
                "html_url": "https://github.com/pnowojski",
                "followers_url": "https://api.github.com/users/pnowojski/followers",
                "following_url": "https://api.github.com/users/pnowojski/following{/other_user}",
                "gists_url": "https://api.github.com/users/pnowojski/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/pnowojski/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/pnowojski/subscriptions",
                "organizations_url": "https://api.github.com/users/pnowojski/orgs",
                "repos_url": "https://api.github.com/users/pnowojski/repos",
                "events_url": "https://api.github.com/users/pnowojski/events{/privacy}",
                "received_events_url": "https://api.github.com/users/pnowojski/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "pnowojski",
                "id": 8957547,
                "node_id": "MDQ6VXNlcjg5NTc1NDc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8957547?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/pnowojski",
                "html_url": "https://github.com/pnowojski",
                "followers_url": "https://api.github.com/users/pnowojski/followers",
                "following_url": "https://api.github.com/users/pnowojski/following{/other_user}",
                "gists_url": "https://api.github.com/users/pnowojski/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/pnowojski/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/pnowojski/subscriptions",
                "organizations_url": "https://api.github.com/users/pnowojski/orgs",
                "repos_url": "https://api.github.com/users/pnowojski/repos",
                "events_url": "https://api.github.com/users/pnowojski/events{/privacy}",
                "received_events_url": "https://api.github.com/users/pnowojski/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "41a21454da1c1ddb38bcd7aaae058b2040257bd4",
                "url": "https://api.github.com/repos/apache/flink/commits/41a21454da1c1ddb38bcd7aaae058b2040257bd4",
                "html_url": "https://github.com/apache/flink/commit/41a21454da1c1ddb38bcd7aaae058b2040257bd4"
            }]
        },
        {
            "sha": "6e1decb077ea6a54b87f335cf4e49b4ad6da954f",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NmUxZGVjYjA3N2VhNmE1NGI4N2YzMzVjZjRlNDliNGFkNmRhOTU0Zg==",
            "commit": {
                "author": {
                    "name": "Piotr Nowojski",
                    "email": "piotr.nowojski@gmail.com",
                    "date": "2021-06-02T08:06:08Z"
                },
                "committer": {
                    "name": "Piotr Nowojski",
                    "email": "piotr.nowojski@gmail.com",
                    "date": "2021-06-09T13:20:55Z"
                },
                "message": "[hotfix][test] Deduplicate test case between SourceStreamTask and SourceOperatorStreamTask",
                "tree": {
                    "sha": "c7513d6991fdd87a046075c805f5f83b220705b9",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/c7513d6991fdd87a046075c805f5f83b220705b9"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/6e1decb077ea6a54b87f335cf4e49b4ad6da954f",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/6e1decb077ea6a54b87f335cf4e49b4ad6da954f",
            "html_url": "https://github.com/apache/flink/commit/6e1decb077ea6a54b87f335cf4e49b4ad6da954f",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/6e1decb077ea6a54b87f335cf4e49b4ad6da954f/comments",
            "author": {
                "login": "pnowojski",
                "id": 8957547,
                "node_id": "MDQ6VXNlcjg5NTc1NDc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8957547?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/pnowojski",
                "html_url": "https://github.com/pnowojski",
                "followers_url": "https://api.github.com/users/pnowojski/followers",
                "following_url": "https://api.github.com/users/pnowojski/following{/other_user}",
                "gists_url": "https://api.github.com/users/pnowojski/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/pnowojski/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/pnowojski/subscriptions",
                "organizations_url": "https://api.github.com/users/pnowojski/orgs",
                "repos_url": "https://api.github.com/users/pnowojski/repos",
                "events_url": "https://api.github.com/users/pnowojski/events{/privacy}",
                "received_events_url": "https://api.github.com/users/pnowojski/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "pnowojski",
                "id": 8957547,
                "node_id": "MDQ6VXNlcjg5NTc1NDc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8957547?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/pnowojski",
                "html_url": "https://github.com/pnowojski",
                "followers_url": "https://api.github.com/users/pnowojski/followers",
                "following_url": "https://api.github.com/users/pnowojski/following{/other_user}",
                "gists_url": "https://api.github.com/users/pnowojski/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/pnowojski/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/pnowojski/subscriptions",
                "organizations_url": "https://api.github.com/users/pnowojski/orgs",
                "repos_url": "https://api.github.com/users/pnowojski/repos",
                "events_url": "https://api.github.com/users/pnowojski/events{/privacy}",
                "received_events_url": "https://api.github.com/users/pnowojski/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "9bf3318d492517f5f8a739610050a24c26179a3b",
                "url": "https://api.github.com/repos/apache/flink/commits/9bf3318d492517f5f8a739610050a24c26179a3b",
                "html_url": "https://github.com/apache/flink/commit/9bf3318d492517f5f8a739610050a24c26179a3b"
            }]
        },
        {
            "sha": "a83f067722e3537b7f7a22f5e153895ea1cf7ef6",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6YTgzZjA2NzcyMmUzNTM3YjdmN2EyMmY1ZTE1Mzg5NWVhMWNmN2VmNg==",
            "commit": {
                "author": {
                    "name": "Piotr Nowojski",
                    "email": "piotr.nowojski@gmail.com",
                    "date": "2021-06-01T13:16:07Z"
                },
                "committer": {
                    "name": "Piotr Nowojski",
                    "email": "piotr.nowojski@gmail.com",
                    "date": "2021-06-09T13:20:55Z"
                },
                "message": "[FLINK-22833][metrics] Set checkpointStartDelay in checkpoint metrics for SourceTasks\n\nThis commit is fixing a bug of checkpointStartDelay being not set in\nCheckpointMetrics of SourceStreamTask and SourceOperatorStreamTask.",
                "tree": {
                    "sha": "23e408d894c0eaf5dc87fa73a14283ef7e123c76",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/23e408d894c0eaf5dc87fa73a14283ef7e123c76"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/a83f067722e3537b7f7a22f5e153895ea1cf7ef6",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/a83f067722e3537b7f7a22f5e153895ea1cf7ef6",
            "html_url": "https://github.com/apache/flink/commit/a83f067722e3537b7f7a22f5e153895ea1cf7ef6",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/a83f067722e3537b7f7a22f5e153895ea1cf7ef6/comments",
            "author": {
                "login": "pnowojski",
                "id": 8957547,
                "node_id": "MDQ6VXNlcjg5NTc1NDc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8957547?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/pnowojski",
                "html_url": "https://github.com/pnowojski",
                "followers_url": "https://api.github.com/users/pnowojski/followers",
                "following_url": "https://api.github.com/users/pnowojski/following{/other_user}",
                "gists_url": "https://api.github.com/users/pnowojski/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/pnowojski/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/pnowojski/subscriptions",
                "organizations_url": "https://api.github.com/users/pnowojski/orgs",
                "repos_url": "https://api.github.com/users/pnowojski/repos",
                "events_url": "https://api.github.com/users/pnowojski/events{/privacy}",
                "received_events_url": "https://api.github.com/users/pnowojski/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "pnowojski",
                "id": 8957547,
                "node_id": "MDQ6VXNlcjg5NTc1NDc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8957547?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/pnowojski",
                "html_url": "https://github.com/pnowojski",
                "followers_url": "https://api.github.com/users/pnowojski/followers",
                "following_url": "https://api.github.com/users/pnowojski/following{/other_user}",
                "gists_url": "https://api.github.com/users/pnowojski/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/pnowojski/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/pnowojski/subscriptions",
                "organizations_url": "https://api.github.com/users/pnowojski/orgs",
                "repos_url": "https://api.github.com/users/pnowojski/repos",
                "events_url": "https://api.github.com/users/pnowojski/events{/privacy}",
                "received_events_url": "https://api.github.com/users/pnowojski/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "6e1decb077ea6a54b87f335cf4e49b4ad6da954f",
                "url": "https://api.github.com/repos/apache/flink/commits/6e1decb077ea6a54b87f335cf4e49b4ad6da954f",
                "html_url": "https://github.com/apache/flink/commit/6e1decb077ea6a54b87f335cf4e49b4ad6da954f"
            }]
        },
        {
            "sha": "e9e2100627a7c62764a11387caf1bed494da4f8e",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZTllMjEwMDYyN2E3YzYyNzY0YTExMzg3Y2FmMWJlZDQ5NGRhNGY4ZQ==",
            "commit": {
                "author": {
                    "name": "Ankush Khanna",
                    "email": "akhanna2@wayfair.com",
                    "date": "2021-05-23T15:41:39Z"
                },
                "committer": {
                    "name": "Arvid Heise",
                    "email": "arvid@ververica.com",
                    "date": "2021-06-09T19:53:14Z"
                },
                "message": "Adding gcs documentation. Connecting flink to gcs.",
                "tree": {
                    "sha": "987678ac85fcd0847b38b907b26c57bd13901e99",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/987678ac85fcd0847b38b907b26c57bd13901e99"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/e9e2100627a7c62764a11387caf1bed494da4f8e",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/e9e2100627a7c62764a11387caf1bed494da4f8e",
            "html_url": "https://github.com/apache/flink/commit/e9e2100627a7c62764a11387caf1bed494da4f8e",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/e9e2100627a7c62764a11387caf1bed494da4f8e/comments",
            "author": null,
            "committer": {
                "login": "AHeise",
                "id": 4559103,
                "node_id": "MDQ6VXNlcjQ1NTkxMDM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/4559103?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/AHeise",
                "html_url": "https://github.com/AHeise",
                "followers_url": "https://api.github.com/users/AHeise/followers",
                "following_url": "https://api.github.com/users/AHeise/following{/other_user}",
                "gists_url": "https://api.github.com/users/AHeise/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/AHeise/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/AHeise/subscriptions",
                "organizations_url": "https://api.github.com/users/AHeise/orgs",
                "repos_url": "https://api.github.com/users/AHeise/repos",
                "events_url": "https://api.github.com/users/AHeise/events{/privacy}",
                "received_events_url": "https://api.github.com/users/AHeise/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "a83f067722e3537b7f7a22f5e153895ea1cf7ef6",
                "url": "https://api.github.com/repos/apache/flink/commits/a83f067722e3537b7f7a22f5e153895ea1cf7ef6",
                "html_url": "https://github.com/apache/flink/commit/a83f067722e3537b7f7a22f5e153895ea1cf7ef6"
            }]
        },
        {
            "sha": "879f19fe95bb3124054faac4702d7c1ade7209e4",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ODc5ZjE5ZmU5NWJiMzEyNDA1NGZhYWM0NzAyZDdjMWFkZTcyMDllNA==",
            "commit": {
                "author": {
                    "name": "Xintong Song",
                    "email": "tonysong820@gmail.com",
                    "date": "2021-06-10T05:19:08Z"
                },
                "committer": {
                    "name": "Xintong Song",
                    "email": "tonysong820@gmail.com",
                    "date": "2021-06-10T09:51:54Z"
                },
                "message": "[FLINK-22312][yarn][test] Fix test instabilities due to expected heartbeat exceptions in log\n\nThis closes #16127",
                "tree": {
                    "sha": "76765b4a25109cd7ff693eef252823b463f0d00c",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/76765b4a25109cd7ff693eef252823b463f0d00c"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/879f19fe95bb3124054faac4702d7c1ade7209e4",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCgAdFiEEGsvLF58sbVnbyFd20SHP9Sk+Y18FAmDB4LoACgkQ0SHP9Sk+\nY1/u2A/8Cr6cfTgSL5mKNR8iba3hBTR2UWpgEsqa2pZwEsXge1jDmJM/SwRzQIAO\nS/IDQqubwt1hUl8MxNfEEdDvcoc4Lr52Ur9+UridMxAMpkw7h+Z1Tm8VkihGou+B\nL/MAKLjEBaqy57OnvqNckUZdpNG3g6FzmmzWMXTQUBYObS9bVzqGZbXe7tYgRU+l\nLIj/YUDMNIpbMUEl9GQsUzdGRqOJagepj1TnWZdWNjrYgPDxspUHXMNbxMKkWzLh\nMCZvXhddoqX6tYCJJVYh5wRTeeRjkXuwL933LlgOq7QzRWWYNWVFRKA7zOnEPJ2f\n2KNZrAXe7D7flMeLn2Lph52fp6CiXpfDdCCDqDj8ESOhr8ORTI7rM6mVXXEp1Eaa\n3br5HRBqaDQ7JDlWOzhc/3tkry13M5QqHiQeYifnIJ+Vqwlu+g315yOPo2K7Opgo\nS3pD0IVRod1YkZsENEHp5KCyIaijUFsA63mVcHyV2vbdmM8rYPFLu4RDxq95j5ti\nS3KFoAWV01u9je2jwOg8qKEP4EW3jU5P9kLf4UtyIQiVfUocWqx3Ejn3INy844N2\nz7Ca6w/6URNRuOJplCqlbIy7LRs4F5S8Kw/oT+JcufjFbScEzhIXSCoxXLy9IP+q\nhFqab8bWjdP3S6SB5xjWhrLkjBM6ehGTjlVSl7RJqzH4ry+W1P4=\n=Qlwl\n-----END PGP SIGNATURE-----",
                    "payload": "tree 76765b4a25109cd7ff693eef252823b463f0d00c\nparent e9e2100627a7c62764a11387caf1bed494da4f8e\nauthor Xintong Song <tonysong820@gmail.com> 1623302348 +0800\ncommitter Xintong Song <tonysong820@gmail.com> 1623318714 +0800\n\n[FLINK-22312][yarn][test] Fix test instabilities due to expected heartbeat exceptions in log\n\nThis closes #16127\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/879f19fe95bb3124054faac4702d7c1ade7209e4",
            "html_url": "https://github.com/apache/flink/commit/879f19fe95bb3124054faac4702d7c1ade7209e4",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/879f19fe95bb3124054faac4702d7c1ade7209e4/comments",
            "author": {
                "login": "xintongsong",
                "id": 6509172,
                "node_id": "MDQ6VXNlcjY1MDkxNzI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6509172?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/xintongsong",
                "html_url": "https://github.com/xintongsong",
                "followers_url": "https://api.github.com/users/xintongsong/followers",
                "following_url": "https://api.github.com/users/xintongsong/following{/other_user}",
                "gists_url": "https://api.github.com/users/xintongsong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/xintongsong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/xintongsong/subscriptions",
                "organizations_url": "https://api.github.com/users/xintongsong/orgs",
                "repos_url": "https://api.github.com/users/xintongsong/repos",
                "events_url": "https://api.github.com/users/xintongsong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/xintongsong/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "xintongsong",
                "id": 6509172,
                "node_id": "MDQ6VXNlcjY1MDkxNzI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6509172?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/xintongsong",
                "html_url": "https://github.com/xintongsong",
                "followers_url": "https://api.github.com/users/xintongsong/followers",
                "following_url": "https://api.github.com/users/xintongsong/following{/other_user}",
                "gists_url": "https://api.github.com/users/xintongsong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/xintongsong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/xintongsong/subscriptions",
                "organizations_url": "https://api.github.com/users/xintongsong/orgs",
                "repos_url": "https://api.github.com/users/xintongsong/repos",
                "events_url": "https://api.github.com/users/xintongsong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/xintongsong/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "e9e2100627a7c62764a11387caf1bed494da4f8e",
                "url": "https://api.github.com/repos/apache/flink/commits/e9e2100627a7c62764a11387caf1bed494da4f8e",
                "html_url": "https://github.com/apache/flink/commit/e9e2100627a7c62764a11387caf1bed494da4f8e"
            }]
        },
        {
            "sha": "f1c85ffc4416b84cfa638b84f2613db047195bfb",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZjFjODVmZmM0NDE2Yjg0Y2ZhNjM4Yjg0ZjI2MTNkYjA0NzE5NWJmYg==",
            "commit": {
                "author": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-06-10T10:17:05Z"
                },
                "committer": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-06-10T13:56:57Z"
                },
                "message": "[FLINK-22952][azure] Remove Ruby usage",
                "tree": {
                    "sha": "617597094f0a8ccce8bba819f022e5578f3d59e6",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/617597094f0a8ccce8bba819f022e5578f3d59e6"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/f1c85ffc4416b84cfa638b84f2613db047195bfb",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/f1c85ffc4416b84cfa638b84f2613db047195bfb",
            "html_url": "https://github.com/apache/flink/commit/f1c85ffc4416b84cfa638b84f2613db047195bfb",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/f1c85ffc4416b84cfa638b84f2613db047195bfb/comments",
            "author": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "879f19fe95bb3124054faac4702d7c1ade7209e4",
                "url": "https://api.github.com/repos/apache/flink/commits/879f19fe95bb3124054faac4702d7c1ade7209e4",
                "html_url": "https://github.com/apache/flink/commit/879f19fe95bb3124054faac4702d7c1ade7209e4"
            }]
        },
        {
            "sha": "dc44739c53cac1d8177e077742a761bbfb39cb59",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZGM0NDczOWM1M2NhYzFkODE3N2UwNzc3NDJhNzYxYmJmYjM5Y2I1OQ==",
            "commit": {
                "author": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-06-11T05:46:16Z"
                },
                "committer": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-06-11T05:47:28Z"
                },
                "message": "[FLINK-22952][auure] Remove Ruby usage",
                "tree": {
                    "sha": "a9c86b2d2aa3a66a5fd7d1bdd06deca5089a32d2",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/a9c86b2d2aa3a66a5fd7d1bdd06deca5089a32d2"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/dc44739c53cac1d8177e077742a761bbfb39cb59",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/dc44739c53cac1d8177e077742a761bbfb39cb59",
            "html_url": "https://github.com/apache/flink/commit/dc44739c53cac1d8177e077742a761bbfb39cb59",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/dc44739c53cac1d8177e077742a761bbfb39cb59/comments",
            "author": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "f1c85ffc4416b84cfa638b84f2613db047195bfb",
                "url": "https://api.github.com/repos/apache/flink/commits/f1c85ffc4416b84cfa638b84f2613db047195bfb",
                "html_url": "https://github.com/apache/flink/commit/f1c85ffc4416b84cfa638b84f2613db047195bfb"
            }]
        },
        {
            "sha": "57383053ca677856158f486a9c5721a96a7b90cd",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NTczODMwNTNjYTY3Nzg1NjE1OGY0ODZhOWM1NzIxYTk2YTdiOTBjZA==",
            "commit": {
                "author": {
                    "name": "Xintong Song",
                    "email": "tonysong820@gmail.com",
                    "date": "2021-06-11T05:59:11Z"
                },
                "committer": {
                    "name": "Xintong Song",
                    "email": "tonysong820@gmail.com",
                    "date": "2021-06-11T06:00:16Z"
                },
                "message": "[hotfix][azure] Fix broken yaml",
                "tree": {
                    "sha": "f07fe6e4ffd5b71b9e9eea44b2ae663e29f44d83",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/f07fe6e4ffd5b71b9e9eea44b2ae663e29f44d83"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/57383053ca677856158f486a9c5721a96a7b90cd",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCgAdFiEEGsvLF58sbVnbyFd20SHP9Sk+Y18FAmDC+/AACgkQ0SHP9Sk+\nY19dkw/+KQTITwPZbjdNNePyeucMpUp7gl9rEZKJ+/TqsEJzbdP2Fn+y0WOdKOEq\n5OmSJAMwE+CISXwhz1vriy43jkeX02jPNEr0Rv/66wRZ+6DfnhJkVjlUjZ6HO5zj\nrkD2K6iEB9iZ3ZPDaLCMbqodcQ3zI2uFeWu8GK9LZVBQk6HPkQvgZP4KQG/dX57g\n84Rxe25m9m9xbOV87pLV8PmU1oSBosmlT9qNtM8VSAjm0Fsg7hMXZfB94DFcLLig\n+q0eNedt+qzAjGlPDoUcz2J15E31NJwuvQsgsaKsPORdwBT1fkCHKwgfP0LUHXXK\nH7Ok74yqgGZ7GS8nA08JQm85UW8gnoUAOAvTb9UDN+9SeRnNbKvAxlI6jHwbIO39\nHwP5g8QKjNqT3BDQ/CWawfFvQGAQ1q1iDeeJk5N6iRMcEOp2zRdMVOb3QbflBcU3\nh6qhf3sMtm10pgxf9XLALwwvcfMVKBckjijt++C4a8at/FN6XoweSaIJSs1Pf0mY\n/C0dFdIPIP0oJi9flnUwdFxznqpEii9rQsqAARf22tVBwk/Fo8TZbRtfxK2GgXbV\nEUsB+pfiV6JMrIwGExTbZkfnKVdbPfOnpk46BzaRPE3UVnQ5DN9tkQDoTPr1VV0o\n+NmQPg6ktpzupqmdRoagKnx/hIdDATkCrjuHmZw7JL0SQu6bv+o=\n=KzAB\n-----END PGP SIGNATURE-----",
                    "payload": "tree f07fe6e4ffd5b71b9e9eea44b2ae663e29f44d83\nparent dc44739c53cac1d8177e077742a761bbfb39cb59\nauthor Xintong Song <tonysong820@gmail.com> 1623391151 +0800\ncommitter Xintong Song <tonysong820@gmail.com> 1623391216 +0800\n\n[hotfix][azure] Fix broken yaml\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/57383053ca677856158f486a9c5721a96a7b90cd",
            "html_url": "https://github.com/apache/flink/commit/57383053ca677856158f486a9c5721a96a7b90cd",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/57383053ca677856158f486a9c5721a96a7b90cd/comments",
            "author": {
                "login": "xintongsong",
                "id": 6509172,
                "node_id": "MDQ6VXNlcjY1MDkxNzI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6509172?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/xintongsong",
                "html_url": "https://github.com/xintongsong",
                "followers_url": "https://api.github.com/users/xintongsong/followers",
                "following_url": "https://api.github.com/users/xintongsong/following{/other_user}",
                "gists_url": "https://api.github.com/users/xintongsong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/xintongsong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/xintongsong/subscriptions",
                "organizations_url": "https://api.github.com/users/xintongsong/orgs",
                "repos_url": "https://api.github.com/users/xintongsong/repos",
                "events_url": "https://api.github.com/users/xintongsong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/xintongsong/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "xintongsong",
                "id": 6509172,
                "node_id": "MDQ6VXNlcjY1MDkxNzI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6509172?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/xintongsong",
                "html_url": "https://github.com/xintongsong",
                "followers_url": "https://api.github.com/users/xintongsong/followers",
                "following_url": "https://api.github.com/users/xintongsong/following{/other_user}",
                "gists_url": "https://api.github.com/users/xintongsong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/xintongsong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/xintongsong/subscriptions",
                "organizations_url": "https://api.github.com/users/xintongsong/orgs",
                "repos_url": "https://api.github.com/users/xintongsong/repos",
                "events_url": "https://api.github.com/users/xintongsong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/xintongsong/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "dc44739c53cac1d8177e077742a761bbfb39cb59",
                "url": "https://api.github.com/repos/apache/flink/commits/dc44739c53cac1d8177e077742a761bbfb39cb59",
                "html_url": "https://github.com/apache/flink/commit/dc44739c53cac1d8177e077742a761bbfb39cb59"
            }]
        },
        {
            "sha": "e107e29fa930d4e08e25882f1b52b0d987741694",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZTEwN2UyOWZhOTMwZDRlMDhlMjU4ODJmMWI1MmIwZDk4Nzc0MTY5NA==",
            "commit": {
                "author": {
                    "name": "Fabian Paul",
                    "email": "fabianpaul@ververica.com",
                    "date": "2021-06-11T07:03:21Z"
                },
                "committer": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-06-11T07:05:04Z"
                },
                "message": "[FLINK-22908][tests] Wait until job has started before testing shutdown",
                "tree": {
                    "sha": "2dd7fe055da7a5b123f25dd5e8827eebcd4acb12",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/2dd7fe055da7a5b123f25dd5e8827eebcd4acb12"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/e107e29fa930d4e08e25882f1b52b0d987741694",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/e107e29fa930d4e08e25882f1b52b0d987741694",
            "html_url": "https://github.com/apache/flink/commit/e107e29fa930d4e08e25882f1b52b0d987741694",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/e107e29fa930d4e08e25882f1b52b0d987741694/comments",
            "author": {
                "login": "fapaul",
                "id": 7405553,
                "node_id": "MDQ6VXNlcjc0MDU1NTM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/7405553?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/fapaul",
                "html_url": "https://github.com/fapaul",
                "followers_url": "https://api.github.com/users/fapaul/followers",
                "following_url": "https://api.github.com/users/fapaul/following{/other_user}",
                "gists_url": "https://api.github.com/users/fapaul/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/fapaul/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/fapaul/subscriptions",
                "organizations_url": "https://api.github.com/users/fapaul/orgs",
                "repos_url": "https://api.github.com/users/fapaul/repos",
                "events_url": "https://api.github.com/users/fapaul/events{/privacy}",
                "received_events_url": "https://api.github.com/users/fapaul/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "57383053ca677856158f486a9c5721a96a7b90cd",
                "url": "https://api.github.com/repos/apache/flink/commits/57383053ca677856158f486a9c5721a96a7b90cd",
                "html_url": "https://github.com/apache/flink/commit/57383053ca677856158f486a9c5721a96a7b90cd"
            }]
        },
        {
            "sha": "1df0bbac32877b2cfddf16a3f31d73e76f0daae9",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MWRmMGJiYWMzMjg3N2IyY2ZkZGYxNmEzZjMxZDczZTc2ZjBkYWFlOQ==",
            "commit": {
                "author": {
                    "name": "CodeCooker17",
                    "email": "jasonlee1781@163.com",
                    "date": "2021-06-11T06:32:17Z"
                },
                "committer": {
                    "name": "Xintong Song",
                    "email": "tonysong820@gmail.com",
                    "date": "2021-06-15T02:05:27Z"
                },
                "message": "[FLINK-22963][doc] correct the description of taskmanager.memory.task.heap.size.\n\nThis closes #16143",
                "tree": {
                    "sha": "d12ee24ebdb1dfaee58cce079d23a0f5ecf72015",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/d12ee24ebdb1dfaee58cce079d23a0f5ecf72015"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/1df0bbac32877b2cfddf16a3f31d73e76f0daae9",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCgAdFiEEGsvLF58sbVnbyFd20SHP9Sk+Y18FAmDICucACgkQ0SHP9Sk+\nY1806xAAxMSoWxfWrmQHGZefQ1M4WOVZjZwokfnLaDWyY0FtuUiVbcCUDeMG7yT/\nsLesNzzjPzZ+SX0HeN9dKvmK6cgq8cK+hkaba9NmEgaqrwdB7P5Q+uQ2jNYOJ1e/\n+J5ulsRWj7qsEDv2Es5SUZgV8jebcyE0cCNUE1OiEdNJMuMIrXhPyb6nnOuWeRth\npjjrHrMJr49BxH2bPvXTZ8Rrox81KllZ+xpOHnnk0Q7VXI6F7ZhVZ+yHgnCgIoSO\naM5A/cT3JQ4DtUJX/cAdGxeFCXdG6gARcNkyi3TKZQ/oYv7FHCVwUOyNkvUtk1tG\nkKXqGYCI5JQPkpITp3kSrlJZoXt67tzBghZNGz9o79Ukxu484Wq6BPTAunjmQkMS\nZiVW360/yFat83OM3dh57YrwpwhOMDa721rRaKK5YyWQr1fqba7BPsgvSn/cVtMN\nwB+etEMQdOLFuoZBJvFxTlw8ezLVm38TjQDkSiuX/dBbAB5rG7JutBIrKeZQemOC\nvXwy2G9RKBon3gsJU3gl81iATGmve+0lH48pMvg+085VAGax+DrDxeO1rA3TMDPL\nw2zirpg8l5tVpyyP/clSatGgGFb9L7cK0sU5qiMFL+iYD6VOrhfCpZOhvvj4YgW3\n5pGO4Rjam24cvL8lGQMWfGK9XmI8ly5rC5HiL8f09QP87WriXzg=\n=xI52\n-----END PGP SIGNATURE-----",
                    "payload": "tree d12ee24ebdb1dfaee58cce079d23a0f5ecf72015\nparent e107e29fa930d4e08e25882f1b52b0d987741694\nauthor CodeCooker17 <jasonlee1781@163.com> 1623393137 +0800\ncommitter Xintong Song <tonysong820@gmail.com> 1623722727 +0800\n\n[FLINK-22963][doc] correct the description of taskmanager.memory.task.heap.size.\n\nThis closes #16143\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/1df0bbac32877b2cfddf16a3f31d73e76f0daae9",
            "html_url": "https://github.com/apache/flink/commit/1df0bbac32877b2cfddf16a3f31d73e76f0daae9",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/1df0bbac32877b2cfddf16a3f31d73e76f0daae9/comments",
            "author": {
                "login": "CodeCooker17",
                "id": 64473732,
                "node_id": "MDQ6VXNlcjY0NDczNzMy",
                "avatar_url": "https://avatars.githubusercontent.com/u/64473732?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/CodeCooker17",
                "html_url": "https://github.com/CodeCooker17",
                "followers_url": "https://api.github.com/users/CodeCooker17/followers",
                "following_url": "https://api.github.com/users/CodeCooker17/following{/other_user}",
                "gists_url": "https://api.github.com/users/CodeCooker17/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/CodeCooker17/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/CodeCooker17/subscriptions",
                "organizations_url": "https://api.github.com/users/CodeCooker17/orgs",
                "repos_url": "https://api.github.com/users/CodeCooker17/repos",
                "events_url": "https://api.github.com/users/CodeCooker17/events{/privacy}",
                "received_events_url": "https://api.github.com/users/CodeCooker17/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "xintongsong",
                "id": 6509172,
                "node_id": "MDQ6VXNlcjY1MDkxNzI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6509172?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/xintongsong",
                "html_url": "https://github.com/xintongsong",
                "followers_url": "https://api.github.com/users/xintongsong/followers",
                "following_url": "https://api.github.com/users/xintongsong/following{/other_user}",
                "gists_url": "https://api.github.com/users/xintongsong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/xintongsong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/xintongsong/subscriptions",
                "organizations_url": "https://api.github.com/users/xintongsong/orgs",
                "repos_url": "https://api.github.com/users/xintongsong/repos",
                "events_url": "https://api.github.com/users/xintongsong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/xintongsong/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "e107e29fa930d4e08e25882f1b52b0d987741694",
                "url": "https://api.github.com/repos/apache/flink/commits/e107e29fa930d4e08e25882f1b52b0d987741694",
                "html_url": "https://github.com/apache/flink/commit/e107e29fa930d4e08e25882f1b52b0d987741694"
            }]
        },
        {
            "sha": "229b9c6be3521fea2e5c8fe51a4468918ecf8bb2",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MjI5YjljNmJlMzUyMWZlYTJlNWM4ZmU1MWE0NDY4OTE4ZWNmOGJiMg==",
            "commit": {
                "author": {
                    "name": "TsReaper",
                    "email": "tsreaper96@gmail.com",
                    "date": "2021-06-15T02:48:05Z"
                },
                "committer": {
                    "name": "JingsongLi",
                    "email": "lzljs3620320@aliyun.com",
                    "date": "2021-06-15T02:49:55Z"
                },
                "message": "[FLINK-22730][table-planner] Add per record code when generating table function collector code for lookup joins\n\nThis closes #16104",
                "tree": {
                    "sha": "d8d095630c964ce84f2e3350c9a52470226f37b5",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/d8d095630c964ce84f2e3350c9a52470226f37b5"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/229b9c6be3521fea2e5c8fe51a4468918ecf8bb2",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/229b9c6be3521fea2e5c8fe51a4468918ecf8bb2",
            "html_url": "https://github.com/apache/flink/commit/229b9c6be3521fea2e5c8fe51a4468918ecf8bb2",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/229b9c6be3521fea2e5c8fe51a4468918ecf8bb2/comments",
            "author": {
                "login": "tsreaper",
                "id": 19909549,
                "node_id": "MDQ6VXNlcjE5OTA5NTQ5",
                "avatar_url": "https://avatars.githubusercontent.com/u/19909549?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tsreaper",
                "html_url": "https://github.com/tsreaper",
                "followers_url": "https://api.github.com/users/tsreaper/followers",
                "following_url": "https://api.github.com/users/tsreaper/following{/other_user}",
                "gists_url": "https://api.github.com/users/tsreaper/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tsreaper/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tsreaper/subscriptions",
                "organizations_url": "https://api.github.com/users/tsreaper/orgs",
                "repos_url": "https://api.github.com/users/tsreaper/repos",
                "events_url": "https://api.github.com/users/tsreaper/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tsreaper/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "JingsongLi",
                "id": 9601882,
                "node_id": "MDQ6VXNlcjk2MDE4ODI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/9601882?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/JingsongLi",
                "html_url": "https://github.com/JingsongLi",
                "followers_url": "https://api.github.com/users/JingsongLi/followers",
                "following_url": "https://api.github.com/users/JingsongLi/following{/other_user}",
                "gists_url": "https://api.github.com/users/JingsongLi/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/JingsongLi/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/JingsongLi/subscriptions",
                "organizations_url": "https://api.github.com/users/JingsongLi/orgs",
                "repos_url": "https://api.github.com/users/JingsongLi/repos",
                "events_url": "https://api.github.com/users/JingsongLi/events{/privacy}",
                "received_events_url": "https://api.github.com/users/JingsongLi/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "1df0bbac32877b2cfddf16a3f31d73e76f0daae9",
                "url": "https://api.github.com/repos/apache/flink/commits/1df0bbac32877b2cfddf16a3f31d73e76f0daae9",
                "html_url": "https://github.com/apache/flink/commit/1df0bbac32877b2cfddf16a3f31d73e76f0daae9"
            }]
        },
        {
            "sha": "4780b5d98e53c7a1cbabf2092b38d4e84fed3b32",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NDc4MGI1ZDk4ZTUzYzdhMWNiYWJmMjA5MmIzOGQ0ZTg0ZmVkM2IzMg==",
            "commit": {
                "author": {
                    "name": "Etienne Chauchot",
                    "email": "echauchot@apache.org",
                    "date": "2021-03-19T15:32:36Z"
                },
                "committer": {
                    "name": "Arvid Heise",
                    "email": "AHeise@users.noreply.github.com",
                    "date": "2021-06-15T05:59:54Z"
                },
                "message": "[FLINK-21389] [format-parquet] add ParquetInputFormat constructor without MessageType parameter and extract the MessageType from file",
                "tree": {
                    "sha": "043941937aeb4adddf3145a0d99a5441f2f660a8",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/043941937aeb4adddf3145a0d99a5441f2f660a8"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/4780b5d98e53c7a1cbabf2092b38d4e84fed3b32",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/4780b5d98e53c7a1cbabf2092b38d4e84fed3b32",
            "html_url": "https://github.com/apache/flink/commit/4780b5d98e53c7a1cbabf2092b38d4e84fed3b32",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/4780b5d98e53c7a1cbabf2092b38d4e84fed3b32/comments",
            "author": {
                "login": "echauchot",
                "id": 8821084,
                "node_id": "MDQ6VXNlcjg4MjEwODQ=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8821084?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/echauchot",
                "html_url": "https://github.com/echauchot",
                "followers_url": "https://api.github.com/users/echauchot/followers",
                "following_url": "https://api.github.com/users/echauchot/following{/other_user}",
                "gists_url": "https://api.github.com/users/echauchot/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/echauchot/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/echauchot/subscriptions",
                "organizations_url": "https://api.github.com/users/echauchot/orgs",
                "repos_url": "https://api.github.com/users/echauchot/repos",
                "events_url": "https://api.github.com/users/echauchot/events{/privacy}",
                "received_events_url": "https://api.github.com/users/echauchot/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "AHeise",
                "id": 4559103,
                "node_id": "MDQ6VXNlcjQ1NTkxMDM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/4559103?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/AHeise",
                "html_url": "https://github.com/AHeise",
                "followers_url": "https://api.github.com/users/AHeise/followers",
                "following_url": "https://api.github.com/users/AHeise/following{/other_user}",
                "gists_url": "https://api.github.com/users/AHeise/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/AHeise/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/AHeise/subscriptions",
                "organizations_url": "https://api.github.com/users/AHeise/orgs",
                "repos_url": "https://api.github.com/users/AHeise/repos",
                "events_url": "https://api.github.com/users/AHeise/events{/privacy}",
                "received_events_url": "https://api.github.com/users/AHeise/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "229b9c6be3521fea2e5c8fe51a4468918ecf8bb2",
                "url": "https://api.github.com/repos/apache/flink/commits/229b9c6be3521fea2e5c8fe51a4468918ecf8bb2",
                "html_url": "https://github.com/apache/flink/commit/229b9c6be3521fea2e5c8fe51a4468918ecf8bb2"
            }]
        },
        {
            "sha": "bf304e49c4e6ea7b8d73cfb7709e87a2e4c8b52a",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6YmYzMDRlNDljNGU2ZWE3YjhkNzNjZmI3NzA5ZTg3YTJlNGM4YjUyYQ==",
            "commit": {
                "author": {
                    "name": "Timo Walther",
                    "email": "twalthr@apache.org",
                    "date": "2021-06-17T11:15:23Z"
                },
                "committer": {
                    "name": "Timo Walther",
                    "email": "twalthr@apache.org",
                    "date": "2021-06-17T11:19:30Z"
                },
                "message": "[hotfix][docs] Fix typos in  Scala Table-DataStream API docs",
                "tree": {
                    "sha": "8283433cbd5a66e32aaf0101dd227533ece3add1",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/8283433cbd5a66e32aaf0101dd227533ece3add1"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/bf304e49c4e6ea7b8d73cfb7709e87a2e4c8b52a",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/bf304e49c4e6ea7b8d73cfb7709e87a2e4c8b52a",
            "html_url": "https://github.com/apache/flink/commit/bf304e49c4e6ea7b8d73cfb7709e87a2e4c8b52a",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/bf304e49c4e6ea7b8d73cfb7709e87a2e4c8b52a/comments",
            "author": {
                "login": "twalthr",
                "id": 5746567,
                "node_id": "MDQ6VXNlcjU3NDY1Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5746567?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/twalthr",
                "html_url": "https://github.com/twalthr",
                "followers_url": "https://api.github.com/users/twalthr/followers",
                "following_url": "https://api.github.com/users/twalthr/following{/other_user}",
                "gists_url": "https://api.github.com/users/twalthr/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/twalthr/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/twalthr/subscriptions",
                "organizations_url": "https://api.github.com/users/twalthr/orgs",
                "repos_url": "https://api.github.com/users/twalthr/repos",
                "events_url": "https://api.github.com/users/twalthr/events{/privacy}",
                "received_events_url": "https://api.github.com/users/twalthr/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "twalthr",
                "id": 5746567,
                "node_id": "MDQ6VXNlcjU3NDY1Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5746567?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/twalthr",
                "html_url": "https://github.com/twalthr",
                "followers_url": "https://api.github.com/users/twalthr/followers",
                "following_url": "https://api.github.com/users/twalthr/following{/other_user}",
                "gists_url": "https://api.github.com/users/twalthr/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/twalthr/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/twalthr/subscriptions",
                "organizations_url": "https://api.github.com/users/twalthr/orgs",
                "repos_url": "https://api.github.com/users/twalthr/repos",
                "events_url": "https://api.github.com/users/twalthr/events{/privacy}",
                "received_events_url": "https://api.github.com/users/twalthr/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "4780b5d98e53c7a1cbabf2092b38d4e84fed3b32",
                "url": "https://api.github.com/repos/apache/flink/commits/4780b5d98e53c7a1cbabf2092b38d4e84fed3b32",
                "html_url": "https://github.com/apache/flink/commit/4780b5d98e53c7a1cbabf2092b38d4e84fed3b32"
            }]
        },
        {
            "sha": "84578222cc84537c2f014573706bf070d3da49da",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ODQ1NzgyMjJjYzg0NTM3YzJmMDE0NTczNzA2YmYwNzBkM2RhNDlkYQ==",
            "commit": {
                "author": {
                    "name": "leiyanfei",
                    "email": "leiyanfei@leiyanfeideMacBook-Pro.local",
                    "date": "2021-06-11T09:20:48Z"
                },
                "committer": {
                    "name": "Roman",
                    "email": "khachatryan.roman@gmail.com",
                    "date": "2021-06-17T15:32:10Z"
                },
                "message": "[FLINK-23003][runtime] Fix resource leak in RocksIncrementalSnapshotStrategy\n\n(cherry picked from commit 8be1058a60565587b465a2237136dbbbb4c168f3)",
                "tree": {
                    "sha": "0d079808d04be06ebbe2cbb5c0c96d0a2abe55d6",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/0d079808d04be06ebbe2cbb5c0c96d0a2abe55d6"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/84578222cc84537c2f014573706bf070d3da49da",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/84578222cc84537c2f014573706bf070d3da49da",
            "html_url": "https://github.com/apache/flink/commit/84578222cc84537c2f014573706bf070d3da49da",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/84578222cc84537c2f014573706bf070d3da49da/comments",
            "author": null,
            "committer": {
                "login": "rkhachatryan",
                "id": 3939322,
                "node_id": "MDQ6VXNlcjM5MzkzMjI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3939322?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rkhachatryan",
                "html_url": "https://github.com/rkhachatryan",
                "followers_url": "https://api.github.com/users/rkhachatryan/followers",
                "following_url": "https://api.github.com/users/rkhachatryan/following{/other_user}",
                "gists_url": "https://api.github.com/users/rkhachatryan/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rkhachatryan/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rkhachatryan/subscriptions",
                "organizations_url": "https://api.github.com/users/rkhachatryan/orgs",
                "repos_url": "https://api.github.com/users/rkhachatryan/repos",
                "events_url": "https://api.github.com/users/rkhachatryan/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rkhachatryan/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "bf304e49c4e6ea7b8d73cfb7709e87a2e4c8b52a",
                "url": "https://api.github.com/repos/apache/flink/commits/bf304e49c4e6ea7b8d73cfb7709e87a2e4c8b52a",
                "html_url": "https://github.com/apache/flink/commit/bf304e49c4e6ea7b8d73cfb7709e87a2e4c8b52a"
            }]
        },
        {
            "sha": "9f90d4b31f1e2316b0e01a10cb0d727ab647677e",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6OWY5MGQ0YjMxZjFlMjMxNmIwZTAxYTEwY2IwZDcyN2FiNjQ3Njc3ZQ==",
            "commit": {
                "author": {
                    "name": "Yangze Guo",
                    "email": "karmagyz@gmail.com",
                    "date": "2021-06-18T02:13:14Z"
                },
                "committer": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-06-18T10:07:40Z"
                },
                "message": "[FLINK-23024][rest] Make TaskManagerInfoWithSlots serializable\n\nThis closes #16188.",
                "tree": {
                    "sha": "bcd05b16a616d4ebfe636878cb96cda77771cbb5",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/bcd05b16a616d4ebfe636878cb96cda77771cbb5"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/9f90d4b31f1e2316b0e01a10cb0d727ab647677e",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEEuUmfpp7/Xe7rw8H1un5Bh8b3PYIFAmDMcGwACgkQun5Bh8b3\nPYKMUg//WXQtvcWfqx3xNOwX+obZSF3jko6GKLZRPkbteJ0LkW9JixRbJVlSv9/6\nLo/uOkJ+aAtMTW/0i7Xxc7CWC9A3PV3MQvmcgzr0pJIUhXPYGzxG8ILHBKlVYWw4\n2KLMtMx4nDEwCORJhsjMFLc1hmAoGHlv7GmZu0zqTPb2Od46vMoM/OX1CIdL3pWT\nm5szw4mRx/LClpnpbS5NaILIDEPiIiiIrtnnKrM4BpHcTQqfqmpvYQXEUauzb3fu\n/QoIhq+sLDYdbU7/ymISjqFBSyDjgpRZ+gxO8ULzDmw1aAxCWlba+WrE9txyl0Jw\nEhtEVT0idgKiKpJw/8gE+y1FJ6RIlXtwGsKh020lcm/GALrq6+rqsXqiwJCjRX82\nD9uMMS9sk0wSN4voWHmzKdOGOu4AVU82pvG2xyoudtVLU9PR+I+WI+rdwph4CL59\nh9J3Fen4hgga/JXoDW35GgaRT/rK3o40q9k1QRhOZ/4divajNlkuqp2GazQM8xJG\njpf2RuKBiyHq+lNEeF7uxo4cn2TZecStdiDHDeHhgISc8H56o4qZe8msOSxI6iQ8\nnK6unSB5ARhSIaEy9bAaMu8t1pwiv8DgvqKeq3aNg0XEZ7CU03Ajw6wXWgOH9A7J\nXmO2Qpgnfpaj9OTvwC79IGbGL1H4VRkTR3wtA8HeTLjFL+ffc5A=\n=thbO\n-----END PGP SIGNATURE-----",
                    "payload": "tree bcd05b16a616d4ebfe636878cb96cda77771cbb5\nparent 84578222cc84537c2f014573706bf070d3da49da\nauthor Yangze Guo <karmagyz@gmail.com> 1623982394 +0800\ncommitter Till Rohrmann <trohrmann@apache.org> 1624010860 +0200\n\n[FLINK-23024][rest] Make TaskManagerInfoWithSlots serializable\n\nThis closes #16188.\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/9f90d4b31f1e2316b0e01a10cb0d727ab647677e",
            "html_url": "https://github.com/apache/flink/commit/9f90d4b31f1e2316b0e01a10cb0d727ab647677e",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/9f90d4b31f1e2316b0e01a10cb0d727ab647677e/comments",
            "author": {
                "login": "KarmaGYZ",
                "id": 8684799,
                "node_id": "MDQ6VXNlcjg2ODQ3OTk=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8684799?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/KarmaGYZ",
                "html_url": "https://github.com/KarmaGYZ",
                "followers_url": "https://api.github.com/users/KarmaGYZ/followers",
                "following_url": "https://api.github.com/users/KarmaGYZ/following{/other_user}",
                "gists_url": "https://api.github.com/users/KarmaGYZ/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/KarmaGYZ/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/KarmaGYZ/subscriptions",
                "organizations_url": "https://api.github.com/users/KarmaGYZ/orgs",
                "repos_url": "https://api.github.com/users/KarmaGYZ/repos",
                "events_url": "https://api.github.com/users/KarmaGYZ/events{/privacy}",
                "received_events_url": "https://api.github.com/users/KarmaGYZ/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "84578222cc84537c2f014573706bf070d3da49da",
                "url": "https://api.github.com/repos/apache/flink/commits/84578222cc84537c2f014573706bf070d3da49da",
                "html_url": "https://github.com/apache/flink/commit/84578222cc84537c2f014573706bf070d3da49da"
            }]
        },
        {
            "sha": "59322aef23cff42c2d4bd38d09ad7eb12790d012",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NTkzMjJhZWYyM2NmZjQyYzJkNGJkMzhkMDlhZDdlYjEyNzkwZDAxMg==",
            "commit": {
                "author": {
                    "name": "Guokuai Huang",
                    "email": "guokuai.huang@shopee.com",
                    "date": "2021-06-16T08:01:53Z"
                },
                "committer": {
                    "name": "Piotr Nowojski",
                    "email": "piotr.nowojski@gmail.com",
                    "date": "2021-06-18T12:49:32Z"
                },
                "message": "[FLINK-22946][runtime] Recycle floating buffer outside the lock to avoid deadlock",
                "tree": {
                    "sha": "0767de8119655f9e02bac28ac8ca9f8a78e11ce1",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/0767de8119655f9e02bac28ac8ca9f8a78e11ce1"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/59322aef23cff42c2d4bd38d09ad7eb12790d012",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/59322aef23cff42c2d4bd38d09ad7eb12790d012",
            "html_url": "https://github.com/apache/flink/commit/59322aef23cff42c2d4bd38d09ad7eb12790d012",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/59322aef23cff42c2d4bd38d09ad7eb12790d012/comments",
            "author": null,
            "committer": {
                "login": "pnowojski",
                "id": 8957547,
                "node_id": "MDQ6VXNlcjg5NTc1NDc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8957547?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/pnowojski",
                "html_url": "https://github.com/pnowojski",
                "followers_url": "https://api.github.com/users/pnowojski/followers",
                "following_url": "https://api.github.com/users/pnowojski/following{/other_user}",
                "gists_url": "https://api.github.com/users/pnowojski/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/pnowojski/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/pnowojski/subscriptions",
                "organizations_url": "https://api.github.com/users/pnowojski/orgs",
                "repos_url": "https://api.github.com/users/pnowojski/repos",
                "events_url": "https://api.github.com/users/pnowojski/events{/privacy}",
                "received_events_url": "https://api.github.com/users/pnowojski/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "9f90d4b31f1e2316b0e01a10cb0d727ab647677e",
                "url": "https://api.github.com/repos/apache/flink/commits/9f90d4b31f1e2316b0e01a10cb0d727ab647677e",
                "html_url": "https://github.com/apache/flink/commit/9f90d4b31f1e2316b0e01a10cb0d727ab647677e"
            }]
        },
        {
            "sha": "4dffdb6e1b2d509a27d3db6d07e4167656c5581d",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NGRmZmRiNmUxYjJkNTA5YTI3ZDNkYjZkMDdlNDE2NzY1NmM1NTgxZA==",
            "commit": {
                "author": {
                    "name": "Xintong Song",
                    "email": "tonysong820@gmail.com",
                    "date": "2021-06-18T09:53:03Z"
                },
                "committer": {
                    "name": "Xintong Song",
                    "email": "tonysong820@gmail.com",
                    "date": "2021-06-18T13:48:30Z"
                },
                "message": "[FLINK_22662][yarn][test] Add logs for YARNHighAvailabilityITCase\n\nThis closes #16197",
                "tree": {
                    "sha": "f6977455cae48dac57f8f7bf28261a9b5ad34dee",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/f6977455cae48dac57f8f7bf28261a9b5ad34dee"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/4dffdb6e1b2d509a27d3db6d07e4167656c5581d",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCgAdFiEEGsvLF58sbVnbyFd20SHP9Sk+Y18FAmDMpC4ACgkQ0SHP9Sk+\nY1/a1xAAvWmoZZzF3nda1T2Wa20DacdGdLp5rNj3sI0LMMcG38rq3SjugWk3ZWUw\n9kSs0gG2qJUdvaHoUODovcYIx/kC63YuMhrFx9khTDBe8bpOfnn03gJS9jX/+jlV\n/mMUkN1x7CugxMb3YNDmu2fHrwG/z3mS8PkII7byTBHHqHQ69ClEfRu5fvVu8mYk\ntkSKGiFCvThdSaA/Y04O17GTJ2gXSiuCga/Q4hIzA+y8yn9nkJSHddZQa9ZFM+yR\nlal+9M4kYIsEyec2CZbbDuvglEU5Q5/cwRPRRsC4D98ZpnLc6d0c8l/wUTPVBYhC\n4RtMMoQEQyQg7nwkUMja6tDvTr1hOXQ2NG7zQqQKIQSkmGXGqr8x5tauAXycOSlP\nY97e2aTAUnT9koRTtZeE/089Vd5XgC5oVDWYXlT34cusEyfg4Tkn4I8OayW7vQUD\nD0+7ftGGT4EcawIFas1HFrfti9Ismvx2RnFqUez0oeOkOfV6JKWJ5zqt3wiknlkj\n/DtqZWpBbYbOC/UwVOsEvudjqUZb7O2bNcpdpN/C/3rIfaldgLzdraLAZG4VoqiO\nxCjYb0POJxZ+6tBIr6I15zBIMmk+J5z/xVnN/lX25ADbxBG5NwHMFktxEB+4AVz+\nqMF4WS0uZPmfZO4OCGqrTN4ile/iqV42eU3YDYSS0PocEVF+6n0=\n=+J6h\n-----END PGP SIGNATURE-----",
                    "payload": "tree f6977455cae48dac57f8f7bf28261a9b5ad34dee\nparent 59322aef23cff42c2d4bd38d09ad7eb12790d012\nauthor Xintong Song <tonysong820@gmail.com> 1624009983 +0800\ncommitter Xintong Song <tonysong820@gmail.com> 1624024110 +0800\n\n[FLINK_22662][yarn][test] Add logs for YARNHighAvailabilityITCase\n\nThis closes #16197\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/4dffdb6e1b2d509a27d3db6d07e4167656c5581d",
            "html_url": "https://github.com/apache/flink/commit/4dffdb6e1b2d509a27d3db6d07e4167656c5581d",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/4dffdb6e1b2d509a27d3db6d07e4167656c5581d/comments",
            "author": {
                "login": "xintongsong",
                "id": 6509172,
                "node_id": "MDQ6VXNlcjY1MDkxNzI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6509172?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/xintongsong",
                "html_url": "https://github.com/xintongsong",
                "followers_url": "https://api.github.com/users/xintongsong/followers",
                "following_url": "https://api.github.com/users/xintongsong/following{/other_user}",
                "gists_url": "https://api.github.com/users/xintongsong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/xintongsong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/xintongsong/subscriptions",
                "organizations_url": "https://api.github.com/users/xintongsong/orgs",
                "repos_url": "https://api.github.com/users/xintongsong/repos",
                "events_url": "https://api.github.com/users/xintongsong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/xintongsong/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "xintongsong",
                "id": 6509172,
                "node_id": "MDQ6VXNlcjY1MDkxNzI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6509172?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/xintongsong",
                "html_url": "https://github.com/xintongsong",
                "followers_url": "https://api.github.com/users/xintongsong/followers",
                "following_url": "https://api.github.com/users/xintongsong/following{/other_user}",
                "gists_url": "https://api.github.com/users/xintongsong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/xintongsong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/xintongsong/subscriptions",
                "organizations_url": "https://api.github.com/users/xintongsong/orgs",
                "repos_url": "https://api.github.com/users/xintongsong/repos",
                "events_url": "https://api.github.com/users/xintongsong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/xintongsong/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "59322aef23cff42c2d4bd38d09ad7eb12790d012",
                "url": "https://api.github.com/repos/apache/flink/commits/59322aef23cff42c2d4bd38d09ad7eb12790d012",
                "html_url": "https://github.com/apache/flink/commit/59322aef23cff42c2d4bd38d09ad7eb12790d012"
            }]
        },
        {
            "sha": "1183fb5f7d258bb24d829efa229e3eb598050faa",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MTE4M2ZiNWY3ZDI1OGJiMjRkODI5ZWZhMjI5ZTNlYjU5ODA1MGZhYQ==",
            "commit": {
                "author": {
                    "name": "Fabian Paul",
                    "email": "fabianpaul@ververica.com",
                    "date": "2021-06-17T08:39:05Z"
                },
                "committer": {
                    "name": "Robert Metzger",
                    "email": "89049+rmetzger@users.noreply.github.com",
                    "date": "2021-06-18T13:55:29Z"
                },
                "message": "[FLINK-22980][tests] Set parallelism on job vertex required by adaptive scheduler",
                "tree": {
                    "sha": "08f6796d37253a4a71a51726783d7ccbeb85f83e",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/08f6796d37253a4a71a51726783d7ccbeb85f83e"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/1183fb5f7d258bb24d829efa229e3eb598050faa",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/1183fb5f7d258bb24d829efa229e3eb598050faa",
            "html_url": "https://github.com/apache/flink/commit/1183fb5f7d258bb24d829efa229e3eb598050faa",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/1183fb5f7d258bb24d829efa229e3eb598050faa/comments",
            "author": {
                "login": "fapaul",
                "id": 7405553,
                "node_id": "MDQ6VXNlcjc0MDU1NTM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/7405553?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/fapaul",
                "html_url": "https://github.com/fapaul",
                "followers_url": "https://api.github.com/users/fapaul/followers",
                "following_url": "https://api.github.com/users/fapaul/following{/other_user}",
                "gists_url": "https://api.github.com/users/fapaul/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/fapaul/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/fapaul/subscriptions",
                "organizations_url": "https://api.github.com/users/fapaul/orgs",
                "repos_url": "https://api.github.com/users/fapaul/repos",
                "events_url": "https://api.github.com/users/fapaul/events{/privacy}",
                "received_events_url": "https://api.github.com/users/fapaul/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "rmetzger",
                "id": 89049,
                "node_id": "MDQ6VXNlcjg5MDQ5",
                "avatar_url": "https://avatars.githubusercontent.com/u/89049?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rmetzger",
                "html_url": "https://github.com/rmetzger",
                "followers_url": "https://api.github.com/users/rmetzger/followers",
                "following_url": "https://api.github.com/users/rmetzger/following{/other_user}",
                "gists_url": "https://api.github.com/users/rmetzger/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rmetzger/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rmetzger/subscriptions",
                "organizations_url": "https://api.github.com/users/rmetzger/orgs",
                "repos_url": "https://api.github.com/users/rmetzger/repos",
                "events_url": "https://api.github.com/users/rmetzger/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rmetzger/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "4dffdb6e1b2d509a27d3db6d07e4167656c5581d",
                "url": "https://api.github.com/repos/apache/flink/commits/4dffdb6e1b2d509a27d3db6d07e4167656c5581d",
                "html_url": "https://github.com/apache/flink/commit/4dffdb6e1b2d509a27d3db6d07e4167656c5581d"
            }]
        },
        {
            "sha": "fae4091f13e96553ea5e23af617ebe6c0dd622ac",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZmFlNDA5MWYxM2U5NjU1M2VhNWUyM2FmNjE3ZWJlNmMwZGQ2MjJhYw==",
            "commit": {
                "author": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-06-04T08:57:08Z"
                },
                "committer": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-06-18T20:54:17Z"
                },
                "message": "[FLINK-22873][config][docs] Add ToC",
                "tree": {
                    "sha": "de2b6621d245b332befe928f7f0350a0975e9993",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/de2b6621d245b332befe928f7f0350a0975e9993"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/fae4091f13e96553ea5e23af617ebe6c0dd622ac",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/fae4091f13e96553ea5e23af617ebe6c0dd622ac",
            "html_url": "https://github.com/apache/flink/commit/fae4091f13e96553ea5e23af617ebe6c0dd622ac",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/fae4091f13e96553ea5e23af617ebe6c0dd622ac/comments",
            "author": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "1183fb5f7d258bb24d829efa229e3eb598050faa",
                "url": "https://api.github.com/repos/apache/flink/commits/1183fb5f7d258bb24d829efa229e3eb598050faa",
                "html_url": "https://github.com/apache/flink/commit/1183fb5f7d258bb24d829efa229e3eb598050faa"
            }]
        },
        {
            "sha": "b4f1a41b1c7564f4966567fbaf6e47c390874700",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6YjRmMWE0MWIxYzc1NjRmNDk2NjU2N2ZiYWY2ZTQ3YzM5MDg3NDcwMA==",
            "commit": {
                "author": {
                    "name": "Yun Tang",
                    "email": "myasuka@live.com",
                    "date": "2021-06-17T08:28:02Z"
                },
                "committer": {
                    "name": "Yun Tang",
                    "email": "tangyun@apache.org",
                    "date": "2021-06-21T02:55:11Z"
                },
                "message": "[FLINK-23018][state] Enable state factories to handle extended state descriptors",
                "tree": {
                    "sha": "cb532c4c1d49e4992709b09d6c4a2c8fc62364a9",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/cb532c4c1d49e4992709b09d6c4a2c8fc62364a9"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/b4f1a41b1c7564f4966567fbaf6e47c390874700",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/b4f1a41b1c7564f4966567fbaf6e47c390874700",
            "html_url": "https://github.com/apache/flink/commit/b4f1a41b1c7564f4966567fbaf6e47c390874700",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/b4f1a41b1c7564f4966567fbaf6e47c390874700/comments",
            "author": {
                "login": "Myasuka",
                "id": 1709104,
                "node_id": "MDQ6VXNlcjE3MDkxMDQ=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1709104?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/Myasuka",
                "html_url": "https://github.com/Myasuka",
                "followers_url": "https://api.github.com/users/Myasuka/followers",
                "following_url": "https://api.github.com/users/Myasuka/following{/other_user}",
                "gists_url": "https://api.github.com/users/Myasuka/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/Myasuka/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/Myasuka/subscriptions",
                "organizations_url": "https://api.github.com/users/Myasuka/orgs",
                "repos_url": "https://api.github.com/users/Myasuka/repos",
                "events_url": "https://api.github.com/users/Myasuka/events{/privacy}",
                "received_events_url": "https://api.github.com/users/Myasuka/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "Myasuka",
                "id": 1709104,
                "node_id": "MDQ6VXNlcjE3MDkxMDQ=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1709104?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/Myasuka",
                "html_url": "https://github.com/Myasuka",
                "followers_url": "https://api.github.com/users/Myasuka/followers",
                "following_url": "https://api.github.com/users/Myasuka/following{/other_user}",
                "gists_url": "https://api.github.com/users/Myasuka/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/Myasuka/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/Myasuka/subscriptions",
                "organizations_url": "https://api.github.com/users/Myasuka/orgs",
                "repos_url": "https://api.github.com/users/Myasuka/repos",
                "events_url": "https://api.github.com/users/Myasuka/events{/privacy}",
                "received_events_url": "https://api.github.com/users/Myasuka/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "fae4091f13e96553ea5e23af617ebe6c0dd622ac",
                "url": "https://api.github.com/repos/apache/flink/commits/fae4091f13e96553ea5e23af617ebe6c0dd622ac",
                "html_url": "https://github.com/apache/flink/commit/fae4091f13e96553ea5e23af617ebe6c0dd622ac"
            }]
        },
        {
            "sha": "3964761b80d2dce532d04704d1a3f4b097a8c5eb",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6Mzk2NDc2MWI4MGQyZGNlNTMyZDA0NzA0ZDFhM2Y0YjA5N2E4YzVlYg==",
            "commit": {
                "author": {
                    "name": "Tony Wei",
                    "email": "tony19920430@gmail.com",
                    "date": "2021-06-15T03:58:12Z"
                },
                "committer": {
                    "name": "Yun Tang",
                    "email": "tangyun@apache.org",
                    "date": "2021-06-21T03:59:50Z"
                },
                "message": "[hotfix][docs] Fix img links",
                "tree": {
                    "sha": "e8446b179bf3def7a29f21d63dca48ef79d9fe8c",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/e8446b179bf3def7a29f21d63dca48ef79d9fe8c"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/3964761b80d2dce532d04704d1a3f4b097a8c5eb",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/3964761b80d2dce532d04704d1a3f4b097a8c5eb",
            "html_url": "https://github.com/apache/flink/commit/3964761b80d2dce532d04704d1a3f4b097a8c5eb",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/3964761b80d2dce532d04704d1a3f4b097a8c5eb/comments",
            "author": {
                "login": "tony810430",
                "id": 14329393,
                "node_id": "MDQ6VXNlcjE0MzI5Mzkz",
                "avatar_url": "https://avatars.githubusercontent.com/u/14329393?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tony810430",
                "html_url": "https://github.com/tony810430",
                "followers_url": "https://api.github.com/users/tony810430/followers",
                "following_url": "https://api.github.com/users/tony810430/following{/other_user}",
                "gists_url": "https://api.github.com/users/tony810430/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tony810430/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tony810430/subscriptions",
                "organizations_url": "https://api.github.com/users/tony810430/orgs",
                "repos_url": "https://api.github.com/users/tony810430/repos",
                "events_url": "https://api.github.com/users/tony810430/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tony810430/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "Myasuka",
                "id": 1709104,
                "node_id": "MDQ6VXNlcjE3MDkxMDQ=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1709104?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/Myasuka",
                "html_url": "https://github.com/Myasuka",
                "followers_url": "https://api.github.com/users/Myasuka/followers",
                "following_url": "https://api.github.com/users/Myasuka/following{/other_user}",
                "gists_url": "https://api.github.com/users/Myasuka/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/Myasuka/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/Myasuka/subscriptions",
                "organizations_url": "https://api.github.com/users/Myasuka/orgs",
                "repos_url": "https://api.github.com/users/Myasuka/repos",
                "events_url": "https://api.github.com/users/Myasuka/events{/privacy}",
                "received_events_url": "https://api.github.com/users/Myasuka/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "b4f1a41b1c7564f4966567fbaf6e47c390874700",
                "url": "https://api.github.com/repos/apache/flink/commits/b4f1a41b1c7564f4966567fbaf6e47c390874700",
                "html_url": "https://github.com/apache/flink/commit/b4f1a41b1c7564f4966567fbaf6e47c390874700"
            }]
        },
        {
            "sha": "d8157b960e6d8d9d4903daf49b8d76d91f27dac9",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZDgxNTdiOTYwZTZkOGQ5ZDQ5MDNkYWY0OWI4ZDc2ZDkxZjI3ZGFjOQ==",
            "commit": {
                "author": {
                    "name": "luoyuxia",
                    "email": "luoyuxia.luoyuxia@alibaba-inc.com",
                    "date": "2021-06-21T06:25:08Z"
                },
                "committer": {
                    "name": "JingsongLi",
                    "email": "lzljs3620320@aliyun.com",
                    "date": "2021-06-21T06:26:21Z"
                },
                "message": "[FLINK-22993][filesystem] Fix the issue that CompactFileWriter won't emit EndCheckpoint with Long.MAX_VALUE checkpointId even though the inputs end\n\nThis closes #16161",
                "tree": {
                    "sha": "ac812fb8e4788121dfb0a2c6c8b501dae55a0822",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/ac812fb8e4788121dfb0a2c6c8b501dae55a0822"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/d8157b960e6d8d9d4903daf49b8d76d91f27dac9",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/d8157b960e6d8d9d4903daf49b8d76d91f27dac9",
            "html_url": "https://github.com/apache/flink/commit/d8157b960e6d8d9d4903daf49b8d76d91f27dac9",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/d8157b960e6d8d9d4903daf49b8d76d91f27dac9/comments",
            "author": {
                "login": "luoyuxia",
                "id": 20389154,
                "node_id": "MDQ6VXNlcjIwMzg5MTU0",
                "avatar_url": "https://avatars.githubusercontent.com/u/20389154?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/luoyuxia",
                "html_url": "https://github.com/luoyuxia",
                "followers_url": "https://api.github.com/users/luoyuxia/followers",
                "following_url": "https://api.github.com/users/luoyuxia/following{/other_user}",
                "gists_url": "https://api.github.com/users/luoyuxia/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/luoyuxia/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/luoyuxia/subscriptions",
                "organizations_url": "https://api.github.com/users/luoyuxia/orgs",
                "repos_url": "https://api.github.com/users/luoyuxia/repos",
                "events_url": "https://api.github.com/users/luoyuxia/events{/privacy}",
                "received_events_url": "https://api.github.com/users/luoyuxia/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "JingsongLi",
                "id": 9601882,
                "node_id": "MDQ6VXNlcjk2MDE4ODI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/9601882?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/JingsongLi",
                "html_url": "https://github.com/JingsongLi",
                "followers_url": "https://api.github.com/users/JingsongLi/followers",
                "following_url": "https://api.github.com/users/JingsongLi/following{/other_user}",
                "gists_url": "https://api.github.com/users/JingsongLi/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/JingsongLi/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/JingsongLi/subscriptions",
                "organizations_url": "https://api.github.com/users/JingsongLi/orgs",
                "repos_url": "https://api.github.com/users/JingsongLi/repos",
                "events_url": "https://api.github.com/users/JingsongLi/events{/privacy}",
                "received_events_url": "https://api.github.com/users/JingsongLi/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "3964761b80d2dce532d04704d1a3f4b097a8c5eb",
                "url": "https://api.github.com/repos/apache/flink/commits/3964761b80d2dce532d04704d1a3f4b097a8c5eb",
                "html_url": "https://github.com/apache/flink/commit/3964761b80d2dce532d04704d1a3f4b097a8c5eb"
            }]
        },
        {
            "sha": "fdabee0d3720f6d1690a7df7fb9329d266b49add",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZmRhYmVlMGQzNzIwZjZkMTY5MGE3ZGY3ZmI5MzI5ZDI2NmI0OWFkZA==",
            "commit": {
                "author": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-06-21T07:01:37Z"
                },
                "committer": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-06-21T07:05:45Z"
                },
                "message": "[FLINK-22987][ci] Fix scala suffix check\n\n* [FLINK-22987][ci] Fix scala suffix check\r\n\r\n* temporarily disable avro registry\r\n\r\n* Add basic precondition that at least 1 clean&infected module must be found\r\n\r\n* Invert exit handling",
                "tree": {
                    "sha": "b7f2991d4f1863d64c651be26cacba899d1f6774",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/b7f2991d4f1863d64c651be26cacba899d1f6774"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/fdabee0d3720f6d1690a7df7fb9329d266b49add",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/fdabee0d3720f6d1690a7df7fb9329d266b49add",
            "html_url": "https://github.com/apache/flink/commit/fdabee0d3720f6d1690a7df7fb9329d266b49add",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/fdabee0d3720f6d1690a7df7fb9329d266b49add/comments",
            "author": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "d8157b960e6d8d9d4903daf49b8d76d91f27dac9",
                "url": "https://api.github.com/repos/apache/flink/commits/d8157b960e6d8d9d4903daf49b8d76d91f27dac9",
                "html_url": "https://github.com/apache/flink/commit/d8157b960e6d8d9d4903daf49b8d76d91f27dac9"
            }]
        },
        {
            "sha": "78327def57451da7781bed98d434fce1033aa7d1",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NzgzMjdkZWY1NzQ1MWRhNzc4MWJlZDk4ZDQzNGZjZTEwMzNhYTdkMQ==",
            "commit": {
                "author": {
                    "name": "Yun Gao",
                    "email": "gaoyunhenhao@gmail.com",
                    "date": "2021-06-18T07:35:24Z"
                },
                "committer": {
                    "name": "Piotr Nowojski",
                    "email": "piotr.nowojski@gmail.com",
                    "date": "2021-06-21T07:18:49Z"
                },
                "message": "[FLINK-21952] Make all the \"Connection reset by peer\" exception wrapped as RemoteTransportException",
                "tree": {
                    "sha": "94b13bfe1e8e6f0359917db7b63cc35bb918d4a1",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/94b13bfe1e8e6f0359917db7b63cc35bb918d4a1"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/78327def57451da7781bed98d434fce1033aa7d1",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/78327def57451da7781bed98d434fce1033aa7d1",
            "html_url": "https://github.com/apache/flink/commit/78327def57451da7781bed98d434fce1033aa7d1",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/78327def57451da7781bed98d434fce1033aa7d1/comments",
            "author": {
                "login": "gaoyunhaii",
                "id": 1683890,
                "node_id": "MDQ6VXNlcjE2ODM4OTA=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1683890?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/gaoyunhaii",
                "html_url": "https://github.com/gaoyunhaii",
                "followers_url": "https://api.github.com/users/gaoyunhaii/followers",
                "following_url": "https://api.github.com/users/gaoyunhaii/following{/other_user}",
                "gists_url": "https://api.github.com/users/gaoyunhaii/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/gaoyunhaii/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/gaoyunhaii/subscriptions",
                "organizations_url": "https://api.github.com/users/gaoyunhaii/orgs",
                "repos_url": "https://api.github.com/users/gaoyunhaii/repos",
                "events_url": "https://api.github.com/users/gaoyunhaii/events{/privacy}",
                "received_events_url": "https://api.github.com/users/gaoyunhaii/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "pnowojski",
                "id": 8957547,
                "node_id": "MDQ6VXNlcjg5NTc1NDc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8957547?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/pnowojski",
                "html_url": "https://github.com/pnowojski",
                "followers_url": "https://api.github.com/users/pnowojski/followers",
                "following_url": "https://api.github.com/users/pnowojski/following{/other_user}",
                "gists_url": "https://api.github.com/users/pnowojski/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/pnowojski/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/pnowojski/subscriptions",
                "organizations_url": "https://api.github.com/users/pnowojski/orgs",
                "repos_url": "https://api.github.com/users/pnowojski/repos",
                "events_url": "https://api.github.com/users/pnowojski/events{/privacy}",
                "received_events_url": "https://api.github.com/users/pnowojski/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "fdabee0d3720f6d1690a7df7fb9329d266b49add",
                "url": "https://api.github.com/repos/apache/flink/commits/fdabee0d3720f6d1690a7df7fb9329d266b49add",
                "html_url": "https://github.com/apache/flink/commit/fdabee0d3720f6d1690a7df7fb9329d266b49add"
            }]
        },
        {
            "sha": "36e7ffb597bd830acbf1c9ccc3754d6232138120",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MzZlN2ZmYjU5N2JkODMwYWNiZjFjOWNjYzM3NTRkNjIzMjEzODEyMA==",
            "commit": {
                "author": {
                    "name": "Anton Kalashnikov",
                    "email": "kaa.dev@yandex.ru",
                    "date": "2021-06-18T12:26:10Z"
                },
                "committer": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-06-21T10:18:11Z"
                },
                "message": "[FLINK-23034][runtime] Added compatibility for ExecutionState in HistoryServer",
                "tree": {
                    "sha": "d9fc339825dc0cfddab9eb7f19f194a13371562d",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/d9fc339825dc0cfddab9eb7f19f194a13371562d"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/36e7ffb597bd830acbf1c9ccc3754d6232138120",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/36e7ffb597bd830acbf1c9ccc3754d6232138120",
            "html_url": "https://github.com/apache/flink/commit/36e7ffb597bd830acbf1c9ccc3754d6232138120",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/36e7ffb597bd830acbf1c9ccc3754d6232138120/comments",
            "author": {
                "login": "akalash",
                "id": 3996532,
                "node_id": "MDQ6VXNlcjM5OTY1MzI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3996532?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/akalash",
                "html_url": "https://github.com/akalash",
                "followers_url": "https://api.github.com/users/akalash/followers",
                "following_url": "https://api.github.com/users/akalash/following{/other_user}",
                "gists_url": "https://api.github.com/users/akalash/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/akalash/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/akalash/subscriptions",
                "organizations_url": "https://api.github.com/users/akalash/orgs",
                "repos_url": "https://api.github.com/users/akalash/repos",
                "events_url": "https://api.github.com/users/akalash/events{/privacy}",
                "received_events_url": "https://api.github.com/users/akalash/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "78327def57451da7781bed98d434fce1033aa7d1",
                "url": "https://api.github.com/repos/apache/flink/commits/78327def57451da7781bed98d434fce1033aa7d1",
                "html_url": "https://github.com/apache/flink/commit/78327def57451da7781bed98d434fce1033aa7d1"
            }]
        },
        {
            "sha": "d0d40718c1eaabc7b1280104218a1197a99896b9",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZDBkNDA3MThjMWVhYWJjN2IxMjgwMTA0MjE4YTExOTdhOTk4OTZiOQ==",
            "commit": {
                "author": {
                    "name": "jinxing64",
                    "email": "jinxing.corey@gmail.com",
                    "date": "2021-06-18T07:34:49Z"
                },
                "committer": {
                    "name": "Piotr Nowojski",
                    "email": "piotr.nowojski@gmail.com",
                    "date": "2021-06-21T15:10:32Z"
                },
                "message": "[FLINK-23030][network] PartitionRequestClientFactory#createPartitionRequestClient should throw when network failure",
                "tree": {
                    "sha": "d9d2ad908644d5fd3cd2a69ad7e43cee2e3f6688",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/d9d2ad908644d5fd3cd2a69ad7e43cee2e3f6688"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/d0d40718c1eaabc7b1280104218a1197a99896b9",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/d0d40718c1eaabc7b1280104218a1197a99896b9",
            "html_url": "https://github.com/apache/flink/commit/d0d40718c1eaabc7b1280104218a1197a99896b9",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/d0d40718c1eaabc7b1280104218a1197a99896b9/comments",
            "author": {
                "login": "jinxing64",
                "id": 4058918,
                "node_id": "MDQ6VXNlcjQwNTg5MTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/4058918?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/jinxing64",
                "html_url": "https://github.com/jinxing64",
                "followers_url": "https://api.github.com/users/jinxing64/followers",
                "following_url": "https://api.github.com/users/jinxing64/following{/other_user}",
                "gists_url": "https://api.github.com/users/jinxing64/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/jinxing64/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/jinxing64/subscriptions",
                "organizations_url": "https://api.github.com/users/jinxing64/orgs",
                "repos_url": "https://api.github.com/users/jinxing64/repos",
                "events_url": "https://api.github.com/users/jinxing64/events{/privacy}",
                "received_events_url": "https://api.github.com/users/jinxing64/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "pnowojski",
                "id": 8957547,
                "node_id": "MDQ6VXNlcjg5NTc1NDc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8957547?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/pnowojski",
                "html_url": "https://github.com/pnowojski",
                "followers_url": "https://api.github.com/users/pnowojski/followers",
                "following_url": "https://api.github.com/users/pnowojski/following{/other_user}",
                "gists_url": "https://api.github.com/users/pnowojski/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/pnowojski/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/pnowojski/subscriptions",
                "organizations_url": "https://api.github.com/users/pnowojski/orgs",
                "repos_url": "https://api.github.com/users/pnowojski/repos",
                "events_url": "https://api.github.com/users/pnowojski/events{/privacy}",
                "received_events_url": "https://api.github.com/users/pnowojski/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "36e7ffb597bd830acbf1c9ccc3754d6232138120",
                "url": "https://api.github.com/repos/apache/flink/commits/36e7ffb597bd830acbf1c9ccc3754d6232138120",
                "html_url": "https://github.com/apache/flink/commit/36e7ffb597bd830acbf1c9ccc3754d6232138120"
            }]
        },
        {
            "sha": "cb5eef6d0aac8c9c51fc41c9fd3d5a4b14eb0fd2",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6Y2I1ZWVmNmQwYWFjOGM5YzUxZmM0MWM5ZmQzZDVhNGIxNGViMGZkMg==",
            "commit": {
                "author": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-06-21T17:04:01Z"
                },
                "committer": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-06-21T17:06:24Z"
                },
                "message": "[FLINK-22045][conf] Sync log level between ZK and shaded-ZK",
                "tree": {
                    "sha": "b4abce4cfceb0fe4fbac8ec0595ec41fdd12e1ef",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/b4abce4cfceb0fe4fbac8ec0595ec41fdd12e1ef"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/cb5eef6d0aac8c9c51fc41c9fd3d5a4b14eb0fd2",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/cb5eef6d0aac8c9c51fc41c9fd3d5a4b14eb0fd2",
            "html_url": "https://github.com/apache/flink/commit/cb5eef6d0aac8c9c51fc41c9fd3d5a4b14eb0fd2",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/cb5eef6d0aac8c9c51fc41c9fd3d5a4b14eb0fd2/comments",
            "author": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "d0d40718c1eaabc7b1280104218a1197a99896b9",
                "url": "https://api.github.com/repos/apache/flink/commits/d0d40718c1eaabc7b1280104218a1197a99896b9",
                "html_url": "https://github.com/apache/flink/commit/d0d40718c1eaabc7b1280104218a1197a99896b9"
            }]
        },
        {
            "sha": "19cf47ba7740b149413b418685bc2ec3e9d6b1da",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MTljZjQ3YmE3NzQwYjE0OTQxM2I0MTg2ODViYzJlYzNlOWQ2YjFkYQ==",
            "commit": {
                "author": {
                    "name": "Michal Ciesielczyk",
                    "email": "michal.ciesielczyk@deep.bi",
                    "date": "2021-05-26T11:43:59Z"
                },
                "committer": {
                    "name": "Arvid Heise",
                    "email": "AHeise@users.noreply.github.com",
                    "date": "2021-06-22T11:31:31Z"
                },
                "message": "[backport-1.13][FLINK-22698][connectors/rabbitmq] Add deliveryTimeout to RabbitMQ source\n\nThis change enables setting the message delivery timeout in the RabbitMQ queueing consumer, allowing to properly stop the job in cases when no new message is available on the queue.\n\nChanges:\n- Add the ability to setDeliveryTimeout on the RMQConnectionConfig and its builder\n- Change default message delivery timeout in the RMQSource to 30 seconds (previously there was no timeout)\n- Extend RabbitMQ source unit tests",
                "tree": {
                    "sha": "6a838e09fef8e0bfd80c5105f6eea0e59fb8d047",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/6a838e09fef8e0bfd80c5105f6eea0e59fb8d047"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/19cf47ba7740b149413b418685bc2ec3e9d6b1da",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/19cf47ba7740b149413b418685bc2ec3e9d6b1da",
            "html_url": "https://github.com/apache/flink/commit/19cf47ba7740b149413b418685bc2ec3e9d6b1da",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/19cf47ba7740b149413b418685bc2ec3e9d6b1da/comments",
            "author": {
                "login": "cmick",
                "id": 2039722,
                "node_id": "MDQ6VXNlcjIwMzk3MjI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/2039722?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/cmick",
                "html_url": "https://github.com/cmick",
                "followers_url": "https://api.github.com/users/cmick/followers",
                "following_url": "https://api.github.com/users/cmick/following{/other_user}",
                "gists_url": "https://api.github.com/users/cmick/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/cmick/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/cmick/subscriptions",
                "organizations_url": "https://api.github.com/users/cmick/orgs",
                "repos_url": "https://api.github.com/users/cmick/repos",
                "events_url": "https://api.github.com/users/cmick/events{/privacy}",
                "received_events_url": "https://api.github.com/users/cmick/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "AHeise",
                "id": 4559103,
                "node_id": "MDQ6VXNlcjQ1NTkxMDM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/4559103?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/AHeise",
                "html_url": "https://github.com/AHeise",
                "followers_url": "https://api.github.com/users/AHeise/followers",
                "following_url": "https://api.github.com/users/AHeise/following{/other_user}",
                "gists_url": "https://api.github.com/users/AHeise/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/AHeise/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/AHeise/subscriptions",
                "organizations_url": "https://api.github.com/users/AHeise/orgs",
                "repos_url": "https://api.github.com/users/AHeise/repos",
                "events_url": "https://api.github.com/users/AHeise/events{/privacy}",
                "received_events_url": "https://api.github.com/users/AHeise/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "cb5eef6d0aac8c9c51fc41c9fd3d5a4b14eb0fd2",
                "url": "https://api.github.com/repos/apache/flink/commits/cb5eef6d0aac8c9c51fc41c9fd3d5a4b14eb0fd2",
                "html_url": "https://github.com/apache/flink/commit/cb5eef6d0aac8c9c51fc41c9fd3d5a4b14eb0fd2"
            }]
        },
        {
            "sha": "890817ac1e2f829f2a9b4d3c620d1bfd3ef81656",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ODkwODE3YWMxZTJmODI5ZjJhOWI0ZDNjNjIwZDFiZmQzZWY4MTY1Ng==",
            "commit": {
                "author": {
                    "name": "Seth Wiesman",
                    "email": "sjwiesman@gmail.com",
                    "date": "2021-06-22T17:11:28Z"
                },
                "committer": {
                    "name": "Seth Wiesman",
                    "email": "sjwiesman@gmail.com",
                    "date": "2021-06-22T17:12:49Z"
                },
                "message": "[hotfix][docs] update JSON plan in operations playground",
                "tree": {
                    "sha": "17fe40a6330c81ef6bd2575604f888c53396c7bf",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/17fe40a6330c81ef6bd2575604f888c53396c7bf"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/890817ac1e2f829f2a9b4d3c620d1bfd3ef81656",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/890817ac1e2f829f2a9b4d3c620d1bfd3ef81656",
            "html_url": "https://github.com/apache/flink/commit/890817ac1e2f829f2a9b4d3c620d1bfd3ef81656",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/890817ac1e2f829f2a9b4d3c620d1bfd3ef81656/comments",
            "author": {
                "login": "sjwiesman",
                "id": 1891970,
                "node_id": "MDQ6VXNlcjE4OTE5NzA=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1891970?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/sjwiesman",
                "html_url": "https://github.com/sjwiesman",
                "followers_url": "https://api.github.com/users/sjwiesman/followers",
                "following_url": "https://api.github.com/users/sjwiesman/following{/other_user}",
                "gists_url": "https://api.github.com/users/sjwiesman/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/sjwiesman/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/sjwiesman/subscriptions",
                "organizations_url": "https://api.github.com/users/sjwiesman/orgs",
                "repos_url": "https://api.github.com/users/sjwiesman/repos",
                "events_url": "https://api.github.com/users/sjwiesman/events{/privacy}",
                "received_events_url": "https://api.github.com/users/sjwiesman/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "sjwiesman",
                "id": 1891970,
                "node_id": "MDQ6VXNlcjE4OTE5NzA=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1891970?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/sjwiesman",
                "html_url": "https://github.com/sjwiesman",
                "followers_url": "https://api.github.com/users/sjwiesman/followers",
                "following_url": "https://api.github.com/users/sjwiesman/following{/other_user}",
                "gists_url": "https://api.github.com/users/sjwiesman/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/sjwiesman/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/sjwiesman/subscriptions",
                "organizations_url": "https://api.github.com/users/sjwiesman/orgs",
                "repos_url": "https://api.github.com/users/sjwiesman/repos",
                "events_url": "https://api.github.com/users/sjwiesman/events{/privacy}",
                "received_events_url": "https://api.github.com/users/sjwiesman/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "19cf47ba7740b149413b418685bc2ec3e9d6b1da",
                "url": "https://api.github.com/repos/apache/flink/commits/19cf47ba7740b149413b418685bc2ec3e9d6b1da",
                "html_url": "https://github.com/apache/flink/commit/19cf47ba7740b149413b418685bc2ec3e9d6b1da"
            }]
        },
        {
            "sha": "8f5b0126d8f0521f01a731143bd5b293b3939b92",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6OGY1YjAxMjZkOGYwNTIxZjAxYTczMTE0M2JkNWIyOTNiMzkzOWI5Mg==",
            "commit": {
                "author": {
                    "name": "Ingo Bürk",
                    "email": "ingo.buerk@tngtech.com",
                    "date": "2021-06-11T10:43:09Z"
                },
                "committer": {
                    "name": "Timo Walther",
                    "email": "twalthr@apache.org",
                    "date": "2021-06-22T17:14:39Z"
                },
                "message": "[FLINK-22788][table-planner-blink] Support equalisers for many fields\n\nWhen working with hundreds of fields, equalisers can fail to compile\nbecause the method body grows beyond 64kb. With this change, instead of\ngenerating all code into one method, we generate a dedicated method per\nfield and then call all of those methods. This doesn't entirely remove\nthe problem, but supports roughly a factor of 10 more fields and is\ncurrently deemed sufficient.\n\nThis closes #16213.",
                "tree": {
                    "sha": "676b5c4f0949fcdeaa6e8ceae3d362280ef7ea9f",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/676b5c4f0949fcdeaa6e8ceae3d362280ef7ea9f"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/8f5b0126d8f0521f01a731143bd5b293b3939b92",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/8f5b0126d8f0521f01a731143bd5b293b3939b92",
            "html_url": "https://github.com/apache/flink/commit/8f5b0126d8f0521f01a731143bd5b293b3939b92",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/8f5b0126d8f0521f01a731143bd5b293b3939b92/comments",
            "author": {
                "login": "Airblader",
                "id": 2392216,
                "node_id": "MDQ6VXNlcjIzOTIyMTY=",
                "avatar_url": "https://avatars.githubusercontent.com/u/2392216?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/Airblader",
                "html_url": "https://github.com/Airblader",
                "followers_url": "https://api.github.com/users/Airblader/followers",
                "following_url": "https://api.github.com/users/Airblader/following{/other_user}",
                "gists_url": "https://api.github.com/users/Airblader/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/Airblader/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/Airblader/subscriptions",
                "organizations_url": "https://api.github.com/users/Airblader/orgs",
                "repos_url": "https://api.github.com/users/Airblader/repos",
                "events_url": "https://api.github.com/users/Airblader/events{/privacy}",
                "received_events_url": "https://api.github.com/users/Airblader/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "twalthr",
                "id": 5746567,
                "node_id": "MDQ6VXNlcjU3NDY1Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5746567?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/twalthr",
                "html_url": "https://github.com/twalthr",
                "followers_url": "https://api.github.com/users/twalthr/followers",
                "following_url": "https://api.github.com/users/twalthr/following{/other_user}",
                "gists_url": "https://api.github.com/users/twalthr/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/twalthr/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/twalthr/subscriptions",
                "organizations_url": "https://api.github.com/users/twalthr/orgs",
                "repos_url": "https://api.github.com/users/twalthr/repos",
                "events_url": "https://api.github.com/users/twalthr/events{/privacy}",
                "received_events_url": "https://api.github.com/users/twalthr/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "890817ac1e2f829f2a9b4d3c620d1bfd3ef81656",
                "url": "https://api.github.com/repos/apache/flink/commits/890817ac1e2f829f2a9b4d3c620d1bfd3ef81656",
                "html_url": "https://github.com/apache/flink/commit/890817ac1e2f829f2a9b4d3c620d1bfd3ef81656"
            }]
        },
        {
            "sha": "4519089d4a45f223ca3ffd2a88864d02a059f8cd",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NDUxOTA4OWQ0YTQ1ZjIyM2NhM2ZmZDJhODg4NjRkMDJhMDU5ZjhjZA==",
            "commit": {
                "author": {
                    "name": "mayue.fight",
                    "email": "mayue.fight@bytedance.com",
                    "date": "2021-06-16T16:35:27Z"
                },
                "committer": {
                    "name": "Roman Khachatryan",
                    "email": "khachatryan.roman@gmail.com",
                    "date": "2021-06-22T18:20:08Z"
                },
                "message": "[FLINK-22886][state] Add unit test for resource leak in RocksIncrementalSnapshotStrategy",
                "tree": {
                    "sha": "9ed879c15bd788ec90d46c821559bf9763993436",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/9ed879c15bd788ec90d46c821559bf9763993436"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/4519089d4a45f223ca3ffd2a88864d02a059f8cd",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/4519089d4a45f223ca3ffd2a88864d02a059f8cd",
            "html_url": "https://github.com/apache/flink/commit/4519089d4a45f223ca3ffd2a88864d02a059f8cd",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/4519089d4a45f223ca3ffd2a88864d02a059f8cd/comments",
            "author": null,
            "committer": {
                "login": "rkhachatryan",
                "id": 3939322,
                "node_id": "MDQ6VXNlcjM5MzkzMjI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3939322?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rkhachatryan",
                "html_url": "https://github.com/rkhachatryan",
                "followers_url": "https://api.github.com/users/rkhachatryan/followers",
                "following_url": "https://api.github.com/users/rkhachatryan/following{/other_user}",
                "gists_url": "https://api.github.com/users/rkhachatryan/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rkhachatryan/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rkhachatryan/subscriptions",
                "organizations_url": "https://api.github.com/users/rkhachatryan/orgs",
                "repos_url": "https://api.github.com/users/rkhachatryan/repos",
                "events_url": "https://api.github.com/users/rkhachatryan/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rkhachatryan/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "8f5b0126d8f0521f01a731143bd5b293b3939b92",
                "url": "https://api.github.com/repos/apache/flink/commits/8f5b0126d8f0521f01a731143bd5b293b3939b92",
                "html_url": "https://github.com/apache/flink/commit/8f5b0126d8f0521f01a731143bd5b293b3939b92"
            }]
        },
        {
            "sha": "d14b5490badf31af64e0763c9d1111a728111a54",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZDE0YjU0OTBiYWRmMzFhZjY0ZTA3NjNjOWQxMTExYTcyODExMWE1NA==",
            "commit": {
                "author": {
                    "name": "Roman Khachatryan",
                    "email": "khachatryan.roman@gmail.com",
                    "date": "2021-05-25T20:29:01Z"
                },
                "committer": {
                    "name": "Roman",
                    "email": "khachatryan.roman@gmail.com",
                    "date": "2021-06-22T22:32:10Z"
                },
                "message": "[FLINK-22462][connectors / jdbc] Fix XA connection leak",
                "tree": {
                    "sha": "153fe8861747c57d27ca77db668b1a2c78f75e8a",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/153fe8861747c57d27ca77db668b1a2c78f75e8a"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/d14b5490badf31af64e0763c9d1111a728111a54",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/d14b5490badf31af64e0763c9d1111a728111a54",
            "html_url": "https://github.com/apache/flink/commit/d14b5490badf31af64e0763c9d1111a728111a54",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/d14b5490badf31af64e0763c9d1111a728111a54/comments",
            "author": {
                "login": "rkhachatryan",
                "id": 3939322,
                "node_id": "MDQ6VXNlcjM5MzkzMjI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3939322?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rkhachatryan",
                "html_url": "https://github.com/rkhachatryan",
                "followers_url": "https://api.github.com/users/rkhachatryan/followers",
                "following_url": "https://api.github.com/users/rkhachatryan/following{/other_user}",
                "gists_url": "https://api.github.com/users/rkhachatryan/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rkhachatryan/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rkhachatryan/subscriptions",
                "organizations_url": "https://api.github.com/users/rkhachatryan/orgs",
                "repos_url": "https://api.github.com/users/rkhachatryan/repos",
                "events_url": "https://api.github.com/users/rkhachatryan/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rkhachatryan/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "rkhachatryan",
                "id": 3939322,
                "node_id": "MDQ6VXNlcjM5MzkzMjI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3939322?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rkhachatryan",
                "html_url": "https://github.com/rkhachatryan",
                "followers_url": "https://api.github.com/users/rkhachatryan/followers",
                "following_url": "https://api.github.com/users/rkhachatryan/following{/other_user}",
                "gists_url": "https://api.github.com/users/rkhachatryan/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rkhachatryan/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rkhachatryan/subscriptions",
                "organizations_url": "https://api.github.com/users/rkhachatryan/orgs",
                "repos_url": "https://api.github.com/users/rkhachatryan/repos",
                "events_url": "https://api.github.com/users/rkhachatryan/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rkhachatryan/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "4519089d4a45f223ca3ffd2a88864d02a059f8cd",
                "url": "https://api.github.com/repos/apache/flink/commits/4519089d4a45f223ca3ffd2a88864d02a059f8cd",
                "html_url": "https://github.com/apache/flink/commit/4519089d4a45f223ca3ffd2a88864d02a059f8cd"
            }]
        },
        {
            "sha": "b2779de1536e38c369142b9fd4f66886d1af6d0e",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6YjI3NzlkZTE1MzZlMzhjMzY5MTQyYjlmZDRmNjY4ODZkMWFmNmQwZQ==",
            "commit": {
                "author": {
                    "name": "Roman Khachatryan",
                    "email": "khachatryan.roman@gmail.com",
                    "date": "2021-05-03T07:50:11Z"
                },
                "committer": {
                    "name": "Roman",
                    "email": "khachatryan.roman@gmail.com",
                    "date": "2021-06-22T22:32:10Z"
                },
                "message": "[FLINK-22462][tests] Fix and harden JdbcExactlyOnceSinkE2eTest\n\n1. Add test against MySQL\n2. Fix multiple issues in the test\n- Indefinite waiting in sources\n- Too early emission causing starvation in maps",
                "tree": {
                    "sha": "2f46c7bf4d4a5e55037a9cbf6c892fdd4b895861",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/2f46c7bf4d4a5e55037a9cbf6c892fdd4b895861"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/b2779de1536e38c369142b9fd4f66886d1af6d0e",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/b2779de1536e38c369142b9fd4f66886d1af6d0e",
            "html_url": "https://github.com/apache/flink/commit/b2779de1536e38c369142b9fd4f66886d1af6d0e",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/b2779de1536e38c369142b9fd4f66886d1af6d0e/comments",
            "author": {
                "login": "rkhachatryan",
                "id": 3939322,
                "node_id": "MDQ6VXNlcjM5MzkzMjI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3939322?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rkhachatryan",
                "html_url": "https://github.com/rkhachatryan",
                "followers_url": "https://api.github.com/users/rkhachatryan/followers",
                "following_url": "https://api.github.com/users/rkhachatryan/following{/other_user}",
                "gists_url": "https://api.github.com/users/rkhachatryan/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rkhachatryan/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rkhachatryan/subscriptions",
                "organizations_url": "https://api.github.com/users/rkhachatryan/orgs",
                "repos_url": "https://api.github.com/users/rkhachatryan/repos",
                "events_url": "https://api.github.com/users/rkhachatryan/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rkhachatryan/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "rkhachatryan",
                "id": 3939322,
                "node_id": "MDQ6VXNlcjM5MzkzMjI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3939322?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rkhachatryan",
                "html_url": "https://github.com/rkhachatryan",
                "followers_url": "https://api.github.com/users/rkhachatryan/followers",
                "following_url": "https://api.github.com/users/rkhachatryan/following{/other_user}",
                "gists_url": "https://api.github.com/users/rkhachatryan/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rkhachatryan/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rkhachatryan/subscriptions",
                "organizations_url": "https://api.github.com/users/rkhachatryan/orgs",
                "repos_url": "https://api.github.com/users/rkhachatryan/repos",
                "events_url": "https://api.github.com/users/rkhachatryan/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rkhachatryan/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "d14b5490badf31af64e0763c9d1111a728111a54",
                "url": "https://api.github.com/repos/apache/flink/commits/d14b5490badf31af64e0763c9d1111a728111a54",
                "html_url": "https://github.com/apache/flink/commit/d14b5490badf31af64e0763c9d1111a728111a54"
            }]
        },
        {
            "sha": "4140455083a0bb0c9240ceb1d2aac6d2024c097d",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NDE0MDQ1NTA4M2EwYmIwYzkyNDBjZWIxZDJhYWM2ZDIwMjRjMDk3ZA==",
            "commit": {
                "author": {
                    "name": "huangxingbo",
                    "email": "hxbks2ks@gmail.com",
                    "date": "2021-06-22T09:53:06Z"
                },
                "committer": {
                    "name": "huangxingbo",
                    "email": "hxbks2ks@gmail.com",
                    "date": "2021-06-23T03:28:36Z"
                },
                "message": "[FLINK-23092][python] Fix the issue that built-in UDAF could not be mixed use with Python UDAF in group window\n\nThis closes #16240.",
                "tree": {
                    "sha": "a1abef4de30fe6c033530044f37f1d2efbc02819",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/a1abef4de30fe6c033530044f37f1d2efbc02819"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/4140455083a0bb0c9240ceb1d2aac6d2024c097d",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/4140455083a0bb0c9240ceb1d2aac6d2024c097d",
            "html_url": "https://github.com/apache/flink/commit/4140455083a0bb0c9240ceb1d2aac6d2024c097d",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/4140455083a0bb0c9240ceb1d2aac6d2024c097d/comments",
            "author": {
                "login": "HuangXingBo",
                "id": 8536293,
                "node_id": "MDQ6VXNlcjg1MzYyOTM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8536293?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/HuangXingBo",
                "html_url": "https://github.com/HuangXingBo",
                "followers_url": "https://api.github.com/users/HuangXingBo/followers",
                "following_url": "https://api.github.com/users/HuangXingBo/following{/other_user}",
                "gists_url": "https://api.github.com/users/HuangXingBo/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/HuangXingBo/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/HuangXingBo/subscriptions",
                "organizations_url": "https://api.github.com/users/HuangXingBo/orgs",
                "repos_url": "https://api.github.com/users/HuangXingBo/repos",
                "events_url": "https://api.github.com/users/HuangXingBo/events{/privacy}",
                "received_events_url": "https://api.github.com/users/HuangXingBo/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "HuangXingBo",
                "id": 8536293,
                "node_id": "MDQ6VXNlcjg1MzYyOTM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8536293?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/HuangXingBo",
                "html_url": "https://github.com/HuangXingBo",
                "followers_url": "https://api.github.com/users/HuangXingBo/followers",
                "following_url": "https://api.github.com/users/HuangXingBo/following{/other_user}",
                "gists_url": "https://api.github.com/users/HuangXingBo/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/HuangXingBo/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/HuangXingBo/subscriptions",
                "organizations_url": "https://api.github.com/users/HuangXingBo/orgs",
                "repos_url": "https://api.github.com/users/HuangXingBo/repos",
                "events_url": "https://api.github.com/users/HuangXingBo/events{/privacy}",
                "received_events_url": "https://api.github.com/users/HuangXingBo/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "b2779de1536e38c369142b9fd4f66886d1af6d0e",
                "url": "https://api.github.com/repos/apache/flink/commits/b2779de1536e38c369142b9fd4f66886d1af6d0e",
                "html_url": "https://github.com/apache/flink/commit/b2779de1536e38c369142b9fd4f66886d1af6d0e"
            }]
        },
        {
            "sha": "1f22ccecf3964b5bdb89d0ad334a6bf667fadde2",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MWYyMmNjZWNmMzk2NGI1YmRiODlkMGFkMzM0YTZiZjY2N2ZhZGRlMg==",
            "commit": {
                "author": {
                    "name": "huangxingbo",
                    "email": "hxbks2ks@gmail.com",
                    "date": "2021-06-15T03:52:17Z"
                },
                "committer": {
                    "name": "huangxingbo",
                    "email": "hxbks2ks@gmail.com",
                    "date": "2021-06-23T06:41:18Z"
                },
                "message": "[FLINK-22982][python] Fix the wrong matching in PythonMapMergeRule\n\nThis closes #16154.",
                "tree": {
                    "sha": "83aae970108185b9c4342577794d8ad9ef641de6",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/83aae970108185b9c4342577794d8ad9ef641de6"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/1f22ccecf3964b5bdb89d0ad334a6bf667fadde2",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/1f22ccecf3964b5bdb89d0ad334a6bf667fadde2",
            "html_url": "https://github.com/apache/flink/commit/1f22ccecf3964b5bdb89d0ad334a6bf667fadde2",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/1f22ccecf3964b5bdb89d0ad334a6bf667fadde2/comments",
            "author": {
                "login": "HuangXingBo",
                "id": 8536293,
                "node_id": "MDQ6VXNlcjg1MzYyOTM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8536293?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/HuangXingBo",
                "html_url": "https://github.com/HuangXingBo",
                "followers_url": "https://api.github.com/users/HuangXingBo/followers",
                "following_url": "https://api.github.com/users/HuangXingBo/following{/other_user}",
                "gists_url": "https://api.github.com/users/HuangXingBo/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/HuangXingBo/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/HuangXingBo/subscriptions",
                "organizations_url": "https://api.github.com/users/HuangXingBo/orgs",
                "repos_url": "https://api.github.com/users/HuangXingBo/repos",
                "events_url": "https://api.github.com/users/HuangXingBo/events{/privacy}",
                "received_events_url": "https://api.github.com/users/HuangXingBo/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "HuangXingBo",
                "id": 8536293,
                "node_id": "MDQ6VXNlcjg1MzYyOTM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8536293?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/HuangXingBo",
                "html_url": "https://github.com/HuangXingBo",
                "followers_url": "https://api.github.com/users/HuangXingBo/followers",
                "following_url": "https://api.github.com/users/HuangXingBo/following{/other_user}",
                "gists_url": "https://api.github.com/users/HuangXingBo/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/HuangXingBo/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/HuangXingBo/subscriptions",
                "organizations_url": "https://api.github.com/users/HuangXingBo/orgs",
                "repos_url": "https://api.github.com/users/HuangXingBo/repos",
                "events_url": "https://api.github.com/users/HuangXingBo/events{/privacy}",
                "received_events_url": "https://api.github.com/users/HuangXingBo/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "4140455083a0bb0c9240ceb1d2aac6d2024c097d",
                "url": "https://api.github.com/repos/apache/flink/commits/4140455083a0bb0c9240ceb1d2aac6d2024c097d",
                "html_url": "https://github.com/apache/flink/commit/4140455083a0bb0c9240ceb1d2aac6d2024c097d"
            }]
        },
        {
            "sha": "644ba4dcea7e37b83ec3aab2f53245a6b1aca3ae",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NjQ0YmE0ZGNlYTdlMzdiODNlYzNhYWIyZjUzMjQ1YTZiMWFjYTNhZQ==",
            "commit": {
                "author": {
                    "name": "Anton Kalashnikov",
                    "email": "kaa.dev@yandex.ru",
                    "date": "2021-06-10T12:20:00Z"
                },
                "committer": {
                    "name": "Dawid Wysakowicz",
                    "email": "dwysakowicz@apache.org",
                    "date": "2021-06-23T06:47:49Z"
                },
                "message": "[FLINK-22961][streaming] firstBarrierArrivalTime is recalculated when the first barrier or the barrier announcement received",
                "tree": {
                    "sha": "b5e109cdb45f1eb92e77bd3f72d48aec90f80f07",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/b5e109cdb45f1eb92e77bd3f72d48aec90f80f07"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/644ba4dcea7e37b83ec3aab2f53245a6b1aca3ae",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEE6pOkNbTiybTJ9TP2MdLdEL/BWi0FAmDS2RUACgkQMdLdEL/B\nWi3trBAAjI4u+udaqIRJY05afMJ6Ap4+tu8TvnkCxqjFhOlpPEucF5XhA2Wz9azf\nqD3CwZTTGrTKqY4YydNZlU9iuYypcu+8ngZKPDlWGznBeg+Yrm3rZuoFiN3Q+Yr9\nCCOM2MINCazSYSeF6Faph9SxplyJ3me5/bigbeCLVLJmAn8QlyXUDpR6AF9ABj8A\naUs+q65iCM50dJaT4KNTmYHS+IxZudCotlIbO3bCGicMNZOCcETnptlqKiorNMNl\nBl4FY5LtvZpmXQKJ8Gqici/c2Je9Xcf2yGHTNz4zTqbwtStxQM85uwmM1W+B23l2\nOdtsbvF53/pYopjnSkupYg031NpyVUXpnAqVFQ1WG7Bcbr7MRM2urO2+TDCMuvFu\nRoa+Cpp2hByXaNTX94ehjJ7nQKNd1rPAu09w83XjimQMqpYqI1NcIOMtiXxztivj\nf+7f3SnfSYtyKUVQuqxxGRcqhNdrIvbgrZ/nj+4l/XFVfw3XKCKWLfS3kgeUDHNf\nFNFjgHE8qb2edRHjpZfKreayhr56MDRHw1hGjGmDswUT28eVtq5rXtWIeMRKfGNc\nHTm9VLdFPMPJz0Kh1soIef6v/Sq/T3ucAasKLsx4b4fV3/RjbFsDWf3i6lWdjvFN\ndQ8Zg3h5n5kgqcTzgnkTIbbg5lT+LfYkzcXFFkC539KYRp5/RxI=\n=Fe7H\n-----END PGP SIGNATURE-----",
                    "payload": "tree b5e109cdb45f1eb92e77bd3f72d48aec90f80f07\nparent 1f22ccecf3964b5bdb89d0ad334a6bf667fadde2\nauthor Anton Kalashnikov <kaa.dev@yandex.ru> 1623327600 +0300\ncommitter Dawid Wysakowicz <dwysakowicz@apache.org> 1624430869 +0200\n\n[FLINK-22961][streaming] firstBarrierArrivalTime is recalculated when the first barrier or the barrier announcement received\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/644ba4dcea7e37b83ec3aab2f53245a6b1aca3ae",
            "html_url": "https://github.com/apache/flink/commit/644ba4dcea7e37b83ec3aab2f53245a6b1aca3ae",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/644ba4dcea7e37b83ec3aab2f53245a6b1aca3ae/comments",
            "author": {
                "login": "akalash",
                "id": 3996532,
                "node_id": "MDQ6VXNlcjM5OTY1MzI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3996532?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/akalash",
                "html_url": "https://github.com/akalash",
                "followers_url": "https://api.github.com/users/akalash/followers",
                "following_url": "https://api.github.com/users/akalash/following{/other_user}",
                "gists_url": "https://api.github.com/users/akalash/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/akalash/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/akalash/subscriptions",
                "organizations_url": "https://api.github.com/users/akalash/orgs",
                "repos_url": "https://api.github.com/users/akalash/repos",
                "events_url": "https://api.github.com/users/akalash/events{/privacy}",
                "received_events_url": "https://api.github.com/users/akalash/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "dawidwys",
                "id": 6242259,
                "node_id": "MDQ6VXNlcjYyNDIyNTk=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6242259?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dawidwys",
                "html_url": "https://github.com/dawidwys",
                "followers_url": "https://api.github.com/users/dawidwys/followers",
                "following_url": "https://api.github.com/users/dawidwys/following{/other_user}",
                "gists_url": "https://api.github.com/users/dawidwys/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dawidwys/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dawidwys/subscriptions",
                "organizations_url": "https://api.github.com/users/dawidwys/orgs",
                "repos_url": "https://api.github.com/users/dawidwys/repos",
                "events_url": "https://api.github.com/users/dawidwys/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dawidwys/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "1f22ccecf3964b5bdb89d0ad334a6bf667fadde2",
                "url": "https://api.github.com/repos/apache/flink/commits/1f22ccecf3964b5bdb89d0ad334a6bf667fadde2",
                "html_url": "https://github.com/apache/flink/commit/1f22ccecf3964b5bdb89d0ad334a6bf667fadde2"
            }]
        },
        {
            "sha": "70f7e2d0a5b31ad60fdb49dc023333330192e0d6",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NzBmN2UyZDBhNWIzMWFkNjBmZGI0OWRjMDIzMzMzMzMwMTkyZTBkNg==",
            "commit": {
                "author": {
                    "name": "Dian Fu",
                    "email": "dianfu@apache.org",
                    "date": "2021-06-23T11:21:03Z"
                },
                "committer": {
                    "name": "Dian Fu",
                    "email": "dianfu@apache.org",
                    "date": "2021-06-23T11:21:03Z"
                },
                "message": "[hotfix][docs] Improve the documentation about the data types supported in Python DataStream API",
                "tree": {
                    "sha": "1dea12cc748b6a7ef8dbff41c24d16e193a8de16",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/1dea12cc748b6a7ef8dbff41c24d16e193a8de16"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/70f7e2d0a5b31ad60fdb49dc023333330192e0d6",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/70f7e2d0a5b31ad60fdb49dc023333330192e0d6",
            "html_url": "https://github.com/apache/flink/commit/70f7e2d0a5b31ad60fdb49dc023333330192e0d6",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/70f7e2d0a5b31ad60fdb49dc023333330192e0d6/comments",
            "author": {
                "login": "dianfu",
                "id": 5466492,
                "node_id": "MDQ6VXNlcjU0NjY0OTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5466492?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dianfu",
                "html_url": "https://github.com/dianfu",
                "followers_url": "https://api.github.com/users/dianfu/followers",
                "following_url": "https://api.github.com/users/dianfu/following{/other_user}",
                "gists_url": "https://api.github.com/users/dianfu/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dianfu/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dianfu/subscriptions",
                "organizations_url": "https://api.github.com/users/dianfu/orgs",
                "repos_url": "https://api.github.com/users/dianfu/repos",
                "events_url": "https://api.github.com/users/dianfu/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dianfu/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "dianfu",
                "id": 5466492,
                "node_id": "MDQ6VXNlcjU0NjY0OTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5466492?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dianfu",
                "html_url": "https://github.com/dianfu",
                "followers_url": "https://api.github.com/users/dianfu/followers",
                "following_url": "https://api.github.com/users/dianfu/following{/other_user}",
                "gists_url": "https://api.github.com/users/dianfu/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dianfu/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dianfu/subscriptions",
                "organizations_url": "https://api.github.com/users/dianfu/orgs",
                "repos_url": "https://api.github.com/users/dianfu/repos",
                "events_url": "https://api.github.com/users/dianfu/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dianfu/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "644ba4dcea7e37b83ec3aab2f53245a6b1aca3ae",
                "url": "https://api.github.com/repos/apache/flink/commits/644ba4dcea7e37b83ec3aab2f53245a6b1aca3ae",
                "html_url": "https://github.com/apache/flink/commit/644ba4dcea7e37b83ec3aab2f53245a6b1aca3ae"
            }]
        },
        {
            "sha": "51880ee4d17e9042f9d81059c7e83b6f6b53b948",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NTE4ODBlZTRkMTdlOTA0MmY5ZDgxMDU5YzdlODNiNmY2YjUzYjk0OA==",
            "commit": {
                "author": {
                    "name": "Stephan Ewen",
                    "email": "sewen@apache.org",
                    "date": "2021-06-22T18:08:35Z"
                },
                "committer": {
                    "name": "Stephan Ewen",
                    "email": "sewen@apache.org",
                    "date": "2021-06-23T11:50:10Z"
                },
                "message": "[FLINK-23001][build] Fix missing Scala suffix by removing unneeded Scala-dependent dependency",
                "tree": {
                    "sha": "241e52f43ac0ad813000b669e100b26d5b68f74c",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/241e52f43ac0ad813000b669e100b26d5b68f74c"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/51880ee4d17e9042f9d81059c7e83b6f6b53b948",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/51880ee4d17e9042f9d81059c7e83b6f6b53b948",
            "html_url": "https://github.com/apache/flink/commit/51880ee4d17e9042f9d81059c7e83b6f6b53b948",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/51880ee4d17e9042f9d81059c7e83b6f6b53b948/comments",
            "author": {
                "login": "StephanEwen",
                "id": 1727146,
                "node_id": "MDQ6VXNlcjE3MjcxNDY=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1727146?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/StephanEwen",
                "html_url": "https://github.com/StephanEwen",
                "followers_url": "https://api.github.com/users/StephanEwen/followers",
                "following_url": "https://api.github.com/users/StephanEwen/following{/other_user}",
                "gists_url": "https://api.github.com/users/StephanEwen/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/StephanEwen/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/StephanEwen/subscriptions",
                "organizations_url": "https://api.github.com/users/StephanEwen/orgs",
                "repos_url": "https://api.github.com/users/StephanEwen/repos",
                "events_url": "https://api.github.com/users/StephanEwen/events{/privacy}",
                "received_events_url": "https://api.github.com/users/StephanEwen/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "StephanEwen",
                "id": 1727146,
                "node_id": "MDQ6VXNlcjE3MjcxNDY=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1727146?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/StephanEwen",
                "html_url": "https://github.com/StephanEwen",
                "followers_url": "https://api.github.com/users/StephanEwen/followers",
                "following_url": "https://api.github.com/users/StephanEwen/following{/other_user}",
                "gists_url": "https://api.github.com/users/StephanEwen/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/StephanEwen/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/StephanEwen/subscriptions",
                "organizations_url": "https://api.github.com/users/StephanEwen/orgs",
                "repos_url": "https://api.github.com/users/StephanEwen/repos",
                "events_url": "https://api.github.com/users/StephanEwen/events{/privacy}",
                "received_events_url": "https://api.github.com/users/StephanEwen/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "70f7e2d0a5b31ad60fdb49dc023333330192e0d6",
                "url": "https://api.github.com/repos/apache/flink/commits/70f7e2d0a5b31ad60fdb49dc023333330192e0d6",
                "html_url": "https://github.com/apache/flink/commit/70f7e2d0a5b31ad60fdb49dc023333330192e0d6"
            }]
        },
        {
            "sha": "728bb3309b74cf6457c5d0b962018a45e470ed05",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NzI4YmIzMzA5Yjc0Y2Y2NDU3YzVkMGI5NjIwMThhNDVlNDcwZWQwNQ==",
            "commit": {
                "author": {
                    "name": "Stephan Ewen",
                    "email": "sewen@apache.org",
                    "date": "2021-06-22T18:10:34Z"
                },
                "committer": {
                    "name": "Stephan Ewen",
                    "email": "sewen@apache.org",
                    "date": "2021-06-23T11:50:10Z"
                },
                "message": "[FLINK-23001][build] Re-enable Scala suffix check for avro-glue-registry module\n\nThis closes #16247",
                "tree": {
                    "sha": "a3d5ce0d638f25290b66a3f49f782663ba7cfc7c",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/a3d5ce0d638f25290b66a3f49f782663ba7cfc7c"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/728bb3309b74cf6457c5d0b962018a45e470ed05",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/728bb3309b74cf6457c5d0b962018a45e470ed05",
            "html_url": "https://github.com/apache/flink/commit/728bb3309b74cf6457c5d0b962018a45e470ed05",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/728bb3309b74cf6457c5d0b962018a45e470ed05/comments",
            "author": {
                "login": "StephanEwen",
                "id": 1727146,
                "node_id": "MDQ6VXNlcjE3MjcxNDY=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1727146?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/StephanEwen",
                "html_url": "https://github.com/StephanEwen",
                "followers_url": "https://api.github.com/users/StephanEwen/followers",
                "following_url": "https://api.github.com/users/StephanEwen/following{/other_user}",
                "gists_url": "https://api.github.com/users/StephanEwen/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/StephanEwen/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/StephanEwen/subscriptions",
                "organizations_url": "https://api.github.com/users/StephanEwen/orgs",
                "repos_url": "https://api.github.com/users/StephanEwen/repos",
                "events_url": "https://api.github.com/users/StephanEwen/events{/privacy}",
                "received_events_url": "https://api.github.com/users/StephanEwen/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "StephanEwen",
                "id": 1727146,
                "node_id": "MDQ6VXNlcjE3MjcxNDY=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1727146?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/StephanEwen",
                "html_url": "https://github.com/StephanEwen",
                "followers_url": "https://api.github.com/users/StephanEwen/followers",
                "following_url": "https://api.github.com/users/StephanEwen/following{/other_user}",
                "gists_url": "https://api.github.com/users/StephanEwen/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/StephanEwen/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/StephanEwen/subscriptions",
                "organizations_url": "https://api.github.com/users/StephanEwen/orgs",
                "repos_url": "https://api.github.com/users/StephanEwen/repos",
                "events_url": "https://api.github.com/users/StephanEwen/events{/privacy}",
                "received_events_url": "https://api.github.com/users/StephanEwen/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "51880ee4d17e9042f9d81059c7e83b6f6b53b948",
                "url": "https://api.github.com/repos/apache/flink/commits/51880ee4d17e9042f9d81059c7e83b6f6b53b948",
                "html_url": "https://github.com/apache/flink/commit/51880ee4d17e9042f9d81059c7e83b6f6b53b948"
            }]
        },
        {
            "sha": "61f1f0f4f09875b5d8f4c2db956aa520facc4b2c",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NjFmMWYwZjRmMDk4NzViNWQ4ZjRjMmRiOTU2YWE1MjBmYWNjNGIyYw==",
            "commit": {
                "author": {
                    "name": "Seth Wiesman",
                    "email": "sjwiesman@gmail.com",
                    "date": "2021-06-21T18:37:41Z"
                },
                "committer": {
                    "name": "Seth Wiesman",
                    "email": "sjwiesman@gmail.com",
                    "date": "2021-06-23T15:07:32Z"
                },
                "message": "[FLINK-23073][formats / CSV] Fix space handling in Row CSV timestamp parser\n\nThis closes #16246",
                "tree": {
                    "sha": "726d675308b9a36fb8e3770fcef488a8c6717bfb",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/726d675308b9a36fb8e3770fcef488a8c6717bfb"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/61f1f0f4f09875b5d8f4c2db956aa520facc4b2c",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/61f1f0f4f09875b5d8f4c2db956aa520facc4b2c",
            "html_url": "https://github.com/apache/flink/commit/61f1f0f4f09875b5d8f4c2db956aa520facc4b2c",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/61f1f0f4f09875b5d8f4c2db956aa520facc4b2c/comments",
            "author": {
                "login": "sjwiesman",
                "id": 1891970,
                "node_id": "MDQ6VXNlcjE4OTE5NzA=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1891970?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/sjwiesman",
                "html_url": "https://github.com/sjwiesman",
                "followers_url": "https://api.github.com/users/sjwiesman/followers",
                "following_url": "https://api.github.com/users/sjwiesman/following{/other_user}",
                "gists_url": "https://api.github.com/users/sjwiesman/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/sjwiesman/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/sjwiesman/subscriptions",
                "organizations_url": "https://api.github.com/users/sjwiesman/orgs",
                "repos_url": "https://api.github.com/users/sjwiesman/repos",
                "events_url": "https://api.github.com/users/sjwiesman/events{/privacy}",
                "received_events_url": "https://api.github.com/users/sjwiesman/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "sjwiesman",
                "id": 1891970,
                "node_id": "MDQ6VXNlcjE4OTE5NzA=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1891970?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/sjwiesman",
                "html_url": "https://github.com/sjwiesman",
                "followers_url": "https://api.github.com/users/sjwiesman/followers",
                "following_url": "https://api.github.com/users/sjwiesman/following{/other_user}",
                "gists_url": "https://api.github.com/users/sjwiesman/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/sjwiesman/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/sjwiesman/subscriptions",
                "organizations_url": "https://api.github.com/users/sjwiesman/orgs",
                "repos_url": "https://api.github.com/users/sjwiesman/repos",
                "events_url": "https://api.github.com/users/sjwiesman/events{/privacy}",
                "received_events_url": "https://api.github.com/users/sjwiesman/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "728bb3309b74cf6457c5d0b962018a45e470ed05",
                "url": "https://api.github.com/repos/apache/flink/commits/728bb3309b74cf6457c5d0b962018a45e470ed05",
                "html_url": "https://github.com/apache/flink/commit/728bb3309b74cf6457c5d0b962018a45e470ed05"
            }]
        },
        {
            "sha": "db30addbc2a206e6bf079b734a28375e63bc9a08",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZGIzMGFkZGJjMmEyMDZlNmJmMDc5YjczNGEyODM3NWU2M2JjOWEwOA==",
            "commit": {
                "author": {
                    "name": "David Anderson",
                    "email": "david@alpinegizmo.com",
                    "date": "2021-06-21T10:49:14Z"
                },
                "committer": {
                    "name": "Seth Wiesman",
                    "email": "sjwiesman@gmail.com",
                    "date": "2021-06-23T16:30:22Z"
                },
                "message": "[FLINK-23059][docs] describe how to create ckp and savepoint dirs in operations playground docs\n\nThis closes #16218",
                "tree": {
                    "sha": "f174b7f69411ce8e1448695297e627604d59d5b1",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/f174b7f69411ce8e1448695297e627604d59d5b1"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/db30addbc2a206e6bf079b734a28375e63bc9a08",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/db30addbc2a206e6bf079b734a28375e63bc9a08",
            "html_url": "https://github.com/apache/flink/commit/db30addbc2a206e6bf079b734a28375e63bc9a08",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/db30addbc2a206e6bf079b734a28375e63bc9a08/comments",
            "author": {
                "login": "alpinegizmo",
                "id": 43608,
                "node_id": "MDQ6VXNlcjQzNjA4",
                "avatar_url": "https://avatars.githubusercontent.com/u/43608?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/alpinegizmo",
                "html_url": "https://github.com/alpinegizmo",
                "followers_url": "https://api.github.com/users/alpinegizmo/followers",
                "following_url": "https://api.github.com/users/alpinegizmo/following{/other_user}",
                "gists_url": "https://api.github.com/users/alpinegizmo/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/alpinegizmo/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/alpinegizmo/subscriptions",
                "organizations_url": "https://api.github.com/users/alpinegizmo/orgs",
                "repos_url": "https://api.github.com/users/alpinegizmo/repos",
                "events_url": "https://api.github.com/users/alpinegizmo/events{/privacy}",
                "received_events_url": "https://api.github.com/users/alpinegizmo/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "sjwiesman",
                "id": 1891970,
                "node_id": "MDQ6VXNlcjE4OTE5NzA=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1891970?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/sjwiesman",
                "html_url": "https://github.com/sjwiesman",
                "followers_url": "https://api.github.com/users/sjwiesman/followers",
                "following_url": "https://api.github.com/users/sjwiesman/following{/other_user}",
                "gists_url": "https://api.github.com/users/sjwiesman/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/sjwiesman/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/sjwiesman/subscriptions",
                "organizations_url": "https://api.github.com/users/sjwiesman/orgs",
                "repos_url": "https://api.github.com/users/sjwiesman/repos",
                "events_url": "https://api.github.com/users/sjwiesman/events{/privacy}",
                "received_events_url": "https://api.github.com/users/sjwiesman/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "61f1f0f4f09875b5d8f4c2db956aa520facc4b2c",
                "url": "https://api.github.com/repos/apache/flink/commits/61f1f0f4f09875b5d8f4c2db956aa520facc4b2c",
                "html_url": "https://github.com/apache/flink/commit/61f1f0f4f09875b5d8f4c2db956aa520facc4b2c"
            }]
        },
        {
            "sha": "28e1f7de58aa534efb533b5de42d2a78f4c4dd96",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MjhlMWY3ZGU1OGFhNTM0ZWZiNTMzYjVkZTQyZDJhNzhmNGM0ZGQ5Ng==",
            "commit": {
                "author": {
                    "name": "Shengkai",
                    "email": "33114724+fsk119@users.noreply.github.com",
                    "date": "2021-06-24T02:27:50Z"
                },
                "committer": {
                    "name": "GitHub",
                    "email": "noreply@github.com",
                    "date": "2021-06-24T02:27:50Z"
                },
                "message": "[FLINK-23025][upsert-kafka] Fix upsert-kafka produce duplicates when enable object reuse\n\nThis closes #16242",
                "tree": {
                    "sha": "4bfb78ce4700e023a8b4cd1cda3397191f3ed45a",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/4bfb78ce4700e023a8b4cd1cda3397191f3ed45a"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/28e1f7de58aa534efb533b5de42d2a78f4c4dd96",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJg0+2mCRBK7hj4Ov3rIwAAvHkIAChSgnEXIFhwwvr8uWa68ACJ\nWm5DUrT7unuXs3aLFE9VZEeqWy21StSTdYDR0fVXSK88K6RrnuER9y1OjYzoA1MD\nd9woJgak9LwewBiLBpLsbDn1++aq1K7JzYPvMEZ2v6cATgMMlqqG7eDHc7/SRoEw\nwQpFIYR66xg0MOUJmAan1Pj0myHML4aPBFeuKYHAxmAQYX6QWLTu61A5II9klqFh\n/eWwtTaZoQnXlpSr1lbUOM1+eKxO35XqxL+bCmSdLjIy7vBs5SonxUvhxdOjKdRb\n9CrSilM3zIBAwxdjpIm0boUEUZGDGdW7VzSxfW+aeCNU3dwknGHOq1FPNLwB0M4=\n=9Wld\n-----END PGP SIGNATURE-----\n",
                    "payload": "tree 4bfb78ce4700e023a8b4cd1cda3397191f3ed45a\nparent db30addbc2a206e6bf079b734a28375e63bc9a08\nauthor Shengkai <33114724+fsk119@users.noreply.github.com> 1624501670 +0800\ncommitter GitHub <noreply@github.com> 1624501670 +0800\n\n[FLINK-23025][upsert-kafka] Fix upsert-kafka produce duplicates when enable object reuse\n\nThis closes #16242"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/28e1f7de58aa534efb533b5de42d2a78f4c4dd96",
            "html_url": "https://github.com/apache/flink/commit/28e1f7de58aa534efb533b5de42d2a78f4c4dd96",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/28e1f7de58aa534efb533b5de42d2a78f4c4dd96/comments",
            "author": {
                "login": "fsk119",
                "id": 33114724,
                "node_id": "MDQ6VXNlcjMzMTE0NzI0",
                "avatar_url": "https://avatars.githubusercontent.com/u/33114724?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/fsk119",
                "html_url": "https://github.com/fsk119",
                "followers_url": "https://api.github.com/users/fsk119/followers",
                "following_url": "https://api.github.com/users/fsk119/following{/other_user}",
                "gists_url": "https://api.github.com/users/fsk119/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/fsk119/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/fsk119/subscriptions",
                "organizations_url": "https://api.github.com/users/fsk119/orgs",
                "repos_url": "https://api.github.com/users/fsk119/repos",
                "events_url": "https://api.github.com/users/fsk119/events{/privacy}",
                "received_events_url": "https://api.github.com/users/fsk119/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "web-flow",
                "id": 19864447,
                "node_id": "MDQ6VXNlcjE5ODY0NDQ3",
                "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/web-flow",
                "html_url": "https://github.com/web-flow",
                "followers_url": "https://api.github.com/users/web-flow/followers",
                "following_url": "https://api.github.com/users/web-flow/following{/other_user}",
                "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions",
                "organizations_url": "https://api.github.com/users/web-flow/orgs",
                "repos_url": "https://api.github.com/users/web-flow/repos",
                "events_url": "https://api.github.com/users/web-flow/events{/privacy}",
                "received_events_url": "https://api.github.com/users/web-flow/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "db30addbc2a206e6bf079b734a28375e63bc9a08",
                "url": "https://api.github.com/repos/apache/flink/commits/db30addbc2a206e6bf079b734a28375e63bc9a08",
                "html_url": "https://github.com/apache/flink/commit/db30addbc2a206e6bf079b734a28375e63bc9a08"
            }]
        },
        {
            "sha": "d755fa945632c135a6179a837d776d21ec28f63c",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZDc1NWZhOTQ1NjMyYzEzNWE2MTc5YTgzN2Q3NzZkMjFlYzI4ZjYzYw==",
            "commit": {
                "author": {
                    "name": "huangxingbo",
                    "email": "hxbks2ks@gmail.com",
                    "date": "2021-06-11T07:55:17Z"
                },
                "committer": {
                    "name": "huangxingbo",
                    "email": "hxbks2ks@gmail.com",
                    "date": "2021-06-24T02:59:38Z"
                },
                "message": "[FLINK-22927][python] Fix the bug of JobStatus\n\nThis closes #16146.",
                "tree": {
                    "sha": "c71472e6d32c58e9dd8ffc8aeab067dcfd869616",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/c71472e6d32c58e9dd8ffc8aeab067dcfd869616"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/d755fa945632c135a6179a837d776d21ec28f63c",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/d755fa945632c135a6179a837d776d21ec28f63c",
            "html_url": "https://github.com/apache/flink/commit/d755fa945632c135a6179a837d776d21ec28f63c",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/d755fa945632c135a6179a837d776d21ec28f63c/comments",
            "author": {
                "login": "HuangXingBo",
                "id": 8536293,
                "node_id": "MDQ6VXNlcjg1MzYyOTM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8536293?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/HuangXingBo",
                "html_url": "https://github.com/HuangXingBo",
                "followers_url": "https://api.github.com/users/HuangXingBo/followers",
                "following_url": "https://api.github.com/users/HuangXingBo/following{/other_user}",
                "gists_url": "https://api.github.com/users/HuangXingBo/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/HuangXingBo/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/HuangXingBo/subscriptions",
                "organizations_url": "https://api.github.com/users/HuangXingBo/orgs",
                "repos_url": "https://api.github.com/users/HuangXingBo/repos",
                "events_url": "https://api.github.com/users/HuangXingBo/events{/privacy}",
                "received_events_url": "https://api.github.com/users/HuangXingBo/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "HuangXingBo",
                "id": 8536293,
                "node_id": "MDQ6VXNlcjg1MzYyOTM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8536293?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/HuangXingBo",
                "html_url": "https://github.com/HuangXingBo",
                "followers_url": "https://api.github.com/users/HuangXingBo/followers",
                "following_url": "https://api.github.com/users/HuangXingBo/following{/other_user}",
                "gists_url": "https://api.github.com/users/HuangXingBo/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/HuangXingBo/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/HuangXingBo/subscriptions",
                "organizations_url": "https://api.github.com/users/HuangXingBo/orgs",
                "repos_url": "https://api.github.com/users/HuangXingBo/repos",
                "events_url": "https://api.github.com/users/HuangXingBo/events{/privacy}",
                "received_events_url": "https://api.github.com/users/HuangXingBo/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "28e1f7de58aa534efb533b5de42d2a78f4c4dd96",
                "url": "https://api.github.com/repos/apache/flink/commits/28e1f7de58aa534efb533b5de42d2a78f4c4dd96",
                "html_url": "https://github.com/apache/flink/commit/28e1f7de58aa534efb533b5de42d2a78f4c4dd96"
            }]
        },
        {
            "sha": "ea3d085f6b19b6dfb36462650344229c9a3ca70b",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZWEzZDA4NWY2YjE5YjZkZmIzNjQ2MjY1MDM0NDIyOWM5YTNjYTcwYg==",
            "commit": {
                "author": {
                    "name": "shizhengchao",
                    "email": "shizhengchao@outlook.com",
                    "date": "2021-06-24T02:11:58Z"
                },
                "committer": {
                    "name": "Rui Li",
                    "email": "lirui@apache.org",
                    "date": "2021-06-24T03:17:44Z"
                },
                "message": "[FLINK-23096][Connectors/Hive] Optimize the SessionState exception capture to print out the correct and useful information\n\nThis closes #16259",
                "tree": {
                    "sha": "20a07f7b5c82d529eeec7e77217629ade6203af1",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/20a07f7b5c82d529eeec7e77217629ade6203af1"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/ea3d085f6b19b6dfb36462650344229c9a3ca70b",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/ea3d085f6b19b6dfb36462650344229c9a3ca70b",
            "html_url": "https://github.com/apache/flink/commit/ea3d085f6b19b6dfb36462650344229c9a3ca70b",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/ea3d085f6b19b6dfb36462650344229c9a3ca70b/comments",
            "author": {
                "login": "shizhengchao",
                "id": 22866465,
                "node_id": "MDQ6VXNlcjIyODY2NDY1",
                "avatar_url": "https://avatars.githubusercontent.com/u/22866465?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/shizhengchao",
                "html_url": "https://github.com/shizhengchao",
                "followers_url": "https://api.github.com/users/shizhengchao/followers",
                "following_url": "https://api.github.com/users/shizhengchao/following{/other_user}",
                "gists_url": "https://api.github.com/users/shizhengchao/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/shizhengchao/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/shizhengchao/subscriptions",
                "organizations_url": "https://api.github.com/users/shizhengchao/orgs",
                "repos_url": "https://api.github.com/users/shizhengchao/repos",
                "events_url": "https://api.github.com/users/shizhengchao/events{/privacy}",
                "received_events_url": "https://api.github.com/users/shizhengchao/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "lirui-apache",
                "id": 5210788,
                "node_id": "MDQ6VXNlcjUyMTA3ODg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5210788?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/lirui-apache",
                "html_url": "https://github.com/lirui-apache",
                "followers_url": "https://api.github.com/users/lirui-apache/followers",
                "following_url": "https://api.github.com/users/lirui-apache/following{/other_user}",
                "gists_url": "https://api.github.com/users/lirui-apache/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/lirui-apache/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/lirui-apache/subscriptions",
                "organizations_url": "https://api.github.com/users/lirui-apache/orgs",
                "repos_url": "https://api.github.com/users/lirui-apache/repos",
                "events_url": "https://api.github.com/users/lirui-apache/events{/privacy}",
                "received_events_url": "https://api.github.com/users/lirui-apache/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "d755fa945632c135a6179a837d776d21ec28f63c",
                "url": "https://api.github.com/repos/apache/flink/commits/d755fa945632c135a6179a837d776d21ec28f63c",
                "html_url": "https://github.com/apache/flink/commit/d755fa945632c135a6179a837d776d21ec28f63c"
            }]
        },
        {
            "sha": "f63bd0b0ab0a40a8b875dbda31e7c2953e34cac6",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZjYzYmQwYjBhYjBhNDBhOGI4NzVkYmRhMzFlN2MyOTUzZTM0Y2FjNg==",
            "commit": {
                "author": {
                    "name": "huangxingbo",
                    "email": "hxbks2ks@gmail.com",
                    "date": "2021-06-23T09:19:23Z"
                },
                "committer": {
                    "name": "Dian Fu",
                    "email": "dianfu@apache.org",
                    "date": "2021-06-24T03:47:35Z"
                },
                "message": "[FLINK-23119][python] Throw exceptions when compiling the job at places where Python UDAF is not supported\n\nThis is to give a more helpful message if Python UDAF is used in places where it's not supported.\n\nThis closes #16254.",
                "tree": {
                    "sha": "ea8adc18d3de14df9455553c6107d6a079b78daa",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/ea8adc18d3de14df9455553c6107d6a079b78daa"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/f63bd0b0ab0a40a8b875dbda31e7c2953e34cac6",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/f63bd0b0ab0a40a8b875dbda31e7c2953e34cac6",
            "html_url": "https://github.com/apache/flink/commit/f63bd0b0ab0a40a8b875dbda31e7c2953e34cac6",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/f63bd0b0ab0a40a8b875dbda31e7c2953e34cac6/comments",
            "author": {
                "login": "HuangXingBo",
                "id": 8536293,
                "node_id": "MDQ6VXNlcjg1MzYyOTM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8536293?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/HuangXingBo",
                "html_url": "https://github.com/HuangXingBo",
                "followers_url": "https://api.github.com/users/HuangXingBo/followers",
                "following_url": "https://api.github.com/users/HuangXingBo/following{/other_user}",
                "gists_url": "https://api.github.com/users/HuangXingBo/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/HuangXingBo/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/HuangXingBo/subscriptions",
                "organizations_url": "https://api.github.com/users/HuangXingBo/orgs",
                "repos_url": "https://api.github.com/users/HuangXingBo/repos",
                "events_url": "https://api.github.com/users/HuangXingBo/events{/privacy}",
                "received_events_url": "https://api.github.com/users/HuangXingBo/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "dianfu",
                "id": 5466492,
                "node_id": "MDQ6VXNlcjU0NjY0OTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5466492?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dianfu",
                "html_url": "https://github.com/dianfu",
                "followers_url": "https://api.github.com/users/dianfu/followers",
                "following_url": "https://api.github.com/users/dianfu/following{/other_user}",
                "gists_url": "https://api.github.com/users/dianfu/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dianfu/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dianfu/subscriptions",
                "organizations_url": "https://api.github.com/users/dianfu/orgs",
                "repos_url": "https://api.github.com/users/dianfu/repos",
                "events_url": "https://api.github.com/users/dianfu/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dianfu/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "ea3d085f6b19b6dfb36462650344229c9a3ca70b",
                "url": "https://api.github.com/repos/apache/flink/commits/ea3d085f6b19b6dfb36462650344229c9a3ca70b",
                "html_url": "https://github.com/apache/flink/commit/ea3d085f6b19b6dfb36462650344229c9a3ca70b"
            }]
        },
        {
            "sha": "147d2b1bff6a055c0f8c928af7afc01dd9aa048b",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MTQ3ZDJiMWJmZjZhMDU1YzBmOGM5MjhhZjdhZmMwMWRkOWFhMDQ4Yg==",
            "commit": {
                "author": {
                    "name": "Lars Bachmann",
                    "email": "Lars.Bachmann@sony.com",
                    "date": "2021-04-29T07:31:51Z"
                },
                "committer": {
                    "name": "Timo Walther",
                    "email": "twalthr@apache.org",
                    "date": "2021-06-24T06:53:36Z"
                },
                "message": "[FLINK-21229][avro-confluent-registry] Add Confluent schema registry SSL support",
                "tree": {
                    "sha": "aaafeac2bc6a8df3360d8d67e44ee89c03d12de4",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/aaafeac2bc6a8df3360d8d67e44ee89c03d12de4"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/147d2b1bff6a055c0f8c928af7afc01dd9aa048b",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/147d2b1bff6a055c0f8c928af7afc01dd9aa048b",
            "html_url": "https://github.com/apache/flink/commit/147d2b1bff6a055c0f8c928af7afc01dd9aa048b",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/147d2b1bff6a055c0f8c928af7afc01dd9aa048b/comments",
            "author": null,
            "committer": {
                "login": "twalthr",
                "id": 5746567,
                "node_id": "MDQ6VXNlcjU3NDY1Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5746567?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/twalthr",
                "html_url": "https://github.com/twalthr",
                "followers_url": "https://api.github.com/users/twalthr/followers",
                "following_url": "https://api.github.com/users/twalthr/following{/other_user}",
                "gists_url": "https://api.github.com/users/twalthr/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/twalthr/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/twalthr/subscriptions",
                "organizations_url": "https://api.github.com/users/twalthr/orgs",
                "repos_url": "https://api.github.com/users/twalthr/repos",
                "events_url": "https://api.github.com/users/twalthr/events{/privacy}",
                "received_events_url": "https://api.github.com/users/twalthr/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "f63bd0b0ab0a40a8b875dbda31e7c2953e34cac6",
                "url": "https://api.github.com/repos/apache/flink/commits/f63bd0b0ab0a40a8b875dbda31e7c2953e34cac6",
                "html_url": "https://github.com/apache/flink/commit/f63bd0b0ab0a40a8b875dbda31e7c2953e34cac6"
            }]
        },
        {
            "sha": "c1cf545ea4c0ed71c3d5ba3caf784436e4224f65",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6YzFjZjU0NWVhNGMwZWQ3MWMzZDViYTNjYWY3ODQ0MzZlNDIyNGY2NQ==",
            "commit": {
                "author": {
                    "name": "Timo Walther",
                    "email": "twalthr@apache.org",
                    "date": "2021-06-23T06:40:56Z"
                },
                "committer": {
                    "name": "Timo Walther",
                    "email": "twalthr@apache.org",
                    "date": "2021-06-24T06:53:36Z"
                },
                "message": "[FLINK-21229][docs] Update avro-confluent docs\n\nThis closes #15808.",
                "tree": {
                    "sha": "e6646332b87aef3482150c6f2be709a87f63acb1",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/e6646332b87aef3482150c6f2be709a87f63acb1"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/c1cf545ea4c0ed71c3d5ba3caf784436e4224f65",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/c1cf545ea4c0ed71c3d5ba3caf784436e4224f65",
            "html_url": "https://github.com/apache/flink/commit/c1cf545ea4c0ed71c3d5ba3caf784436e4224f65",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/c1cf545ea4c0ed71c3d5ba3caf784436e4224f65/comments",
            "author": {
                "login": "twalthr",
                "id": 5746567,
                "node_id": "MDQ6VXNlcjU3NDY1Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5746567?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/twalthr",
                "html_url": "https://github.com/twalthr",
                "followers_url": "https://api.github.com/users/twalthr/followers",
                "following_url": "https://api.github.com/users/twalthr/following{/other_user}",
                "gists_url": "https://api.github.com/users/twalthr/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/twalthr/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/twalthr/subscriptions",
                "organizations_url": "https://api.github.com/users/twalthr/orgs",
                "repos_url": "https://api.github.com/users/twalthr/repos",
                "events_url": "https://api.github.com/users/twalthr/events{/privacy}",
                "received_events_url": "https://api.github.com/users/twalthr/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "twalthr",
                "id": 5746567,
                "node_id": "MDQ6VXNlcjU3NDY1Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5746567?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/twalthr",
                "html_url": "https://github.com/twalthr",
                "followers_url": "https://api.github.com/users/twalthr/followers",
                "following_url": "https://api.github.com/users/twalthr/following{/other_user}",
                "gists_url": "https://api.github.com/users/twalthr/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/twalthr/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/twalthr/subscriptions",
                "organizations_url": "https://api.github.com/users/twalthr/orgs",
                "repos_url": "https://api.github.com/users/twalthr/repos",
                "events_url": "https://api.github.com/users/twalthr/events{/privacy}",
                "received_events_url": "https://api.github.com/users/twalthr/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "147d2b1bff6a055c0f8c928af7afc01dd9aa048b",
                "url": "https://api.github.com/repos/apache/flink/commits/147d2b1bff6a055c0f8c928af7afc01dd9aa048b",
                "html_url": "https://github.com/apache/flink/commit/147d2b1bff6a055c0f8c928af7afc01dd9aa048b"
            }]
        },
        {
            "sha": "5baeb0a46eb45071b66bcdbc6c9a24b03822658f",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NWJhZWIwYTQ2ZWI0NTA3MWI2NmJjZGJjNmM5YTI0YjAzODIyNjU4Zg==",
            "commit": {
                "author": {
                    "name": "Emre Kartoglu",
                    "email": "iemrek@gmail.com",
                    "date": "2021-06-18T09:00:49Z"
                },
                "committer": {
                    "name": "Danny Cranmer",
                    "email": "dannycranmer@apache.org",
                    "date": "2021-06-24T08:27:22Z"
                },
                "message": "[FLINK-23009][kinesis] Upgrade Guava for Flink Connector Kinesis\n\nAlso make flink-sql-connector-kinesis use the Guava library\ncoming transitively from the connector-kinesis dependency.",
                "tree": {
                    "sha": "8d7febfb4e99f9394a881501bb1479ae279b36cd",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/8d7febfb4e99f9394a881501bb1479ae279b36cd"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/5baeb0a46eb45071b66bcdbc6c9a24b03822658f",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/5baeb0a46eb45071b66bcdbc6c9a24b03822658f",
            "html_url": "https://github.com/apache/flink/commit/5baeb0a46eb45071b66bcdbc6c9a24b03822658f",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/5baeb0a46eb45071b66bcdbc6c9a24b03822658f/comments",
            "author": {
                "login": "iemre",
                "id": 969071,
                "node_id": "MDQ6VXNlcjk2OTA3MQ==",
                "avatar_url": "https://avatars.githubusercontent.com/u/969071?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/iemre",
                "html_url": "https://github.com/iemre",
                "followers_url": "https://api.github.com/users/iemre/followers",
                "following_url": "https://api.github.com/users/iemre/following{/other_user}",
                "gists_url": "https://api.github.com/users/iemre/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/iemre/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/iemre/subscriptions",
                "organizations_url": "https://api.github.com/users/iemre/orgs",
                "repos_url": "https://api.github.com/users/iemre/repos",
                "events_url": "https://api.github.com/users/iemre/events{/privacy}",
                "received_events_url": "https://api.github.com/users/iemre/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "dannycranmer",
                "id": 4950503,
                "node_id": "MDQ6VXNlcjQ5NTA1MDM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/4950503?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dannycranmer",
                "html_url": "https://github.com/dannycranmer",
                "followers_url": "https://api.github.com/users/dannycranmer/followers",
                "following_url": "https://api.github.com/users/dannycranmer/following{/other_user}",
                "gists_url": "https://api.github.com/users/dannycranmer/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dannycranmer/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dannycranmer/subscriptions",
                "organizations_url": "https://api.github.com/users/dannycranmer/orgs",
                "repos_url": "https://api.github.com/users/dannycranmer/repos",
                "events_url": "https://api.github.com/users/dannycranmer/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dannycranmer/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "c1cf545ea4c0ed71c3d5ba3caf784436e4224f65",
                "url": "https://api.github.com/repos/apache/flink/commits/c1cf545ea4c0ed71c3d5ba3caf784436e4224f65",
                "html_url": "https://github.com/apache/flink/commit/c1cf545ea4c0ed71c3d5ba3caf784436e4224f65"
            }]
        },
        {
            "sha": "0db977dee2cf0e74ec2d42ceff7b7a0f519ad673",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MGRiOTc3ZGVlMmNmMGU3NGVjMmQ0MmNlZmY3YjdhMGY1MTlhZDY3Mw==",
            "commit": {
                "author": {
                    "name": "HuangXingBo",
                    "email": "hxbks2ks@gmail.com",
                    "date": "2021-06-24T11:41:22Z"
                },
                "committer": {
                    "name": "GitHub",
                    "email": "noreply@github.com",
                    "date": "2021-06-24T11:41:22Z"
                },
                "message": "[FLINK-23121][python] Fix the issue that InternalRow is exposed to users in Python UDAF (#16269)",
                "tree": {
                    "sha": "61b6b3bd270be3e0d09a5f655829ec1d07905dc5",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/61b6b3bd270be3e0d09a5f655829ec1d07905dc5"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/0db977dee2cf0e74ec2d42ceff7b7a0f519ad673",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJg1G9iCRBK7hj4Ov3rIwAAwcQIAKQy86jpr8EdPQ+X6i3yhaOo\nRHi60ng6nccg6mOhwWh/U3bO7Hr1CUGkU9y8/kJv8cbOpsZ2aoQaiDTRLuBDBcg2\n3j7vxFgqcOWFVd+lob3Dayug6O41y+s+Tokvji8waIp0ABBMYc0HCQd3lGFWyYL7\n2DmDDgx1TJThyo+g0WnxUkUpD0vkWxAnBFMRLSu4/uxCp92/ZNGymZEpGHH2H7HN\nC+sFrSnrNbxYPI/Ik6L7gkSlMmbqKqzkQgPTL9NGjD3htvs3spf1/LYKCz94tl+V\nFWTgmChxS414qwF+O9gLnc1FZvw+lwXISW2DHK6gG0nPESjTbkE8YS5G6gXiDiw=\n=xbb+\n-----END PGP SIGNATURE-----\n",
                    "payload": "tree 61b6b3bd270be3e0d09a5f655829ec1d07905dc5\nparent 5baeb0a46eb45071b66bcdbc6c9a24b03822658f\nauthor HuangXingBo <hxbks2ks@gmail.com> 1624534882 +0800\ncommitter GitHub <noreply@github.com> 1624534882 +0800\n\n[FLINK-23121][python] Fix the issue that InternalRow is exposed to users in Python UDAF (#16269)\n\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/0db977dee2cf0e74ec2d42ceff7b7a0f519ad673",
            "html_url": "https://github.com/apache/flink/commit/0db977dee2cf0e74ec2d42ceff7b7a0f519ad673",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/0db977dee2cf0e74ec2d42ceff7b7a0f519ad673/comments",
            "author": {
                "login": "HuangXingBo",
                "id": 8536293,
                "node_id": "MDQ6VXNlcjg1MzYyOTM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8536293?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/HuangXingBo",
                "html_url": "https://github.com/HuangXingBo",
                "followers_url": "https://api.github.com/users/HuangXingBo/followers",
                "following_url": "https://api.github.com/users/HuangXingBo/following{/other_user}",
                "gists_url": "https://api.github.com/users/HuangXingBo/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/HuangXingBo/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/HuangXingBo/subscriptions",
                "organizations_url": "https://api.github.com/users/HuangXingBo/orgs",
                "repos_url": "https://api.github.com/users/HuangXingBo/repos",
                "events_url": "https://api.github.com/users/HuangXingBo/events{/privacy}",
                "received_events_url": "https://api.github.com/users/HuangXingBo/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "web-flow",
                "id": 19864447,
                "node_id": "MDQ6VXNlcjE5ODY0NDQ3",
                "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/web-flow",
                "html_url": "https://github.com/web-flow",
                "followers_url": "https://api.github.com/users/web-flow/followers",
                "following_url": "https://api.github.com/users/web-flow/following{/other_user}",
                "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions",
                "organizations_url": "https://api.github.com/users/web-flow/orgs",
                "repos_url": "https://api.github.com/users/web-flow/repos",
                "events_url": "https://api.github.com/users/web-flow/events{/privacy}",
                "received_events_url": "https://api.github.com/users/web-flow/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "5baeb0a46eb45071b66bcdbc6c9a24b03822658f",
                "url": "https://api.github.com/repos/apache/flink/commits/5baeb0a46eb45071b66bcdbc6c9a24b03822658f",
                "html_url": "https://github.com/apache/flink/commit/5baeb0a46eb45071b66bcdbc6c9a24b03822658f"
            }]
        },
        {
            "sha": "4695fa5fb7f90d843b4dae7b2dfb5c9ff807b701",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NDY5NWZhNWZiN2Y5MGQ4NDNiNGRhZTdiMmRmYjVjOWZmODA3YjcwMQ==",
            "commit": {
                "author": {
                    "name": "Dian Fu",
                    "email": "dianfu@apache.org",
                    "date": "2021-06-24T07:26:11Z"
                },
                "committer": {
                    "name": "Dian Fu",
                    "email": "dianfu@apache.org",
                    "date": "2021-06-25T01:54:31Z"
                },
                "message": "[FLINK-23133][python] Properly handle the dependencies when mixing use of Python Table API and Python DataStream API\n\nThis closes #16272.",
                "tree": {
                    "sha": "9f70a32c1429ab53ac53847873766ed2d2d3ed0c",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/9f70a32c1429ab53ac53847873766ed2d2d3ed0c"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/4695fa5fb7f90d843b4dae7b2dfb5c9ff807b701",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/4695fa5fb7f90d843b4dae7b2dfb5c9ff807b701",
            "html_url": "https://github.com/apache/flink/commit/4695fa5fb7f90d843b4dae7b2dfb5c9ff807b701",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/4695fa5fb7f90d843b4dae7b2dfb5c9ff807b701/comments",
            "author": {
                "login": "dianfu",
                "id": 5466492,
                "node_id": "MDQ6VXNlcjU0NjY0OTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5466492?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dianfu",
                "html_url": "https://github.com/dianfu",
                "followers_url": "https://api.github.com/users/dianfu/followers",
                "following_url": "https://api.github.com/users/dianfu/following{/other_user}",
                "gists_url": "https://api.github.com/users/dianfu/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dianfu/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dianfu/subscriptions",
                "organizations_url": "https://api.github.com/users/dianfu/orgs",
                "repos_url": "https://api.github.com/users/dianfu/repos",
                "events_url": "https://api.github.com/users/dianfu/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dianfu/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "dianfu",
                "id": 5466492,
                "node_id": "MDQ6VXNlcjU0NjY0OTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5466492?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dianfu",
                "html_url": "https://github.com/dianfu",
                "followers_url": "https://api.github.com/users/dianfu/followers",
                "following_url": "https://api.github.com/users/dianfu/following{/other_user}",
                "gists_url": "https://api.github.com/users/dianfu/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dianfu/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dianfu/subscriptions",
                "organizations_url": "https://api.github.com/users/dianfu/orgs",
                "repos_url": "https://api.github.com/users/dianfu/repos",
                "events_url": "https://api.github.com/users/dianfu/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dianfu/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "0db977dee2cf0e74ec2d42ceff7b7a0f519ad673",
                "url": "https://api.github.com/repos/apache/flink/commits/0db977dee2cf0e74ec2d42ceff7b7a0f519ad673",
                "html_url": "https://github.com/apache/flink/commit/0db977dee2cf0e74ec2d42ceff7b7a0f519ad673"
            }]
        },
        {
            "sha": "e163f19ccc0c3072a078c0303971fc5366568fb4",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZTE2M2YxOWNjYzBjMzA3MmEwNzhjMDMwMzk3MWZjNTM2NjU2OGZiNA==",
            "commit": {
                "author": {
                    "name": "Dian Fu",
                    "email": "dianfu@apache.org",
                    "date": "2021-06-24T08:38:41Z"
                },
                "committer": {
                    "name": "Dian Fu",
                    "email": "dianfu@apache.org",
                    "date": "2021-06-25T02:23:07Z"
                },
                "message": "[FLINK-23138][python] Raise an exception if types other than PickledBytesTypeInfo are specified for state descriptor\n\nThis closes #16276.",
                "tree": {
                    "sha": "5c55e01ea38f8f79e58a092d2667e230f7fd42b5",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/5c55e01ea38f8f79e58a092d2667e230f7fd42b5"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/e163f19ccc0c3072a078c0303971fc5366568fb4",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/e163f19ccc0c3072a078c0303971fc5366568fb4",
            "html_url": "https://github.com/apache/flink/commit/e163f19ccc0c3072a078c0303971fc5366568fb4",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/e163f19ccc0c3072a078c0303971fc5366568fb4/comments",
            "author": {
                "login": "dianfu",
                "id": 5466492,
                "node_id": "MDQ6VXNlcjU0NjY0OTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5466492?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dianfu",
                "html_url": "https://github.com/dianfu",
                "followers_url": "https://api.github.com/users/dianfu/followers",
                "following_url": "https://api.github.com/users/dianfu/following{/other_user}",
                "gists_url": "https://api.github.com/users/dianfu/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dianfu/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dianfu/subscriptions",
                "organizations_url": "https://api.github.com/users/dianfu/orgs",
                "repos_url": "https://api.github.com/users/dianfu/repos",
                "events_url": "https://api.github.com/users/dianfu/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dianfu/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "dianfu",
                "id": 5466492,
                "node_id": "MDQ6VXNlcjU0NjY0OTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5466492?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dianfu",
                "html_url": "https://github.com/dianfu",
                "followers_url": "https://api.github.com/users/dianfu/followers",
                "following_url": "https://api.github.com/users/dianfu/following{/other_user}",
                "gists_url": "https://api.github.com/users/dianfu/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dianfu/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dianfu/subscriptions",
                "organizations_url": "https://api.github.com/users/dianfu/orgs",
                "repos_url": "https://api.github.com/users/dianfu/repos",
                "events_url": "https://api.github.com/users/dianfu/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dianfu/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "4695fa5fb7f90d843b4dae7b2dfb5c9ff807b701",
                "url": "https://api.github.com/repos/apache/flink/commits/4695fa5fb7f90d843b4dae7b2dfb5c9ff807b701",
                "html_url": "https://github.com/apache/flink/commit/4695fa5fb7f90d843b4dae7b2dfb5c9ff807b701"
            }]
        },
        {
            "sha": "7d71b0b0d771e456460be9984f3d95b4d1500aa2",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6N2Q3MWIwYjBkNzcxZTQ1NjQ2MGJlOTk4NGYzZDk1YjRkMTUwMGFhMg==",
            "commit": {
                "author": {
                    "name": "Xintong Song",
                    "email": "tonysong820@gmail.com",
                    "date": "2021-06-25T03:36:38Z"
                },
                "committer": {
                    "name": "Xintong Song",
                    "email": "tonysong820@gmail.com",
                    "date": "2021-06-25T03:36:38Z"
                },
                "message": "[FLINK-23151] Revert \"[FLINK-23009][kinesis] Upgrade Guava for Flink Connector Kinesis\"\n\nThis reverts commit 5baeb0a46eb45071b66bcdbc6c9a24b03822658f.",
                "tree": {
                    "sha": "a01a9f02270abda934c4a1e430416bcfdfe1b943",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/a01a9f02270abda934c4a1e430416bcfdfe1b943"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/7d71b0b0d771e456460be9984f3d95b4d1500aa2",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCgAdFiEEGsvLF58sbVnbyFd20SHP9Sk+Y18FAmDVT1AACgkQ0SHP9Sk+\nY1+rlA/+MJHpWkwOQWnYYi+uHCfU8cjOBnlJ+QN7nrNmfL0BGo9WPPLhIW6hDsNO\nDhi4iyT9HBEnsvZiun9Od6YdBrQNdoU5cJTfhwKqFpZDF90/NjFjQxqBPpJKPUnD\n2QLxpJzwdsFAJQHFOsLHixNPS9A3rBBxs4sGLc11hksWT8+AiT7aLStVxJcWeEHg\nPptki11Dl5FrudkJuWWwFGN7Ap97hrEC4uKN3RJQXg76GMaWQeti03w6hyU2wzLB\nZJLefj+/otVZwo8R8hIUnwymgEnWyHRIMhhMouDhKIPRe6rSaNnMFgvQJ7bxCInn\nd4vtwPxjtpaZeQDt1dxYt6Qq/fr/VlTO/0fYBM/MUTOttP3dpeUEQZChnjt4jPot\nnZTV9N/OD7AbvD8glX9yYFx2P4EqfIVxhXA9bsjLzuDCcyMXxbkSPoUvWb7PzLfG\nsDdPZgtqCcZFM0PDE4dqaW4MJuU/Gk8MHJ4YqFxK/kX85ZoCxS5f3ze1rLkp3hjg\n7rn5acP34zbHqCi4P+oNpPUlLG+yAcL4/FR+0LGNh9HS8lgDSxLDIv6OO9NLbmGO\nOQRwb/jUHCs64ZT15Pktn34rKCTfCfWgnEHQYh4ENe9f/VrdRyMoZ45Z/96ZK6Aw\nOYdpmWZGqS2ng6NgKToeISB0wqvxFT5qhLoZZoWY9erSHkEkN/8=\n=txs6\n-----END PGP SIGNATURE-----",
                    "payload": "tree a01a9f02270abda934c4a1e430416bcfdfe1b943\nparent e163f19ccc0c3072a078c0303971fc5366568fb4\nauthor Xintong Song <tonysong820@gmail.com> 1624592198 +0800\ncommitter Xintong Song <tonysong820@gmail.com> 1624592198 +0800\n\n[FLINK-23151] Revert \"[FLINK-23009][kinesis] Upgrade Guava for Flink Connector Kinesis\"\n\nThis reverts commit 5baeb0a46eb45071b66bcdbc6c9a24b03822658f.\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/7d71b0b0d771e456460be9984f3d95b4d1500aa2",
            "html_url": "https://github.com/apache/flink/commit/7d71b0b0d771e456460be9984f3d95b4d1500aa2",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/7d71b0b0d771e456460be9984f3d95b4d1500aa2/comments",
            "author": {
                "login": "xintongsong",
                "id": 6509172,
                "node_id": "MDQ6VXNlcjY1MDkxNzI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6509172?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/xintongsong",
                "html_url": "https://github.com/xintongsong",
                "followers_url": "https://api.github.com/users/xintongsong/followers",
                "following_url": "https://api.github.com/users/xintongsong/following{/other_user}",
                "gists_url": "https://api.github.com/users/xintongsong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/xintongsong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/xintongsong/subscriptions",
                "organizations_url": "https://api.github.com/users/xintongsong/orgs",
                "repos_url": "https://api.github.com/users/xintongsong/repos",
                "events_url": "https://api.github.com/users/xintongsong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/xintongsong/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "xintongsong",
                "id": 6509172,
                "node_id": "MDQ6VXNlcjY1MDkxNzI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6509172?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/xintongsong",
                "html_url": "https://github.com/xintongsong",
                "followers_url": "https://api.github.com/users/xintongsong/followers",
                "following_url": "https://api.github.com/users/xintongsong/following{/other_user}",
                "gists_url": "https://api.github.com/users/xintongsong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/xintongsong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/xintongsong/subscriptions",
                "organizations_url": "https://api.github.com/users/xintongsong/orgs",
                "repos_url": "https://api.github.com/users/xintongsong/repos",
                "events_url": "https://api.github.com/users/xintongsong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/xintongsong/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "e163f19ccc0c3072a078c0303971fc5366568fb4",
                "url": "https://api.github.com/repos/apache/flink/commits/e163f19ccc0c3072a078c0303971fc5366568fb4",
                "html_url": "https://github.com/apache/flink/commit/e163f19ccc0c3072a078c0303971fc5366568fb4"
            }]
        },
        {
            "sha": "86581e90fb59289c4ad4be24495a9895d1099176",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ODY1ODFlOTBmYjU5Mjg5YzRhZDRiZTI0NDk1YTk4OTVkMTA5OTE3Ng==",
            "commit": {
                "author": {
                    "name": "Rui Li",
                    "email": "lirui@apache.org",
                    "date": "2021-06-17T08:49:51Z"
                },
                "committer": {
                    "name": "Rui Li",
                    "email": "lirui@apache.org",
                    "date": "2021-06-25T04:01:22Z"
                },
                "message": "[FLINK-23010][hive] HivePartitionFetcherContextBase shouldn't list folders to discover new partitions\n\nThis closes #16182",
                "tree": {
                    "sha": "0f812d2583203de30757d26302b8041c59fd815b",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/0f812d2583203de30757d26302b8041c59fd815b"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/86581e90fb59289c4ad4be24495a9895d1099176",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/86581e90fb59289c4ad4be24495a9895d1099176",
            "html_url": "https://github.com/apache/flink/commit/86581e90fb59289c4ad4be24495a9895d1099176",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/86581e90fb59289c4ad4be24495a9895d1099176/comments",
            "author": {
                "login": "lirui-apache",
                "id": 5210788,
                "node_id": "MDQ6VXNlcjUyMTA3ODg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5210788?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/lirui-apache",
                "html_url": "https://github.com/lirui-apache",
                "followers_url": "https://api.github.com/users/lirui-apache/followers",
                "following_url": "https://api.github.com/users/lirui-apache/following{/other_user}",
                "gists_url": "https://api.github.com/users/lirui-apache/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/lirui-apache/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/lirui-apache/subscriptions",
                "organizations_url": "https://api.github.com/users/lirui-apache/orgs",
                "repos_url": "https://api.github.com/users/lirui-apache/repos",
                "events_url": "https://api.github.com/users/lirui-apache/events{/privacy}",
                "received_events_url": "https://api.github.com/users/lirui-apache/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "lirui-apache",
                "id": 5210788,
                "node_id": "MDQ6VXNlcjUyMTA3ODg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5210788?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/lirui-apache",
                "html_url": "https://github.com/lirui-apache",
                "followers_url": "https://api.github.com/users/lirui-apache/followers",
                "following_url": "https://api.github.com/users/lirui-apache/following{/other_user}",
                "gists_url": "https://api.github.com/users/lirui-apache/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/lirui-apache/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/lirui-apache/subscriptions",
                "organizations_url": "https://api.github.com/users/lirui-apache/orgs",
                "repos_url": "https://api.github.com/users/lirui-apache/repos",
                "events_url": "https://api.github.com/users/lirui-apache/events{/privacy}",
                "received_events_url": "https://api.github.com/users/lirui-apache/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "7d71b0b0d771e456460be9984f3d95b4d1500aa2",
                "url": "https://api.github.com/repos/apache/flink/commits/7d71b0b0d771e456460be9984f3d95b4d1500aa2",
                "html_url": "https://github.com/apache/flink/commit/7d71b0b0d771e456460be9984f3d95b4d1500aa2"
            }]
        },
        {
            "sha": "6634b3fc4ef7305513cef067b15edc3d4fa61e7f",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NjYzNGIzZmM0ZWY3MzA1NTEzY2VmMDY3YjE1ZWRjM2Q0ZmE2MWU3Zg==",
            "commit": {
                "author": {
                    "name": "Robert Metzger",
                    "email": "rmetzger@apache.org",
                    "date": "2021-06-24T13:12:55Z"
                },
                "committer": {
                    "name": "Robert Metzger",
                    "email": "rmetzger@apache.org",
                    "date": "2021-06-25T09:40:56Z"
                },
                "message": "[FLINK-23129][docs] Document ApplicationMode limitations\n\nThis closes #16281",
                "tree": {
                    "sha": "565d2fee4011fb37c8e73eb32290bd31a0e656b4",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/565d2fee4011fb37c8e73eb32290bd31a0e656b4"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/6634b3fc4ef7305513cef067b15edc3d4fa61e7f",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/6634b3fc4ef7305513cef067b15edc3d4fa61e7f",
            "html_url": "https://github.com/apache/flink/commit/6634b3fc4ef7305513cef067b15edc3d4fa61e7f",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/6634b3fc4ef7305513cef067b15edc3d4fa61e7f/comments",
            "author": {
                "login": "rmetzger",
                "id": 89049,
                "node_id": "MDQ6VXNlcjg5MDQ5",
                "avatar_url": "https://avatars.githubusercontent.com/u/89049?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rmetzger",
                "html_url": "https://github.com/rmetzger",
                "followers_url": "https://api.github.com/users/rmetzger/followers",
                "following_url": "https://api.github.com/users/rmetzger/following{/other_user}",
                "gists_url": "https://api.github.com/users/rmetzger/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rmetzger/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rmetzger/subscriptions",
                "organizations_url": "https://api.github.com/users/rmetzger/orgs",
                "repos_url": "https://api.github.com/users/rmetzger/repos",
                "events_url": "https://api.github.com/users/rmetzger/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rmetzger/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "rmetzger",
                "id": 89049,
                "node_id": "MDQ6VXNlcjg5MDQ5",
                "avatar_url": "https://avatars.githubusercontent.com/u/89049?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rmetzger",
                "html_url": "https://github.com/rmetzger",
                "followers_url": "https://api.github.com/users/rmetzger/followers",
                "following_url": "https://api.github.com/users/rmetzger/following{/other_user}",
                "gists_url": "https://api.github.com/users/rmetzger/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rmetzger/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rmetzger/subscriptions",
                "organizations_url": "https://api.github.com/users/rmetzger/orgs",
                "repos_url": "https://api.github.com/users/rmetzger/repos",
                "events_url": "https://api.github.com/users/rmetzger/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rmetzger/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "86581e90fb59289c4ad4be24495a9895d1099176",
                "url": "https://api.github.com/repos/apache/flink/commits/86581e90fb59289c4ad4be24495a9895d1099176",
                "html_url": "https://github.com/apache/flink/commit/86581e90fb59289c4ad4be24495a9895d1099176"
            }]
        },
        {
            "sha": "fa52d7d53c8852f12dba912089c759689fd92668",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZmE1MmQ3ZDUzYzg4NTJmMTJkYmE5MTIwODljNzU5Njg5ZmQ5MjY2OA==",
            "commit": {
                "author": {
                    "name": "Robert Metzger",
                    "email": "rmetzger@apache.org",
                    "date": "2021-06-21T20:19:49Z"
                },
                "committer": {
                    "name": "Robert Metzger",
                    "email": "rmetzger@apache.org",
                    "date": "2021-06-25T13:58:15Z"
                },
                "message": "[hotfix] Fix some typos in comments",
                "tree": {
                    "sha": "86900779336c20315728355f660cc0e99e82cada",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/86900779336c20315728355f660cc0e99e82cada"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/fa52d7d53c8852f12dba912089c759689fd92668",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/fa52d7d53c8852f12dba912089c759689fd92668",
            "html_url": "https://github.com/apache/flink/commit/fa52d7d53c8852f12dba912089c759689fd92668",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/fa52d7d53c8852f12dba912089c759689fd92668/comments",
            "author": {
                "login": "rmetzger",
                "id": 89049,
                "node_id": "MDQ6VXNlcjg5MDQ5",
                "avatar_url": "https://avatars.githubusercontent.com/u/89049?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rmetzger",
                "html_url": "https://github.com/rmetzger",
                "followers_url": "https://api.github.com/users/rmetzger/followers",
                "following_url": "https://api.github.com/users/rmetzger/following{/other_user}",
                "gists_url": "https://api.github.com/users/rmetzger/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rmetzger/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rmetzger/subscriptions",
                "organizations_url": "https://api.github.com/users/rmetzger/orgs",
                "repos_url": "https://api.github.com/users/rmetzger/repos",
                "events_url": "https://api.github.com/users/rmetzger/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rmetzger/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "rmetzger",
                "id": 89049,
                "node_id": "MDQ6VXNlcjg5MDQ5",
                "avatar_url": "https://avatars.githubusercontent.com/u/89049?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rmetzger",
                "html_url": "https://github.com/rmetzger",
                "followers_url": "https://api.github.com/users/rmetzger/followers",
                "following_url": "https://api.github.com/users/rmetzger/following{/other_user}",
                "gists_url": "https://api.github.com/users/rmetzger/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rmetzger/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rmetzger/subscriptions",
                "organizations_url": "https://api.github.com/users/rmetzger/orgs",
                "repos_url": "https://api.github.com/users/rmetzger/repos",
                "events_url": "https://api.github.com/users/rmetzger/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rmetzger/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "6634b3fc4ef7305513cef067b15edc3d4fa61e7f",
                "url": "https://api.github.com/repos/apache/flink/commits/6634b3fc4ef7305513cef067b15edc3d4fa61e7f",
                "html_url": "https://github.com/apache/flink/commit/6634b3fc4ef7305513cef067b15edc3d4fa61e7f"
            }]
        },
        {
            "sha": "cd54b584371b67e67015d104d34c2f19a446e2b3",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6Y2Q1NGI1ODQzNzFiNjdlNjcwMTVkMTA0ZDM0YzJmMTlhNDQ2ZTJiMw==",
            "commit": {
                "author": {
                    "name": "Robert Metzger",
                    "email": "rmetzger@apache.org",
                    "date": "2021-06-21T20:21:21Z"
                },
                "committer": {
                    "name": "Robert Metzger",
                    "email": "rmetzger@apache.org",
                    "date": "2021-06-25T13:58:16Z"
                },
                "message": "[FLINK-22464][tests] Fix OperatorCoordinator test which is stalling or slow with AdaptiveScheduler\n\nThis closes #16229",
                "tree": {
                    "sha": "6c34d3945220a3da055f5d8da18c92bad440caac",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/6c34d3945220a3da055f5d8da18c92bad440caac"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/cd54b584371b67e67015d104d34c2f19a446e2b3",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/cd54b584371b67e67015d104d34c2f19a446e2b3",
            "html_url": "https://github.com/apache/flink/commit/cd54b584371b67e67015d104d34c2f19a446e2b3",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/cd54b584371b67e67015d104d34c2f19a446e2b3/comments",
            "author": {
                "login": "rmetzger",
                "id": 89049,
                "node_id": "MDQ6VXNlcjg5MDQ5",
                "avatar_url": "https://avatars.githubusercontent.com/u/89049?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rmetzger",
                "html_url": "https://github.com/rmetzger",
                "followers_url": "https://api.github.com/users/rmetzger/followers",
                "following_url": "https://api.github.com/users/rmetzger/following{/other_user}",
                "gists_url": "https://api.github.com/users/rmetzger/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rmetzger/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rmetzger/subscriptions",
                "organizations_url": "https://api.github.com/users/rmetzger/orgs",
                "repos_url": "https://api.github.com/users/rmetzger/repos",
                "events_url": "https://api.github.com/users/rmetzger/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rmetzger/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "rmetzger",
                "id": 89049,
                "node_id": "MDQ6VXNlcjg5MDQ5",
                "avatar_url": "https://avatars.githubusercontent.com/u/89049?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rmetzger",
                "html_url": "https://github.com/rmetzger",
                "followers_url": "https://api.github.com/users/rmetzger/followers",
                "following_url": "https://api.github.com/users/rmetzger/following{/other_user}",
                "gists_url": "https://api.github.com/users/rmetzger/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rmetzger/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rmetzger/subscriptions",
                "organizations_url": "https://api.github.com/users/rmetzger/orgs",
                "repos_url": "https://api.github.com/users/rmetzger/repos",
                "events_url": "https://api.github.com/users/rmetzger/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rmetzger/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "fa52d7d53c8852f12dba912089c759689fd92668",
                "url": "https://api.github.com/repos/apache/flink/commits/fa52d7d53c8852f12dba912089c759689fd92668",
                "html_url": "https://github.com/apache/flink/commit/fa52d7d53c8852f12dba912089c759689fd92668"
            }]
        },
        {
            "sha": "fe5f2d1aa3552a24f06306c341e8d34e1d287ed2",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZmU1ZjJkMWFhMzU1MmEyNGYwNjMwNmMzNDFlOGQzNGUxZDI4N2VkMg==",
            "commit": {
                "author": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-06-23T14:24:23Z"
                },
                "committer": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-06-25T15:41:59Z"
                },
                "message": "[hotfix] Let RunnablesTest extend TestLogger",
                "tree": {
                    "sha": "079ea1245ae58484b27a1358bbd177f3976277fd",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/079ea1245ae58484b27a1358bbd177f3976277fd"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/fe5f2d1aa3552a24f06306c341e8d34e1d287ed2",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEEuUmfpp7/Xe7rw8H1un5Bh8b3PYIFAmDV+UcACgkQun5Bh8b3\nPYKN7g/+LNwJ43nK/UlIcp3hziBzhQazxI2ly8Ll5u2B613zREcNrPSCzAjQeGg2\nYKPbKqVf72aIT2Dn6gS/DUnYBWk0/Wa2DrKdvN9LsWSUeKxcd0LtV4Mqqgcb7SnJ\n3gZJJB9T7QqCKuC/XVKA+CvOwbISYG8A3kJDC9o2Z3c1/Eh3blkOJ75+t13eafN9\nHwaoVenS+NhCBTokhZbBTPily2kRVH6bzvYgrHWZ6bz5VqXQSE7GrnZq2UJRkKj7\nyOpaS6K4rq2iXiYs4Dn1K2k4iFhwFNNH/o8JFIl/dIwg5bg4eDCV1r35qiXw9zKN\nVJ0yXEcFmAHZoGIK8KeSs7bLf7nXKm/yMcGiuhsxbqWqnNORpY7c8rhauEaqNjWu\nAB523+eipRqmb410M029FzwJxrhuOqNINrzm/fBzQNZOl//OgVmAkEhdhEI/vD6f\nntKCBlSnMjTF6aBWNGqnNK33HFi5DGQIzPw9JHSvSNsbCeeyyn5xR+QI+UJQnqDM\nA6s6VEhCYJtw4kq3A+WsYSNYaALZ17vtJroInn5nXbrha0c+O7Hw4elgfL5Fd6eO\n9rLqDqCeroQ1VuqTzDZSDvZgAL6djD0vJ6JobdcFJauBdWxuICjMeJaOIRqpHvNt\n839B55XShRWkwjrxpVv+30hXcqwbX9s+YquCGqzWM5Nc1SF6x3k=\n=pvzA\n-----END PGP SIGNATURE-----",
                    "payload": "tree 079ea1245ae58484b27a1358bbd177f3976277fd\nparent cd54b584371b67e67015d104d34c2f19a446e2b3\nauthor Till Rohrmann <trohrmann@apache.org> 1624458263 +0200\ncommitter Till Rohrmann <trohrmann@apache.org> 1624635719 +0200\n\n[hotfix] Let RunnablesTest extend TestLogger\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/fe5f2d1aa3552a24f06306c341e8d34e1d287ed2",
            "html_url": "https://github.com/apache/flink/commit/fe5f2d1aa3552a24f06306c341e8d34e1d287ed2",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/fe5f2d1aa3552a24f06306c341e8d34e1d287ed2/comments",
            "author": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "cd54b584371b67e67015d104d34c2f19a446e2b3",
                "url": "https://api.github.com/repos/apache/flink/commits/cd54b584371b67e67015d104d34c2f19a446e2b3",
                "html_url": "https://github.com/apache/flink/commit/cd54b584371b67e67015d104d34c2f19a446e2b3"
            }]
        },
        {
            "sha": "d9121d701d6a1b1e950ed6d41f5c91d5321477e3",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZDkxMjFkNzAxZDZhMWIxZTk1MGVkNmQ0MWY1YzkxZDUzMjE0NzdlMw==",
            "commit": {
                "author": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-06-23T14:26:23Z"
                },
                "committer": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-06-25T15:42:06Z"
                },
                "message": "[FLINK-23045][tests] Harden RunnablesTest by not relying on timeout\n\nThis commit hardens the RunnablesTest.testExecutorService_uncaughtExceptionHandler to not rely\non timeouts to check whether the uncaught exception handler was called.\n\nThis closes #16262.",
                "tree": {
                    "sha": "387af010e0f41a82efb69df348616d989bc8bc17",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/387af010e0f41a82efb69df348616d989bc8bc17"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/d9121d701d6a1b1e950ed6d41f5c91d5321477e3",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEEuUmfpp7/Xe7rw8H1un5Bh8b3PYIFAmDV+VgACgkQun5Bh8b3\nPYKg2A//aS3iewz5ehOyZvQFNBsOaw5gipxyJp9nOfQZwq1J9oX+cN/MEaEAoGhu\nSXqo2HK1moK4RyXw+DQuDapzxhI7JqoND6pJqLXHXg7RfP1Z8zdUeCyFZzY3PBcH\nUYVxUUdcgrnobEFdR3uWtD4UcuygN8zfSCgSpJUGFoEe9dQ9T2N22F8l/fpxg+b9\nguIowK9KBshxnpiazAFd4az0Gdr9T7jCMGns9T6dIbVMbIgOwbUTLowwwXD9tkW+\n9C/xeROb18JepKaQsZ0bpdZUiW14mA6OhwunoKY+i0AknJOLC7Ppg5TYHZblnpg1\n94rqIvtI4XrmJsZ91ZoyDnIdzOFiwZnzAMLZWYG6t2ETIIZTR6ZkvSP8QOfqQkIL\ngfd5l+bdOolDtJCQDa6RrIjaI8SlM3K3m9MIosO6NXX2ZcM8bNXzwFD2Q9woHrmW\nWmlE9SG8Yfo1SYMMGB4kEuVobXQeyXTeX/SPRgivUHqpfeXvZ5sQObUA5fnFjqgJ\ndGvY4XqhtBEdtkHHxyvkZjH+4iWgdpWWGQSz3dJwKLnu44ooFzAT8LXgjK5Yy4s5\ng7HXAxvYYa+o1gFNcgbNUMvH4GEuiEYzHyaLPYyCmOtDWjhzznFR4MkdbHYKEy32\nRpylwDPzO0XzLNYm2w9t/LJrX9GVswTsbeohEtdcdk+s/OvXyXI=\n=kaY+\n-----END PGP SIGNATURE-----",
                    "payload": "tree 387af010e0f41a82efb69df348616d989bc8bc17\nparent fe5f2d1aa3552a24f06306c341e8d34e1d287ed2\nauthor Till Rohrmann <trohrmann@apache.org> 1624458383 +0200\ncommitter Till Rohrmann <trohrmann@apache.org> 1624635726 +0200\n\n[FLINK-23045][tests] Harden RunnablesTest by not relying on timeout\n\nThis commit hardens the RunnablesTest.testExecutorService_uncaughtExceptionHandler to not rely\non timeouts to check whether the uncaught exception handler was called.\n\nThis closes #16262.\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/d9121d701d6a1b1e950ed6d41f5c91d5321477e3",
            "html_url": "https://github.com/apache/flink/commit/d9121d701d6a1b1e950ed6d41f5c91d5321477e3",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/d9121d701d6a1b1e950ed6d41f5c91d5321477e3/comments",
            "author": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "fe5f2d1aa3552a24f06306c341e8d34e1d287ed2",
                "url": "https://api.github.com/repos/apache/flink/commits/fe5f2d1aa3552a24f06306c341e8d34e1d287ed2",
                "html_url": "https://github.com/apache/flink/commit/fe5f2d1aa3552a24f06306c341e8d34e1d287ed2"
            }]
        },
        {
            "sha": "ad1e45753d3aab557b64192ffb9d1b15a62acc6b",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6YWQxZTQ1NzUzZDNhYWI1NTdiNjQxOTJmZmI5ZDFiMTVhNjJhY2M2Yg==",
            "commit": {
                "author": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-06-25T15:39:21Z"
                },
                "committer": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-06-25T15:42:16Z"
                },
                "message": "[hotfix][tests] Correct variable name in RunnablesTest.testExecutorService_uncaughtExceptionHandler",
                "tree": {
                    "sha": "a56821b464884a6372d39888b71d4e1fa34ef4db",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/a56821b464884a6372d39888b71d4e1fa34ef4db"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/ad1e45753d3aab557b64192ffb9d1b15a62acc6b",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEEuUmfpp7/Xe7rw8H1un5Bh8b3PYIFAmDV+VgACgkQun5Bh8b3\nPYLlAw//eDNjaPkq7YqcG2ao2eGvQDoXwGIA3KxkyRW/IFc76qI/JXzncrLEHCRW\nSbkKj/bnsXA2YzjZ6ealK1oJrolUcbPQm3kVnZ8tudA+Xikf7W8fjG4j/ZXTz3Dr\ngZIQwEeK0RImCa3W0203LNH/XiiofgcwxtHCr7q7icpCqsTlJA0VfFOY+00O2Okx\nSj4lKB4CD3GUmPSEMdJgaACnqwebn6jceZagRZVNguVam8XykaSUuwkDa++AnbUW\nEDZNn48Qb/pq+Se9wfmww9m6UcCXSi6Xj2kaICBHxcG0+NRp86AAXvo0hA1k6Htg\nytf6qhTsZQAwhJcPlWpZ9JWTe5gy/Dn517+tdDHdjcO0W3ESdjx3t6AguGjV93cJ\nKZPt1q4/s/0HqaM+2hOa6PVhI66xhcf1Eo8xuvE+TJYd0arxgWQEBlXbzcDYAGMD\nhqmpTpVht3+iBSMNYR8aLHPRTfrqoNy2vnty7T4mFmv7wwTi+XWRomBl5gMqglhI\nOkDzLSqLbODCQJXkYa/oE4fVt5H2KPhLqXjr+8KKSZ3h2GBCJSfM1Q2db3auhsoP\nhEdW6SFpmdpzOlkbKDEH0tzpdWiyzmetQb3mb6tXUJF/NZmBCH7zv0+sUt7t720G\n2vH9NS3ZZlJNq6HEHquKI3gTnKQSbsFUP530KrCmrYN9tC5126E=\n=E9Au\n-----END PGP SIGNATURE-----",
                    "payload": "tree a56821b464884a6372d39888b71d4e1fa34ef4db\nparent d9121d701d6a1b1e950ed6d41f5c91d5321477e3\nauthor Till Rohrmann <trohrmann@apache.org> 1624635561 +0200\ncommitter Till Rohrmann <trohrmann@apache.org> 1624635736 +0200\n\n[hotfix][tests] Correct variable name in RunnablesTest.testExecutorService_uncaughtExceptionHandler\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/ad1e45753d3aab557b64192ffb9d1b15a62acc6b",
            "html_url": "https://github.com/apache/flink/commit/ad1e45753d3aab557b64192ffb9d1b15a62acc6b",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/ad1e45753d3aab557b64192ffb9d1b15a62acc6b/comments",
            "author": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "d9121d701d6a1b1e950ed6d41f5c91d5321477e3",
                "url": "https://api.github.com/repos/apache/flink/commits/d9121d701d6a1b1e950ed6d41f5c91d5321477e3",
                "html_url": "https://github.com/apache/flink/commit/d9121d701d6a1b1e950ed6d41f5c91d5321477e3"
            }]
        },
        {
            "sha": "5080af02fbd5417a480936236864485deec45464",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NTA4MGFmMDJmYmQ1NDE3YTQ4MDkzNjIzNjg2NDQ4NWRlZWM0NTQ2NA==",
            "commit": {
                "author": {
                    "name": "Han Wei",
                    "email": "gsywr@sina.com",
                    "date": "2021-06-25T15:43:33Z"
                },
                "committer": {
                    "name": "Jark Wu",
                    "email": "jark@apache.org",
                    "date": "2021-06-25T15:54:21Z"
                },
                "message": "[FLINK-23157][docs][table] Fix missing comma in \"Versioned Tables\" page\n\nThis closes #16289",
                "tree": {
                    "sha": "15bb6e3fff40833d3cbec2f491775dea579dd903",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/15bb6e3fff40833d3cbec2f491775dea579dd903"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/5080af02fbd5417a480936236864485deec45464",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEE4sRUF77VwQQVTzQQhbrLWu+uMgIFAmDV/C0ACgkQhbrLWu+u\nMgIXwQ//Q2w8tDXk+gojexA+d3k2FJSO/SribZNySiYFPxbttgWm+6O6GHnTApkq\ntJrvDrT9D8epiltJTxR4ehF3y2KBdH9hjwl/2YBUQ8JOpc+7YckmaD9TNCQPje5c\nfwPuX99P8XkztvdRbXZy0itqGKBxbvmumsMbYanW7rzUypwJh3xh2i4wYUEH0Pdb\nVB9jDDL3vO4v2CvbRPzXBf0ht22Q5fNUE+5Qh5gmQuTl7LMsdkbIIrUPjyh1wD7k\naGO3iAhtuu+PsSoyJtvPoOV91gO0UK5QWEaKNMaKHkBOp3S5FVMMgY+paxMIgz+8\n1tYNmz0vhF6j15ZRSVLeuxMe5NTgV5/4wvqSQ1yNts0CfP3RTVN/LHwvVuyZtMPf\nJ3pxkXMz8gGU75bQKpsZyiOYuTuwIlsPd8b/z9SEEicOepy6OINZLmVym+A02tdI\nWdApmcHpK6YmLdlNlwMj6CpvSk24sZa8hwupUdlDfnyjtWSDu9w7nIeNVG731sbN\nVVEmBconkUIIRJsxGsPP7myfjDi8PFf1srNE0vTJYNo2Nogn4zg44etsgoc4ojxw\nJ+l4c1/OeTr+WNSm6DhSW9eZicj1LlAtQT22FPF+baWYYxUcj0m30OazYGoZ2JUp\nSeVjHpp/Zw3Ob3ib2Cy24hoynJu1MO4EsqXTqHKaTehiRQArG+w=\n=XLXn\n-----END PGP SIGNATURE-----",
                    "payload": "tree 15bb6e3fff40833d3cbec2f491775dea579dd903\nparent ad1e45753d3aab557b64192ffb9d1b15a62acc6b\nauthor Han Wei <gsywr@sina.com> 1624635813 +0800\ncommitter Jark Wu <jark@apache.org> 1624636461 +0800\n\n[FLINK-23157][docs][table] Fix missing comma in \"Versioned Tables\" page\n\nThis closes #16289"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/5080af02fbd5417a480936236864485deec45464",
            "html_url": "https://github.com/apache/flink/commit/5080af02fbd5417a480936236864485deec45464",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/5080af02fbd5417a480936236864485deec45464/comments",
            "author": {
                "login": "hanwei-36",
                "id": 76390748,
                "node_id": "MDQ6VXNlcjc2MzkwNzQ4",
                "avatar_url": "https://avatars.githubusercontent.com/u/76390748?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/hanwei-36",
                "html_url": "https://github.com/hanwei-36",
                "followers_url": "https://api.github.com/users/hanwei-36/followers",
                "following_url": "https://api.github.com/users/hanwei-36/following{/other_user}",
                "gists_url": "https://api.github.com/users/hanwei-36/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/hanwei-36/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/hanwei-36/subscriptions",
                "organizations_url": "https://api.github.com/users/hanwei-36/orgs",
                "repos_url": "https://api.github.com/users/hanwei-36/repos",
                "events_url": "https://api.github.com/users/hanwei-36/events{/privacy}",
                "received_events_url": "https://api.github.com/users/hanwei-36/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "wuchong",
                "id": 5378924,
                "node_id": "MDQ6VXNlcjUzNzg5MjQ=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5378924?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/wuchong",
                "html_url": "https://github.com/wuchong",
                "followers_url": "https://api.github.com/users/wuchong/followers",
                "following_url": "https://api.github.com/users/wuchong/following{/other_user}",
                "gists_url": "https://api.github.com/users/wuchong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/wuchong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/wuchong/subscriptions",
                "organizations_url": "https://api.github.com/users/wuchong/orgs",
                "repos_url": "https://api.github.com/users/wuchong/repos",
                "events_url": "https://api.github.com/users/wuchong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/wuchong/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "ad1e45753d3aab557b64192ffb9d1b15a62acc6b",
                "url": "https://api.github.com/repos/apache/flink/commits/ad1e45753d3aab557b64192ffb9d1b15a62acc6b",
                "html_url": "https://github.com/apache/flink/commit/ad1e45753d3aab557b64192ffb9d1b15a62acc6b"
            }]
        },
        {
            "sha": "b06862333119359afba6a8f43ed08a55a7c7e57b",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6YjA2ODYyMzMzMTE5MzU5YWZiYTZhOGY0M2VkMDhhNTVhN2M3ZTU3Yg==",
            "commit": {
                "author": {
                    "name": "Arvid Heise",
                    "email": "arvid@ververica.com",
                    "date": "2021-06-24T09:02:39Z"
                },
                "committer": {
                    "name": "Arvid Heise",
                    "email": "AHeise@users.noreply.github.com",
                    "date": "2021-06-26T05:58:27Z"
                },
                "message": "[FLINK-22492][test] Use order-agnostic check in KinesisTableApiITCase.\n\nThe query doesn't impose any ordering and a reorder may happen as is.",
                "tree": {
                    "sha": "db2cad2f90a25e4bd686522978f9eb1db6906684",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/db2cad2f90a25e4bd686522978f9eb1db6906684"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/b06862333119359afba6a8f43ed08a55a7c7e57b",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/b06862333119359afba6a8f43ed08a55a7c7e57b",
            "html_url": "https://github.com/apache/flink/commit/b06862333119359afba6a8f43ed08a55a7c7e57b",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/b06862333119359afba6a8f43ed08a55a7c7e57b/comments",
            "author": {
                "login": "AHeise",
                "id": 4559103,
                "node_id": "MDQ6VXNlcjQ1NTkxMDM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/4559103?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/AHeise",
                "html_url": "https://github.com/AHeise",
                "followers_url": "https://api.github.com/users/AHeise/followers",
                "following_url": "https://api.github.com/users/AHeise/following{/other_user}",
                "gists_url": "https://api.github.com/users/AHeise/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/AHeise/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/AHeise/subscriptions",
                "organizations_url": "https://api.github.com/users/AHeise/orgs",
                "repos_url": "https://api.github.com/users/AHeise/repos",
                "events_url": "https://api.github.com/users/AHeise/events{/privacy}",
                "received_events_url": "https://api.github.com/users/AHeise/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "AHeise",
                "id": 4559103,
                "node_id": "MDQ6VXNlcjQ1NTkxMDM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/4559103?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/AHeise",
                "html_url": "https://github.com/AHeise",
                "followers_url": "https://api.github.com/users/AHeise/followers",
                "following_url": "https://api.github.com/users/AHeise/following{/other_user}",
                "gists_url": "https://api.github.com/users/AHeise/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/AHeise/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/AHeise/subscriptions",
                "organizations_url": "https://api.github.com/users/AHeise/orgs",
                "repos_url": "https://api.github.com/users/AHeise/repos",
                "events_url": "https://api.github.com/users/AHeise/events{/privacy}",
                "received_events_url": "https://api.github.com/users/AHeise/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "5080af02fbd5417a480936236864485deec45464",
                "url": "https://api.github.com/repos/apache/flink/commits/5080af02fbd5417a480936236864485deec45464",
                "html_url": "https://github.com/apache/flink/commit/5080af02fbd5417a480936236864485deec45464"
            }]
        },
        {
            "sha": "862f14e411f4d5e8d7bc21a1dc003aeb507c8889",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ODYyZjE0ZTQxMWY0ZDVlOGQ3YmMyMWExZGMwMDNhZWI1MDdjODg4OQ==",
            "commit": {
                "author": {
                    "name": "Dian Fu",
                    "email": "dianfu@apache.org",
                    "date": "2021-06-23T09:20:20Z"
                },
                "committer": {
                    "name": "Dian Fu",
                    "email": "dianfu@apache.org",
                    "date": "2021-06-27T02:11:28Z"
                },
                "message": "[FLINK-23120][python] Fix ByteArrayWrapperSerializer.serialize to use writeInt to serialize the length\n\nThis closes #16258.",
                "tree": {
                    "sha": "71426434212e4e7c9a46beae4de38d4c5d303f62",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/71426434212e4e7c9a46beae4de38d4c5d303f62"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/862f14e411f4d5e8d7bc21a1dc003aeb507c8889",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/862f14e411f4d5e8d7bc21a1dc003aeb507c8889",
            "html_url": "https://github.com/apache/flink/commit/862f14e411f4d5e8d7bc21a1dc003aeb507c8889",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/862f14e411f4d5e8d7bc21a1dc003aeb507c8889/comments",
            "author": {
                "login": "dianfu",
                "id": 5466492,
                "node_id": "MDQ6VXNlcjU0NjY0OTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5466492?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dianfu",
                "html_url": "https://github.com/dianfu",
                "followers_url": "https://api.github.com/users/dianfu/followers",
                "following_url": "https://api.github.com/users/dianfu/following{/other_user}",
                "gists_url": "https://api.github.com/users/dianfu/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dianfu/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dianfu/subscriptions",
                "organizations_url": "https://api.github.com/users/dianfu/orgs",
                "repos_url": "https://api.github.com/users/dianfu/repos",
                "events_url": "https://api.github.com/users/dianfu/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dianfu/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "dianfu",
                "id": 5466492,
                "node_id": "MDQ6VXNlcjU0NjY0OTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5466492?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dianfu",
                "html_url": "https://github.com/dianfu",
                "followers_url": "https://api.github.com/users/dianfu/followers",
                "following_url": "https://api.github.com/users/dianfu/following{/other_user}",
                "gists_url": "https://api.github.com/users/dianfu/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dianfu/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dianfu/subscriptions",
                "organizations_url": "https://api.github.com/users/dianfu/orgs",
                "repos_url": "https://api.github.com/users/dianfu/repos",
                "events_url": "https://api.github.com/users/dianfu/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dianfu/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "b06862333119359afba6a8f43ed08a55a7c7e57b",
                "url": "https://api.github.com/repos/apache/flink/commits/b06862333119359afba6a8f43ed08a55a7c7e57b",
                "html_url": "https://github.com/apache/flink/commit/b06862333119359afba6a8f43ed08a55a7c7e57b"
            }]
        },
        {
            "sha": "54c681835a8c73a498d8139ff09a400dcf1b182b",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NTRjNjgxODM1YThjNzNhNDk4ZDgxMzlmZjA5YTQwMGRjZjFiMTgyYg==",
            "commit": {
                "author": {
                    "name": "mans2singh",
                    "email": "mans2singh@users.noreply.github.com",
                    "date": "2021-06-27T05:14:33Z"
                },
                "committer": {
                    "name": "Jark Wu",
                    "email": "jark@apache.org",
                    "date": "2021-06-27T05:15:12Z"
                },
                "message": "[FLINK-23162][docs] Update column used in expression for creating table in \"Time Attribute\" page\n\nThis closes #16301",
                "tree": {
                    "sha": "e44f4c8f18de8eba23e8c69d2b6d822748f53fd1",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/e44f4c8f18de8eba23e8c69d2b6d822748f53fd1"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/54c681835a8c73a498d8139ff09a400dcf1b182b",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEE4sRUF77VwQQVTzQQhbrLWu+uMgIFAmDYCWAACgkQhbrLWu+u\nMgKknxAApCscZBLNzGeBgd1qD1PfZ7Ey2/cov9NXhgRth52/2ghGu5BIYJ9Msgn4\nzKXUJYvt0Uygw9HUVb2autFslZVyP86OnCdjHgLKzfju+YO5vA/8eafIX29NVJ1E\nHuPCE2YhK4SKDw5fKin0Hgjob3CAeHHTT8AjAZC9RUMuf0Pti5Jn/EIUS7Y2Dho8\nUtfiaJt2Yf/8ZbNcCefZk5vFtkBYNa4RHa3nTseOcuWgQUnCdaFdwQccOo2q9xNB\nWNX4gQwmjAtl436iJOluureKqGvaqY8x55zUIuiHGUycrlhLPcQdC7seEJGY29a1\nhrvAyvJpeJ5cu0NLVQdDemxssjNVJDeRG66obLUaUoa3PcIHMZXm0yiCPsWW5Jmh\n/4DM4FaYdhnyXoBDQGey0T/p9ezvFOpwZzwApe1/5pUEaZiLTAxRkQ8Q4op3L6Mg\nneYwQ8iFGGT1xZZx9D4MeBex1r+hkoQF4fPimjB5Ht9t/CADcb5HDgwdDR1upVMV\ntQV/+38mQWGL0++pmZK5MS2vS0+lsguuUeezXGVt2alw+G5+CCJnjTtqfSE4cnFw\nVfVWoL9q5FjFljBr17LtIBvzu1l6u/gAUFAvLi8jVPP/OtKcAmo6s8i+lSsEvhJ4\nAeN03l4AJL+cE/XYQXD+ks6036AOs7NdOkEV4BLNWWORXjiX6UA=\n=ao79\n-----END PGP SIGNATURE-----",
                    "payload": "tree e44f4c8f18de8eba23e8c69d2b6d822748f53fd1\nparent 862f14e411f4d5e8d7bc21a1dc003aeb507c8889\nauthor mans2singh <mans2singh@users.noreply.github.com> 1624770873 -0400\ncommitter Jark Wu <jark@apache.org> 1624770912 +0800\n\n[FLINK-23162][docs] Update column used in expression for creating table in \"Time Attribute\" page\n\nThis closes #16301"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/54c681835a8c73a498d8139ff09a400dcf1b182b",
            "html_url": "https://github.com/apache/flink/commit/54c681835a8c73a498d8139ff09a400dcf1b182b",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/54c681835a8c73a498d8139ff09a400dcf1b182b/comments",
            "author": {
                "login": "mans2singh",
                "id": 8467404,
                "node_id": "MDQ6VXNlcjg0Njc0MDQ=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8467404?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/mans2singh",
                "html_url": "https://github.com/mans2singh",
                "followers_url": "https://api.github.com/users/mans2singh/followers",
                "following_url": "https://api.github.com/users/mans2singh/following{/other_user}",
                "gists_url": "https://api.github.com/users/mans2singh/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/mans2singh/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/mans2singh/subscriptions",
                "organizations_url": "https://api.github.com/users/mans2singh/orgs",
                "repos_url": "https://api.github.com/users/mans2singh/repos",
                "events_url": "https://api.github.com/users/mans2singh/events{/privacy}",
                "received_events_url": "https://api.github.com/users/mans2singh/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "wuchong",
                "id": 5378924,
                "node_id": "MDQ6VXNlcjUzNzg5MjQ=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5378924?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/wuchong",
                "html_url": "https://github.com/wuchong",
                "followers_url": "https://api.github.com/users/wuchong/followers",
                "following_url": "https://api.github.com/users/wuchong/following{/other_user}",
                "gists_url": "https://api.github.com/users/wuchong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/wuchong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/wuchong/subscriptions",
                "organizations_url": "https://api.github.com/users/wuchong/orgs",
                "repos_url": "https://api.github.com/users/wuchong/repos",
                "events_url": "https://api.github.com/users/wuchong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/wuchong/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "862f14e411f4d5e8d7bc21a1dc003aeb507c8889",
                "url": "https://api.github.com/repos/apache/flink/commits/862f14e411f4d5e8d7bc21a1dc003aeb507c8889",
                "html_url": "https://github.com/apache/flink/commit/862f14e411f4d5e8d7bc21a1dc003aeb507c8889"
            }]
        },
        {
            "sha": "ec42374cbc4608cdf2e5a457c98da5dbefa65250",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZWM0MjM3NGNiYzQ2MDhjZGYyZTVhNDU3Yzk4ZGE1ZGJlZmE2NTI1MA==",
            "commit": {
                "author": {
                    "name": "Emre Kartoglu",
                    "email": "iemrek@gmail.com",
                    "date": "2021-06-18T09:00:49Z"
                },
                "committer": {
                    "name": "Danny Cranmer",
                    "email": "dannycranmer@apache.org",
                    "date": "2021-06-28T06:49:17Z"
                },
                "message": "[FLINK-23009][kinesis] Upgrade Guava for Flink Connector Kinesis\n\nAlso make flink-sql-connector-kinesis use the Guava library\ncoming transitively from the connector-kinesis dependency.",
                "tree": {
                    "sha": "878bdd8f13df59abca95c54fdd0a1779175cf5c6",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/878bdd8f13df59abca95c54fdd0a1779175cf5c6"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/ec42374cbc4608cdf2e5a457c98da5dbefa65250",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/ec42374cbc4608cdf2e5a457c98da5dbefa65250",
            "html_url": "https://github.com/apache/flink/commit/ec42374cbc4608cdf2e5a457c98da5dbefa65250",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/ec42374cbc4608cdf2e5a457c98da5dbefa65250/comments",
            "author": {
                "login": "iemre",
                "id": 969071,
                "node_id": "MDQ6VXNlcjk2OTA3MQ==",
                "avatar_url": "https://avatars.githubusercontent.com/u/969071?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/iemre",
                "html_url": "https://github.com/iemre",
                "followers_url": "https://api.github.com/users/iemre/followers",
                "following_url": "https://api.github.com/users/iemre/following{/other_user}",
                "gists_url": "https://api.github.com/users/iemre/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/iemre/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/iemre/subscriptions",
                "organizations_url": "https://api.github.com/users/iemre/orgs",
                "repos_url": "https://api.github.com/users/iemre/repos",
                "events_url": "https://api.github.com/users/iemre/events{/privacy}",
                "received_events_url": "https://api.github.com/users/iemre/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "dannycranmer",
                "id": 4950503,
                "node_id": "MDQ6VXNlcjQ5NTA1MDM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/4950503?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dannycranmer",
                "html_url": "https://github.com/dannycranmer",
                "followers_url": "https://api.github.com/users/dannycranmer/followers",
                "following_url": "https://api.github.com/users/dannycranmer/following{/other_user}",
                "gists_url": "https://api.github.com/users/dannycranmer/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dannycranmer/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dannycranmer/subscriptions",
                "organizations_url": "https://api.github.com/users/dannycranmer/orgs",
                "repos_url": "https://api.github.com/users/dannycranmer/repos",
                "events_url": "https://api.github.com/users/dannycranmer/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dannycranmer/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "54c681835a8c73a498d8139ff09a400dcf1b182b",
                "url": "https://api.github.com/repos/apache/flink/commits/54c681835a8c73a498d8139ff09a400dcf1b182b",
                "html_url": "https://github.com/apache/flink/commit/54c681835a8c73a498d8139ff09a400dcf1b182b"
            }]
        },
        {
            "sha": "d64674fd635e242bcb0473017117e34966bc42c9",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZDY0Njc0ZmQ2MzVlMjQyYmNiMDQ3MzAxNzExN2UzNDk2NmJjNDJjOQ==",
            "commit": {
                "author": {
                    "name": "Danny Cranmer",
                    "email": "dannycranmer@apache.org",
                    "date": "2021-06-25T21:26:14Z"
                },
                "committer": {
                    "name": "Danny Cranmer",
                    "email": "dannycranmer@apache.org",
                    "date": "2021-06-28T06:49:17Z"
                },
                "message": "[FLINK-23009][kinesis] Including missing dependency in SQL jar resulting in e2e test failure",
                "tree": {
                    "sha": "ad6652742b0b85878f87781a00805b70ab4b3a38",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/ad6652742b0b85878f87781a00805b70ab4b3a38"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/d64674fd635e242bcb0473017117e34966bc42c9",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/d64674fd635e242bcb0473017117e34966bc42c9",
            "html_url": "https://github.com/apache/flink/commit/d64674fd635e242bcb0473017117e34966bc42c9",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/d64674fd635e242bcb0473017117e34966bc42c9/comments",
            "author": {
                "login": "dannycranmer",
                "id": 4950503,
                "node_id": "MDQ6VXNlcjQ5NTA1MDM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/4950503?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dannycranmer",
                "html_url": "https://github.com/dannycranmer",
                "followers_url": "https://api.github.com/users/dannycranmer/followers",
                "following_url": "https://api.github.com/users/dannycranmer/following{/other_user}",
                "gists_url": "https://api.github.com/users/dannycranmer/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dannycranmer/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dannycranmer/subscriptions",
                "organizations_url": "https://api.github.com/users/dannycranmer/orgs",
                "repos_url": "https://api.github.com/users/dannycranmer/repos",
                "events_url": "https://api.github.com/users/dannycranmer/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dannycranmer/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "dannycranmer",
                "id": 4950503,
                "node_id": "MDQ6VXNlcjQ5NTA1MDM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/4950503?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dannycranmer",
                "html_url": "https://github.com/dannycranmer",
                "followers_url": "https://api.github.com/users/dannycranmer/followers",
                "following_url": "https://api.github.com/users/dannycranmer/following{/other_user}",
                "gists_url": "https://api.github.com/users/dannycranmer/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dannycranmer/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dannycranmer/subscriptions",
                "organizations_url": "https://api.github.com/users/dannycranmer/orgs",
                "repos_url": "https://api.github.com/users/dannycranmer/repos",
                "events_url": "https://api.github.com/users/dannycranmer/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dannycranmer/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "ec42374cbc4608cdf2e5a457c98da5dbefa65250",
                "url": "https://api.github.com/repos/apache/flink/commits/ec42374cbc4608cdf2e5a457c98da5dbefa65250",
                "html_url": "https://github.com/apache/flink/commit/ec42374cbc4608cdf2e5a457c98da5dbefa65250"
            }]
        },
        {
            "sha": "045e68dd412b05b123e7d2b278b4eb9f9afe07ec",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MDQ1ZTY4ZGQ0MTJiMDViMTIzZTdkMmIyNzhiNGViOWY5YWZlMDdlYw==",
            "commit": {
                "author": {
                    "name": "Anton Kalashnikov",
                    "email": "kaa.dev@yandex.ru",
                    "date": "2021-06-23T14:12:50Z"
                },
                "committer": {
                    "name": "Dawid Wysakowicz",
                    "email": "dwysakowicz@apache.org",
                    "date": "2021-06-28T10:46:48Z"
                },
                "message": "[FLINK-22966][runtime] StateAssignmentOperation returns only not null state handles",
                "tree": {
                    "sha": "517fea568006e606ad2218e72c498244af8fc1ee",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/517fea568006e606ad2218e72c498244af8fc1ee"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/045e68dd412b05b123e7d2b278b4eb9f9afe07ec",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEE6pOkNbTiybTJ9TP2MdLdEL/BWi0FAmDZqJgACgkQMdLdEL/B\nWi07Rg//WrH3vlG1flsjvsGb6isVa31du0Z+I4BYirJSt54puXekyDzXK0rvhUfP\nAVWIssuFpclSDVVJVoFEErnxvf8G5lVwThu4KYdEwX4iJRGgbMK/QLxPOo+ZIoGY\nige1RfTLFoe3u+lXygxsP9jo+HxDP9dkIaUO7m2D8qRmVib69UNvU0QNQFTPkJoN\nS66Wuznv1f5+IfgXZlYPoNlPhUgr7KmwDVIScO1qJ4y9vVlk3U7ikFwA0jUyMTHl\nGCPJASofr/A3sC6LzMCiqjVA8iDRUxZK43ekGp07HWeDN6ZPIUK1u7BNQGbxElSC\nzVcyVi8sZtzQgbXiybFEVsMJAiTRebERUWZKSWJ061h1tCiyWom0/mLyyjRQHOoC\nWeAH963fIV3jUdPGCcqXyAWT0H7GMoF6Oc3M4EcBNeP1KhkDxi0HoXKJIxrL4ptU\nbuFWeY9JjLrO8YImRfQuTjfG0XqPUds4hE3ORsxIYpK8rxeNRmNxk9RbFE2/hLSz\n/JuI9XLXsjDqNNv1y1fNNZi1IzhuxBRb3Hg0KI3Q/X4h/6JoscIi1Epc4hYHWnet\n6dfJx0jauv8xxeYN2R8HFzbap51Ucia0HVGbshHabIIwmH8tGclCyFMZScgWCmyg\nYu45icQzlDb1YiJn508CKPhyZ314aRqzIsEFatBwbLhpC7jCmy8=\n=UMTZ\n-----END PGP SIGNATURE-----",
                    "payload": "tree 517fea568006e606ad2218e72c498244af8fc1ee\nparent d64674fd635e242bcb0473017117e34966bc42c9\nauthor Anton Kalashnikov <kaa.dev@yandex.ru> 1624457570 +0300\ncommitter Dawid Wysakowicz <dwysakowicz@apache.org> 1624877208 +0200\n\n[FLINK-22966][runtime] StateAssignmentOperation returns only not null state handles\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/045e68dd412b05b123e7d2b278b4eb9f9afe07ec",
            "html_url": "https://github.com/apache/flink/commit/045e68dd412b05b123e7d2b278b4eb9f9afe07ec",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/045e68dd412b05b123e7d2b278b4eb9f9afe07ec/comments",
            "author": {
                "login": "akalash",
                "id": 3996532,
                "node_id": "MDQ6VXNlcjM5OTY1MzI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3996532?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/akalash",
                "html_url": "https://github.com/akalash",
                "followers_url": "https://api.github.com/users/akalash/followers",
                "following_url": "https://api.github.com/users/akalash/following{/other_user}",
                "gists_url": "https://api.github.com/users/akalash/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/akalash/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/akalash/subscriptions",
                "organizations_url": "https://api.github.com/users/akalash/orgs",
                "repos_url": "https://api.github.com/users/akalash/repos",
                "events_url": "https://api.github.com/users/akalash/events{/privacy}",
                "received_events_url": "https://api.github.com/users/akalash/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "dawidwys",
                "id": 6242259,
                "node_id": "MDQ6VXNlcjYyNDIyNTk=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6242259?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dawidwys",
                "html_url": "https://github.com/dawidwys",
                "followers_url": "https://api.github.com/users/dawidwys/followers",
                "following_url": "https://api.github.com/users/dawidwys/following{/other_user}",
                "gists_url": "https://api.github.com/users/dawidwys/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dawidwys/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dawidwys/subscriptions",
                "organizations_url": "https://api.github.com/users/dawidwys/orgs",
                "repos_url": "https://api.github.com/users/dawidwys/repos",
                "events_url": "https://api.github.com/users/dawidwys/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dawidwys/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "d64674fd635e242bcb0473017117e34966bc42c9",
                "url": "https://api.github.com/repos/apache/flink/commits/d64674fd635e242bcb0473017117e34966bc42c9",
                "html_url": "https://github.com/apache/flink/commit/d64674fd635e242bcb0473017117e34966bc42c9"
            }]
        },
        {
            "sha": "b389e3f446e020dcc59294204c83d88adaba26c7",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6YjM4OWUzZjQ0NmUwMjBkY2M1OTI5NDIwNGM4M2Q4OGFkYWJhMjZjNw==",
            "commit": {
                "author": {
                    "name": "Robert Metzger",
                    "email": "rmetzger@apache.org",
                    "date": "2021-06-17T06:08:25Z"
                },
                "committer": {
                    "name": "Robert Metzger",
                    "email": "rmetzger@apache.org",
                    "date": "2021-06-28T13:51:39Z"
                },
                "message": "[hotfix][docs] Mention -D argument for CLI",
                "tree": {
                    "sha": "d9ff5c8af1d614c2a9b5e19e9e1f48c4963f16b0",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/d9ff5c8af1d614c2a9b5e19e9e1f48c4963f16b0"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/b389e3f446e020dcc59294204c83d88adaba26c7",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/b389e3f446e020dcc59294204c83d88adaba26c7",
            "html_url": "https://github.com/apache/flink/commit/b389e3f446e020dcc59294204c83d88adaba26c7",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/b389e3f446e020dcc59294204c83d88adaba26c7/comments",
            "author": {
                "login": "rmetzger",
                "id": 89049,
                "node_id": "MDQ6VXNlcjg5MDQ5",
                "avatar_url": "https://avatars.githubusercontent.com/u/89049?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rmetzger",
                "html_url": "https://github.com/rmetzger",
                "followers_url": "https://api.github.com/users/rmetzger/followers",
                "following_url": "https://api.github.com/users/rmetzger/following{/other_user}",
                "gists_url": "https://api.github.com/users/rmetzger/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rmetzger/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rmetzger/subscriptions",
                "organizations_url": "https://api.github.com/users/rmetzger/orgs",
                "repos_url": "https://api.github.com/users/rmetzger/repos",
                "events_url": "https://api.github.com/users/rmetzger/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rmetzger/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "rmetzger",
                "id": 89049,
                "node_id": "MDQ6VXNlcjg5MDQ5",
                "avatar_url": "https://avatars.githubusercontent.com/u/89049?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rmetzger",
                "html_url": "https://github.com/rmetzger",
                "followers_url": "https://api.github.com/users/rmetzger/followers",
                "following_url": "https://api.github.com/users/rmetzger/following{/other_user}",
                "gists_url": "https://api.github.com/users/rmetzger/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rmetzger/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rmetzger/subscriptions",
                "organizations_url": "https://api.github.com/users/rmetzger/orgs",
                "repos_url": "https://api.github.com/users/rmetzger/repos",
                "events_url": "https://api.github.com/users/rmetzger/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rmetzger/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "045e68dd412b05b123e7d2b278b4eb9f9afe07ec",
                "url": "https://api.github.com/repos/apache/flink/commits/045e68dd412b05b123e7d2b278b4eb9f9afe07ec",
                "html_url": "https://github.com/apache/flink/commit/045e68dd412b05b123e7d2b278b4eb9f9afe07ec"
            }]
        },
        {
            "sha": "fb42772920366dceb26d593d1c1da75afd3309c9",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZmI0Mjc3MjkyMDM2NmRjZWIyNmQ1OTNkMWMxZGE3NWFmZDMzMDljOQ==",
            "commit": {
                "author": {
                    "name": "Robert Metzger",
                    "email": "rmetzger@apache.org",
                    "date": "2021-06-25T07:22:50Z"
                },
                "committer": {
                    "name": "Robert Metzger",
                    "email": "rmetzger@apache.org",
                    "date": "2021-06-28T13:51:39Z"
                },
                "message": "[FLINK-23052][ci] Improve stability of maven snapshot deployment",
                "tree": {
                    "sha": "5265cdb569186e2395af5c8e94ebb0bdb728eedb",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/5265cdb569186e2395af5c8e94ebb0bdb728eedb"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/fb42772920366dceb26d593d1c1da75afd3309c9",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/fb42772920366dceb26d593d1c1da75afd3309c9",
            "html_url": "https://github.com/apache/flink/commit/fb42772920366dceb26d593d1c1da75afd3309c9",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/fb42772920366dceb26d593d1c1da75afd3309c9/comments",
            "author": {
                "login": "rmetzger",
                "id": 89049,
                "node_id": "MDQ6VXNlcjg5MDQ5",
                "avatar_url": "https://avatars.githubusercontent.com/u/89049?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rmetzger",
                "html_url": "https://github.com/rmetzger",
                "followers_url": "https://api.github.com/users/rmetzger/followers",
                "following_url": "https://api.github.com/users/rmetzger/following{/other_user}",
                "gists_url": "https://api.github.com/users/rmetzger/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rmetzger/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rmetzger/subscriptions",
                "organizations_url": "https://api.github.com/users/rmetzger/orgs",
                "repos_url": "https://api.github.com/users/rmetzger/repos",
                "events_url": "https://api.github.com/users/rmetzger/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rmetzger/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "rmetzger",
                "id": 89049,
                "node_id": "MDQ6VXNlcjg5MDQ5",
                "avatar_url": "https://avatars.githubusercontent.com/u/89049?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rmetzger",
                "html_url": "https://github.com/rmetzger",
                "followers_url": "https://api.github.com/users/rmetzger/followers",
                "following_url": "https://api.github.com/users/rmetzger/following{/other_user}",
                "gists_url": "https://api.github.com/users/rmetzger/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rmetzger/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rmetzger/subscriptions",
                "organizations_url": "https://api.github.com/users/rmetzger/orgs",
                "repos_url": "https://api.github.com/users/rmetzger/repos",
                "events_url": "https://api.github.com/users/rmetzger/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rmetzger/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "b389e3f446e020dcc59294204c83d88adaba26c7",
                "url": "https://api.github.com/repos/apache/flink/commits/b389e3f446e020dcc59294204c83d88adaba26c7",
                "html_url": "https://github.com/apache/flink/commit/b389e3f446e020dcc59294204c83d88adaba26c7"
            }]
        },
        {
            "sha": "1ffdc082b6d6368cd66e15ea6b4c591ea99a9c37",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MWZmZGMwODJiNmQ2MzY4Y2Q2NmUxNWVhNmI0YzU5MWVhOTlhOWMzNw==",
            "commit": {
                "author": {
                    "name": "Dian Fu",
                    "email": "dianfu@apache.org",
                    "date": "2021-06-28T12:14:51Z"
                },
                "committer": {
                    "name": "Dian Fu",
                    "email": "dianfu@apache.org",
                    "date": "2021-06-28T23:15:14Z"
                },
                "message": "[FLINK-23166][python] Fix ZipUtils to handle properly for softlinks\n\nThis closes #16309.",
                "tree": {
                    "sha": "012461ef4eda0b86fc41962d14eaf41403e80f80",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/012461ef4eda0b86fc41962d14eaf41403e80f80"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/1ffdc082b6d6368cd66e15ea6b4c591ea99a9c37",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/1ffdc082b6d6368cd66e15ea6b4c591ea99a9c37",
            "html_url": "https://github.com/apache/flink/commit/1ffdc082b6d6368cd66e15ea6b4c591ea99a9c37",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/1ffdc082b6d6368cd66e15ea6b4c591ea99a9c37/comments",
            "author": {
                "login": "dianfu",
                "id": 5466492,
                "node_id": "MDQ6VXNlcjU0NjY0OTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5466492?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dianfu",
                "html_url": "https://github.com/dianfu",
                "followers_url": "https://api.github.com/users/dianfu/followers",
                "following_url": "https://api.github.com/users/dianfu/following{/other_user}",
                "gists_url": "https://api.github.com/users/dianfu/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dianfu/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dianfu/subscriptions",
                "organizations_url": "https://api.github.com/users/dianfu/orgs",
                "repos_url": "https://api.github.com/users/dianfu/repos",
                "events_url": "https://api.github.com/users/dianfu/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dianfu/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "dianfu",
                "id": 5466492,
                "node_id": "MDQ6VXNlcjU0NjY0OTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5466492?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dianfu",
                "html_url": "https://github.com/dianfu",
                "followers_url": "https://api.github.com/users/dianfu/followers",
                "following_url": "https://api.github.com/users/dianfu/following{/other_user}",
                "gists_url": "https://api.github.com/users/dianfu/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dianfu/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dianfu/subscriptions",
                "organizations_url": "https://api.github.com/users/dianfu/orgs",
                "repos_url": "https://api.github.com/users/dianfu/repos",
                "events_url": "https://api.github.com/users/dianfu/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dianfu/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "fb42772920366dceb26d593d1c1da75afd3309c9",
                "url": "https://api.github.com/repos/apache/flink/commits/fb42772920366dceb26d593d1c1da75afd3309c9",
                "html_url": "https://github.com/apache/flink/commit/fb42772920366dceb26d593d1c1da75afd3309c9"
            }]
        },
        {
            "sha": "b80c8ef618e5d4db439402200270fcd881d2f5ab",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6YjgwYzhlZjYxOGU1ZDRkYjQzOTQwMjIwMDI3MGZjZDg4MWQyZjVhYg==",
            "commit": {
                "author": {
                    "name": "Danny Cranmer",
                    "email": "dannycranmer@apache.org",
                    "date": "2021-06-18T13:21:45Z"
                },
                "committer": {
                    "name": "Danny Cranmer",
                    "email": "dannycranmer@apache.org",
                    "date": "2021-06-29T07:25:41Z"
                },
                "message": "[FLINK-18182][kinesis] Updating to latest AWS SDK for Kinesis connector",
                "tree": {
                    "sha": "beee3d084cd4bfff96514895fdac673070a676b7",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/beee3d084cd4bfff96514895fdac673070a676b7"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/b80c8ef618e5d4db439402200270fcd881d2f5ab",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/b80c8ef618e5d4db439402200270fcd881d2f5ab",
            "html_url": "https://github.com/apache/flink/commit/b80c8ef618e5d4db439402200270fcd881d2f5ab",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/b80c8ef618e5d4db439402200270fcd881d2f5ab/comments",
            "author": {
                "login": "dannycranmer",
                "id": 4950503,
                "node_id": "MDQ6VXNlcjQ5NTA1MDM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/4950503?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dannycranmer",
                "html_url": "https://github.com/dannycranmer",
                "followers_url": "https://api.github.com/users/dannycranmer/followers",
                "following_url": "https://api.github.com/users/dannycranmer/following{/other_user}",
                "gists_url": "https://api.github.com/users/dannycranmer/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dannycranmer/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dannycranmer/subscriptions",
                "organizations_url": "https://api.github.com/users/dannycranmer/orgs",
                "repos_url": "https://api.github.com/users/dannycranmer/repos",
                "events_url": "https://api.github.com/users/dannycranmer/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dannycranmer/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "dannycranmer",
                "id": 4950503,
                "node_id": "MDQ6VXNlcjQ5NTA1MDM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/4950503?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dannycranmer",
                "html_url": "https://github.com/dannycranmer",
                "followers_url": "https://api.github.com/users/dannycranmer/followers",
                "following_url": "https://api.github.com/users/dannycranmer/following{/other_user}",
                "gists_url": "https://api.github.com/users/dannycranmer/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dannycranmer/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dannycranmer/subscriptions",
                "organizations_url": "https://api.github.com/users/dannycranmer/orgs",
                "repos_url": "https://api.github.com/users/dannycranmer/repos",
                "events_url": "https://api.github.com/users/dannycranmer/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dannycranmer/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "1ffdc082b6d6368cd66e15ea6b4c591ea99a9c37",
                "url": "https://api.github.com/repos/apache/flink/commits/1ffdc082b6d6368cd66e15ea6b4c591ea99a9c37",
                "html_url": "https://github.com/apache/flink/commit/1ffdc082b6d6368cd66e15ea6b4c591ea99a9c37"
            }]
        },
        {
            "sha": "fdc09154d5f4bb4c618da0e0f224ded4a807916f",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZmRjMDkxNTRkNWY0YmI0YzYxOGRhMGUwZjIyNGRlZDRhODA3OTE2Zg==",
            "commit": {
                "author": {
                    "name": "Arvid Heise",
                    "email": "arvid@ververica.com",
                    "date": "2021-06-29T13:00:32Z"
                },
                "committer": {
                    "name": "Arvid Heise",
                    "email": "AHeise@users.noreply.github.com",
                    "date": "2021-06-30T07:43:28Z"
                },
                "message": "[FLINK-22964][connector/common] Exclude flink-core from connector-common dependencies.\n\nConnectors get shaded into the user jar and as such should contain no unnecessary dependencies to flink. However, connector-base is exposing `flink-core` which then by default gets shaded into the user jar. Except for 6MB of extra size, the dependency also causes class loading issues, when `classloader.parent-first-patterns` does not include `o.a.f`.",
                "tree": {
                    "sha": "452003f191bca99fbb4469475570058c8f3be709",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/452003f191bca99fbb4469475570058c8f3be709"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/fdc09154d5f4bb4c618da0e0f224ded4a807916f",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/fdc09154d5f4bb4c618da0e0f224ded4a807916f",
            "html_url": "https://github.com/apache/flink/commit/fdc09154d5f4bb4c618da0e0f224ded4a807916f",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/fdc09154d5f4bb4c618da0e0f224ded4a807916f/comments",
            "author": {
                "login": "AHeise",
                "id": 4559103,
                "node_id": "MDQ6VXNlcjQ1NTkxMDM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/4559103?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/AHeise",
                "html_url": "https://github.com/AHeise",
                "followers_url": "https://api.github.com/users/AHeise/followers",
                "following_url": "https://api.github.com/users/AHeise/following{/other_user}",
                "gists_url": "https://api.github.com/users/AHeise/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/AHeise/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/AHeise/subscriptions",
                "organizations_url": "https://api.github.com/users/AHeise/orgs",
                "repos_url": "https://api.github.com/users/AHeise/repos",
                "events_url": "https://api.github.com/users/AHeise/events{/privacy}",
                "received_events_url": "https://api.github.com/users/AHeise/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "AHeise",
                "id": 4559103,
                "node_id": "MDQ6VXNlcjQ1NTkxMDM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/4559103?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/AHeise",
                "html_url": "https://github.com/AHeise",
                "followers_url": "https://api.github.com/users/AHeise/followers",
                "following_url": "https://api.github.com/users/AHeise/following{/other_user}",
                "gists_url": "https://api.github.com/users/AHeise/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/AHeise/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/AHeise/subscriptions",
                "organizations_url": "https://api.github.com/users/AHeise/orgs",
                "repos_url": "https://api.github.com/users/AHeise/repos",
                "events_url": "https://api.github.com/users/AHeise/events{/privacy}",
                "received_events_url": "https://api.github.com/users/AHeise/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "b80c8ef618e5d4db439402200270fcd881d2f5ab",
                "url": "https://api.github.com/repos/apache/flink/commits/b80c8ef618e5d4db439402200270fcd881d2f5ab",
                "html_url": "https://github.com/apache/flink/commit/b80c8ef618e5d4db439402200270fcd881d2f5ab"
            }]
        },
        {
            "sha": "2711e80b04fe592fa5ce6b18b58b84492ae78f48",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MjcxMWU4MGIwNGZlNTkyZmE1Y2U2YjE4YjU4Yjg0NDkyYWU3OGY0OA==",
            "commit": {
                "author": {
                    "name": "Arvid Heise",
                    "email": "arvid@ververica.com",
                    "date": "2021-06-23T15:16:17Z"
                },
                "committer": {
                    "name": "Arvid Heise",
                    "email": "AHeise@users.noreply.github.com",
                    "date": "2021-06-30T07:50:31Z"
                },
                "message": "[hotfix][datastream] Remove raw casts in ContinuousFileReaderOperator.",
                "tree": {
                    "sha": "129c054e4fc09be10ad715beb01c882e61f4f73c",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/129c054e4fc09be10ad715beb01c882e61f4f73c"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/2711e80b04fe592fa5ce6b18b58b84492ae78f48",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/2711e80b04fe592fa5ce6b18b58b84492ae78f48",
            "html_url": "https://github.com/apache/flink/commit/2711e80b04fe592fa5ce6b18b58b84492ae78f48",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/2711e80b04fe592fa5ce6b18b58b84492ae78f48/comments",
            "author": {
                "login": "AHeise",
                "id": 4559103,
                "node_id": "MDQ6VXNlcjQ1NTkxMDM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/4559103?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/AHeise",
                "html_url": "https://github.com/AHeise",
                "followers_url": "https://api.github.com/users/AHeise/followers",
                "following_url": "https://api.github.com/users/AHeise/following{/other_user}",
                "gists_url": "https://api.github.com/users/AHeise/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/AHeise/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/AHeise/subscriptions",
                "organizations_url": "https://api.github.com/users/AHeise/orgs",
                "repos_url": "https://api.github.com/users/AHeise/repos",
                "events_url": "https://api.github.com/users/AHeise/events{/privacy}",
                "received_events_url": "https://api.github.com/users/AHeise/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "AHeise",
                "id": 4559103,
                "node_id": "MDQ6VXNlcjQ1NTkxMDM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/4559103?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/AHeise",
                "html_url": "https://github.com/AHeise",
                "followers_url": "https://api.github.com/users/AHeise/followers",
                "following_url": "https://api.github.com/users/AHeise/following{/other_user}",
                "gists_url": "https://api.github.com/users/AHeise/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/AHeise/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/AHeise/subscriptions",
                "organizations_url": "https://api.github.com/users/AHeise/orgs",
                "repos_url": "https://api.github.com/users/AHeise/repos",
                "events_url": "https://api.github.com/users/AHeise/events{/privacy}",
                "received_events_url": "https://api.github.com/users/AHeise/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "fdc09154d5f4bb4c618da0e0f224ded4a807916f",
                "url": "https://api.github.com/repos/apache/flink/commits/fdc09154d5f4bb4c618da0e0f224ded4a807916f",
                "html_url": "https://github.com/apache/flink/commit/fdc09154d5f4bb4c618da0e0f224ded4a807916f"
            }]
        },
        {
            "sha": "8636a4e08b9eaaef838ac3b2a4ae83afadd5a202",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ODYzNmE0ZTA4YjllYWFlZjgzOGFjM2IyYTRhZTgzYWZhZGQ1YTIwMg==",
            "commit": {
                "author": {
                    "name": "Arvid Heise",
                    "email": "arvid@ververica.com",
                    "date": "2021-06-23T15:08:16Z"
                },
                "committer": {
                    "name": "Arvid Heise",
                    "email": "AHeise@users.noreply.github.com",
                    "date": "2021-06-30T07:50:31Z"
                },
                "message": "[FLINK-20888][runtime] Close outputs in OperatorChain.\n\nOperatorChain creates the outputs and owns them, so that it should also close them. Specific operators should not close the outputs.\n\nAlso, ChainingOutput should never close the chained operator; it's not owning the operator.",
                "tree": {
                    "sha": "4fc7d362ce0cc33d04494acecce5b743f86bcb01",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/4fc7d362ce0cc33d04494acecce5b743f86bcb01"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/8636a4e08b9eaaef838ac3b2a4ae83afadd5a202",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/8636a4e08b9eaaef838ac3b2a4ae83afadd5a202",
            "html_url": "https://github.com/apache/flink/commit/8636a4e08b9eaaef838ac3b2a4ae83afadd5a202",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/8636a4e08b9eaaef838ac3b2a4ae83afadd5a202/comments",
            "author": {
                "login": "AHeise",
                "id": 4559103,
                "node_id": "MDQ6VXNlcjQ1NTkxMDM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/4559103?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/AHeise",
                "html_url": "https://github.com/AHeise",
                "followers_url": "https://api.github.com/users/AHeise/followers",
                "following_url": "https://api.github.com/users/AHeise/following{/other_user}",
                "gists_url": "https://api.github.com/users/AHeise/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/AHeise/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/AHeise/subscriptions",
                "organizations_url": "https://api.github.com/users/AHeise/orgs",
                "repos_url": "https://api.github.com/users/AHeise/repos",
                "events_url": "https://api.github.com/users/AHeise/events{/privacy}",
                "received_events_url": "https://api.github.com/users/AHeise/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "AHeise",
                "id": 4559103,
                "node_id": "MDQ6VXNlcjQ1NTkxMDM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/4559103?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/AHeise",
                "html_url": "https://github.com/AHeise",
                "followers_url": "https://api.github.com/users/AHeise/followers",
                "following_url": "https://api.github.com/users/AHeise/following{/other_user}",
                "gists_url": "https://api.github.com/users/AHeise/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/AHeise/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/AHeise/subscriptions",
                "organizations_url": "https://api.github.com/users/AHeise/orgs",
                "repos_url": "https://api.github.com/users/AHeise/repos",
                "events_url": "https://api.github.com/users/AHeise/events{/privacy}",
                "received_events_url": "https://api.github.com/users/AHeise/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "2711e80b04fe592fa5ce6b18b58b84492ae78f48",
                "url": "https://api.github.com/repos/apache/flink/commits/2711e80b04fe592fa5ce6b18b58b84492ae78f48",
                "html_url": "https://github.com/apache/flink/commit/2711e80b04fe592fa5ce6b18b58b84492ae78f48"
            }]
        },
        {
            "sha": "dcc5616cd72a90ff0467b50af3328790d980f0ea",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZGNjNTYxNmNkNzJhOTBmZjA0NjdiNTBhZjMzMjg3OTBkOTgwZjBlYQ==",
            "commit": {
                "author": {
                    "name": "zoucao",
                    "email": "32817398+zoucao@users.noreply.github.com",
                    "date": "2021-06-30T08:56:08Z"
                },
                "committer": {
                    "name": "Jark Wu",
                    "email": "jark@apache.org",
                    "date": "2021-06-30T08:57:05Z"
                },
                "message": "[FLINK-23156][docs][table] Fix links related to \"docs/dev/table/sql/queries\" (#16323)",
                "tree": {
                    "sha": "a9b8a22fd4f7eccad7201f2ad2ce3253b2a6db6d",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/a9b8a22fd4f7eccad7201f2ad2ce3253b2a6db6d"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/dcc5616cd72a90ff0467b50af3328790d980f0ea",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEE4sRUF77VwQQVTzQQhbrLWu+uMgIFAmDcMeEACgkQhbrLWu+u\nMgI4tA//XMI1wfaaphnki3dZP2XcSJt3xbxTYXiCFowKXDXWjlUJe/9yRUZHg+E4\n2xbLU44R4atsPANeFfDPzdNUo/l+oVNJ/czDSwh3t/HwgTaByT+shJpMercc++9u\nDD/lZa35dkQgW510wX3GWmiyduuj+6CYgOLdTBzsOnq8Yp3zohPZDf7gjXXNL0Ue\nUXbwl5hpwmrgJK8hUUf2hQXWxwhAF4uuxAWCRJIQikGKL18J6TiGFdy1iT4heguv\nZ53mhWJcMFLFOUntJsKTWsbhQ7pPmcU5gQDuRknzsXe9RUKa/G/bQLkxBm9Rlnpi\nt7pmHJimEJ4S/V/l8un+2tVddgsCndJ4GIkBt62yAjHUm4GC68ig7jozBPcIyRKP\nI+1jBOLKCIC/77Xa9ZTw7enAdxRRlPY17K7+8zcrY6N/K+KiyG4qRlRvcH6MEGHf\nIB1sOcxYQokKCE0O79EOdndDAODlmZvwpTpca5MM7BVRwFcnOWihKvLIMSfcrfS+\nLamZdnto+gXLk7KKFq101C7wEbCYhRKxK0U+FaTeTvvW+cirFFb783QE7HUbjMWG\nMlgDGeXy64BaAOhjwGllh3+OUEMT0Qgagh2MXaLcqz+idQgGzZknCvYqQEWgEtAH\nY/J9sSwBCNEyvesPKEhtbAbu2aaCLKYz73fbCsBPmS+J6IKcuo0=\n=Vrcb\n-----END PGP SIGNATURE-----",
                    "payload": "tree a9b8a22fd4f7eccad7201f2ad2ce3253b2a6db6d\nparent 8636a4e08b9eaaef838ac3b2a4ae83afadd5a202\nauthor zoucao <32817398+zoucao@users.noreply.github.com> 1625043368 +0800\ncommitter Jark Wu <jark@apache.org> 1625043425 +0800\n\n[FLINK-23156][docs][table] Fix links related to \"docs/dev/table/sql/queries\" (#16323)\n\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/dcc5616cd72a90ff0467b50af3328790d980f0ea",
            "html_url": "https://github.com/apache/flink/commit/dcc5616cd72a90ff0467b50af3328790d980f0ea",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/dcc5616cd72a90ff0467b50af3328790d980f0ea/comments",
            "author": {
                "login": "zoucao",
                "id": 32817398,
                "node_id": "MDQ6VXNlcjMyODE3Mzk4",
                "avatar_url": "https://avatars.githubusercontent.com/u/32817398?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zoucao",
                "html_url": "https://github.com/zoucao",
                "followers_url": "https://api.github.com/users/zoucao/followers",
                "following_url": "https://api.github.com/users/zoucao/following{/other_user}",
                "gists_url": "https://api.github.com/users/zoucao/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zoucao/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zoucao/subscriptions",
                "organizations_url": "https://api.github.com/users/zoucao/orgs",
                "repos_url": "https://api.github.com/users/zoucao/repos",
                "events_url": "https://api.github.com/users/zoucao/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zoucao/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "wuchong",
                "id": 5378924,
                "node_id": "MDQ6VXNlcjUzNzg5MjQ=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5378924?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/wuchong",
                "html_url": "https://github.com/wuchong",
                "followers_url": "https://api.github.com/users/wuchong/followers",
                "following_url": "https://api.github.com/users/wuchong/following{/other_user}",
                "gists_url": "https://api.github.com/users/wuchong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/wuchong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/wuchong/subscriptions",
                "organizations_url": "https://api.github.com/users/wuchong/orgs",
                "repos_url": "https://api.github.com/users/wuchong/repos",
                "events_url": "https://api.github.com/users/wuchong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/wuchong/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "8636a4e08b9eaaef838ac3b2a4ae83afadd5a202",
                "url": "https://api.github.com/repos/apache/flink/commits/8636a4e08b9eaaef838ac3b2a4ae83afadd5a202",
                "html_url": "https://github.com/apache/flink/commit/8636a4e08b9eaaef838ac3b2a4ae83afadd5a202"
            }]
        },
        {
            "sha": "46fdc5fb0207cd5671d3404a551bd27bdedb554d",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NDZmZGM1ZmIwMjA3Y2Q1NjcxZDM0MDRhNTUxYmQyN2JkZWRiNTU0ZA==",
            "commit": {
                "author": {
                    "name": "Roman Khachatryan",
                    "email": "khachatryan.roman@gmail.com",
                    "date": "2021-06-29T19:17:07Z"
                },
                "committer": {
                    "name": "Roman",
                    "email": "khachatryan.roman@gmail.com",
                    "date": "2021-06-30T09:05:55Z"
                },
                "message": "[FLINK-22462][tests] Fix JdbcExactlyOnceSinkE2eTest by pausing emission until checkpoint confirmed\n\nCurrently, the test job makes too many attempts with little progress and\neventually times out.\nToo many attempts are made because each checkpoint can be failed by any\nFailingMapper that reaches its randomly chosen threshold. And if some\nsubtask becomes back-pressured then any of three others will likely fail\nthe checkpoint, reverting the progress.\nThis change makes sources to pause for the checkpoint confirmation; and\nfixes static fields so that it runs more reliably in a loop locally.",
                "tree": {
                    "sha": "7fe3e02a65c1b352a0e5cda75aad6b6abd0af2dc",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/7fe3e02a65c1b352a0e5cda75aad6b6abd0af2dc"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/46fdc5fb0207cd5671d3404a551bd27bdedb554d",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/46fdc5fb0207cd5671d3404a551bd27bdedb554d",
            "html_url": "https://github.com/apache/flink/commit/46fdc5fb0207cd5671d3404a551bd27bdedb554d",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/46fdc5fb0207cd5671d3404a551bd27bdedb554d/comments",
            "author": {
                "login": "rkhachatryan",
                "id": 3939322,
                "node_id": "MDQ6VXNlcjM5MzkzMjI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3939322?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rkhachatryan",
                "html_url": "https://github.com/rkhachatryan",
                "followers_url": "https://api.github.com/users/rkhachatryan/followers",
                "following_url": "https://api.github.com/users/rkhachatryan/following{/other_user}",
                "gists_url": "https://api.github.com/users/rkhachatryan/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rkhachatryan/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rkhachatryan/subscriptions",
                "organizations_url": "https://api.github.com/users/rkhachatryan/orgs",
                "repos_url": "https://api.github.com/users/rkhachatryan/repos",
                "events_url": "https://api.github.com/users/rkhachatryan/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rkhachatryan/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "rkhachatryan",
                "id": 3939322,
                "node_id": "MDQ6VXNlcjM5MzkzMjI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3939322?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rkhachatryan",
                "html_url": "https://github.com/rkhachatryan",
                "followers_url": "https://api.github.com/users/rkhachatryan/followers",
                "following_url": "https://api.github.com/users/rkhachatryan/following{/other_user}",
                "gists_url": "https://api.github.com/users/rkhachatryan/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rkhachatryan/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rkhachatryan/subscriptions",
                "organizations_url": "https://api.github.com/users/rkhachatryan/orgs",
                "repos_url": "https://api.github.com/users/rkhachatryan/repos",
                "events_url": "https://api.github.com/users/rkhachatryan/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rkhachatryan/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "dcc5616cd72a90ff0467b50af3328790d980f0ea",
                "url": "https://api.github.com/repos/apache/flink/commits/dcc5616cd72a90ff0467b50af3328790d980f0ea",
                "html_url": "https://github.com/apache/flink/commit/dcc5616cd72a90ff0467b50af3328790d980f0ea"
            }]
        },
        {
            "sha": "2d229fc6521b4fc924a4a66347d71b72a1455f77",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MmQyMjlmYzY1MjFiNGZjOTI0YTRhNjYzNDdkNzFiNzJhMTQ1NWY3Nw==",
            "commit": {
                "author": {
                    "name": "Gen Luo",
                    "email": "luogen.lg@gmail.com",
                    "date": "2021-06-28T07:29:45Z"
                },
                "committer": {
                    "name": "Zhu Zhu",
                    "email": "reedpor@gmail.com",
                    "date": "2021-06-30T11:11:52Z"
                },
                "message": "[FLINK-22954][runtime] Avoid StackOverflowException when a large scale job is canceling or failing\n\nCancel all pending requests of a canceled/failed execution version, or the requests may be fulfilled with a slot released by a previously fulfilled task and then released immediately, which is executed recursively and may cause StackOverflowException when the scale is too large.",
                "tree": {
                    "sha": "876e5cfde1f6665d88aa9aa1a307b5c794affa18",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/876e5cfde1f6665d88aa9aa1a307b5c794affa18"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/2d229fc6521b4fc924a4a66347d71b72a1455f77",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/2d229fc6521b4fc924a4a66347d71b72a1455f77",
            "html_url": "https://github.com/apache/flink/commit/2d229fc6521b4fc924a4a66347d71b72a1455f77",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/2d229fc6521b4fc924a4a66347d71b72a1455f77/comments",
            "author": {
                "login": "pltbkd",
                "id": 86285274,
                "node_id": "MDQ6VXNlcjg2Mjg1Mjc0",
                "avatar_url": "https://avatars.githubusercontent.com/u/86285274?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/pltbkd",
                "html_url": "https://github.com/pltbkd",
                "followers_url": "https://api.github.com/users/pltbkd/followers",
                "following_url": "https://api.github.com/users/pltbkd/following{/other_user}",
                "gists_url": "https://api.github.com/users/pltbkd/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/pltbkd/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/pltbkd/subscriptions",
                "organizations_url": "https://api.github.com/users/pltbkd/orgs",
                "repos_url": "https://api.github.com/users/pltbkd/repos",
                "events_url": "https://api.github.com/users/pltbkd/events{/privacy}",
                "received_events_url": "https://api.github.com/users/pltbkd/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "zhuzhurk",
                "id": 5869249,
                "node_id": "MDQ6VXNlcjU4NjkyNDk=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5869249?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zhuzhurk",
                "html_url": "https://github.com/zhuzhurk",
                "followers_url": "https://api.github.com/users/zhuzhurk/followers",
                "following_url": "https://api.github.com/users/zhuzhurk/following{/other_user}",
                "gists_url": "https://api.github.com/users/zhuzhurk/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zhuzhurk/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zhuzhurk/subscriptions",
                "organizations_url": "https://api.github.com/users/zhuzhurk/orgs",
                "repos_url": "https://api.github.com/users/zhuzhurk/repos",
                "events_url": "https://api.github.com/users/zhuzhurk/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zhuzhurk/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "46fdc5fb0207cd5671d3404a551bd27bdedb554d",
                "url": "https://api.github.com/repos/apache/flink/commits/46fdc5fb0207cd5671d3404a551bd27bdedb554d",
                "html_url": "https://github.com/apache/flink/commit/46fdc5fb0207cd5671d3404a551bd27bdedb554d"
            }]
        },
        {
            "sha": "7fef5f3ee318ebe569dced326cc29037077e1098",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6N2ZlZjVmM2VlMzE4ZWJlNTY5ZGNlZDMyNmNjMjkwMzcwNzdlMTA5OA==",
            "commit": {
                "author": {
                    "name": "weizheng92",
                    "email": "wei_zheng@inspur.com",
                    "date": "2021-07-01T09:44:55Z"
                },
                "committer": {
                    "name": "Jark Wu",
                    "email": "jark@apache.org",
                    "date": "2021-07-01T09:52:39Z"
                },
                "message": "[FLINK-23200][docs][table] Fix code example typo in \"Table API\" page (#16338)",
                "tree": {
                    "sha": "4aa2b89519970b2a9bd39efc68135671028c342d",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/4aa2b89519970b2a9bd39efc68135671028c342d"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/7fef5f3ee318ebe569dced326cc29037077e1098",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEE4sRUF77VwQQVTzQQhbrLWu+uMgIFAmDdkGcACgkQhbrLWu+u\nMgI1pA//YB8cBTDQB5DqbSZHea6UkiQuPC0nLGwVK4VxTIGLYu2ZDQhpFY6kgSl+\nR80WKTfjfZcdmyiFcnL++qWbZBnku8JfJxGt9V92wEUtZEisTh91CX9IfU4V242M\nDrLU1f3cfHhNPEPWcxJ4hljWqHVFnNDTHtBw4a/ONBd6nD06gInKTVjiwYHnWOuG\nmUBIB8PGVayls8AYVJM5peEqHzt2zCph/zNFGMq3/ZyeU2L+b1EmjraCrsevvARY\nmx4OoHrR5OkUhvacV/vnqcJVQ7VIXWnDASRgHN4MGJo4eHQGpRkchoT9Tt7A/+zf\niIEsutnTOmLGEc8s2dVLSfMKvXYUCLpImbb+dimD80hDVPIk+RNGuSMwZtTcsu1C\ncvlP0YjmLI/+gedFWr7nWkODqEZWVpDpSFyLoANc558zJ5ZX8TyEqt8BqsdoMxva\n29SmXOHZDeFVoT103XnEC8RW753T5RR/Jq3a7quCR1pgnffbIIFzIFe+qfec6CSR\nEhPeBC7D048uv1EYOw8bHWqpYoc52NaGWr9gubS4HGi3DDoLLqT9cpsHiXXH1dr8\nAIDyo9oVjtS0liUfifqDFX2tmYwzbvKau6xLvARueOzN6rv5C9p1C0eF2QDQzHyT\nhBpMua9Pnnag8c4itSsBkUZDY8k2x3i/ZKTo4TqK07uW4WW3phA=\n=3EX+\n-----END PGP SIGNATURE-----",
                    "payload": "tree 4aa2b89519970b2a9bd39efc68135671028c342d\nparent 2d229fc6521b4fc924a4a66347d71b72a1455f77\nauthor weizheng92 <wei_zheng@inspur.com> 1625132695 +0800\ncommitter Jark Wu <jark@apache.org> 1625133159 +0800\n\n[FLINK-23200][docs][table] Fix code example typo in \"Table API\" page (#16338)\n\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/7fef5f3ee318ebe569dced326cc29037077e1098",
            "html_url": "https://github.com/apache/flink/commit/7fef5f3ee318ebe569dced326cc29037077e1098",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/7fef5f3ee318ebe569dced326cc29037077e1098/comments",
            "author": {
                "login": "weizheng92",
                "id": 11443175,
                "node_id": "MDQ6VXNlcjExNDQzMTc1",
                "avatar_url": "https://avatars.githubusercontent.com/u/11443175?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/weizheng92",
                "html_url": "https://github.com/weizheng92",
                "followers_url": "https://api.github.com/users/weizheng92/followers",
                "following_url": "https://api.github.com/users/weizheng92/following{/other_user}",
                "gists_url": "https://api.github.com/users/weizheng92/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/weizheng92/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/weizheng92/subscriptions",
                "organizations_url": "https://api.github.com/users/weizheng92/orgs",
                "repos_url": "https://api.github.com/users/weizheng92/repos",
                "events_url": "https://api.github.com/users/weizheng92/events{/privacy}",
                "received_events_url": "https://api.github.com/users/weizheng92/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "wuchong",
                "id": 5378924,
                "node_id": "MDQ6VXNlcjUzNzg5MjQ=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5378924?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/wuchong",
                "html_url": "https://github.com/wuchong",
                "followers_url": "https://api.github.com/users/wuchong/followers",
                "following_url": "https://api.github.com/users/wuchong/following{/other_user}",
                "gists_url": "https://api.github.com/users/wuchong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/wuchong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/wuchong/subscriptions",
                "organizations_url": "https://api.github.com/users/wuchong/orgs",
                "repos_url": "https://api.github.com/users/wuchong/repos",
                "events_url": "https://api.github.com/users/wuchong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/wuchong/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "2d229fc6521b4fc924a4a66347d71b72a1455f77",
                "url": "https://api.github.com/repos/apache/flink/commits/2d229fc6521b4fc924a4a66347d71b72a1455f77",
                "html_url": "https://github.com/apache/flink/commit/2d229fc6521b4fc924a4a66347d71b72a1455f77"
            }]
        },
        {
            "sha": "32c0ef1f71be76697ffd9eb3125e3bd87d36e212",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MzJjMGVmMWY3MWJlNzY2OTdmZmQ5ZWIzMTI1ZTNiZDg3ZDM2ZTIxMg==",
            "commit": {
                "author": {
                    "name": "Yun Tang",
                    "email": "myasuka@live.com",
                    "date": "2021-06-17T07:47:23Z"
                },
                "committer": {
                    "name": "Yun Tang",
                    "email": "tangyun@apache.org",
                    "date": "2021-07-02T07:31:43Z"
                },
                "message": "[FLINK-22528][docs] Document latency tracking metrics for state accesses",
                "tree": {
                    "sha": "9cab2a852a3f6fddd301810cb3ad5050a9eb0e61",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/9cab2a852a3f6fddd301810cb3ad5050a9eb0e61"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/32c0ef1f71be76697ffd9eb3125e3bd87d36e212",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/32c0ef1f71be76697ffd9eb3125e3bd87d36e212",
            "html_url": "https://github.com/apache/flink/commit/32c0ef1f71be76697ffd9eb3125e3bd87d36e212",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/32c0ef1f71be76697ffd9eb3125e3bd87d36e212/comments",
            "author": {
                "login": "Myasuka",
                "id": 1709104,
                "node_id": "MDQ6VXNlcjE3MDkxMDQ=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1709104?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/Myasuka",
                "html_url": "https://github.com/Myasuka",
                "followers_url": "https://api.github.com/users/Myasuka/followers",
                "following_url": "https://api.github.com/users/Myasuka/following{/other_user}",
                "gists_url": "https://api.github.com/users/Myasuka/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/Myasuka/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/Myasuka/subscriptions",
                "organizations_url": "https://api.github.com/users/Myasuka/orgs",
                "repos_url": "https://api.github.com/users/Myasuka/repos",
                "events_url": "https://api.github.com/users/Myasuka/events{/privacy}",
                "received_events_url": "https://api.github.com/users/Myasuka/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "Myasuka",
                "id": 1709104,
                "node_id": "MDQ6VXNlcjE3MDkxMDQ=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1709104?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/Myasuka",
                "html_url": "https://github.com/Myasuka",
                "followers_url": "https://api.github.com/users/Myasuka/followers",
                "following_url": "https://api.github.com/users/Myasuka/following{/other_user}",
                "gists_url": "https://api.github.com/users/Myasuka/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/Myasuka/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/Myasuka/subscriptions",
                "organizations_url": "https://api.github.com/users/Myasuka/orgs",
                "repos_url": "https://api.github.com/users/Myasuka/repos",
                "events_url": "https://api.github.com/users/Myasuka/events{/privacy}",
                "received_events_url": "https://api.github.com/users/Myasuka/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "7fef5f3ee318ebe569dced326cc29037077e1098",
                "url": "https://api.github.com/repos/apache/flink/commits/7fef5f3ee318ebe569dced326cc29037077e1098",
                "html_url": "https://github.com/apache/flink/commit/7fef5f3ee318ebe569dced326cc29037077e1098"
            }]
        },
        {
            "sha": "d0bf474cec5cc079172160ba070070de1a14e59c",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZDBiZjQ3NGNlYzVjYzA3OTE3MjE2MGJhMDcwMDcwZGUxYTE0ZTU5Yw==",
            "commit": {
                "author": {
                    "name": "Rui Li",
                    "email": "lirui@apache.org",
                    "date": "2021-06-30T12:52:57Z"
                },
                "committer": {
                    "name": "Rui Li",
                    "email": "lirui@apache.org",
                    "date": "2021-07-02T07:42:26Z"
                },
                "message": "[FLINK-23168][table-common][table-api-java] GenericInMemoryCatalog shouldn't merge properties for alter DB operation",
                "tree": {
                    "sha": "23cf6e6794d977536e4a98cc623e4fb973af1dce",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/23cf6e6794d977536e4a98cc623e4fb973af1dce"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/d0bf474cec5cc079172160ba070070de1a14e59c",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/d0bf474cec5cc079172160ba070070de1a14e59c",
            "html_url": "https://github.com/apache/flink/commit/d0bf474cec5cc079172160ba070070de1a14e59c",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/d0bf474cec5cc079172160ba070070de1a14e59c/comments",
            "author": {
                "login": "lirui-apache",
                "id": 5210788,
                "node_id": "MDQ6VXNlcjUyMTA3ODg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5210788?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/lirui-apache",
                "html_url": "https://github.com/lirui-apache",
                "followers_url": "https://api.github.com/users/lirui-apache/followers",
                "following_url": "https://api.github.com/users/lirui-apache/following{/other_user}",
                "gists_url": "https://api.github.com/users/lirui-apache/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/lirui-apache/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/lirui-apache/subscriptions",
                "organizations_url": "https://api.github.com/users/lirui-apache/orgs",
                "repos_url": "https://api.github.com/users/lirui-apache/repos",
                "events_url": "https://api.github.com/users/lirui-apache/events{/privacy}",
                "received_events_url": "https://api.github.com/users/lirui-apache/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "lirui-apache",
                "id": 5210788,
                "node_id": "MDQ6VXNlcjUyMTA3ODg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5210788?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/lirui-apache",
                "html_url": "https://github.com/lirui-apache",
                "followers_url": "https://api.github.com/users/lirui-apache/followers",
                "following_url": "https://api.github.com/users/lirui-apache/following{/other_user}",
                "gists_url": "https://api.github.com/users/lirui-apache/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/lirui-apache/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/lirui-apache/subscriptions",
                "organizations_url": "https://api.github.com/users/lirui-apache/orgs",
                "repos_url": "https://api.github.com/users/lirui-apache/repos",
                "events_url": "https://api.github.com/users/lirui-apache/events{/privacy}",
                "received_events_url": "https://api.github.com/users/lirui-apache/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "32c0ef1f71be76697ffd9eb3125e3bd87d36e212",
                "url": "https://api.github.com/repos/apache/flink/commits/32c0ef1f71be76697ffd9eb3125e3bd87d36e212",
                "html_url": "https://github.com/apache/flink/commit/32c0ef1f71be76697ffd9eb3125e3bd87d36e212"
            }]
        },
        {
            "sha": "2075d0facdcfbac9f3f060e8b274dd485f365829",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MjA3NWQwZmFjZGNmYmFjOWYzZjA2MGU4YjI3NGRkNDg1ZjM2NTgyOQ==",
            "commit": {
                "author": {
                    "name": "Rui Li",
                    "email": "lirui@apache.org",
                    "date": "2021-06-30T12:53:27Z"
                },
                "committer": {
                    "name": "Rui Li",
                    "email": "lirui@apache.org",
                    "date": "2021-07-02T07:42:26Z"
                },
                "message": "[FLINK-23168][hive] HiveCatalog shouldn't merge properties for alter DB operation\n\nThis closes #16335",
                "tree": {
                    "sha": "dd65ec7795a3c488fd413179a1024dfd59e288c2",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/dd65ec7795a3c488fd413179a1024dfd59e288c2"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/2075d0facdcfbac9f3f060e8b274dd485f365829",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/2075d0facdcfbac9f3f060e8b274dd485f365829",
            "html_url": "https://github.com/apache/flink/commit/2075d0facdcfbac9f3f060e8b274dd485f365829",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/2075d0facdcfbac9f3f060e8b274dd485f365829/comments",
            "author": {
                "login": "lirui-apache",
                "id": 5210788,
                "node_id": "MDQ6VXNlcjUyMTA3ODg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5210788?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/lirui-apache",
                "html_url": "https://github.com/lirui-apache",
                "followers_url": "https://api.github.com/users/lirui-apache/followers",
                "following_url": "https://api.github.com/users/lirui-apache/following{/other_user}",
                "gists_url": "https://api.github.com/users/lirui-apache/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/lirui-apache/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/lirui-apache/subscriptions",
                "organizations_url": "https://api.github.com/users/lirui-apache/orgs",
                "repos_url": "https://api.github.com/users/lirui-apache/repos",
                "events_url": "https://api.github.com/users/lirui-apache/events{/privacy}",
                "received_events_url": "https://api.github.com/users/lirui-apache/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "lirui-apache",
                "id": 5210788,
                "node_id": "MDQ6VXNlcjUyMTA3ODg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5210788?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/lirui-apache",
                "html_url": "https://github.com/lirui-apache",
                "followers_url": "https://api.github.com/users/lirui-apache/followers",
                "following_url": "https://api.github.com/users/lirui-apache/following{/other_user}",
                "gists_url": "https://api.github.com/users/lirui-apache/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/lirui-apache/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/lirui-apache/subscriptions",
                "organizations_url": "https://api.github.com/users/lirui-apache/orgs",
                "repos_url": "https://api.github.com/users/lirui-apache/repos",
                "events_url": "https://api.github.com/users/lirui-apache/events{/privacy}",
                "received_events_url": "https://api.github.com/users/lirui-apache/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "d0bf474cec5cc079172160ba070070de1a14e59c",
                "url": "https://api.github.com/repos/apache/flink/commits/d0bf474cec5cc079172160ba070070de1a14e59c",
                "html_url": "https://github.com/apache/flink/commit/d0bf474cec5cc079172160ba070070de1a14e59c"
            }]
        },
        {
            "sha": "5c4be8a89643422d2335243a1a58edfa45ea4721",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NWM0YmU4YTg5NjQzNDIyZDIzMzUyNDNhMWE1OGVkZmE0NWVhNDcyMQ==",
            "commit": {
                "author": {
                    "name": "Etienne Chauchot",
                    "email": "echauchot@apache.org",
                    "date": "2021-06-23T10:24:14Z"
                },
                "committer": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-07-02T15:45:04Z"
                },
                "message": "[hotfix][release-notes] Update release notes for 1.13 with accumulators semantics change in MiniClusterJobClient\n\nFLINK-18685 changed the semantics of the MiniClusterJobClient. This commit updates the 1.13 release notes\naccordingly.\n\nThis closes #16256.",
                "tree": {
                    "sha": "71d26cddc49ae687e8893d75d37eaecef1f7c8b3",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/71d26cddc49ae687e8893d75d37eaecef1f7c8b3"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/5c4be8a89643422d2335243a1a58edfa45ea4721",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEEuUmfpp7/Xe7rw8H1un5Bh8b3PYIFAmDfNIAACgkQun5Bh8b3\nPYLoAg//byrEHqhZ9ibEIZ9kYl/7o74ajrPgcMX4lxFdY2/ojvfWqaqfrai5rfWW\n5KV3ApFMU9Sq3Qt5kWeCHl/2E35bb+7/Lh2G76fv7mHN69ojPDsk+E8FuQydmFb/\nsNgR2Z45GnnSTRp49YNSkecD9XHSWnSFk3zMCiqjAK2TIL/nbNKcS+x1rpVrPMVP\nRSV/Rhcshei2HfuD1os//oTu4dchAQzYhHsOF1Ck75iMdxNkrd8xtDSZx6vVzoXS\nwZxZpUGdnUKsEnZEowINBxLPFn/lBjNybDYKcmuxNHspdqsYnFW2hXztWm80gjSs\nOtNEwTmxOQo8IT5nVhQJBama549mMrJewI8qlYk30GVaXCHwMY6QWROeNlJmc64O\nuWFoThFmXIMBRJIOFoX0W66bTCSjJo/q/WV/PFmcGhAj794pjx1cYWNi4vzux3Fd\nk+HVm5YkIUwknhm/TmoE58kUcv/7AaERLcWWIjPjj5js0f0WrEQBc2JLSmyQDYLO\nLEm6s5Vgw52zd7K48UsbaVMmgcEn4XtPQCmmxEZPyrTI37Z9RxE2RquLQRwyDqkc\nyfmFAkzha3l7yhUWyHMMmstWWtvWYiDeIBwH41g8IO9Tvt9YG3/VdK6e+aAtX/TS\n5lPhw1OmxvaPW8Zzf/dUmbI3YCfm69iKV+IMWOORFpyKY8/IyFg=\n=4vpf\n-----END PGP SIGNATURE-----",
                    "payload": "tree 71d26cddc49ae687e8893d75d37eaecef1f7c8b3\nparent 2075d0facdcfbac9f3f060e8b274dd485f365829\nauthor Etienne Chauchot <echauchot@apache.org> 1624443854 +0200\ncommitter Till Rohrmann <trohrmann@apache.org> 1625240704 +0200\n\n[hotfix][release-notes] Update release notes for 1.13 with accumulators semantics change in MiniClusterJobClient\n\nFLINK-18685 changed the semantics of the MiniClusterJobClient. This commit updates the 1.13 release notes\naccordingly.\n\nThis closes #16256.\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/5c4be8a89643422d2335243a1a58edfa45ea4721",
            "html_url": "https://github.com/apache/flink/commit/5c4be8a89643422d2335243a1a58edfa45ea4721",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/5c4be8a89643422d2335243a1a58edfa45ea4721/comments",
            "author": {
                "login": "echauchot",
                "id": 8821084,
                "node_id": "MDQ6VXNlcjg4MjEwODQ=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8821084?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/echauchot",
                "html_url": "https://github.com/echauchot",
                "followers_url": "https://api.github.com/users/echauchot/followers",
                "following_url": "https://api.github.com/users/echauchot/following{/other_user}",
                "gists_url": "https://api.github.com/users/echauchot/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/echauchot/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/echauchot/subscriptions",
                "organizations_url": "https://api.github.com/users/echauchot/orgs",
                "repos_url": "https://api.github.com/users/echauchot/repos",
                "events_url": "https://api.github.com/users/echauchot/events{/privacy}",
                "received_events_url": "https://api.github.com/users/echauchot/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "2075d0facdcfbac9f3f060e8b274dd485f365829",
                "url": "https://api.github.com/repos/apache/flink/commits/2075d0facdcfbac9f3f060e8b274dd485f365829",
                "html_url": "https://github.com/apache/flink/commit/2075d0facdcfbac9f3f060e8b274dd485f365829"
            }]
        },
        {
            "sha": "ad60fdcc13cb21e1622c82e3365b68a0408dcb8b",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6YWQ2MGZkY2MxM2NiMjFlMTYyMmM4MmUzMzY1YjY4YTA0MDhkY2I4Yg==",
            "commit": {
                "author": {
                    "name": "Kevin Fan",
                    "email": "25916269+RollsBean@users.noreply.github.com",
                    "date": "2021-07-05T02:44:06Z"
                },
                "committer": {
                    "name": "Jark Wu",
                    "email": "jark@apache.org",
                    "date": "2021-07-05T02:45:26Z"
                },
                "message": "[FLINK-23226][docs-zh] Fix Flink Chinese doc learn-flink/etl transformation.svg display issue\n\nThis closes #16364",
                "tree": {
                    "sha": "816be3f06cf078445653a3c4e7b0f63211f19c94",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/816be3f06cf078445653a3c4e7b0f63211f19c94"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/ad60fdcc13cb21e1622c82e3365b68a0408dcb8b",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEE4sRUF77VwQQVTzQQhbrLWu+uMgIFAmDickYACgkQhbrLWu+u\nMgIV8xAAi7Ln0NY5keFPu7+WQO5HOj/9mR24y9mTj8/ODk9zZOf2OEHMrBP1lsz8\nBZPxq0m7ZqsWjsDm/mXJRjTL7Vb8VuDCdbnud+CC+MzfspvT97F4c75EAiftjpNd\n3EYUdAA6v+EPw5UrM58Wq1zMfe1BmZiaTWcDoyy3m50T2xkU6nQK0C/DXwC7bq0S\nMkq4PDBwcuv2GOEznvvgHaEI/I4AhaxxQTHiOs9PzbLoY8/x32m0/wSg9MBdlL9H\neAqPpG4r2OMyiby3TCeV1jjQo/nY9KKYLQDROUw4vuo3b/Imd7zTYFjhu0r51WJM\nmtJGcgdMakPhs8Dq6QV150jdXEZ0qA/4IUYBTTCGsV2qARpZllxzKIm0Q4ID5Jbr\nkmk7jipe2YLBse3kVT61bA9Q5Qu1Gs1chfb/qJAxFGi482bKYYhiX4N9B9Cx4/R5\nZQSxgpQG7aW7dHAbo02YJsAC1vz6UF3oKSUJw7rUtIP3Ri2f7Px1ff4H2DEfHAY/\n71LSUABxQwneaooPeEtjJnurFpqQAs/GA9XCroPmrZHskPuRwmJzBbDYBeYVZ4OX\nzs43LuOqkkRhnCef0xD3j+Gffxlzu2fn5cqTVDMIM7z2LQ56UCi9nx3fOQTT7NVA\n0YXxIqmcpugODRv0t1n+pa1k5f7QLZ8h7S1QIoM8bbj1lLjo9Xc=\n=rKQz\n-----END PGP SIGNATURE-----",
                    "payload": "tree 816be3f06cf078445653a3c4e7b0f63211f19c94\nparent 5c4be8a89643422d2335243a1a58edfa45ea4721\nauthor Kevin Fan <25916269+RollsBean@users.noreply.github.com> 1625453046 +0800\ncommitter Jark Wu <jark@apache.org> 1625453126 +0800\n\n[FLINK-23226][docs-zh] Fix Flink Chinese doc learn-flink/etl transformation.svg display issue\n\nThis closes #16364"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/ad60fdcc13cb21e1622c82e3365b68a0408dcb8b",
            "html_url": "https://github.com/apache/flink/commit/ad60fdcc13cb21e1622c82e3365b68a0408dcb8b",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/ad60fdcc13cb21e1622c82e3365b68a0408dcb8b/comments",
            "author": {
                "login": "RollsBean",
                "id": 25916269,
                "node_id": "MDQ6VXNlcjI1OTE2MjY5",
                "avatar_url": "https://avatars.githubusercontent.com/u/25916269?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/RollsBean",
                "html_url": "https://github.com/RollsBean",
                "followers_url": "https://api.github.com/users/RollsBean/followers",
                "following_url": "https://api.github.com/users/RollsBean/following{/other_user}",
                "gists_url": "https://api.github.com/users/RollsBean/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/RollsBean/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/RollsBean/subscriptions",
                "organizations_url": "https://api.github.com/users/RollsBean/orgs",
                "repos_url": "https://api.github.com/users/RollsBean/repos",
                "events_url": "https://api.github.com/users/RollsBean/events{/privacy}",
                "received_events_url": "https://api.github.com/users/RollsBean/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "wuchong",
                "id": 5378924,
                "node_id": "MDQ6VXNlcjUzNzg5MjQ=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5378924?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/wuchong",
                "html_url": "https://github.com/wuchong",
                "followers_url": "https://api.github.com/users/wuchong/followers",
                "following_url": "https://api.github.com/users/wuchong/following{/other_user}",
                "gists_url": "https://api.github.com/users/wuchong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/wuchong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/wuchong/subscriptions",
                "organizations_url": "https://api.github.com/users/wuchong/orgs",
                "repos_url": "https://api.github.com/users/wuchong/repos",
                "events_url": "https://api.github.com/users/wuchong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/wuchong/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "5c4be8a89643422d2335243a1a58edfa45ea4721",
                "url": "https://api.github.com/repos/apache/flink/commits/5c4be8a89643422d2335243a1a58edfa45ea4721",
                "html_url": "https://github.com/apache/flink/commit/5c4be8a89643422d2335243a1a58edfa45ea4721"
            }]
        },
        {
            "sha": "51c02e434629722ed622c72b9132f973ce51d3a8",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NTFjMDJlNDM0NjI5NzIyZWQ2MjJjNzJiOTEzMmY5NzNjZTUxZDNhOA==",
            "commit": {
                "author": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-07-01T07:44:24Z"
                },
                "committer": {
                    "name": "Xintong Song",
                    "email": "tonysong820@gmail.com",
                    "date": "2021-07-05T03:06:57Z"
                },
                "message": "[FLINK-23196][tests] use MiniClusterResource",
                "tree": {
                    "sha": "4fa05e096ba00a53b037315bf5adfb9bcef0e779",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/4fa05e096ba00a53b037315bf5adfb9bcef0e779"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/51c02e434629722ed622c72b9132f973ce51d3a8",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCgAdFiEEGsvLF58sbVnbyFd20SHP9Sk+Y18FAmDid1EACgkQ0SHP9Sk+\nY18IuBAAwPn/lzDF1qc5nu3crZU/tXpcrh+uSxMBcC2tjEkdacua8oAw4nOmdEkq\nmRlMpbViQ8Ta98mX500euXXX1ejZNWs7yvId2Cp+8JS4A3bltZw0H3WbaYrorXZ/\nxDtAVRVOGrgP8ZOaLFUEwVy31XqC7qzzG9WagCrglYAanzFVtedGWwPvy/HqlF+0\n/4IA8oimDBJPD6GKRkPyG2QnS0w5WPFEZnHCGwVmqZZVrBQwZZzJ8PFfRmK3dKUk\nisNWF3RNil1tDxTK0TzTQ4WzezDeiicNciD2ikHWO+H//OCuQsZV7w+1ZGoHFgF/\n6vcJb/by3/DGPnoIWjVIjVJFDwR+Feeh1dATMsNt8IjLBtUFIuER3mlid1xqnlJW\nU4mEanhd9UA4bxg3VFk6ViuUXgCdjbkPZd44Kwsf5PCoL5o+9JbOQyu6qauPBldF\nlwa26s3hj6w5n7sY2UaK7SLgT74fCdH9fvNTBep7+O+CZ7yLB7u+bBpKHJRA/r3A\ng1ustQxFgfUqsniK7Y/UrzyTCHfiaE7PCPsgT76gEZyN7p53qsqeZhIxkYFg6X7Y\n6WghfIqNix4dSg7FE4q4Vq2m35mJxmlqK1EIZljfe3J4OzXJaDZVXOhdvCcAfl0O\nU9fGPpVrh2j4m9dRLXH32IGhivCBv7lQOGaqiKkWTCYTX+8WTsA=\n=mXdx\n-----END PGP SIGNATURE-----",
                    "payload": "tree 4fa05e096ba00a53b037315bf5adfb9bcef0e779\nparent ad60fdcc13cb21e1622c82e3365b68a0408dcb8b\nauthor Chesnay Schepler <chesnay@apache.org> 1625125464 +0200\ncommitter Xintong Song <tonysong820@gmail.com> 1625454417 +0800\n\n[FLINK-23196][tests] use MiniClusterResource\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/51c02e434629722ed622c72b9132f973ce51d3a8",
            "html_url": "https://github.com/apache/flink/commit/51c02e434629722ed622c72b9132f973ce51d3a8",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/51c02e434629722ed622c72b9132f973ce51d3a8/comments",
            "author": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "xintongsong",
                "id": 6509172,
                "node_id": "MDQ6VXNlcjY1MDkxNzI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6509172?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/xintongsong",
                "html_url": "https://github.com/xintongsong",
                "followers_url": "https://api.github.com/users/xintongsong/followers",
                "following_url": "https://api.github.com/users/xintongsong/following{/other_user}",
                "gists_url": "https://api.github.com/users/xintongsong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/xintongsong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/xintongsong/subscriptions",
                "organizations_url": "https://api.github.com/users/xintongsong/orgs",
                "repos_url": "https://api.github.com/users/xintongsong/repos",
                "events_url": "https://api.github.com/users/xintongsong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/xintongsong/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "ad60fdcc13cb21e1622c82e3365b68a0408dcb8b",
                "url": "https://api.github.com/repos/apache/flink/commits/ad60fdcc13cb21e1622c82e3365b68a0408dcb8b",
                "html_url": "https://github.com/apache/flink/commit/ad60fdcc13cb21e1622c82e3365b68a0408dcb8b"
            }]
        },
        {
            "sha": "28b09e575bd174685a15d93345d0f87a37d6f002",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MjhiMDllNTc1YmQxNzQ2ODVhMTVkOTMzNDVkMGY4N2EzN2Q2ZjAwMg==",
            "commit": {
                "author": {
                    "name": "Rui Li",
                    "email": "lirui@apache.org",
                    "date": "2021-06-11T13:25:46Z"
                },
                "committer": {
                    "name": "Rui Li",
                    "email": "lirui@apache.org",
                    "date": "2021-07-06T03:33:09Z"
                },
                "message": "[FLINK-22884][hive] HiveCatalog should mark views as generic and store schema in properties\n\nThis closes #16149",
                "tree": {
                    "sha": "6a988b0117eebcebae849f9d1dd2647d2b93c342",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/6a988b0117eebcebae849f9d1dd2647d2b93c342"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/28b09e575bd174685a15d93345d0f87a37d6f002",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/28b09e575bd174685a15d93345d0f87a37d6f002",
            "html_url": "https://github.com/apache/flink/commit/28b09e575bd174685a15d93345d0f87a37d6f002",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/28b09e575bd174685a15d93345d0f87a37d6f002/comments",
            "author": {
                "login": "lirui-apache",
                "id": 5210788,
                "node_id": "MDQ6VXNlcjUyMTA3ODg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5210788?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/lirui-apache",
                "html_url": "https://github.com/lirui-apache",
                "followers_url": "https://api.github.com/users/lirui-apache/followers",
                "following_url": "https://api.github.com/users/lirui-apache/following{/other_user}",
                "gists_url": "https://api.github.com/users/lirui-apache/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/lirui-apache/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/lirui-apache/subscriptions",
                "organizations_url": "https://api.github.com/users/lirui-apache/orgs",
                "repos_url": "https://api.github.com/users/lirui-apache/repos",
                "events_url": "https://api.github.com/users/lirui-apache/events{/privacy}",
                "received_events_url": "https://api.github.com/users/lirui-apache/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "lirui-apache",
                "id": 5210788,
                "node_id": "MDQ6VXNlcjUyMTA3ODg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5210788?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/lirui-apache",
                "html_url": "https://github.com/lirui-apache",
                "followers_url": "https://api.github.com/users/lirui-apache/followers",
                "following_url": "https://api.github.com/users/lirui-apache/following{/other_user}",
                "gists_url": "https://api.github.com/users/lirui-apache/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/lirui-apache/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/lirui-apache/subscriptions",
                "organizations_url": "https://api.github.com/users/lirui-apache/orgs",
                "repos_url": "https://api.github.com/users/lirui-apache/repos",
                "events_url": "https://api.github.com/users/lirui-apache/events{/privacy}",
                "received_events_url": "https://api.github.com/users/lirui-apache/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "51c02e434629722ed622c72b9132f973ce51d3a8",
                "url": "https://api.github.com/repos/apache/flink/commits/51c02e434629722ed622c72b9132f973ce51d3a8",
                "html_url": "https://github.com/apache/flink/commit/51c02e434629722ed622c72b9132f973ce51d3a8"
            }]
        },
        {
            "sha": "9526541f51e0cb472fbad350a52b840f88c31004",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6OTUyNjU0MWY1MWUwY2I0NzJmYmFkMzUwYTUyYjg0MGY4OGMzMTAwNA==",
            "commit": {
                "author": {
                    "name": "hapihu",
                    "email": "w.gh123@qq.com",
                    "date": "2021-07-06T06:41:30Z"
                },
                "committer": {
                    "name": "Jark Wu",
                    "email": "jark@apache.org",
                    "date": "2021-07-06T06:42:17Z"
                },
                "message": "[FLINK-23260][docs] Fix the link for Page \"docs/libs/gelly/overview\" (#16382)",
                "tree": {
                    "sha": "6fcbdc601e28983e3b6187e74bc296ec5c7b4e66",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/6fcbdc601e28983e3b6187e74bc296ec5c7b4e66"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/9526541f51e0cb472fbad350a52b840f88c31004",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEE4sRUF77VwQQVTzQQhbrLWu+uMgIFAmDj+0kACgkQhbrLWu+u\nMgKcWQ/+JgXTEMEpOjHDitOs7KM0TbLnJr3msTO0XBPOg3wKgn1gI3j3vly6JvDF\ncbwJym1EiRv/dK16Ka7mAZq8o4utZKmbxGggyHrXSZIY87nSZKEPww5BuM7YecYh\nwHRj/K5qql/7e6wKY0noTUyIxGK+m9rT8LcyjvYgGUgQqTqOe0a6tRTarYACfJYS\ncWXuHXXA4ZnpobP6nQ1lhcfyhJ+kbbP4+tuvdZv9sdrlC+tmN0qXotaM8Oy0QzKD\nSWuMGZ1hfS9VXQSnWoBXpQotn/nV/i/yb3kLdsLgjOkan5WH/ZpMAlfIt3GfwTnn\n/chUcJY8jN7fMhW7A6G3vXdphvefmgunIMvwmgtmTDM1trHa0pe0zoGPD5137H3y\nBHdu3gmqTtrXvThKKvldWpKhqAEw/Gk1c8Y3INWkLqBPyk5fb2PP+w9E8INUgpAm\ndshTM4U7HeQoAOfFiI7QV9rs1e9XMOXM04856Py3pjtZjUKT7dBpT80uoUQ0dt+2\no/Ba5v6DiWznvHyBcrMNEi+rWa6v6fpr9Qt5+ZOIgQ+1RYpKcCsZVGUOisYD3d2x\nfdsYsgaohUFLZMhnQeZ8OU/SEz1aRdeMAqajCL+o3OraRbYp7xqMLeFGvd8t1asM\nUK3F0wlyYgxznUwfq2tNs9ULT4F4F+upe5ZsS9K+GS8KJNPZQBs=\n=8m1+\n-----END PGP SIGNATURE-----",
                    "payload": "tree 6fcbdc601e28983e3b6187e74bc296ec5c7b4e66\nparent 28b09e575bd174685a15d93345d0f87a37d6f002\nauthor hapihu <w.gh123@qq.com> 1625553690 +0800\ncommitter Jark Wu <jark@apache.org> 1625553737 +0800\n\n[FLINK-23260][docs] Fix the link for Page \"docs/libs/gelly/overview\" (#16382)\n\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/9526541f51e0cb472fbad350a52b840f88c31004",
            "html_url": "https://github.com/apache/flink/commit/9526541f51e0cb472fbad350a52b840f88c31004",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/9526541f51e0cb472fbad350a52b840f88c31004/comments",
            "author": {
                "login": "hapihu",
                "id": 20364527,
                "node_id": "MDQ6VXNlcjIwMzY0NTI3",
                "avatar_url": "https://avatars.githubusercontent.com/u/20364527?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/hapihu",
                "html_url": "https://github.com/hapihu",
                "followers_url": "https://api.github.com/users/hapihu/followers",
                "following_url": "https://api.github.com/users/hapihu/following{/other_user}",
                "gists_url": "https://api.github.com/users/hapihu/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/hapihu/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/hapihu/subscriptions",
                "organizations_url": "https://api.github.com/users/hapihu/orgs",
                "repos_url": "https://api.github.com/users/hapihu/repos",
                "events_url": "https://api.github.com/users/hapihu/events{/privacy}",
                "received_events_url": "https://api.github.com/users/hapihu/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "wuchong",
                "id": 5378924,
                "node_id": "MDQ6VXNlcjUzNzg5MjQ=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5378924?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/wuchong",
                "html_url": "https://github.com/wuchong",
                "followers_url": "https://api.github.com/users/wuchong/followers",
                "following_url": "https://api.github.com/users/wuchong/following{/other_user}",
                "gists_url": "https://api.github.com/users/wuchong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/wuchong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/wuchong/subscriptions",
                "organizations_url": "https://api.github.com/users/wuchong/orgs",
                "repos_url": "https://api.github.com/users/wuchong/repos",
                "events_url": "https://api.github.com/users/wuchong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/wuchong/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "28b09e575bd174685a15d93345d0f87a37d6f002",
                "url": "https://api.github.com/repos/apache/flink/commits/28b09e575bd174685a15d93345d0f87a37d6f002",
                "html_url": "https://github.com/apache/flink/commit/28b09e575bd174685a15d93345d0f87a37d6f002"
            }]
        },
        {
            "sha": "8ac80279d7d0d19af0d0bf2b7129ec7304c628eb",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6OGFjODAyNzlkN2QwZDE5YWYwZDBiZjJiNzEyOWVjNzMwNGM2MjhlYg==",
            "commit": {
                "author": {
                    "name": "hapihu",
                    "email": "w.gh123@qq.com",
                    "date": "2021-07-06T06:43:57Z"
                },
                "committer": {
                    "name": "Jark Wu",
                    "email": "jark@apache.org",
                    "date": "2021-07-06T06:44:29Z"
                },
                "message": "[FLINK-23259][docs] Fix the link for page \"docs/dev/datastream/operators/overview\" (#16381)",
                "tree": {
                    "sha": "2213801b654a174b16f0b1446da848f301d2132d",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/2213801b654a174b16f0b1446da848f301d2132d"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/8ac80279d7d0d19af0d0bf2b7129ec7304c628eb",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEE4sRUF77VwQQVTzQQhbrLWu+uMgIFAmDj+80ACgkQhbrLWu+u\nMgJBCQ//b8HrmISq5jzKRHvtwxYfPA1hcnRfDX/X8ylqb6SHsuLgzKlMPSBRDXBp\nu2QjiH6eStsN3Nf/dx8ZaSyqLxjj8djLOKpyDXjrvok9wMS2tcFM7p3z3wv2v33k\nXK4F6nEl2/pfJ4oT8HKTH6bzPK+Uclaj5kqj+3PJgaQefodfN809qXbxLaIS1uzo\np6cARgj/jcq521b81oI0FLgxo/SiLkKLhiURujzXR9IbAmdWDz2YOCPiKxT6ym5F\nrFJ2ZXuzFnIaWz7QRhhoLLDJebEzRnyCQj/2FLjPrYxIEPdx09jZ0/d7F/1M9kIy\nz2PExQc+soxgMADlbBg4INy+ZCqqTnMnUuWaCTFv8L0AHgWIzzJ+Q55pB86keq3U\n+H+1H5yCR/qGPxTGXZadMSQpQkjANQ5dP2EhohUNV8EP8qk0wrZKESTa2x16j8YV\n0sZoIkgVUGXs71aZqj6114sjsC8pPXBw7KmOEaxUMS54yB4KGCYwvqC/qSxrocKS\nRRXMZshkJoGLDTLIx12DihZgplqV02E3h20yF6PGWXo2tedXp5mgz3vAVgV/8/Y+\n9rYQPtOR0qpGAUcYvyxsOtmjaVxo1x7b45utZdgyWXhXKFINhua5lp6ALNvVJUhQ\np985kO36ws7SlNep9eUPPRr3B1JKi0L5i9f8L2Nu0qBMcCepOOs=\n=xOwT\n-----END PGP SIGNATURE-----",
                    "payload": "tree 2213801b654a174b16f0b1446da848f301d2132d\nparent 9526541f51e0cb472fbad350a52b840f88c31004\nauthor hapihu <w.gh123@qq.com> 1625553837 +0800\ncommitter Jark Wu <jark@apache.org> 1625553869 +0800\n\n[FLINK-23259][docs] Fix the link for page \"docs/dev/datastream/operators/overview\" (#16381)\n\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/8ac80279d7d0d19af0d0bf2b7129ec7304c628eb",
            "html_url": "https://github.com/apache/flink/commit/8ac80279d7d0d19af0d0bf2b7129ec7304c628eb",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/8ac80279d7d0d19af0d0bf2b7129ec7304c628eb/comments",
            "author": {
                "login": "hapihu",
                "id": 20364527,
                "node_id": "MDQ6VXNlcjIwMzY0NTI3",
                "avatar_url": "https://avatars.githubusercontent.com/u/20364527?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/hapihu",
                "html_url": "https://github.com/hapihu",
                "followers_url": "https://api.github.com/users/hapihu/followers",
                "following_url": "https://api.github.com/users/hapihu/following{/other_user}",
                "gists_url": "https://api.github.com/users/hapihu/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/hapihu/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/hapihu/subscriptions",
                "organizations_url": "https://api.github.com/users/hapihu/orgs",
                "repos_url": "https://api.github.com/users/hapihu/repos",
                "events_url": "https://api.github.com/users/hapihu/events{/privacy}",
                "received_events_url": "https://api.github.com/users/hapihu/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "wuchong",
                "id": 5378924,
                "node_id": "MDQ6VXNlcjUzNzg5MjQ=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5378924?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/wuchong",
                "html_url": "https://github.com/wuchong",
                "followers_url": "https://api.github.com/users/wuchong/followers",
                "following_url": "https://api.github.com/users/wuchong/following{/other_user}",
                "gists_url": "https://api.github.com/users/wuchong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/wuchong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/wuchong/subscriptions",
                "organizations_url": "https://api.github.com/users/wuchong/orgs",
                "repos_url": "https://api.github.com/users/wuchong/repos",
                "events_url": "https://api.github.com/users/wuchong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/wuchong/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "9526541f51e0cb472fbad350a52b840f88c31004",
                "url": "https://api.github.com/repos/apache/flink/commits/9526541f51e0cb472fbad350a52b840f88c31004",
                "html_url": "https://github.com/apache/flink/commit/9526541f51e0cb472fbad350a52b840f88c31004"
            }]
        },
        {
            "sha": "9d77656381f55d05a3eb74c6c6c6de873de2b7c7",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6OWQ3NzY1NjM4MWY1NWQwNWEzZWI3NGM2YzZjNmRlODczZGUyYjdjNw==",
            "commit": {
                "author": {
                    "name": "Fabian Paul",
                    "email": "fabianpaul@ververica.com",
                    "date": "2021-07-05T08:59:48Z"
                },
                "committer": {
                    "name": "Arvid Heise",
                    "email": "AHeise@users.noreply.github.com",
                    "date": "2021-07-06T08:14:46Z"
                },
                "message": "[FLINK-23248][datastream] Close SinkWriter when calling dispose\n\nWithout this change the SinkWriter was only closed\nwhen the operator finishes and not during failing.\nNow, the SinkWriter is closed on dispose which is\ncalled on finish and on failure.",
                "tree": {
                    "sha": "8c5780b863e1cbc28ec4dbcb492b32bb9a38dde9",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/8c5780b863e1cbc28ec4dbcb492b32bb9a38dde9"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/9d77656381f55d05a3eb74c6c6c6de873de2b7c7",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/9d77656381f55d05a3eb74c6c6c6de873de2b7c7",
            "html_url": "https://github.com/apache/flink/commit/9d77656381f55d05a3eb74c6c6c6de873de2b7c7",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/9d77656381f55d05a3eb74c6c6c6de873de2b7c7/comments",
            "author": {
                "login": "fapaul",
                "id": 7405553,
                "node_id": "MDQ6VXNlcjc0MDU1NTM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/7405553?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/fapaul",
                "html_url": "https://github.com/fapaul",
                "followers_url": "https://api.github.com/users/fapaul/followers",
                "following_url": "https://api.github.com/users/fapaul/following{/other_user}",
                "gists_url": "https://api.github.com/users/fapaul/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/fapaul/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/fapaul/subscriptions",
                "organizations_url": "https://api.github.com/users/fapaul/orgs",
                "repos_url": "https://api.github.com/users/fapaul/repos",
                "events_url": "https://api.github.com/users/fapaul/events{/privacy}",
                "received_events_url": "https://api.github.com/users/fapaul/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "AHeise",
                "id": 4559103,
                "node_id": "MDQ6VXNlcjQ1NTkxMDM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/4559103?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/AHeise",
                "html_url": "https://github.com/AHeise",
                "followers_url": "https://api.github.com/users/AHeise/followers",
                "following_url": "https://api.github.com/users/AHeise/following{/other_user}",
                "gists_url": "https://api.github.com/users/AHeise/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/AHeise/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/AHeise/subscriptions",
                "organizations_url": "https://api.github.com/users/AHeise/orgs",
                "repos_url": "https://api.github.com/users/AHeise/repos",
                "events_url": "https://api.github.com/users/AHeise/events{/privacy}",
                "received_events_url": "https://api.github.com/users/AHeise/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "8ac80279d7d0d19af0d0bf2b7129ec7304c628eb",
                "url": "https://api.github.com/repos/apache/flink/commits/8ac80279d7d0d19af0d0bf2b7129ec7304c628eb",
                "html_url": "https://github.com/apache/flink/commit/8ac80279d7d0d19af0d0bf2b7129ec7304c628eb"
            }]
        },
        {
            "sha": "ca7955a691c6dbf4102b499ed73e452a30650620",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6Y2E3OTU1YTY5MWM2ZGJmNDEwMmI0OTllZDczZTQ1MmEzMDY1MDYyMA==",
            "commit": {
                "author": {
                    "name": "fangliang",
                    "email": "568693125@qq.com",
                    "date": "2021-07-06T13:56:21Z"
                },
                "committer": {
                    "name": "Jark Wu",
                    "email": "jark@apache.org",
                    "date": "2021-07-06T13:56:54Z"
                },
                "message": "[FLINK-23270][docs][table] Impove description of Regular Joins section (#16392)\n\nCo-authored-by: liufangliang <tanghao@xiaohongshu.com>",
                "tree": {
                    "sha": "3962ac1d938a81cbcb5d310c715e313d06ba1126",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/3962ac1d938a81cbcb5d310c715e313d06ba1126"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/ca7955a691c6dbf4102b499ed73e452a30650620",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEE4sRUF77VwQQVTzQQhbrLWu+uMgIFAmDkYSYACgkQhbrLWu+u\nMgKazhAAk231/Gurtsm0uKEk+zfWpImBBrsiX5vgnjG77elRy/GMkrTlD/7t9CO5\ngdw1jQCRjyStlGayiDOYoB93Pwr6Ld1YYHdV5jKpZ4jL31W11sqClDwFuKx5CO6a\nyD097eAtraJsq1i4uZfBcPH2ZsGdnzJ7xClrHegHgWPzF9HWMoHaegDjpHZshnne\ny0w0zckiXmZt6dGauLOE/WZ1tzbJeuak1kGoXjBfZa7C12IqFV3XKL85eED8o2wS\nByMIz8pH538bbs1kiqNpDxnQ4JDHWXb/AIctgALAMUNB4upCHMfI0VahXPr71nE+\nbeVw2ZXDGzTWM/wYTyrpm5B9GFhQB5oUqqPkkV18fC9nAVEm/HMKDMZKKbcd+mgj\npa+Yi0Y32dxkWkjBXN6wXny2bfk6a5LIHgjA6PSCpAgWS+ggCySWWvTp0PKB+yTa\nQiCHceX0nfwVhQ5IrNUgz1wsTwEgnAlanLDZyQHkOeMEGy0SB/LKUjoD3ygrzZg6\na8+JhCRXhEijySh60qGYENW0lv/u1vY0JNvTg1SSBwxerURUtwrhoOxYhxnHjB5b\nWKiI+vzNQRVB7xiWa77o26QddlivHiqZQhyEp2jlB5jfUnkDjUd+hvZGLFHVPcBd\nr+9sekyNGZwW0m1b/0RWgEJ5VqdBX4IXqqEk/+++W8WgPusvAiM=\n=UzD2\n-----END PGP SIGNATURE-----",
                    "payload": "tree 3962ac1d938a81cbcb5d310c715e313d06ba1126\nparent 9d77656381f55d05a3eb74c6c6c6de873de2b7c7\nauthor fangliang <568693125@qq.com> 1625579781 +0800\ncommitter Jark Wu <jark@apache.org> 1625579814 +0800\n\n[FLINK-23270][docs][table] Impove description of Regular Joins section (#16392)\n\nCo-authored-by: liufangliang <tanghao@xiaohongshu.com>"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/ca7955a691c6dbf4102b499ed73e452a30650620",
            "html_url": "https://github.com/apache/flink/commit/ca7955a691c6dbf4102b499ed73e452a30650620",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/ca7955a691c6dbf4102b499ed73e452a30650620/comments",
            "author": {
                "login": "pyscala",
                "id": 20840332,
                "node_id": "MDQ6VXNlcjIwODQwMzMy",
                "avatar_url": "https://avatars.githubusercontent.com/u/20840332?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/pyscala",
                "html_url": "https://github.com/pyscala",
                "followers_url": "https://api.github.com/users/pyscala/followers",
                "following_url": "https://api.github.com/users/pyscala/following{/other_user}",
                "gists_url": "https://api.github.com/users/pyscala/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/pyscala/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/pyscala/subscriptions",
                "organizations_url": "https://api.github.com/users/pyscala/orgs",
                "repos_url": "https://api.github.com/users/pyscala/repos",
                "events_url": "https://api.github.com/users/pyscala/events{/privacy}",
                "received_events_url": "https://api.github.com/users/pyscala/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "wuchong",
                "id": 5378924,
                "node_id": "MDQ6VXNlcjUzNzg5MjQ=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5378924?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/wuchong",
                "html_url": "https://github.com/wuchong",
                "followers_url": "https://api.github.com/users/wuchong/followers",
                "following_url": "https://api.github.com/users/wuchong/following{/other_user}",
                "gists_url": "https://api.github.com/users/wuchong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/wuchong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/wuchong/subscriptions",
                "organizations_url": "https://api.github.com/users/wuchong/orgs",
                "repos_url": "https://api.github.com/users/wuchong/repos",
                "events_url": "https://api.github.com/users/wuchong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/wuchong/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "9d77656381f55d05a3eb74c6c6c6de873de2b7c7",
                "url": "https://api.github.com/repos/apache/flink/commits/9d77656381f55d05a3eb74c6c6c6de873de2b7c7",
                "html_url": "https://github.com/apache/flink/commit/9d77656381f55d05a3eb74c6c6c6de873de2b7c7"
            }]
        },
        {
            "sha": "0be246bb4baefaea0f6ad903f6a13687278c6b33",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MGJlMjQ2YmI0YmFlZmFlYTBmNmFkOTAzZjZhMTM2ODcyNzhjNmIzMw==",
            "commit": {
                "author": {
                    "name": "sv3ndk",
                    "email": "svend.vanderveken@gmail.com",
                    "date": "2021-07-03T06:08:19Z"
                },
                "committer": {
                    "name": "Seth Wiesman",
                    "email": "sjwiesman@gmail.com",
                    "date": "2021-07-06T14:17:31Z"
                },
                "message": "[FLINK-22996][docs] fix documentation of COALESCE\n\nThis fixes #16362",
                "tree": {
                    "sha": "2993ecbe44c0124af5071b11fc8c6e9f03db1ddc",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/2993ecbe44c0124af5071b11fc8c6e9f03db1ddc"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/0be246bb4baefaea0f6ad903f6a13687278c6b33",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/0be246bb4baefaea0f6ad903f6a13687278c6b33",
            "html_url": "https://github.com/apache/flink/commit/0be246bb4baefaea0f6ad903f6a13687278c6b33",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/0be246bb4baefaea0f6ad903f6a13687278c6b33/comments",
            "author": {
                "login": "sv3ndk",
                "id": 1214071,
                "node_id": "MDQ6VXNlcjEyMTQwNzE=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1214071?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/sv3ndk",
                "html_url": "https://github.com/sv3ndk",
                "followers_url": "https://api.github.com/users/sv3ndk/followers",
                "following_url": "https://api.github.com/users/sv3ndk/following{/other_user}",
                "gists_url": "https://api.github.com/users/sv3ndk/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/sv3ndk/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/sv3ndk/subscriptions",
                "organizations_url": "https://api.github.com/users/sv3ndk/orgs",
                "repos_url": "https://api.github.com/users/sv3ndk/repos",
                "events_url": "https://api.github.com/users/sv3ndk/events{/privacy}",
                "received_events_url": "https://api.github.com/users/sv3ndk/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "sjwiesman",
                "id": 1891970,
                "node_id": "MDQ6VXNlcjE4OTE5NzA=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1891970?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/sjwiesman",
                "html_url": "https://github.com/sjwiesman",
                "followers_url": "https://api.github.com/users/sjwiesman/followers",
                "following_url": "https://api.github.com/users/sjwiesman/following{/other_user}",
                "gists_url": "https://api.github.com/users/sjwiesman/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/sjwiesman/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/sjwiesman/subscriptions",
                "organizations_url": "https://api.github.com/users/sjwiesman/orgs",
                "repos_url": "https://api.github.com/users/sjwiesman/repos",
                "events_url": "https://api.github.com/users/sjwiesman/events{/privacy}",
                "received_events_url": "https://api.github.com/users/sjwiesman/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "ca7955a691c6dbf4102b499ed73e452a30650620",
                "url": "https://api.github.com/repos/apache/flink/commits/ca7955a691c6dbf4102b499ed73e452a30650620",
                "html_url": "https://github.com/apache/flink/commit/ca7955a691c6dbf4102b499ed73e452a30650620"
            }]
        },
        {
            "sha": "4ccf970cfc1d0d4e929b356fe24bca5d90d9ceea",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NGNjZjk3MGNmYzFkMGQ0ZTkyOWIzNTZmZTI0YmNhNWQ5MGQ5Y2VlYQ==",
            "commit": {
                "author": {
                    "name": "Yik San Chan",
                    "email": "evan.chanyiksan@gmail.com",
                    "date": "2021-07-06T09:32:32Z"
                },
                "committer": {
                    "name": "Seth Wiesman",
                    "email": "sjwiesman@gmail.com",
                    "date": "2021-07-06T14:20:59Z"
                },
                "message": "[hotfix][docs] Fix code snippet with incorrect scala syntax\n\nThis closes #16391",
                "tree": {
                    "sha": "32ae0f153631af9aed9e3a7ff9c5e2afbca2d7e9",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/32ae0f153631af9aed9e3a7ff9c5e2afbca2d7e9"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/4ccf970cfc1d0d4e929b356fe24bca5d90d9ceea",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/4ccf970cfc1d0d4e929b356fe24bca5d90d9ceea",
            "html_url": "https://github.com/apache/flink/commit/4ccf970cfc1d0d4e929b356fe24bca5d90d9ceea",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/4ccf970cfc1d0d4e929b356fe24bca5d90d9ceea/comments",
            "author": {
                "login": "YikSanChan",
                "id": 17229109,
                "node_id": "MDQ6VXNlcjE3MjI5MTA5",
                "avatar_url": "https://avatars.githubusercontent.com/u/17229109?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/YikSanChan",
                "html_url": "https://github.com/YikSanChan",
                "followers_url": "https://api.github.com/users/YikSanChan/followers",
                "following_url": "https://api.github.com/users/YikSanChan/following{/other_user}",
                "gists_url": "https://api.github.com/users/YikSanChan/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/YikSanChan/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/YikSanChan/subscriptions",
                "organizations_url": "https://api.github.com/users/YikSanChan/orgs",
                "repos_url": "https://api.github.com/users/YikSanChan/repos",
                "events_url": "https://api.github.com/users/YikSanChan/events{/privacy}",
                "received_events_url": "https://api.github.com/users/YikSanChan/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "sjwiesman",
                "id": 1891970,
                "node_id": "MDQ6VXNlcjE4OTE5NzA=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1891970?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/sjwiesman",
                "html_url": "https://github.com/sjwiesman",
                "followers_url": "https://api.github.com/users/sjwiesman/followers",
                "following_url": "https://api.github.com/users/sjwiesman/following{/other_user}",
                "gists_url": "https://api.github.com/users/sjwiesman/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/sjwiesman/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/sjwiesman/subscriptions",
                "organizations_url": "https://api.github.com/users/sjwiesman/orgs",
                "repos_url": "https://api.github.com/users/sjwiesman/repos",
                "events_url": "https://api.github.com/users/sjwiesman/events{/privacy}",
                "received_events_url": "https://api.github.com/users/sjwiesman/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "0be246bb4baefaea0f6ad903f6a13687278c6b33",
                "url": "https://api.github.com/repos/apache/flink/commits/0be246bb4baefaea0f6ad903f6a13687278c6b33",
                "html_url": "https://github.com/apache/flink/commit/0be246bb4baefaea0f6ad903f6a13687278c6b33"
            }]
        },
        {
            "sha": "2c24525392685426a8c637ed77002d71ea2a4b78",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MmMyNDUyNTM5MjY4NTQyNmE4YzYzN2VkNzcwMDJkNzFlYTJhNGI3OA==",
            "commit": {
                "author": {
                    "name": "Yik San Chan",
                    "email": "evan.chanyiksan@gmail.com",
                    "date": "2021-07-06T09:25:45Z"
                },
                "committer": {
                    "name": "Seth Wiesman",
                    "email": "sjwiesman@gmail.com",
                    "date": "2021-07-06T14:25:08Z"
                },
                "message": "[hotfix][docs] fix typo in SQL functions\n\nThis closes #16390",
                "tree": {
                    "sha": "6548333f616ac1016769836787d14d2d036e3ac3",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/6548333f616ac1016769836787d14d2d036e3ac3"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/2c24525392685426a8c637ed77002d71ea2a4b78",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/2c24525392685426a8c637ed77002d71ea2a4b78",
            "html_url": "https://github.com/apache/flink/commit/2c24525392685426a8c637ed77002d71ea2a4b78",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/2c24525392685426a8c637ed77002d71ea2a4b78/comments",
            "author": {
                "login": "YikSanChan",
                "id": 17229109,
                "node_id": "MDQ6VXNlcjE3MjI5MTA5",
                "avatar_url": "https://avatars.githubusercontent.com/u/17229109?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/YikSanChan",
                "html_url": "https://github.com/YikSanChan",
                "followers_url": "https://api.github.com/users/YikSanChan/followers",
                "following_url": "https://api.github.com/users/YikSanChan/following{/other_user}",
                "gists_url": "https://api.github.com/users/YikSanChan/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/YikSanChan/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/YikSanChan/subscriptions",
                "organizations_url": "https://api.github.com/users/YikSanChan/orgs",
                "repos_url": "https://api.github.com/users/YikSanChan/repos",
                "events_url": "https://api.github.com/users/YikSanChan/events{/privacy}",
                "received_events_url": "https://api.github.com/users/YikSanChan/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "sjwiesman",
                "id": 1891970,
                "node_id": "MDQ6VXNlcjE4OTE5NzA=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1891970?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/sjwiesman",
                "html_url": "https://github.com/sjwiesman",
                "followers_url": "https://api.github.com/users/sjwiesman/followers",
                "following_url": "https://api.github.com/users/sjwiesman/following{/other_user}",
                "gists_url": "https://api.github.com/users/sjwiesman/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/sjwiesman/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/sjwiesman/subscriptions",
                "organizations_url": "https://api.github.com/users/sjwiesman/orgs",
                "repos_url": "https://api.github.com/users/sjwiesman/repos",
                "events_url": "https://api.github.com/users/sjwiesman/events{/privacy}",
                "received_events_url": "https://api.github.com/users/sjwiesman/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "4ccf970cfc1d0d4e929b356fe24bca5d90d9ceea",
                "url": "https://api.github.com/repos/apache/flink/commits/4ccf970cfc1d0d4e929b356fe24bca5d90d9ceea",
                "html_url": "https://github.com/apache/flink/commit/4ccf970cfc1d0d4e929b356fe24bca5d90d9ceea"
            }]
        },
        {
            "sha": "c830bde767c8080509f24fc688350cff0eb9f3ed",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6YzgzMGJkZTc2N2M4MDgwNTA5ZjI0ZmM2ODgzNTBjZmYwZWI5ZjNlZA==",
            "commit": {
                "author": {
                    "name": "Michal Ciesielczyk",
                    "email": "michal.ciesielczyk@deep.bi",
                    "date": "2021-06-29T22:23:42Z"
                },
                "committer": {
                    "name": "Arvid Heise",
                    "email": "AHeise@users.noreply.github.com",
                    "date": "2021-07-06T16:45:08Z"
                },
                "message": "[FLINK-23182][connectors/rabbitmq] Fix connection leak in RMQSource",
                "tree": {
                    "sha": "b1b2749f9df8c8fb5ab8f51d41e2eb247f4e882f",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/b1b2749f9df8c8fb5ab8f51d41e2eb247f4e882f"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/c830bde767c8080509f24fc688350cff0eb9f3ed",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/c830bde767c8080509f24fc688350cff0eb9f3ed",
            "html_url": "https://github.com/apache/flink/commit/c830bde767c8080509f24fc688350cff0eb9f3ed",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/c830bde767c8080509f24fc688350cff0eb9f3ed/comments",
            "author": {
                "login": "cmick",
                "id": 2039722,
                "node_id": "MDQ6VXNlcjIwMzk3MjI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/2039722?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/cmick",
                "html_url": "https://github.com/cmick",
                "followers_url": "https://api.github.com/users/cmick/followers",
                "following_url": "https://api.github.com/users/cmick/following{/other_user}",
                "gists_url": "https://api.github.com/users/cmick/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/cmick/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/cmick/subscriptions",
                "organizations_url": "https://api.github.com/users/cmick/orgs",
                "repos_url": "https://api.github.com/users/cmick/repos",
                "events_url": "https://api.github.com/users/cmick/events{/privacy}",
                "received_events_url": "https://api.github.com/users/cmick/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "AHeise",
                "id": 4559103,
                "node_id": "MDQ6VXNlcjQ1NTkxMDM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/4559103?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/AHeise",
                "html_url": "https://github.com/AHeise",
                "followers_url": "https://api.github.com/users/AHeise/followers",
                "following_url": "https://api.github.com/users/AHeise/following{/other_user}",
                "gists_url": "https://api.github.com/users/AHeise/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/AHeise/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/AHeise/subscriptions",
                "organizations_url": "https://api.github.com/users/AHeise/orgs",
                "repos_url": "https://api.github.com/users/AHeise/repos",
                "events_url": "https://api.github.com/users/AHeise/events{/privacy}",
                "received_events_url": "https://api.github.com/users/AHeise/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "2c24525392685426a8c637ed77002d71ea2a4b78",
                "url": "https://api.github.com/repos/apache/flink/commits/2c24525392685426a8c637ed77002d71ea2a4b78",
                "html_url": "https://github.com/apache/flink/commit/2c24525392685426a8c637ed77002d71ea2a4b78"
            }]
        },
        {
            "sha": "79019bc1196fb65a04f7533d6abc3776a4dcb652",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NzkwMTliYzExOTZmYjY1YTA0Zjc1MzNkNmFiYzM3NzZhNGRjYjY1Mg==",
            "commit": {
                "author": {
                    "name": "SteNicholas",
                    "email": "programgeek@163.com",
                    "date": "2021-07-07T05:10:08Z"
                },
                "committer": {
                    "name": "huangxingbo",
                    "email": "hxbks2ks@gmail.com",
                    "date": "2021-07-07T12:44:16Z"
                },
                "message": "[FLINK-23280][python] Fix the issue that Python ExplainDetails does not have JSON_EXECUTION_PLAN option\n\nThis closes #16407.",
                "tree": {
                    "sha": "f6c7d8856147781040c59a4e9a758958be73c9f6",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/f6c7d8856147781040c59a4e9a758958be73c9f6"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/79019bc1196fb65a04f7533d6abc3776a4dcb652",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/79019bc1196fb65a04f7533d6abc3776a4dcb652",
            "html_url": "https://github.com/apache/flink/commit/79019bc1196fb65a04f7533d6abc3776a4dcb652",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/79019bc1196fb65a04f7533d6abc3776a4dcb652/comments",
            "author": {
                "login": "SteNicholas",
                "id": 10048174,
                "node_id": "MDQ6VXNlcjEwMDQ4MTc0",
                "avatar_url": "https://avatars.githubusercontent.com/u/10048174?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/SteNicholas",
                "html_url": "https://github.com/SteNicholas",
                "followers_url": "https://api.github.com/users/SteNicholas/followers",
                "following_url": "https://api.github.com/users/SteNicholas/following{/other_user}",
                "gists_url": "https://api.github.com/users/SteNicholas/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/SteNicholas/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/SteNicholas/subscriptions",
                "organizations_url": "https://api.github.com/users/SteNicholas/orgs",
                "repos_url": "https://api.github.com/users/SteNicholas/repos",
                "events_url": "https://api.github.com/users/SteNicholas/events{/privacy}",
                "received_events_url": "https://api.github.com/users/SteNicholas/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "HuangXingBo",
                "id": 8536293,
                "node_id": "MDQ6VXNlcjg1MzYyOTM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8536293?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/HuangXingBo",
                "html_url": "https://github.com/HuangXingBo",
                "followers_url": "https://api.github.com/users/HuangXingBo/followers",
                "following_url": "https://api.github.com/users/HuangXingBo/following{/other_user}",
                "gists_url": "https://api.github.com/users/HuangXingBo/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/HuangXingBo/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/HuangXingBo/subscriptions",
                "organizations_url": "https://api.github.com/users/HuangXingBo/orgs",
                "repos_url": "https://api.github.com/users/HuangXingBo/repos",
                "events_url": "https://api.github.com/users/HuangXingBo/events{/privacy}",
                "received_events_url": "https://api.github.com/users/HuangXingBo/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "c830bde767c8080509f24fc688350cff0eb9f3ed",
                "url": "https://api.github.com/repos/apache/flink/commits/c830bde767c8080509f24fc688350cff0eb9f3ed",
                "html_url": "https://github.com/apache/flink/commit/c830bde767c8080509f24fc688350cff0eb9f3ed"
            }]
        },
        {
            "sha": "97101390755639f0f014794f726a25136637ee58",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6OTcxMDEzOTA3NTU2MzlmMGYwMTQ3OTRmNzI2YTI1MTM2NjM3ZWU1OA==",
            "commit": {
                "author": {
                    "name": "Roc Marshal",
                    "email": "flinker@126.com",
                    "date": "2021-07-01T10:36:04Z"
                },
                "committer": {
                    "name": "Seth Wiesman",
                    "email": "sjwiesman@gmail.com",
                    "date": "2021-07-07T16:02:47Z"
                },
                "message": "[hotfix][docs] Fixed errors references for  'site.scala version suffix' and 'site.version'\n\nThis closes #16340",
                "tree": {
                    "sha": "750ac301bdc5a0bd085cd9335c6dfc1dc2724d56",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/750ac301bdc5a0bd085cd9335c6dfc1dc2724d56"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/97101390755639f0f014794f726a25136637ee58",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/97101390755639f0f014794f726a25136637ee58",
            "html_url": "https://github.com/apache/flink/commit/97101390755639f0f014794f726a25136637ee58",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/97101390755639f0f014794f726a25136637ee58/comments",
            "author": {
                "login": "RocMarshal",
                "id": 64569824,
                "node_id": "MDQ6VXNlcjY0NTY5ODI0",
                "avatar_url": "https://avatars.githubusercontent.com/u/64569824?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/RocMarshal",
                "html_url": "https://github.com/RocMarshal",
                "followers_url": "https://api.github.com/users/RocMarshal/followers",
                "following_url": "https://api.github.com/users/RocMarshal/following{/other_user}",
                "gists_url": "https://api.github.com/users/RocMarshal/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/RocMarshal/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/RocMarshal/subscriptions",
                "organizations_url": "https://api.github.com/users/RocMarshal/orgs",
                "repos_url": "https://api.github.com/users/RocMarshal/repos",
                "events_url": "https://api.github.com/users/RocMarshal/events{/privacy}",
                "received_events_url": "https://api.github.com/users/RocMarshal/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "sjwiesman",
                "id": 1891970,
                "node_id": "MDQ6VXNlcjE4OTE5NzA=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1891970?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/sjwiesman",
                "html_url": "https://github.com/sjwiesman",
                "followers_url": "https://api.github.com/users/sjwiesman/followers",
                "following_url": "https://api.github.com/users/sjwiesman/following{/other_user}",
                "gists_url": "https://api.github.com/users/sjwiesman/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/sjwiesman/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/sjwiesman/subscriptions",
                "organizations_url": "https://api.github.com/users/sjwiesman/orgs",
                "repos_url": "https://api.github.com/users/sjwiesman/repos",
                "events_url": "https://api.github.com/users/sjwiesman/events{/privacy}",
                "received_events_url": "https://api.github.com/users/sjwiesman/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "79019bc1196fb65a04f7533d6abc3776a4dcb652",
                "url": "https://api.github.com/repos/apache/flink/commits/79019bc1196fb65a04f7533d6abc3776a4dcb652",
                "html_url": "https://github.com/apache/flink/commit/79019bc1196fb65a04f7533d6abc3776a4dcb652"
            }]
        },
        {
            "sha": "848d4baf7054781de82d731d6ed60bb10d44d8e0",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ODQ4ZDRiYWY3MDU0NzgxZGU4MmQ3MzFkNmVkNjBiYjEwZDQ0ZDhlMA==",
            "commit": {
                "author": {
                    "name": "Matthias Pohl",
                    "email": "matthias@ververica.com",
                    "date": "2021-07-06T07:29:47Z"
                },
                "committer": {
                    "name": "Chesnay Schepler",
                    "email": "chesnay@apache.org",
                    "date": "2021-07-07T18:27:44Z"
                },
                "message": "[FLINK-21445][clients] Adds configuration to ClassPathPackagedProgramRetriever",
                "tree": {
                    "sha": "49a4c0db0b265f7e2852a2569560507f886730cf",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/49a4c0db0b265f7e2852a2569560507f886730cf"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/848d4baf7054781de82d731d6ed60bb10d44d8e0",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/848d4baf7054781de82d731d6ed60bb10d44d8e0",
            "html_url": "https://github.com/apache/flink/commit/848d4baf7054781de82d731d6ed60bb10d44d8e0",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/848d4baf7054781de82d731d6ed60bb10d44d8e0/comments",
            "author": {
                "login": "XComp",
                "id": 1101012,
                "node_id": "MDQ6VXNlcjExMDEwMTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1101012?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/XComp",
                "html_url": "https://github.com/XComp",
                "followers_url": "https://api.github.com/users/XComp/followers",
                "following_url": "https://api.github.com/users/XComp/following{/other_user}",
                "gists_url": "https://api.github.com/users/XComp/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/XComp/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/XComp/subscriptions",
                "organizations_url": "https://api.github.com/users/XComp/orgs",
                "repos_url": "https://api.github.com/users/XComp/repos",
                "events_url": "https://api.github.com/users/XComp/events{/privacy}",
                "received_events_url": "https://api.github.com/users/XComp/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "zentol",
                "id": 5725237,
                "node_id": "MDQ6VXNlcjU3MjUyMzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5725237?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/zentol",
                "html_url": "https://github.com/zentol",
                "followers_url": "https://api.github.com/users/zentol/followers",
                "following_url": "https://api.github.com/users/zentol/following{/other_user}",
                "gists_url": "https://api.github.com/users/zentol/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/zentol/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/zentol/subscriptions",
                "organizations_url": "https://api.github.com/users/zentol/orgs",
                "repos_url": "https://api.github.com/users/zentol/repos",
                "events_url": "https://api.github.com/users/zentol/events{/privacy}",
                "received_events_url": "https://api.github.com/users/zentol/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "97101390755639f0f014794f726a25136637ee58",
                "url": "https://api.github.com/repos/apache/flink/commits/97101390755639f0f014794f726a25136637ee58",
                "html_url": "https://github.com/apache/flink/commit/97101390755639f0f014794f726a25136637ee58"
            }]
        },
        {
            "sha": "3909c9f0a11e8b38b264db9e7716fb41e75cc524",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MzkwOWM5ZjBhMTFlOGIzOGIyNjRkYjllNzcxNmZiNDFlNzVjYzUyNA==",
            "commit": {
                "author": {
                    "name": "Roman Khachatryan",
                    "email": "khachatryan.roman@gmail.com",
                    "date": "2021-07-06T20:34:11Z"
                },
                "committer": {
                    "name": "Roman Khachatryan",
                    "email": "khachatryan.roman@gmail.com",
                    "date": "2021-07-07T21:31:37Z"
                },
                "message": "[FLINK-22889] Add debug statements to JdbcExactlyOnceSinkE2eTest",
                "tree": {
                    "sha": "2f359b5baecb7cd56555fa5e87a3aff0659ed8b7",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/2f359b5baecb7cd56555fa5e87a3aff0659ed8b7"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/3909c9f0a11e8b38b264db9e7716fb41e75cc524",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/3909c9f0a11e8b38b264db9e7716fb41e75cc524",
            "html_url": "https://github.com/apache/flink/commit/3909c9f0a11e8b38b264db9e7716fb41e75cc524",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/3909c9f0a11e8b38b264db9e7716fb41e75cc524/comments",
            "author": {
                "login": "rkhachatryan",
                "id": 3939322,
                "node_id": "MDQ6VXNlcjM5MzkzMjI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3939322?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rkhachatryan",
                "html_url": "https://github.com/rkhachatryan",
                "followers_url": "https://api.github.com/users/rkhachatryan/followers",
                "following_url": "https://api.github.com/users/rkhachatryan/following{/other_user}",
                "gists_url": "https://api.github.com/users/rkhachatryan/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rkhachatryan/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rkhachatryan/subscriptions",
                "organizations_url": "https://api.github.com/users/rkhachatryan/orgs",
                "repos_url": "https://api.github.com/users/rkhachatryan/repos",
                "events_url": "https://api.github.com/users/rkhachatryan/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rkhachatryan/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "rkhachatryan",
                "id": 3939322,
                "node_id": "MDQ6VXNlcjM5MzkzMjI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3939322?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rkhachatryan",
                "html_url": "https://github.com/rkhachatryan",
                "followers_url": "https://api.github.com/users/rkhachatryan/followers",
                "following_url": "https://api.github.com/users/rkhachatryan/following{/other_user}",
                "gists_url": "https://api.github.com/users/rkhachatryan/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rkhachatryan/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rkhachatryan/subscriptions",
                "organizations_url": "https://api.github.com/users/rkhachatryan/orgs",
                "repos_url": "https://api.github.com/users/rkhachatryan/repos",
                "events_url": "https://api.github.com/users/rkhachatryan/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rkhachatryan/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "848d4baf7054781de82d731d6ed60bb10d44d8e0",
                "url": "https://api.github.com/repos/apache/flink/commits/848d4baf7054781de82d731d6ed60bb10d44d8e0",
                "html_url": "https://github.com/apache/flink/commit/848d4baf7054781de82d731d6ed60bb10d44d8e0"
            }]
        },
        {
            "sha": "447452d0cdbec9a6d97e96dcb89977e52c27750e",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NDQ3NDUyZDBjZGJlYzlhNmQ5N2U5NmRjYjg5OTc3ZTUyYzI3NzUwZQ==",
            "commit": {
                "author": {
                    "name": "TsReaper",
                    "email": "tsreaper96@gmail.com",
                    "date": "2021-07-08T02:23:59Z"
                },
                "committer": {
                    "name": "GitHub",
                    "email": "noreply@github.com",
                    "date": "2021-07-08T02:23:59Z"
                },
                "message": "[FLINK-23184][table-runtime] Fix compile error in code generation of unary plus and minus\n\nThis closes #16411",
                "tree": {
                    "sha": "27d797cf9304b24f62afc6e778773ef35155a329",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/27d797cf9304b24f62afc6e778773ef35155a329"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/447452d0cdbec9a6d97e96dcb89977e52c27750e",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJg5mG/CRBK7hj4Ov3rIwAAthYIAJn8yyER6/zfcwruez52i21d\n3uNYKDFsHBWIh/D5P1LEhVTjba5q6ZdQupchyJ7Vxcd489pvoIsmPzFeBu21Xd69\nX7tjHPyAcoI9ek6tV0OTbbGm4Vc9K8IHmpx1ZE2nrqOXPbQU0+rP9hWsKIcanF+J\n6HQud8c4iPdL2acxw0VE2GpvlfM3CyWWzS+HZJf55qFgxkaogx+1bZ67ejoBBfeK\ncQXPSgrmjCWJvPOpKBQDGFZE+CcNCBp+1X+nNwSwKEcX/6tskJlYm0p+bnSFIuEV\nY/y1m5V+JskEj7DhfDSB1Z3ShOTagoUQiJj3FVGUPCzQgYaf1M8hkOTs1ybDWMk=\n=BPfZ\n-----END PGP SIGNATURE-----\n",
                    "payload": "tree 27d797cf9304b24f62afc6e778773ef35155a329\nparent 3909c9f0a11e8b38b264db9e7716fb41e75cc524\nauthor TsReaper <tsreaper96@gmail.com> 1625711039 +0800\ncommitter GitHub <noreply@github.com> 1625711039 +0800\n\n[FLINK-23184][table-runtime] Fix compile error in code generation of unary plus and minus\n\nThis closes #16411"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/447452d0cdbec9a6d97e96dcb89977e52c27750e",
            "html_url": "https://github.com/apache/flink/commit/447452d0cdbec9a6d97e96dcb89977e52c27750e",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/447452d0cdbec9a6d97e96dcb89977e52c27750e/comments",
            "author": {
                "login": "tsreaper",
                "id": 19909549,
                "node_id": "MDQ6VXNlcjE5OTA5NTQ5",
                "avatar_url": "https://avatars.githubusercontent.com/u/19909549?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tsreaper",
                "html_url": "https://github.com/tsreaper",
                "followers_url": "https://api.github.com/users/tsreaper/followers",
                "following_url": "https://api.github.com/users/tsreaper/following{/other_user}",
                "gists_url": "https://api.github.com/users/tsreaper/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tsreaper/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tsreaper/subscriptions",
                "organizations_url": "https://api.github.com/users/tsreaper/orgs",
                "repos_url": "https://api.github.com/users/tsreaper/repos",
                "events_url": "https://api.github.com/users/tsreaper/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tsreaper/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "web-flow",
                "id": 19864447,
                "node_id": "MDQ6VXNlcjE5ODY0NDQ3",
                "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/web-flow",
                "html_url": "https://github.com/web-flow",
                "followers_url": "https://api.github.com/users/web-flow/followers",
                "following_url": "https://api.github.com/users/web-flow/following{/other_user}",
                "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions",
                "organizations_url": "https://api.github.com/users/web-flow/orgs",
                "repos_url": "https://api.github.com/users/web-flow/repos",
                "events_url": "https://api.github.com/users/web-flow/events{/privacy}",
                "received_events_url": "https://api.github.com/users/web-flow/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "3909c9f0a11e8b38b264db9e7716fb41e75cc524",
                "url": "https://api.github.com/repos/apache/flink/commits/3909c9f0a11e8b38b264db9e7716fb41e75cc524",
                "html_url": "https://github.com/apache/flink/commit/3909c9f0a11e8b38b264db9e7716fb41e75cc524"
            }]
        },
        {
            "sha": "f14307b869e1e9b518784276311ce6afb112312d",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZjE0MzA3Yjg2OWUxZTliNTE4Nzg0Mjc2MzExY2U2YWZiMTEyMzEyZA==",
            "commit": {
                "author": {
                    "name": "Rui Li",
                    "email": "lirui@apache.org",
                    "date": "2021-07-05T07:31:30Z"
                },
                "committer": {
                    "name": "Rui Li",
                    "email": "lirui@apache.org",
                    "date": "2021-07-08T03:49:10Z"
                },
                "message": "[FLINK-23178][hive] Raise an error for writing stream data into partitioned hive tables without a partition committer\n\nThis closes #16370",
                "tree": {
                    "sha": "e57af79a84be9d385e477329232d5db5f005e301",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/e57af79a84be9d385e477329232d5db5f005e301"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/f14307b869e1e9b518784276311ce6afb112312d",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/f14307b869e1e9b518784276311ce6afb112312d",
            "html_url": "https://github.com/apache/flink/commit/f14307b869e1e9b518784276311ce6afb112312d",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/f14307b869e1e9b518784276311ce6afb112312d/comments",
            "author": {
                "login": "lirui-apache",
                "id": 5210788,
                "node_id": "MDQ6VXNlcjUyMTA3ODg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5210788?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/lirui-apache",
                "html_url": "https://github.com/lirui-apache",
                "followers_url": "https://api.github.com/users/lirui-apache/followers",
                "following_url": "https://api.github.com/users/lirui-apache/following{/other_user}",
                "gists_url": "https://api.github.com/users/lirui-apache/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/lirui-apache/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/lirui-apache/subscriptions",
                "organizations_url": "https://api.github.com/users/lirui-apache/orgs",
                "repos_url": "https://api.github.com/users/lirui-apache/repos",
                "events_url": "https://api.github.com/users/lirui-apache/events{/privacy}",
                "received_events_url": "https://api.github.com/users/lirui-apache/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "lirui-apache",
                "id": 5210788,
                "node_id": "MDQ6VXNlcjUyMTA3ODg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5210788?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/lirui-apache",
                "html_url": "https://github.com/lirui-apache",
                "followers_url": "https://api.github.com/users/lirui-apache/followers",
                "following_url": "https://api.github.com/users/lirui-apache/following{/other_user}",
                "gists_url": "https://api.github.com/users/lirui-apache/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/lirui-apache/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/lirui-apache/subscriptions",
                "organizations_url": "https://api.github.com/users/lirui-apache/orgs",
                "repos_url": "https://api.github.com/users/lirui-apache/repos",
                "events_url": "https://api.github.com/users/lirui-apache/events{/privacy}",
                "received_events_url": "https://api.github.com/users/lirui-apache/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "447452d0cdbec9a6d97e96dcb89977e52c27750e",
                "url": "https://api.github.com/repos/apache/flink/commits/447452d0cdbec9a6d97e96dcb89977e52c27750e",
                "html_url": "https://github.com/apache/flink/commit/447452d0cdbec9a6d97e96dcb89977e52c27750e"
            }]
        },
        {
            "sha": "8057026bb6a8a7c869c4ddea769778db8cc064c9",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ODA1NzAyNmJiNmE4YTdjODY5YzRkZGVhNzY5Nzc4ZGI4Y2MwNjRjOQ==",
            "commit": {
                "author": {
                    "name": "TsReaper",
                    "email": "tsreaper96@gmail.com",
                    "date": "2021-07-05T07:31:32Z"
                },
                "committer": {
                    "name": "Piotr Nowojski",
                    "email": "piotr.nowojski@gmail.com",
                    "date": "2021-07-08T06:31:54Z"
                },
                "message": "[FLINK-22443][streaming-java] Fix overflow in MultipleInputSelectionHandler",
                "tree": {
                    "sha": "fe5c2f3e54acbac4cb3a521bc375c0b8202abf92",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/fe5c2f3e54acbac4cb3a521bc375c0b8202abf92"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/8057026bb6a8a7c869c4ddea769778db8cc064c9",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/8057026bb6a8a7c869c4ddea769778db8cc064c9",
            "html_url": "https://github.com/apache/flink/commit/8057026bb6a8a7c869c4ddea769778db8cc064c9",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/8057026bb6a8a7c869c4ddea769778db8cc064c9/comments",
            "author": {
                "login": "tsreaper",
                "id": 19909549,
                "node_id": "MDQ6VXNlcjE5OTA5NTQ5",
                "avatar_url": "https://avatars.githubusercontent.com/u/19909549?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tsreaper",
                "html_url": "https://github.com/tsreaper",
                "followers_url": "https://api.github.com/users/tsreaper/followers",
                "following_url": "https://api.github.com/users/tsreaper/following{/other_user}",
                "gists_url": "https://api.github.com/users/tsreaper/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tsreaper/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tsreaper/subscriptions",
                "organizations_url": "https://api.github.com/users/tsreaper/orgs",
                "repos_url": "https://api.github.com/users/tsreaper/repos",
                "events_url": "https://api.github.com/users/tsreaper/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tsreaper/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "pnowojski",
                "id": 8957547,
                "node_id": "MDQ6VXNlcjg5NTc1NDc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8957547?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/pnowojski",
                "html_url": "https://github.com/pnowojski",
                "followers_url": "https://api.github.com/users/pnowojski/followers",
                "following_url": "https://api.github.com/users/pnowojski/following{/other_user}",
                "gists_url": "https://api.github.com/users/pnowojski/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/pnowojski/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/pnowojski/subscriptions",
                "organizations_url": "https://api.github.com/users/pnowojski/orgs",
                "repos_url": "https://api.github.com/users/pnowojski/repos",
                "events_url": "https://api.github.com/users/pnowojski/events{/privacy}",
                "received_events_url": "https://api.github.com/users/pnowojski/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "f14307b869e1e9b518784276311ce6afb112312d",
                "url": "https://api.github.com/repos/apache/flink/commits/f14307b869e1e9b518784276311ce6afb112312d",
                "html_url": "https://github.com/apache/flink/commit/f14307b869e1e9b518784276311ce6afb112312d"
            }]
        },
        {
            "sha": "d410612745a12a668cdd48a8087087f0540d0e00",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZDQxMDYxMjc0NWExMmE2NjhjZGQ0OGE4MDg3MDg3ZjA1NDBkMGUwMA==",
            "commit": {
                "author": {
                    "name": "Xintong Song",
                    "email": "tonysong820@gmail.com",
                    "date": "2021-07-08T02:40:44Z"
                },
                "committer": {
                    "name": "Xintong Song",
                    "email": "tonysong820@gmail.com",
                    "date": "2021-07-09T01:42:33Z"
                },
                "message": "[hotfix] Minor clean-ups in YARNHighAvailabilityITCase",
                "tree": {
                    "sha": "1c7e70d7de91f209409100b0e4cc9b4e2a530736",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/1c7e70d7de91f209409100b0e4cc9b4e2a530736"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/d410612745a12a668cdd48a8087087f0540d0e00",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCgAdFiEEGsvLF58sbVnbyFd20SHP9Sk+Y18FAmDnqYkACgkQ0SHP9Sk+\nY1/VWQ//TToNvsRFkiydwyOTdsL2apHt74KyCeB0NQUqTuim7KDHw01qnO0/FXgC\nCgAtss5jNNAkToIg4FbqzENDNpd/ZzFWoAdcBTByQLco6tW0ezLdCCF7aCuQghSx\nPojN5GTK17YLRn64kzBviwxBba1leGILEG5dHMWXqgoR1V/1w7fh49Q9EhQGk/3P\nswizoajWfY2zcBp5YlAm3f4wm/aTKxxtpvFEcxBxVquGEUe1Opx9JkgTStw7SMib\naHbahtxQ9SMuw/jyHZDDfhpuopCjNcig2noV5UQ6lGIbKSLYXyxYPa8jiKKDKofA\nxymX6wQrXAFN1zeLELh2MXH+neLQIn82TtFDqZ32S0gfY5fXXgk/1yuIfzBqPSHa\n3uCB+n5Pn4+mhMho5SXUko/Cr6Gm/4qUXjRbeTe/ovxDPWyPtWUm/NAWMirIvlqG\nd9kS1FAqfyR8Oi50NfMHXqfasictgMpPjFYSgj/b01wwHznDCszdUMXN04izjw2X\ngVqiCfbHMDaJQgg0BFOodzffYjtspI75e/jGb8vBisH4ZkYQW7tPGOdDZKNfdlzq\nk0UXEfzru+mw/KCAZrw7qLt4DnsgoMI9jqjpxRffw21Bk2FffKfAZoPYgtD3N5HS\nYwEhQvlzLmMP0F8O40NW0d7gxsl3X94BfpCnzjYLALffsp/pzp4=\n=/Q3V\n-----END PGP SIGNATURE-----",
                    "payload": "tree 1c7e70d7de91f209409100b0e4cc9b4e2a530736\nparent 8057026bb6a8a7c869c4ddea769778db8cc064c9\nauthor Xintong Song <tonysong820@gmail.com> 1625712044 +0800\ncommitter Xintong Song <tonysong820@gmail.com> 1625794953 +0800\n\n[hotfix] Minor clean-ups in YARNHighAvailabilityITCase\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/d410612745a12a668cdd48a8087087f0540d0e00",
            "html_url": "https://github.com/apache/flink/commit/d410612745a12a668cdd48a8087087f0540d0e00",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/d410612745a12a668cdd48a8087087f0540d0e00/comments",
            "author": {
                "login": "xintongsong",
                "id": 6509172,
                "node_id": "MDQ6VXNlcjY1MDkxNzI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6509172?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/xintongsong",
                "html_url": "https://github.com/xintongsong",
                "followers_url": "https://api.github.com/users/xintongsong/followers",
                "following_url": "https://api.github.com/users/xintongsong/following{/other_user}",
                "gists_url": "https://api.github.com/users/xintongsong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/xintongsong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/xintongsong/subscriptions",
                "organizations_url": "https://api.github.com/users/xintongsong/orgs",
                "repos_url": "https://api.github.com/users/xintongsong/repos",
                "events_url": "https://api.github.com/users/xintongsong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/xintongsong/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "xintongsong",
                "id": 6509172,
                "node_id": "MDQ6VXNlcjY1MDkxNzI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6509172?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/xintongsong",
                "html_url": "https://github.com/xintongsong",
                "followers_url": "https://api.github.com/users/xintongsong/followers",
                "following_url": "https://api.github.com/users/xintongsong/following{/other_user}",
                "gists_url": "https://api.github.com/users/xintongsong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/xintongsong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/xintongsong/subscriptions",
                "organizations_url": "https://api.github.com/users/xintongsong/orgs",
                "repos_url": "https://api.github.com/users/xintongsong/repos",
                "events_url": "https://api.github.com/users/xintongsong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/xintongsong/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "8057026bb6a8a7c869c4ddea769778db8cc064c9",
                "url": "https://api.github.com/repos/apache/flink/commits/8057026bb6a8a7c869c4ddea769778db8cc064c9",
                "html_url": "https://github.com/apache/flink/commit/8057026bb6a8a7c869c4ddea769778db8cc064c9"
            }]
        },
        {
            "sha": "76edcdade12c3ebc2157debf80f4fe398c541a12",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NzZlZGNkYWRlMTJjM2ViYzIxNTdkZWJmODBmNGZlMzk4YzU0MWExMg==",
            "commit": {
                "author": {
                    "name": "Xintong Song",
                    "email": "tonysong820@gmail.com",
                    "date": "2021-07-06T10:19:14Z"
                },
                "committer": {
                    "name": "Xintong Song",
                    "email": "tonysong820@gmail.com",
                    "date": "2021-07-09T01:42:34Z"
                },
                "message": "[FLINK-22662][yarn][test] Stabilize YARNHighAvailabilityITCase\n\nThis closes #16395",
                "tree": {
                    "sha": "53b9d7e797bf66f5fd53c9a6f0adb552ad2cd4c9",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/53b9d7e797bf66f5fd53c9a6f0adb552ad2cd4c9"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/76edcdade12c3ebc2157debf80f4fe398c541a12",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCgAdFiEEGsvLF58sbVnbyFd20SHP9Sk+Y18FAmDnqYoACgkQ0SHP9Sk+\nY19Xlw/+PYXRKO/fKIHd921k2TPnhKg6/+RmQf53UU+AhNi2G7Sl2+MDNlhsvjDt\nHFg/iTQOFUKBy5Wk4HbCD6cgljbRaxL3qAbLISZiOpP4XR3Fv5lb1yCXHmhZ9W9l\nP6FpoB+9TNEWiEcCryQ4AHIKAQlUmIBnicgdbyusX+TawP2iTuGvE89ZifcIByAi\nQWJAHV8pHFOTBRsuggU6GoGSGJOk7HiAyVyMpMN23/4lX0P9y3qKsMTeQ7fezU2W\nyK/3gMAQT1NYydUnOeIythF8x8+ibj9S1/sBzwJoFs9xre5uaAidfWEmhYxE/Se1\nWUxLqI0I/o4F63c/Zgj9E/Jf/fE3mkNIunFm4SubF7AiH5ZJFxQrO1YRR0ook2bk\n4WFG7Aylg+YwRz/+vfolyjbPWj7pM0XBBghnMJn/EtvJPUd9DS1YqEq+8l5hx9rc\nNS/HiB3JzF3M0ftB22ANu9Mo9hdUZwLfbo/DnUIviUJmuo3fhYM/5GsegUPW9JZz\nlr5C0ZcXnNXPYmnM5sRc7DO7cWjGxOVL7PCmGNBjTs/RFSpa/ogt9fN6Av2Hi6LS\n4yB1ekuYM9BrmNZmz1J4k5ga904az4TKoXZtNbuhBqhJWwXDDlz9OriMhDWoe4F0\na8xSBe7bQlK5ijft43PFCoHKgwnPOP0JAIVoE7/v3Zk4jDxjsXE=\n=blcP\n-----END PGP SIGNATURE-----",
                    "payload": "tree 53b9d7e797bf66f5fd53c9a6f0adb552ad2cd4c9\nparent d410612745a12a668cdd48a8087087f0540d0e00\nauthor Xintong Song <tonysong820@gmail.com> 1625566754 +0800\ncommitter Xintong Song <tonysong820@gmail.com> 1625794954 +0800\n\n[FLINK-22662][yarn][test] Stabilize YARNHighAvailabilityITCase\n\nThis closes #16395\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/76edcdade12c3ebc2157debf80f4fe398c541a12",
            "html_url": "https://github.com/apache/flink/commit/76edcdade12c3ebc2157debf80f4fe398c541a12",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/76edcdade12c3ebc2157debf80f4fe398c541a12/comments",
            "author": {
                "login": "xintongsong",
                "id": 6509172,
                "node_id": "MDQ6VXNlcjY1MDkxNzI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6509172?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/xintongsong",
                "html_url": "https://github.com/xintongsong",
                "followers_url": "https://api.github.com/users/xintongsong/followers",
                "following_url": "https://api.github.com/users/xintongsong/following{/other_user}",
                "gists_url": "https://api.github.com/users/xintongsong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/xintongsong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/xintongsong/subscriptions",
                "organizations_url": "https://api.github.com/users/xintongsong/orgs",
                "repos_url": "https://api.github.com/users/xintongsong/repos",
                "events_url": "https://api.github.com/users/xintongsong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/xintongsong/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "xintongsong",
                "id": 6509172,
                "node_id": "MDQ6VXNlcjY1MDkxNzI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6509172?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/xintongsong",
                "html_url": "https://github.com/xintongsong",
                "followers_url": "https://api.github.com/users/xintongsong/followers",
                "following_url": "https://api.github.com/users/xintongsong/following{/other_user}",
                "gists_url": "https://api.github.com/users/xintongsong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/xintongsong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/xintongsong/subscriptions",
                "organizations_url": "https://api.github.com/users/xintongsong/orgs",
                "repos_url": "https://api.github.com/users/xintongsong/repos",
                "events_url": "https://api.github.com/users/xintongsong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/xintongsong/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "d410612745a12a668cdd48a8087087f0540d0e00",
                "url": "https://api.github.com/repos/apache/flink/commits/d410612745a12a668cdd48a8087087f0540d0e00",
                "html_url": "https://github.com/apache/flink/commit/d410612745a12a668cdd48a8087087f0540d0e00"
            }]
        },
        {
            "sha": "8359fa8a9149392d964f52e7492b4dc24d74bb15",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ODM1OWZhOGE5MTQ5MzkyZDk2NGY1MmU3NDkyYjRkYzI0ZDc0YmIxNQ==",
            "commit": {
                "author": {
                    "name": "Ada Wong",
                    "email": "wuren@dtstack.com",
                    "date": "2021-07-02T08:06:09Z"
                },
                "committer": {
                    "name": "Rui Li",
                    "email": "lirui@apache.org",
                    "date": "2021-07-09T04:12:37Z"
                },
                "message": "[FLINK-23074][connector-hive] Shade parquet class in hive-exec to prevent conflict with flink-parquet module\n\nThis closes #16423",
                "tree": {
                    "sha": "39b11e65f6e67cb026399ecd02f3783ddaa5bc3b",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/39b11e65f6e67cb026399ecd02f3783ddaa5bc3b"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/8359fa8a9149392d964f52e7492b4dc24d74bb15",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/8359fa8a9149392d964f52e7492b4dc24d74bb15",
            "html_url": "https://github.com/apache/flink/commit/8359fa8a9149392d964f52e7492b4dc24d74bb15",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/8359fa8a9149392d964f52e7492b4dc24d74bb15/comments",
            "author": {
                "login": "deadwind4",
                "id": 12015546,
                "node_id": "MDQ6VXNlcjEyMDE1NTQ2",
                "avatar_url": "https://avatars.githubusercontent.com/u/12015546?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/deadwind4",
                "html_url": "https://github.com/deadwind4",
                "followers_url": "https://api.github.com/users/deadwind4/followers",
                "following_url": "https://api.github.com/users/deadwind4/following{/other_user}",
                "gists_url": "https://api.github.com/users/deadwind4/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/deadwind4/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/deadwind4/subscriptions",
                "organizations_url": "https://api.github.com/users/deadwind4/orgs",
                "repos_url": "https://api.github.com/users/deadwind4/repos",
                "events_url": "https://api.github.com/users/deadwind4/events{/privacy}",
                "received_events_url": "https://api.github.com/users/deadwind4/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "lirui-apache",
                "id": 5210788,
                "node_id": "MDQ6VXNlcjUyMTA3ODg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5210788?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/lirui-apache",
                "html_url": "https://github.com/lirui-apache",
                "followers_url": "https://api.github.com/users/lirui-apache/followers",
                "following_url": "https://api.github.com/users/lirui-apache/following{/other_user}",
                "gists_url": "https://api.github.com/users/lirui-apache/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/lirui-apache/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/lirui-apache/subscriptions",
                "organizations_url": "https://api.github.com/users/lirui-apache/orgs",
                "repos_url": "https://api.github.com/users/lirui-apache/repos",
                "events_url": "https://api.github.com/users/lirui-apache/events{/privacy}",
                "received_events_url": "https://api.github.com/users/lirui-apache/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "76edcdade12c3ebc2157debf80f4fe398c541a12",
                "url": "https://api.github.com/repos/apache/flink/commits/76edcdade12c3ebc2157debf80f4fe398c541a12",
                "html_url": "https://github.com/apache/flink/commit/76edcdade12c3ebc2157debf80f4fe398c541a12"
            }]
        },
        {
            "sha": "51e4ee24a48b475ce6e19b6c06c43c12d5dce42d",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NTFlNGVlMjRhNDhiNDc1Y2U2ZTE5YjZjMDZjNDNjMTJkNWRjZTQyZA==",
            "commit": {
                "author": {
                    "name": "Timo Walther",
                    "email": "twalthr@apache.org",
                    "date": "2021-07-08T08:49:53Z"
                },
                "committer": {
                    "name": "Timo Walther",
                    "email": "twalthr@apache.org",
                    "date": "2021-07-09T07:31:37Z"
                },
                "message": "[FLINK-23306][table] Reduce usages of legacy TableSchema\n\nThis closes #16425.",
                "tree": {
                    "sha": "433b07166dc3b7f0dfcb7b4d9ab79862887508bf",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/433b07166dc3b7f0dfcb7b4d9ab79862887508bf"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/51e4ee24a48b475ce6e19b6c06c43c12d5dce42d",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/51e4ee24a48b475ce6e19b6c06c43c12d5dce42d",
            "html_url": "https://github.com/apache/flink/commit/51e4ee24a48b475ce6e19b6c06c43c12d5dce42d",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/51e4ee24a48b475ce6e19b6c06c43c12d5dce42d/comments",
            "author": {
                "login": "twalthr",
                "id": 5746567,
                "node_id": "MDQ6VXNlcjU3NDY1Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5746567?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/twalthr",
                "html_url": "https://github.com/twalthr",
                "followers_url": "https://api.github.com/users/twalthr/followers",
                "following_url": "https://api.github.com/users/twalthr/following{/other_user}",
                "gists_url": "https://api.github.com/users/twalthr/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/twalthr/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/twalthr/subscriptions",
                "organizations_url": "https://api.github.com/users/twalthr/orgs",
                "repos_url": "https://api.github.com/users/twalthr/repos",
                "events_url": "https://api.github.com/users/twalthr/events{/privacy}",
                "received_events_url": "https://api.github.com/users/twalthr/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "twalthr",
                "id": 5746567,
                "node_id": "MDQ6VXNlcjU3NDY1Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5746567?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/twalthr",
                "html_url": "https://github.com/twalthr",
                "followers_url": "https://api.github.com/users/twalthr/followers",
                "following_url": "https://api.github.com/users/twalthr/following{/other_user}",
                "gists_url": "https://api.github.com/users/twalthr/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/twalthr/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/twalthr/subscriptions",
                "organizations_url": "https://api.github.com/users/twalthr/orgs",
                "repos_url": "https://api.github.com/users/twalthr/repos",
                "events_url": "https://api.github.com/users/twalthr/events{/privacy}",
                "received_events_url": "https://api.github.com/users/twalthr/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "8359fa8a9149392d964f52e7492b4dc24d74bb15",
                "url": "https://api.github.com/repos/apache/flink/commits/8359fa8a9149392d964f52e7492b4dc24d74bb15",
                "html_url": "https://github.com/apache/flink/commit/8359fa8a9149392d964f52e7492b4dc24d74bb15"
            }]
        },
        {
            "sha": "3708cc4cf9382f18e2f8e48b91d7c7dac74d607b",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MzcwOGNjNGNmOTM4MmYxOGUyZjhlNDhiOTFkN2M3ZGFjNzRkNjA3Yg==",
            "commit": {
                "author": {
                    "name": "David Moravek",
                    "email": "dmvk@apache.org",
                    "date": "2021-07-07T13:27:07Z"
                },
                "committer": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-07-09T14:03:19Z"
                },
                "message": "[FLINK-22819][yarn] Remove 'yarn.am.liveness-monitor.expiry-interval-ms' override for tests.\n\nThis is an interval between AM container allocation and actually running RM Client inside this container,\nwhich can take longer in resource limited environment such as CI. If heartbeats between AM and RM don't\nwork and a test relies on this, then it will fail a bit later because the default value is 5 minutes.\n\nThis closes #16413.",
                "tree": {
                    "sha": "194c7a9b5eb6494377b0e0e82df9dca455b76e86",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/194c7a9b5eb6494377b0e0e82df9dca455b76e86"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/3708cc4cf9382f18e2f8e48b91d7c7dac74d607b",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEEuUmfpp7/Xe7rw8H1un5Bh8b3PYIFAmDoVycACgkQun5Bh8b3\nPYL38w//S+/Xqdos4wgeYOgtlXhz1bZsrn3l33udp2AlXo/2ZDLsr4bxLPiQ/qOd\n7VyzUymINlA+TZjLkbfw5b+v7X0syrjkWy9HosvKh+QJr+Xxs07dg4sCHnvZL9n7\n9prUt9dNExOtPkrp8DXSebRmLVy6N3DJ+8rmOMmqHXff8vvrlIaqfxP1/PNUuBYs\naR5Cjgj6fe51i+SlouZqnrSAHDifw0X4N0UeX9TK7Ng4q1wEONUQo5A9kElnIrfi\n934kv+Iuu/6nf4m4DbO0YGIxj4tnfqbDxT/RmvTvnL3iav8ExhoLqnNHMidIzzdj\nEQUnq3WhCm2J4UtFhL/0mUwpiP6Twmuuc9x1bl0S6ZoNZegbj2qNa/YXs2dWfB7F\nSZowFAsPJmodLFNKaE7pLNxls0YpD1Oa9uY2dG5OGZpx1boCXypo9lwm0aWplWiS\nBx6UBHiZXuC6p4TDLi8nF9sfkwtHnYtlAfIUad4RX+BaGQWxWHeb51XZhEWkacG9\nvsOocLKA1MXflW34KmpXO7plx0rINEFCgk1a8rX52SgnExedibANVW8oYjxiHqCQ\ndJU36pKl682NnZGWE2vGc3AZeYLOAUN7WMfaAgcLGNZ/EWSAo46DvjIWgQRS6Wwt\niWuLkDLjwYW93QvyDv6VjkCG7jX839AfBaoW1aEfkKh75hqdNlE=\n=fI91\n-----END PGP SIGNATURE-----",
                    "payload": "tree 194c7a9b5eb6494377b0e0e82df9dca455b76e86\nparent 51e4ee24a48b475ce6e19b6c06c43c12d5dce42d\nauthor David Moravek <dmvk@apache.org> 1625664427 +0200\ncommitter Till Rohrmann <trohrmann@apache.org> 1625839399 +0200\n\n[FLINK-22819][yarn] Remove 'yarn.am.liveness-monitor.expiry-interval-ms' override for tests.\n\nThis is an interval between AM container allocation and actually running RM Client inside this container,\nwhich can take longer in resource limited environment such as CI. If heartbeats between AM and RM don't\nwork and a test relies on this, then it will fail a bit later because the default value is 5 minutes.\n\nThis closes #16413.\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/3708cc4cf9382f18e2f8e48b91d7c7dac74d607b",
            "html_url": "https://github.com/apache/flink/commit/3708cc4cf9382f18e2f8e48b91d7c7dac74d607b",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/3708cc4cf9382f18e2f8e48b91d7c7dac74d607b/comments",
            "author": {
                "login": "dmvk",
                "id": 299781,
                "node_id": "MDQ6VXNlcjI5OTc4MQ==",
                "avatar_url": "https://avatars.githubusercontent.com/u/299781?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dmvk",
                "html_url": "https://github.com/dmvk",
                "followers_url": "https://api.github.com/users/dmvk/followers",
                "following_url": "https://api.github.com/users/dmvk/following{/other_user}",
                "gists_url": "https://api.github.com/users/dmvk/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dmvk/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dmvk/subscriptions",
                "organizations_url": "https://api.github.com/users/dmvk/orgs",
                "repos_url": "https://api.github.com/users/dmvk/repos",
                "events_url": "https://api.github.com/users/dmvk/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dmvk/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "51e4ee24a48b475ce6e19b6c06c43c12d5dce42d",
                "url": "https://api.github.com/repos/apache/flink/commits/51e4ee24a48b475ce6e19b6c06c43c12d5dce42d",
                "html_url": "https://github.com/apache/flink/commit/51e4ee24a48b475ce6e19b6c06c43c12d5dce42d"
            }]
        },
        {
            "sha": "e01575337bfe12e40644b0aeff9fa89e9e00ffd1",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZTAxNTc1MzM3YmZlMTJlNDA2NDRiMGFlZmY5ZmE4OWU5ZTAwZmZkMQ==",
            "commit": {
                "author": {
                    "name": "Seth Wiesman",
                    "email": "sjwiesman@gmail.com",
                    "date": "2021-07-09T20:29:12Z"
                },
                "committer": {
                    "name": "Seth Wiesman",
                    "email": "sjwiesman@gmail.com",
                    "date": "2021-07-09T21:36:18Z"
                },
                "message": "[hotfix][docs] Update release notes for 1.13 with state backend migration details\n\nCo-authored-by: David Anderson <david@alpinegizmo.com>",
                "tree": {
                    "sha": "4381a433ad08ff24d0abe5481fd6bb5e53732c7e",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/4381a433ad08ff24d0abe5481fd6bb5e53732c7e"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/e01575337bfe12e40644b0aeff9fa89e9e00ffd1",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/e01575337bfe12e40644b0aeff9fa89e9e00ffd1",
            "html_url": "https://github.com/apache/flink/commit/e01575337bfe12e40644b0aeff9fa89e9e00ffd1",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/e01575337bfe12e40644b0aeff9fa89e9e00ffd1/comments",
            "author": {
                "login": "sjwiesman",
                "id": 1891970,
                "node_id": "MDQ6VXNlcjE4OTE5NzA=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1891970?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/sjwiesman",
                "html_url": "https://github.com/sjwiesman",
                "followers_url": "https://api.github.com/users/sjwiesman/followers",
                "following_url": "https://api.github.com/users/sjwiesman/following{/other_user}",
                "gists_url": "https://api.github.com/users/sjwiesman/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/sjwiesman/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/sjwiesman/subscriptions",
                "organizations_url": "https://api.github.com/users/sjwiesman/orgs",
                "repos_url": "https://api.github.com/users/sjwiesman/repos",
                "events_url": "https://api.github.com/users/sjwiesman/events{/privacy}",
                "received_events_url": "https://api.github.com/users/sjwiesman/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "sjwiesman",
                "id": 1891970,
                "node_id": "MDQ6VXNlcjE4OTE5NzA=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1891970?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/sjwiesman",
                "html_url": "https://github.com/sjwiesman",
                "followers_url": "https://api.github.com/users/sjwiesman/followers",
                "following_url": "https://api.github.com/users/sjwiesman/following{/other_user}",
                "gists_url": "https://api.github.com/users/sjwiesman/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/sjwiesman/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/sjwiesman/subscriptions",
                "organizations_url": "https://api.github.com/users/sjwiesman/orgs",
                "repos_url": "https://api.github.com/users/sjwiesman/repos",
                "events_url": "https://api.github.com/users/sjwiesman/events{/privacy}",
                "received_events_url": "https://api.github.com/users/sjwiesman/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "3708cc4cf9382f18e2f8e48b91d7c7dac74d607b",
                "url": "https://api.github.com/repos/apache/flink/commits/3708cc4cf9382f18e2f8e48b91d7c7dac74d607b",
                "html_url": "https://github.com/apache/flink/commit/3708cc4cf9382f18e2f8e48b91d7c7dac74d607b"
            }]
        },
        {
            "sha": "92398d42498e61554566ab2dcfd8a5fa8f2a64a2",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6OTIzOThkNDI0OThlNjE1NTQ1NjZhYjJkY2ZkOGE1ZmE4ZjJhNjRhMg==",
            "commit": {
                "author": {
                    "name": "GuoWei Ma",
                    "email": "guowei.mgw@gmail.com",
                    "date": "2021-07-09T09:13:10Z"
                },
                "committer": {
                    "name": "GuoWei Ma",
                    "email": "guowei.mgw@gmail.com",
                    "date": "2021-07-12T02:44:28Z"
                },
                "message": "[FLINK-23235][connector] Fix SinkITCase instability\n\nThis closes #16441.",
                "tree": {
                    "sha": "ae0ef052984a38198844c3a7c3aad8f5d3628317",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/ae0ef052984a38198844c3a7c3aad8f5d3628317"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/92398d42498e61554566ab2dcfd8a5fa8f2a64a2",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/92398d42498e61554566ab2dcfd8a5fa8f2a64a2",
            "html_url": "https://github.com/apache/flink/commit/92398d42498e61554566ab2dcfd8a5fa8f2a64a2",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/92398d42498e61554566ab2dcfd8a5fa8f2a64a2/comments",
            "author": {
                "login": "guoweiM",
                "id": 26054913,
                "node_id": "MDQ6VXNlcjI2MDU0OTEz",
                "avatar_url": "https://avatars.githubusercontent.com/u/26054913?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/guoweiM",
                "html_url": "https://github.com/guoweiM",
                "followers_url": "https://api.github.com/users/guoweiM/followers",
                "following_url": "https://api.github.com/users/guoweiM/following{/other_user}",
                "gists_url": "https://api.github.com/users/guoweiM/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/guoweiM/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/guoweiM/subscriptions",
                "organizations_url": "https://api.github.com/users/guoweiM/orgs",
                "repos_url": "https://api.github.com/users/guoweiM/repos",
                "events_url": "https://api.github.com/users/guoweiM/events{/privacy}",
                "received_events_url": "https://api.github.com/users/guoweiM/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "guoweiM",
                "id": 26054913,
                "node_id": "MDQ6VXNlcjI2MDU0OTEz",
                "avatar_url": "https://avatars.githubusercontent.com/u/26054913?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/guoweiM",
                "html_url": "https://github.com/guoweiM",
                "followers_url": "https://api.github.com/users/guoweiM/followers",
                "following_url": "https://api.github.com/users/guoweiM/following{/other_user}",
                "gists_url": "https://api.github.com/users/guoweiM/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/guoweiM/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/guoweiM/subscriptions",
                "organizations_url": "https://api.github.com/users/guoweiM/orgs",
                "repos_url": "https://api.github.com/users/guoweiM/repos",
                "events_url": "https://api.github.com/users/guoweiM/events{/privacy}",
                "received_events_url": "https://api.github.com/users/guoweiM/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "e01575337bfe12e40644b0aeff9fa89e9e00ffd1",
                "url": "https://api.github.com/repos/apache/flink/commits/e01575337bfe12e40644b0aeff9fa89e9e00ffd1",
                "html_url": "https://github.com/apache/flink/commit/e01575337bfe12e40644b0aeff9fa89e9e00ffd1"
            }]
        },
        {
            "sha": "65ca5159fe96507c12bcda2adb9b07bd5675ebf2",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NjVjYTUxNTlmZTk2NTA3YzEyYmNkYTJhZGI5YjA3YmQ1Njc1ZWJmMg==",
            "commit": {
                "author": {
                    "name": "Yun Gao",
                    "email": "gaoyunhenhao@gmail.com",
                    "date": "2021-07-04T14:17:42Z"
                },
                "committer": {
                    "name": "Piotr Nowojski",
                    "email": "pnowojski@users.noreply.github.com",
                    "date": "2021-07-12T09:54:22Z"
                },
                "message": "[FLINK-23223] Notifies if there are available data on resumption for pipelined subpartition",
                "tree": {
                    "sha": "e4004e9ca638d2d16f54e16a55caa9a3ce49033a",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/e4004e9ca638d2d16f54e16a55caa9a3ce49033a"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/65ca5159fe96507c12bcda2adb9b07bd5675ebf2",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/65ca5159fe96507c12bcda2adb9b07bd5675ebf2",
            "html_url": "https://github.com/apache/flink/commit/65ca5159fe96507c12bcda2adb9b07bd5675ebf2",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/65ca5159fe96507c12bcda2adb9b07bd5675ebf2/comments",
            "author": {
                "login": "gaoyunhaii",
                "id": 1683890,
                "node_id": "MDQ6VXNlcjE2ODM4OTA=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1683890?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/gaoyunhaii",
                "html_url": "https://github.com/gaoyunhaii",
                "followers_url": "https://api.github.com/users/gaoyunhaii/followers",
                "following_url": "https://api.github.com/users/gaoyunhaii/following{/other_user}",
                "gists_url": "https://api.github.com/users/gaoyunhaii/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/gaoyunhaii/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/gaoyunhaii/subscriptions",
                "organizations_url": "https://api.github.com/users/gaoyunhaii/orgs",
                "repos_url": "https://api.github.com/users/gaoyunhaii/repos",
                "events_url": "https://api.github.com/users/gaoyunhaii/events{/privacy}",
                "received_events_url": "https://api.github.com/users/gaoyunhaii/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "pnowojski",
                "id": 8957547,
                "node_id": "MDQ6VXNlcjg5NTc1NDc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8957547?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/pnowojski",
                "html_url": "https://github.com/pnowojski",
                "followers_url": "https://api.github.com/users/pnowojski/followers",
                "following_url": "https://api.github.com/users/pnowojski/following{/other_user}",
                "gists_url": "https://api.github.com/users/pnowojski/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/pnowojski/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/pnowojski/subscriptions",
                "organizations_url": "https://api.github.com/users/pnowojski/orgs",
                "repos_url": "https://api.github.com/users/pnowojski/repos",
                "events_url": "https://api.github.com/users/pnowojski/events{/privacy}",
                "received_events_url": "https://api.github.com/users/pnowojski/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "92398d42498e61554566ab2dcfd8a5fa8f2a64a2",
                "url": "https://api.github.com/repos/apache/flink/commits/92398d42498e61554566ab2dcfd8a5fa8f2a64a2",
                "html_url": "https://github.com/apache/flink/commit/92398d42498e61554566ab2dcfd8a5fa8f2a64a2"
            }]
        },
        {
            "sha": "94716aee66c6048dc27af11b82b865912cbb7441",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6OTQ3MTZhZWU2NmM2MDQ4ZGMyN2FmMTFiODJiODY1OTEyY2JiNzQ0MQ==",
            "commit": {
                "author": {
                    "name": "Roman Khachatryan",
                    "email": "khachatryan.roman@gmail.com",
                    "date": "2021-07-12T00:16:52Z"
                },
                "committer": {
                    "name": "Roman Khachatryan",
                    "email": "khachatryan.roman@gmail.com",
                    "date": "2021-07-12T13:21:41Z"
                },
                "message": "[hotfix][runtime] Log TaskThread StackTrace from the WatchDog\n\nShow where the task is stuck when the watchdog goes off (interrupted isn't triggered).\nMotivated by debugging FLINK-22889.",
                "tree": {
                    "sha": "f6e4ded29201be121c4c2e2b0868c49cbfa712f6",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/f6e4ded29201be121c4c2e2b0868c49cbfa712f6"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/94716aee66c6048dc27af11b82b865912cbb7441",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/94716aee66c6048dc27af11b82b865912cbb7441",
            "html_url": "https://github.com/apache/flink/commit/94716aee66c6048dc27af11b82b865912cbb7441",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/94716aee66c6048dc27af11b82b865912cbb7441/comments",
            "author": {
                "login": "rkhachatryan",
                "id": 3939322,
                "node_id": "MDQ6VXNlcjM5MzkzMjI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3939322?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rkhachatryan",
                "html_url": "https://github.com/rkhachatryan",
                "followers_url": "https://api.github.com/users/rkhachatryan/followers",
                "following_url": "https://api.github.com/users/rkhachatryan/following{/other_user}",
                "gists_url": "https://api.github.com/users/rkhachatryan/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rkhachatryan/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rkhachatryan/subscriptions",
                "organizations_url": "https://api.github.com/users/rkhachatryan/orgs",
                "repos_url": "https://api.github.com/users/rkhachatryan/repos",
                "events_url": "https://api.github.com/users/rkhachatryan/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rkhachatryan/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "rkhachatryan",
                "id": 3939322,
                "node_id": "MDQ6VXNlcjM5MzkzMjI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3939322?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rkhachatryan",
                "html_url": "https://github.com/rkhachatryan",
                "followers_url": "https://api.github.com/users/rkhachatryan/followers",
                "following_url": "https://api.github.com/users/rkhachatryan/following{/other_user}",
                "gists_url": "https://api.github.com/users/rkhachatryan/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rkhachatryan/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rkhachatryan/subscriptions",
                "organizations_url": "https://api.github.com/users/rkhachatryan/orgs",
                "repos_url": "https://api.github.com/users/rkhachatryan/repos",
                "events_url": "https://api.github.com/users/rkhachatryan/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rkhachatryan/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "65ca5159fe96507c12bcda2adb9b07bd5675ebf2",
                "url": "https://api.github.com/repos/apache/flink/commits/65ca5159fe96507c12bcda2adb9b07bd5675ebf2",
                "html_url": "https://github.com/apache/flink/commit/65ca5159fe96507c12bcda2adb9b07bd5675ebf2"
            }]
        },
        {
            "sha": "4d865341e16f668899e4295e9d85cc5258145e24",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6NGQ4NjUzNDFlMTZmNjY4ODk5ZTQyOTVlOWQ4NWNjNTI1ODE0NWUyNA==",
            "commit": {
                "author": {
                    "name": "Yangze Guo",
                    "email": "karmagyz@gmail.com",
                    "date": "2021-07-12T09:44:19Z"
                },
                "committer": {
                    "name": "Xintong Song",
                    "email": "tonysong820@gmail.com",
                    "date": "2021-07-13T02:14:16Z"
                },
                "message": "[FLINK-23359][test] Fix the number of available slots in testResourceCanBeAllocatedForDifferentJobAfterFree\n\nThis closes #16469",
                "tree": {
                    "sha": "2a83215beb18d40467135af4b6aeab911c429eb6",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/2a83215beb18d40467135af4b6aeab911c429eb6"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/4d865341e16f668899e4295e9d85cc5258145e24",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCgAdFiEEGsvLF58sbVnbyFd20SHP9Sk+Y18FAmDs9vgACgkQ0SHP9Sk+\nY1+mIRAAzK38/EdE0I1c5/xgDxEN3g/+2C4FEWwu85R1vqO5DoHzjqXvxR88DdHR\nsw7BgsCNhFTkElVEQSRUOewiXqJU1uMNIMcZ1v/M+9D0JxH9hCGOg46v2FTdVYdb\ncthh8GPh1C+rLdyzVLBFM8sra1tUiW+dplWZ3EJJhUwGewFHV3Phx8uJTVjBsyXU\nhLj4UuccH9oiDL7Ltup62AunFieXj2JQ7X2iZHAkkQX6RN1R6NlwBInLItltOP43\nknlrWgn6adDFPEtsC7lBI1i48V9I3P/CKH88i7ata9K50AMEiNvcdmoG78kzTLcE\n0ByAAKqrKVRg1gfJ0gawzD8qOckN8Pdh+GybIBp5ha3Le1B/nhAtnv7z7TfMHmRn\no3hX7hgG7K+6cZVAbzE4dU7N1aHNFLw/uf7GcR+WRIk6tJWc2IPcmrSbxbv1889B\nkOIaT8LuXsM5a+xblGx6d8WrH92SnwsylCwIN1oBSGApJNZxKUqhKRf5XuiKwB8b\na2z1Xv1FbN3KjUHGOwmdP5dH/N8LRSL23u3dVhphx4GjFhmClBoGdICdsV/OiD/g\n+76a3nzBPxCrdRvPil3J+z8Ze+Re16AgUMGTpZHK4rgubY0z1Y5Ua2UWXov3Cyni\nFPGXMIGzalAFeg0TqczXLzNRpsY/a4DBRH519W6XxqC1VE6YIL4=\n=rgxY\n-----END PGP SIGNATURE-----",
                    "payload": "tree 2a83215beb18d40467135af4b6aeab911c429eb6\nparent 94716aee66c6048dc27af11b82b865912cbb7441\nauthor Yangze Guo <karmagyz@gmail.com> 1626083059 +0800\ncommitter Xintong Song <tonysong820@gmail.com> 1626142456 +0800\n\n[FLINK-23359][test] Fix the number of available slots in testResourceCanBeAllocatedForDifferentJobAfterFree\n\nThis closes #16469\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/4d865341e16f668899e4295e9d85cc5258145e24",
            "html_url": "https://github.com/apache/flink/commit/4d865341e16f668899e4295e9d85cc5258145e24",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/4d865341e16f668899e4295e9d85cc5258145e24/comments",
            "author": {
                "login": "KarmaGYZ",
                "id": 8684799,
                "node_id": "MDQ6VXNlcjg2ODQ3OTk=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8684799?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/KarmaGYZ",
                "html_url": "https://github.com/KarmaGYZ",
                "followers_url": "https://api.github.com/users/KarmaGYZ/followers",
                "following_url": "https://api.github.com/users/KarmaGYZ/following{/other_user}",
                "gists_url": "https://api.github.com/users/KarmaGYZ/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/KarmaGYZ/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/KarmaGYZ/subscriptions",
                "organizations_url": "https://api.github.com/users/KarmaGYZ/orgs",
                "repos_url": "https://api.github.com/users/KarmaGYZ/repos",
                "events_url": "https://api.github.com/users/KarmaGYZ/events{/privacy}",
                "received_events_url": "https://api.github.com/users/KarmaGYZ/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "xintongsong",
                "id": 6509172,
                "node_id": "MDQ6VXNlcjY1MDkxNzI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6509172?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/xintongsong",
                "html_url": "https://github.com/xintongsong",
                "followers_url": "https://api.github.com/users/xintongsong/followers",
                "following_url": "https://api.github.com/users/xintongsong/following{/other_user}",
                "gists_url": "https://api.github.com/users/xintongsong/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/xintongsong/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/xintongsong/subscriptions",
                "organizations_url": "https://api.github.com/users/xintongsong/orgs",
                "repos_url": "https://api.github.com/users/xintongsong/repos",
                "events_url": "https://api.github.com/users/xintongsong/events{/privacy}",
                "received_events_url": "https://api.github.com/users/xintongsong/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "94716aee66c6048dc27af11b82b865912cbb7441",
                "url": "https://api.github.com/repos/apache/flink/commits/94716aee66c6048dc27af11b82b865912cbb7441",
                "html_url": "https://github.com/apache/flink/commit/94716aee66c6048dc27af11b82b865912cbb7441"
            }]
        },
        {
            "sha": "ef21d506bebee0ac6466d4abe2f844ef7c15cde5",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZWYyMWQ1MDZiZWJlZTBhYzY0NjZkNGFiZTJmODQ0ZWY3YzE1Y2RlNQ==",
            "commit": {
                "author": {
                    "name": "Qingsheng Ren",
                    "email": "renqschn@gmail.com",
                    "date": "2021-06-01T00:37:57Z"
                },
                "committer": {
                    "name": "Jiangjie (Becket) Qin",
                    "email": "becket.qin@gmail.com",
                    "date": "2021-07-13T02:40:51Z"
                },
                "message": "[FLINK-22722][docs/kafka] Add documentation for Kafka new source (#15974)\n\n(cherry picked from commit b582991b8b2b8dadb89e71d5002c4a9cc2055e34)",
                "tree": {
                    "sha": "1459e7c84f6d78871a741d3249338435a2b09cf1",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/1459e7c84f6d78871a741d3249338435a2b09cf1"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/ef21d506bebee0ac6466d4abe2f844ef7c15cde5",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/ef21d506bebee0ac6466d4abe2f844ef7c15cde5",
            "html_url": "https://github.com/apache/flink/commit/ef21d506bebee0ac6466d4abe2f844ef7c15cde5",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/ef21d506bebee0ac6466d4abe2f844ef7c15cde5/comments",
            "author": {
                "login": "PatrickRen",
                "id": 18453087,
                "node_id": "MDQ6VXNlcjE4NDUzMDg3",
                "avatar_url": "https://avatars.githubusercontent.com/u/18453087?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/PatrickRen",
                "html_url": "https://github.com/PatrickRen",
                "followers_url": "https://api.github.com/users/PatrickRen/followers",
                "following_url": "https://api.github.com/users/PatrickRen/following{/other_user}",
                "gists_url": "https://api.github.com/users/PatrickRen/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/PatrickRen/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/PatrickRen/subscriptions",
                "organizations_url": "https://api.github.com/users/PatrickRen/orgs",
                "repos_url": "https://api.github.com/users/PatrickRen/repos",
                "events_url": "https://api.github.com/users/PatrickRen/events{/privacy}",
                "received_events_url": "https://api.github.com/users/PatrickRen/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "becketqin",
                "id": 5778611,
                "node_id": "MDQ6VXNlcjU3Nzg2MTE=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5778611?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/becketqin",
                "html_url": "https://github.com/becketqin",
                "followers_url": "https://api.github.com/users/becketqin/followers",
                "following_url": "https://api.github.com/users/becketqin/following{/other_user}",
                "gists_url": "https://api.github.com/users/becketqin/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/becketqin/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/becketqin/subscriptions",
                "organizations_url": "https://api.github.com/users/becketqin/orgs",
                "repos_url": "https://api.github.com/users/becketqin/repos",
                "events_url": "https://api.github.com/users/becketqin/events{/privacy}",
                "received_events_url": "https://api.github.com/users/becketqin/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "4d865341e16f668899e4295e9d85cc5258145e24",
                "url": "https://api.github.com/repos/apache/flink/commits/4d865341e16f668899e4295e9d85cc5258145e24",
                "html_url": "https://github.com/apache/flink/commit/4d865341e16f668899e4295e9d85cc5258145e24"
            }]
        },
        {
            "sha": "1e8619e0d5f9d82d987af41ba897370920cb9310",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MWU4NjE5ZTBkNWY5ZDgyZDk4N2FmNDFiYTg5NzM3MDkyMGNiOTMxMA==",
            "commit": {
                "author": {
                    "name": "Qingsheng Ren",
                    "email": "renqschn@gmail.com",
                    "date": "2021-06-29T03:53:50Z"
                },
                "committer": {
                    "name": "Jiangjie (Becket) Qin",
                    "email": "becket.qin@gmail.com",
                    "date": "2021-07-13T02:40:51Z"
                },
                "message": "[hotfix][testutil] Add test utilization for listening metric registration\n\n(cherry picked from commit 8bb629460ae45b841034be660aaace3851f141fe)",
                "tree": {
                    "sha": "1d3f76161eb1cbbac9b0e949c9383abcd7619ce3",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/1d3f76161eb1cbbac9b0e949c9383abcd7619ce3"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/1e8619e0d5f9d82d987af41ba897370920cb9310",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/1e8619e0d5f9d82d987af41ba897370920cb9310",
            "html_url": "https://github.com/apache/flink/commit/1e8619e0d5f9d82d987af41ba897370920cb9310",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/1e8619e0d5f9d82d987af41ba897370920cb9310/comments",
            "author": {
                "login": "PatrickRen",
                "id": 18453087,
                "node_id": "MDQ6VXNlcjE4NDUzMDg3",
                "avatar_url": "https://avatars.githubusercontent.com/u/18453087?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/PatrickRen",
                "html_url": "https://github.com/PatrickRen",
                "followers_url": "https://api.github.com/users/PatrickRen/followers",
                "following_url": "https://api.github.com/users/PatrickRen/following{/other_user}",
                "gists_url": "https://api.github.com/users/PatrickRen/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/PatrickRen/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/PatrickRen/subscriptions",
                "organizations_url": "https://api.github.com/users/PatrickRen/orgs",
                "repos_url": "https://api.github.com/users/PatrickRen/repos",
                "events_url": "https://api.github.com/users/PatrickRen/events{/privacy}",
                "received_events_url": "https://api.github.com/users/PatrickRen/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "becketqin",
                "id": 5778611,
                "node_id": "MDQ6VXNlcjU3Nzg2MTE=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5778611?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/becketqin",
                "html_url": "https://github.com/becketqin",
                "followers_url": "https://api.github.com/users/becketqin/followers",
                "following_url": "https://api.github.com/users/becketqin/following{/other_user}",
                "gists_url": "https://api.github.com/users/becketqin/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/becketqin/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/becketqin/subscriptions",
                "organizations_url": "https://api.github.com/users/becketqin/orgs",
                "repos_url": "https://api.github.com/users/becketqin/repos",
                "events_url": "https://api.github.com/users/becketqin/events{/privacy}",
                "received_events_url": "https://api.github.com/users/becketqin/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "ef21d506bebee0ac6466d4abe2f844ef7c15cde5",
                "url": "https://api.github.com/repos/apache/flink/commits/ef21d506bebee0ac6466d4abe2f844ef7c15cde5",
                "html_url": "https://github.com/apache/flink/commit/ef21d506bebee0ac6466d4abe2f844ef7c15cde5"
            }]
        },
        {
            "sha": "2c455f324b9ec7ef053253cf4904413b1e5f7a98",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MmM0NTVmMzI0YjllYzdlZjA1MzI1M2NmNDkwNDQxM2IxZTVmN2E5OA==",
            "commit": {
                "author": {
                    "name": "Qingsheng Ren",
                    "email": "renqschn@gmail.com",
                    "date": "2021-06-08T03:57:52Z"
                },
                "committer": {
                    "name": "Jiangjie (Becket) Qin",
                    "email": "becket.qin@gmail.com",
                    "date": "2021-07-13T02:40:51Z"
                },
                "message": "[FLINK-22766][connector/kafka] Report offsets and Kafka consumer metrics in Flink metric group\n\n(cherry picked from commit b094a932845db5539fc07b032d49d0bcefd15df2)",
                "tree": {
                    "sha": "5feb8c47533479484021aadae273ef1779d75cb4",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/5feb8c47533479484021aadae273ef1779d75cb4"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/2c455f324b9ec7ef053253cf4904413b1e5f7a98",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/2c455f324b9ec7ef053253cf4904413b1e5f7a98",
            "html_url": "https://github.com/apache/flink/commit/2c455f324b9ec7ef053253cf4904413b1e5f7a98",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/2c455f324b9ec7ef053253cf4904413b1e5f7a98/comments",
            "author": {
                "login": "PatrickRen",
                "id": 18453087,
                "node_id": "MDQ6VXNlcjE4NDUzMDg3",
                "avatar_url": "https://avatars.githubusercontent.com/u/18453087?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/PatrickRen",
                "html_url": "https://github.com/PatrickRen",
                "followers_url": "https://api.github.com/users/PatrickRen/followers",
                "following_url": "https://api.github.com/users/PatrickRen/following{/other_user}",
                "gists_url": "https://api.github.com/users/PatrickRen/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/PatrickRen/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/PatrickRen/subscriptions",
                "organizations_url": "https://api.github.com/users/PatrickRen/orgs",
                "repos_url": "https://api.github.com/users/PatrickRen/repos",
                "events_url": "https://api.github.com/users/PatrickRen/events{/privacy}",
                "received_events_url": "https://api.github.com/users/PatrickRen/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "becketqin",
                "id": 5778611,
                "node_id": "MDQ6VXNlcjU3Nzg2MTE=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5778611?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/becketqin",
                "html_url": "https://github.com/becketqin",
                "followers_url": "https://api.github.com/users/becketqin/followers",
                "following_url": "https://api.github.com/users/becketqin/following{/other_user}",
                "gists_url": "https://api.github.com/users/becketqin/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/becketqin/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/becketqin/subscriptions",
                "organizations_url": "https://api.github.com/users/becketqin/orgs",
                "repos_url": "https://api.github.com/users/becketqin/repos",
                "events_url": "https://api.github.com/users/becketqin/events{/privacy}",
                "received_events_url": "https://api.github.com/users/becketqin/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "1e8619e0d5f9d82d987af41ba897370920cb9310",
                "url": "https://api.github.com/repos/apache/flink/commits/1e8619e0d5f9d82d987af41ba897370920cb9310",
                "html_url": "https://github.com/apache/flink/commit/1e8619e0d5f9d82d987af41ba897370920cb9310"
            }]
        },
        {
            "sha": "c1f30eefe82841f2269e6cba300eb342b1193741",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6YzFmMzBlZWZlODI4NDFmMjI2OWU2Y2JhMzAwZWIzNDJiMTE5Mzc0MQ==",
            "commit": {
                "author": {
                    "name": "huangxingbo",
                    "email": "hxbks2ks@gmail.com",
                    "date": "2021-07-13T11:36:48Z"
                },
                "committer": {
                    "name": "huangxingbo",
                    "email": "hxbks2ks@gmail.com",
                    "date": "2021-07-13T11:36:48Z"
                },
                "message": "[FLINK-23368][python] Fix the wrong mapping of state cache in PyFlink",
                "tree": {
                    "sha": "39f3f86b4e24545901e76ef66249121c36ba3912",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/39f3f86b4e24545901e76ef66249121c36ba3912"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/c1f30eefe82841f2269e6cba300eb342b1193741",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/c1f30eefe82841f2269e6cba300eb342b1193741",
            "html_url": "https://github.com/apache/flink/commit/c1f30eefe82841f2269e6cba300eb342b1193741",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/c1f30eefe82841f2269e6cba300eb342b1193741/comments",
            "author": {
                "login": "HuangXingBo",
                "id": 8536293,
                "node_id": "MDQ6VXNlcjg1MzYyOTM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8536293?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/HuangXingBo",
                "html_url": "https://github.com/HuangXingBo",
                "followers_url": "https://api.github.com/users/HuangXingBo/followers",
                "following_url": "https://api.github.com/users/HuangXingBo/following{/other_user}",
                "gists_url": "https://api.github.com/users/HuangXingBo/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/HuangXingBo/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/HuangXingBo/subscriptions",
                "organizations_url": "https://api.github.com/users/HuangXingBo/orgs",
                "repos_url": "https://api.github.com/users/HuangXingBo/repos",
                "events_url": "https://api.github.com/users/HuangXingBo/events{/privacy}",
                "received_events_url": "https://api.github.com/users/HuangXingBo/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "HuangXingBo",
                "id": 8536293,
                "node_id": "MDQ6VXNlcjg1MzYyOTM=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8536293?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/HuangXingBo",
                "html_url": "https://github.com/HuangXingBo",
                "followers_url": "https://api.github.com/users/HuangXingBo/followers",
                "following_url": "https://api.github.com/users/HuangXingBo/following{/other_user}",
                "gists_url": "https://api.github.com/users/HuangXingBo/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/HuangXingBo/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/HuangXingBo/subscriptions",
                "organizations_url": "https://api.github.com/users/HuangXingBo/orgs",
                "repos_url": "https://api.github.com/users/HuangXingBo/repos",
                "events_url": "https://api.github.com/users/HuangXingBo/events{/privacy}",
                "received_events_url": "https://api.github.com/users/HuangXingBo/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "2c455f324b9ec7ef053253cf4904413b1e5f7a98",
                "url": "https://api.github.com/repos/apache/flink/commits/2c455f324b9ec7ef053253cf4904413b1e5f7a98",
                "html_url": "https://github.com/apache/flink/commit/2c455f324b9ec7ef053253cf4904413b1e5f7a98"
            }]
        },
        {
            "sha": "1fa52e1a93d025bc8482987ddac04c94142fc6cc",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MWZhNTJlMWE5M2QwMjViYzg0ODI5ODdkZGFjMDRjOTQxNDJmYzZjYw==",
            "commit": {
                "author": {
                    "name": "Yun Gao",
                    "email": "gaoyunhenhao@gmail.com",
                    "date": "2021-07-09T23:06:22Z"
                },
                "committer": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-07-13T12:19:39Z"
                },
                "message": "[FLINK-23233][runtime] Ensure checkpoints confirmed after all the failed events processed for OepratorCoordinator\n\nThis closes #16432.",
                "tree": {
                    "sha": "c60231ab89ae2550b1de6e4a254f71783cdc7277",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/c60231ab89ae2550b1de6e4a254f71783cdc7277"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/1fa52e1a93d025bc8482987ddac04c94142fc6cc",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEEuUmfpp7/Xe7rw8H1un5Bh8b3PYIFAmDthNsACgkQun5Bh8b3\nPYJDnQ//WGr1NFqKX+z8CILzsJrRTHcl8kURrW3GHSVSkNKGfD9t8PSFeioBePXF\njQWDLdooJbSkQp5TKJ+ZvHUNTUCdxWgrXACqfmBOQczxAZe8Q9TMYCqni12SwJis\nDSLPJhRdCOtoxKsY2FS2teZbDhdIAOSSbYMKNhW8Kkr1hTKmjatT1Nz/lLWNv54+\nVMF8hH1hGeHxZzbZpNFMOTS37lnmEA2tBjSLJRyFEwk1IT0Ak5Bk+eOhijhYf8Jx\ntHA1Vv92Qy2PHHKatMAfzh/zhMNhWfhvb5Dx6LXdty/bVfoDYbaTATX5nGFkZhuN\nQMhKiLubTQ4x0GdTuBO36G05J8G4Vey/mJzl/6daEqGP+LmcbDhy59e949BmDTiN\nMJFQ6AwqgNuMI/BKu2bEiFO1GSFrMvh3jqP7gvZdig026U39JXfgPnrAGsEsJedp\n0nKCCNwm+DzA8psOCMA2wIQZtAh69ppOqznmkbIQXARe0tl3rq+TyDFa335AXbiq\n8DKtA60Kr7ZiE67/bNgHygcWQBbcBDmhrSE2fVWQj3zxQzUVdalgFnObuVkOj2GX\ndrVt87qerG0XKRJTX7AbEvaXmlCFlZjP8Kq0uveF5Wivi702UI91Mt0XFpDIMbnK\n3UcZSx20BcKXgldAZcNup74bUBbcrC6WD0STBVi2eCHmtQiJH30=\n=HKoo\n-----END PGP SIGNATURE-----",
                    "payload": "tree c60231ab89ae2550b1de6e4a254f71783cdc7277\nparent c1f30eefe82841f2269e6cba300eb342b1193741\nauthor Yun Gao <gaoyunhenhao@gmail.com> 1625871982 +0800\ncommitter Till Rohrmann <trohrmann@apache.org> 1626178779 +0200\n\n[FLINK-23233][runtime] Ensure checkpoints confirmed after all the failed events processed for OepratorCoordinator\n\nThis closes #16432.\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/1fa52e1a93d025bc8482987ddac04c94142fc6cc",
            "html_url": "https://github.com/apache/flink/commit/1fa52e1a93d025bc8482987ddac04c94142fc6cc",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/1fa52e1a93d025bc8482987ddac04c94142fc6cc/comments",
            "author": {
                "login": "gaoyunhaii",
                "id": 1683890,
                "node_id": "MDQ6VXNlcjE2ODM4OTA=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1683890?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/gaoyunhaii",
                "html_url": "https://github.com/gaoyunhaii",
                "followers_url": "https://api.github.com/users/gaoyunhaii/followers",
                "following_url": "https://api.github.com/users/gaoyunhaii/following{/other_user}",
                "gists_url": "https://api.github.com/users/gaoyunhaii/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/gaoyunhaii/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/gaoyunhaii/subscriptions",
                "organizations_url": "https://api.github.com/users/gaoyunhaii/orgs",
                "repos_url": "https://api.github.com/users/gaoyunhaii/repos",
                "events_url": "https://api.github.com/users/gaoyunhaii/events{/privacy}",
                "received_events_url": "https://api.github.com/users/gaoyunhaii/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "c1f30eefe82841f2269e6cba300eb342b1193741",
                "url": "https://api.github.com/repos/apache/flink/commits/c1f30eefe82841f2269e6cba300eb342b1193741",
                "html_url": "https://github.com/apache/flink/commit/c1f30eefe82841f2269e6cba300eb342b1193741"
            }]
        },
        {
            "sha": "037687c2ea1f1b81cc77b14c11ad529b30da4db5",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MDM3Njg3YzJlYTFmMWI4MWNjNzdiMTRjMTFhZDUyOWIzMGRhNGRiNQ==",
            "commit": {
                "author": {
                    "name": "Roman Khachatryan",
                    "email": "khachatryan.roman@gmail.com",
                    "date": "2021-07-12T00:27:47Z"
                },
                "committer": {
                    "name": "Roman Khachatryan",
                    "email": "khachatryan.roman@gmail.com",
                    "date": "2021-07-13T17:46:20Z"
                },
                "message": "[hotfix][runtime] Log slot pool status if unable to fulfill job requirements",
                "tree": {
                    "sha": "957e1446d41cb3bdb7a20aad6734441b778b27a1",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/957e1446d41cb3bdb7a20aad6734441b778b27a1"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/037687c2ea1f1b81cc77b14c11ad529b30da4db5",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/037687c2ea1f1b81cc77b14c11ad529b30da4db5",
            "html_url": "https://github.com/apache/flink/commit/037687c2ea1f1b81cc77b14c11ad529b30da4db5",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/037687c2ea1f1b81cc77b14c11ad529b30da4db5/comments",
            "author": {
                "login": "rkhachatryan",
                "id": 3939322,
                "node_id": "MDQ6VXNlcjM5MzkzMjI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3939322?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rkhachatryan",
                "html_url": "https://github.com/rkhachatryan",
                "followers_url": "https://api.github.com/users/rkhachatryan/followers",
                "following_url": "https://api.github.com/users/rkhachatryan/following{/other_user}",
                "gists_url": "https://api.github.com/users/rkhachatryan/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rkhachatryan/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rkhachatryan/subscriptions",
                "organizations_url": "https://api.github.com/users/rkhachatryan/orgs",
                "repos_url": "https://api.github.com/users/rkhachatryan/repos",
                "events_url": "https://api.github.com/users/rkhachatryan/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rkhachatryan/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "rkhachatryan",
                "id": 3939322,
                "node_id": "MDQ6VXNlcjM5MzkzMjI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3939322?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rkhachatryan",
                "html_url": "https://github.com/rkhachatryan",
                "followers_url": "https://api.github.com/users/rkhachatryan/followers",
                "following_url": "https://api.github.com/users/rkhachatryan/following{/other_user}",
                "gists_url": "https://api.github.com/users/rkhachatryan/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rkhachatryan/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rkhachatryan/subscriptions",
                "organizations_url": "https://api.github.com/users/rkhachatryan/orgs",
                "repos_url": "https://api.github.com/users/rkhachatryan/repos",
                "events_url": "https://api.github.com/users/rkhachatryan/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rkhachatryan/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "1fa52e1a93d025bc8482987ddac04c94142fc6cc",
                "url": "https://api.github.com/repos/apache/flink/commits/1fa52e1a93d025bc8482987ddac04c94142fc6cc",
                "html_url": "https://github.com/apache/flink/commit/1fa52e1a93d025bc8482987ddac04c94142fc6cc"
            }]
        },
        {
            "sha": "17a294daacdc67b1939607a41e67e56af2fa6888",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MTdhMjk0ZGFhY2RjNjdiMTkzOTYwN2E0MWU2N2U1NmFmMmZhNjg4OA==",
            "commit": {
                "author": {
                    "name": "Stephan Ewen",
                    "email": "sewen@apache.org",
                    "date": "2021-07-13T12:36:32Z"
                },
                "committer": {
                    "name": "Stephan Ewen",
                    "email": "sewen@apache.org",
                    "date": "2021-07-13T22:07:47Z"
                },
                "message": "[FLINK-22545][coordination] Fix check during creation of Source Coordinator thread.\n\nThe check was meant as a safeguard to prevent re-instantiation after fatal errors killed a previous thread.\nBut the check was susceptible to thread termination due to idleness in the executor.\n\nThis updates the check to only fail if there is in fact an instantiation next to a running thread, or after a\npreviously crashed thread.",
                "tree": {
                    "sha": "01f806b057c2c3be75876b6b6bb5beeafddb4b34",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/01f806b057c2c3be75876b6b6bb5beeafddb4b34"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/17a294daacdc67b1939607a41e67e56af2fa6888",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/17a294daacdc67b1939607a41e67e56af2fa6888",
            "html_url": "https://github.com/apache/flink/commit/17a294daacdc67b1939607a41e67e56af2fa6888",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/17a294daacdc67b1939607a41e67e56af2fa6888/comments",
            "author": {
                "login": "StephanEwen",
                "id": 1727146,
                "node_id": "MDQ6VXNlcjE3MjcxNDY=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1727146?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/StephanEwen",
                "html_url": "https://github.com/StephanEwen",
                "followers_url": "https://api.github.com/users/StephanEwen/followers",
                "following_url": "https://api.github.com/users/StephanEwen/following{/other_user}",
                "gists_url": "https://api.github.com/users/StephanEwen/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/StephanEwen/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/StephanEwen/subscriptions",
                "organizations_url": "https://api.github.com/users/StephanEwen/orgs",
                "repos_url": "https://api.github.com/users/StephanEwen/repos",
                "events_url": "https://api.github.com/users/StephanEwen/events{/privacy}",
                "received_events_url": "https://api.github.com/users/StephanEwen/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "StephanEwen",
                "id": 1727146,
                "node_id": "MDQ6VXNlcjE3MjcxNDY=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1727146?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/StephanEwen",
                "html_url": "https://github.com/StephanEwen",
                "followers_url": "https://api.github.com/users/StephanEwen/followers",
                "following_url": "https://api.github.com/users/StephanEwen/following{/other_user}",
                "gists_url": "https://api.github.com/users/StephanEwen/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/StephanEwen/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/StephanEwen/subscriptions",
                "organizations_url": "https://api.github.com/users/StephanEwen/orgs",
                "repos_url": "https://api.github.com/users/StephanEwen/repos",
                "events_url": "https://api.github.com/users/StephanEwen/events{/privacy}",
                "received_events_url": "https://api.github.com/users/StephanEwen/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "037687c2ea1f1b81cc77b14c11ad529b30da4db5",
                "url": "https://api.github.com/repos/apache/flink/commits/037687c2ea1f1b81cc77b14c11ad529b30da4db5",
                "html_url": "https://github.com/apache/flink/commit/037687c2ea1f1b81cc77b14c11ad529b30da4db5"
            }]
        },
        {
            "sha": "361877021d5ad9d6b9f076f4cffbe0472262cd8f",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MzYxODc3MDIxZDVhZDlkNmI5ZjA3NmY0Y2ZmYmUwNDcyMjYyY2Q4Zg==",
            "commit": {
                "author": {
                    "name": "Nico Kruber",
                    "email": "nico@ververica.com",
                    "date": "2021-06-16T16:16:32Z"
                },
                "committer": {
                    "name": "Nico Kruber",
                    "email": "nico.kruber@gmail.com",
                    "date": "2021-07-14T08:08:49Z"
                },
                "message": "[FLINK-23312][ci] speed up compilation for e2e tests\n\nThe \"compile\" builder already applies all checks so we can use -Dfast here;\nalso, the web UI is not actually needed in the E2E tests.",
                "tree": {
                    "sha": "91418431c4f99bc4dcab689ab076f6b01c680e4b",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/91418431c4f99bc4dcab689ab076f6b01c680e4b"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/361877021d5ad9d6b9f076f4cffbe0472262cd8f",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/361877021d5ad9d6b9f076f4cffbe0472262cd8f",
            "html_url": "https://github.com/apache/flink/commit/361877021d5ad9d6b9f076f4cffbe0472262cd8f",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/361877021d5ad9d6b9f076f4cffbe0472262cd8f/comments",
            "author": {
                "login": "NicoK",
                "id": 213026,
                "node_id": "MDQ6VXNlcjIxMzAyNg==",
                "avatar_url": "https://avatars.githubusercontent.com/u/213026?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/NicoK",
                "html_url": "https://github.com/NicoK",
                "followers_url": "https://api.github.com/users/NicoK/followers",
                "following_url": "https://api.github.com/users/NicoK/following{/other_user}",
                "gists_url": "https://api.github.com/users/NicoK/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/NicoK/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/NicoK/subscriptions",
                "organizations_url": "https://api.github.com/users/NicoK/orgs",
                "repos_url": "https://api.github.com/users/NicoK/repos",
                "events_url": "https://api.github.com/users/NicoK/events{/privacy}",
                "received_events_url": "https://api.github.com/users/NicoK/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "NicoK",
                "id": 213026,
                "node_id": "MDQ6VXNlcjIxMzAyNg==",
                "avatar_url": "https://avatars.githubusercontent.com/u/213026?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/NicoK",
                "html_url": "https://github.com/NicoK",
                "followers_url": "https://api.github.com/users/NicoK/followers",
                "following_url": "https://api.github.com/users/NicoK/following{/other_user}",
                "gists_url": "https://api.github.com/users/NicoK/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/NicoK/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/NicoK/subscriptions",
                "organizations_url": "https://api.github.com/users/NicoK/orgs",
                "repos_url": "https://api.github.com/users/NicoK/repos",
                "events_url": "https://api.github.com/users/NicoK/events{/privacy}",
                "received_events_url": "https://api.github.com/users/NicoK/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "17a294daacdc67b1939607a41e67e56af2fa6888",
                "url": "https://api.github.com/repos/apache/flink/commits/17a294daacdc67b1939607a41e67e56af2fa6888",
                "html_url": "https://github.com/apache/flink/commit/17a294daacdc67b1939607a41e67e56af2fa6888"
            }]
        },
        {
            "sha": "950ea33cb6ec5716ff26750eddf8a7bd4b869d0e",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6OTUwZWEzM2NiNmVjNTcxNmZmMjY3NTBlZGRmOGE3YmQ0Yjg2OWQwZQ==",
            "commit": {
                "author": {
                    "name": "Stephan Ewen",
                    "email": "sewen@apache.org",
                    "date": "2021-07-13T15:01:39Z"
                },
                "committer": {
                    "name": "Stephan Ewen",
                    "email": "sewen@apache.org",
                    "date": "2021-07-14T14:26:34Z"
                },
                "message": "[FLINK-22547][tests] Harden OperatorCoordinatorHolderTest.\n\nEnsure that the 'FutureCompletedAfterSendingEventsCoordinator' cannot exit before it has completed\nthe triggered checkpoint (completed the checkpoint future).",
                "tree": {
                    "sha": "12466bf989b6c01f1c82f0d4c92c06775c9b3054",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/12466bf989b6c01f1c82f0d4c92c06775c9b3054"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/950ea33cb6ec5716ff26750eddf8a7bd4b869d0e",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/950ea33cb6ec5716ff26750eddf8a7bd4b869d0e",
            "html_url": "https://github.com/apache/flink/commit/950ea33cb6ec5716ff26750eddf8a7bd4b869d0e",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/950ea33cb6ec5716ff26750eddf8a7bd4b869d0e/comments",
            "author": {
                "login": "StephanEwen",
                "id": 1727146,
                "node_id": "MDQ6VXNlcjE3MjcxNDY=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1727146?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/StephanEwen",
                "html_url": "https://github.com/StephanEwen",
                "followers_url": "https://api.github.com/users/StephanEwen/followers",
                "following_url": "https://api.github.com/users/StephanEwen/following{/other_user}",
                "gists_url": "https://api.github.com/users/StephanEwen/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/StephanEwen/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/StephanEwen/subscriptions",
                "organizations_url": "https://api.github.com/users/StephanEwen/orgs",
                "repos_url": "https://api.github.com/users/StephanEwen/repos",
                "events_url": "https://api.github.com/users/StephanEwen/events{/privacy}",
                "received_events_url": "https://api.github.com/users/StephanEwen/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "StephanEwen",
                "id": 1727146,
                "node_id": "MDQ6VXNlcjE3MjcxNDY=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1727146?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/StephanEwen",
                "html_url": "https://github.com/StephanEwen",
                "followers_url": "https://api.github.com/users/StephanEwen/followers",
                "following_url": "https://api.github.com/users/StephanEwen/following{/other_user}",
                "gists_url": "https://api.github.com/users/StephanEwen/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/StephanEwen/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/StephanEwen/subscriptions",
                "organizations_url": "https://api.github.com/users/StephanEwen/orgs",
                "repos_url": "https://api.github.com/users/StephanEwen/repos",
                "events_url": "https://api.github.com/users/StephanEwen/events{/privacy}",
                "received_events_url": "https://api.github.com/users/StephanEwen/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "361877021d5ad9d6b9f076f4cffbe0472262cd8f",
                "url": "https://api.github.com/repos/apache/flink/commits/361877021d5ad9d6b9f076f4cffbe0472262cd8f",
                "html_url": "https://github.com/apache/flink/commit/361877021d5ad9d6b9f076f4cffbe0472262cd8f"
            }]
        },
        {
            "sha": "1db1112fa0e5e5e51be00e2b0bdceab76d5ce3e3",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MWRiMTExMmZhMGU1ZTVlNTFiZTAwZTJiMGJkY2VhYjc2ZDVjZTNlMw==",
            "commit": {
                "author": {
                    "name": "Ingo Bürk",
                    "email": "ingo.buerk@tngtech.com",
                    "date": "2021-07-06T12:01:46Z"
                },
                "committer": {
                    "name": "Timo Walther",
                    "email": "twalthr@apache.org",
                    "date": "2021-07-15T06:26:32Z"
                },
                "message": "[FLINK-23188][table-planner] Preserve function identifier during filter pushdown\n\nWhen a source implements SupportsFilterPushdown, filters are converted from\nRexNode to Expression, and rejected filters are subsequently converted\nback. However, during this conversion the function identifier for built-in\nfunctions was lost, causing an exception downstream.\n\nThis closes #16396.",
                "tree": {
                    "sha": "230ab43881f2de2e00213bd3abc383cd0c9a2067",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/230ab43881f2de2e00213bd3abc383cd0c9a2067"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/1db1112fa0e5e5e51be00e2b0bdceab76d5ce3e3",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/1db1112fa0e5e5e51be00e2b0bdceab76d5ce3e3",
            "html_url": "https://github.com/apache/flink/commit/1db1112fa0e5e5e51be00e2b0bdceab76d5ce3e3",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/1db1112fa0e5e5e51be00e2b0bdceab76d5ce3e3/comments",
            "author": {
                "login": "Airblader",
                "id": 2392216,
                "node_id": "MDQ6VXNlcjIzOTIyMTY=",
                "avatar_url": "https://avatars.githubusercontent.com/u/2392216?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/Airblader",
                "html_url": "https://github.com/Airblader",
                "followers_url": "https://api.github.com/users/Airblader/followers",
                "following_url": "https://api.github.com/users/Airblader/following{/other_user}",
                "gists_url": "https://api.github.com/users/Airblader/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/Airblader/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/Airblader/subscriptions",
                "organizations_url": "https://api.github.com/users/Airblader/orgs",
                "repos_url": "https://api.github.com/users/Airblader/repos",
                "events_url": "https://api.github.com/users/Airblader/events{/privacy}",
                "received_events_url": "https://api.github.com/users/Airblader/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "twalthr",
                "id": 5746567,
                "node_id": "MDQ6VXNlcjU3NDY1Njc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5746567?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/twalthr",
                "html_url": "https://github.com/twalthr",
                "followers_url": "https://api.github.com/users/twalthr/followers",
                "following_url": "https://api.github.com/users/twalthr/following{/other_user}",
                "gists_url": "https://api.github.com/users/twalthr/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/twalthr/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/twalthr/subscriptions",
                "organizations_url": "https://api.github.com/users/twalthr/orgs",
                "repos_url": "https://api.github.com/users/twalthr/repos",
                "events_url": "https://api.github.com/users/twalthr/events{/privacy}",
                "received_events_url": "https://api.github.com/users/twalthr/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "950ea33cb6ec5716ff26750eddf8a7bd4b869d0e",
                "url": "https://api.github.com/repos/apache/flink/commits/950ea33cb6ec5716ff26750eddf8a7bd4b869d0e",
                "html_url": "https://github.com/apache/flink/commit/950ea33cb6ec5716ff26750eddf8a7bd4b869d0e"
            }]
        },
        {
            "sha": "004d3b58e4f4637efb09e3c7c84f01c3bd64ad9f",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MDA0ZDNiNThlNGY0NjM3ZWZiMDllM2M3Yzg0ZjAxYzNiZDY0YWQ5Zg==",
            "commit": {
                "author": {
                    "name": "yuxia Luo",
                    "email": "luoyuxia.luoyuxia@alibaba-inc.com",
                    "date": "2021-07-08T07:54:24Z"
                },
                "committer": {
                    "name": "Rui Li",
                    "email": "lirui@apache.org",
                    "date": "2021-07-15T11:39:50Z"
                },
                "message": "[FLINK-22898][Connectors/Hive] return default-parallelism in HiveParallelismInference when there is no source infer\n\nThis closes #16421",
                "tree": {
                    "sha": "0e910407c84e0222dd72d55ae5c562456624f20d",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/0e910407c84e0222dd72d55ae5c562456624f20d"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/004d3b58e4f4637efb09e3c7c84f01c3bd64ad9f",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/004d3b58e4f4637efb09e3c7c84f01c3bd64ad9f",
            "html_url": "https://github.com/apache/flink/commit/004d3b58e4f4637efb09e3c7c84f01c3bd64ad9f",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/004d3b58e4f4637efb09e3c7c84f01c3bd64ad9f/comments",
            "author": {
                "login": "luoyuxia",
                "id": 20389154,
                "node_id": "MDQ6VXNlcjIwMzg5MTU0",
                "avatar_url": "https://avatars.githubusercontent.com/u/20389154?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/luoyuxia",
                "html_url": "https://github.com/luoyuxia",
                "followers_url": "https://api.github.com/users/luoyuxia/followers",
                "following_url": "https://api.github.com/users/luoyuxia/following{/other_user}",
                "gists_url": "https://api.github.com/users/luoyuxia/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/luoyuxia/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/luoyuxia/subscriptions",
                "organizations_url": "https://api.github.com/users/luoyuxia/orgs",
                "repos_url": "https://api.github.com/users/luoyuxia/repos",
                "events_url": "https://api.github.com/users/luoyuxia/events{/privacy}",
                "received_events_url": "https://api.github.com/users/luoyuxia/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "lirui-apache",
                "id": 5210788,
                "node_id": "MDQ6VXNlcjUyMTA3ODg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5210788?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/lirui-apache",
                "html_url": "https://github.com/lirui-apache",
                "followers_url": "https://api.github.com/users/lirui-apache/followers",
                "following_url": "https://api.github.com/users/lirui-apache/following{/other_user}",
                "gists_url": "https://api.github.com/users/lirui-apache/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/lirui-apache/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/lirui-apache/subscriptions",
                "organizations_url": "https://api.github.com/users/lirui-apache/orgs",
                "repos_url": "https://api.github.com/users/lirui-apache/repos",
                "events_url": "https://api.github.com/users/lirui-apache/events{/privacy}",
                "received_events_url": "https://api.github.com/users/lirui-apache/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "1db1112fa0e5e5e51be00e2b0bdceab76d5ce3e3",
                "url": "https://api.github.com/repos/apache/flink/commits/1db1112fa0e5e5e51be00e2b0bdceab76d5ce3e3",
                "html_url": "https://github.com/apache/flink/commit/1db1112fa0e5e5e51be00e2b0bdceab76d5ce3e3"
            }]
        },
        {
            "sha": "7c6b0265e954da45386042bd2ead0102aabe2d1d",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6N2M2YjAyNjVlOTU0ZGE0NTM4NjA0MmJkMmVhZDAxMDJhYWJlMmQxZA==",
            "commit": {
                "author": {
                    "name": "Anton Kalashnikov",
                    "email": "kaa.dev@yandex.ru",
                    "date": "2021-07-15T09:30:52Z"
                },
                "committer": {
                    "name": "Dawid Wysakowicz",
                    "email": "dwysakowicz@apache.org",
                    "date": "2021-07-15T15:14:39Z"
                },
                "message": "[FLINK-23201][streaming] Calculate checkpoint alignment time only for last started checkpoint",
                "tree": {
                    "sha": "d445c5e37bc06a5e2a5bf48cd672bea00df6af62",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/d445c5e37bc06a5e2a5bf48cd672bea00df6af62"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/7c6b0265e954da45386042bd2ead0102aabe2d1d",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/7c6b0265e954da45386042bd2ead0102aabe2d1d",
            "html_url": "https://github.com/apache/flink/commit/7c6b0265e954da45386042bd2ead0102aabe2d1d",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/7c6b0265e954da45386042bd2ead0102aabe2d1d/comments",
            "author": {
                "login": "akalash",
                "id": 3996532,
                "node_id": "MDQ6VXNlcjM5OTY1MzI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3996532?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/akalash",
                "html_url": "https://github.com/akalash",
                "followers_url": "https://api.github.com/users/akalash/followers",
                "following_url": "https://api.github.com/users/akalash/following{/other_user}",
                "gists_url": "https://api.github.com/users/akalash/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/akalash/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/akalash/subscriptions",
                "organizations_url": "https://api.github.com/users/akalash/orgs",
                "repos_url": "https://api.github.com/users/akalash/repos",
                "events_url": "https://api.github.com/users/akalash/events{/privacy}",
                "received_events_url": "https://api.github.com/users/akalash/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "dawidwys",
                "id": 6242259,
                "node_id": "MDQ6VXNlcjYyNDIyNTk=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6242259?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dawidwys",
                "html_url": "https://github.com/dawidwys",
                "followers_url": "https://api.github.com/users/dawidwys/followers",
                "following_url": "https://api.github.com/users/dawidwys/following{/other_user}",
                "gists_url": "https://api.github.com/users/dawidwys/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dawidwys/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dawidwys/subscriptions",
                "organizations_url": "https://api.github.com/users/dawidwys/orgs",
                "repos_url": "https://api.github.com/users/dawidwys/repos",
                "events_url": "https://api.github.com/users/dawidwys/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dawidwys/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "004d3b58e4f4637efb09e3c7c84f01c3bd64ad9f",
                "url": "https://api.github.com/repos/apache/flink/commits/004d3b58e4f4637efb09e3c7c84f01c3bd64ad9f",
                "html_url": "https://github.com/apache/flink/commit/004d3b58e4f4637efb09e3c7c84f01c3bd64ad9f"
            }]
        },
        {
            "sha": "b6d89fe5d5ed6daefe75657e9c6bf75dfadb07bb",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6YjZkODlmZTVkNWVkNmRhZWZlNzU2NTdlOWM2YmY3NWRmYWRiMDdiYg==",
            "commit": {
                "author": {
                    "name": "Anton Kalashnikov",
                    "email": "kaa.dev@yandex.ru",
                    "date": "2021-07-15T09:34:25Z"
                },
                "committer": {
                    "name": "Dawid Wysakowicz",
                    "email": "dwysakowicz@apache.org",
                    "date": "2021-07-15T15:14:39Z"
                },
                "message": "[FLINK-23201][streaming] Reset alignment only for the currently processed checkpoint",
                "tree": {
                    "sha": "7862ef7446ec03b0fbb6047bfe30ebddc6b3284c",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/7862ef7446ec03b0fbb6047bfe30ebddc6b3284c"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/b6d89fe5d5ed6daefe75657e9c6bf75dfadb07bb",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/b6d89fe5d5ed6daefe75657e9c6bf75dfadb07bb",
            "html_url": "https://github.com/apache/flink/commit/b6d89fe5d5ed6daefe75657e9c6bf75dfadb07bb",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/b6d89fe5d5ed6daefe75657e9c6bf75dfadb07bb/comments",
            "author": {
                "login": "akalash",
                "id": 3996532,
                "node_id": "MDQ6VXNlcjM5OTY1MzI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3996532?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/akalash",
                "html_url": "https://github.com/akalash",
                "followers_url": "https://api.github.com/users/akalash/followers",
                "following_url": "https://api.github.com/users/akalash/following{/other_user}",
                "gists_url": "https://api.github.com/users/akalash/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/akalash/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/akalash/subscriptions",
                "organizations_url": "https://api.github.com/users/akalash/orgs",
                "repos_url": "https://api.github.com/users/akalash/repos",
                "events_url": "https://api.github.com/users/akalash/events{/privacy}",
                "received_events_url": "https://api.github.com/users/akalash/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "dawidwys",
                "id": 6242259,
                "node_id": "MDQ6VXNlcjYyNDIyNTk=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6242259?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dawidwys",
                "html_url": "https://github.com/dawidwys",
                "followers_url": "https://api.github.com/users/dawidwys/followers",
                "following_url": "https://api.github.com/users/dawidwys/following{/other_user}",
                "gists_url": "https://api.github.com/users/dawidwys/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dawidwys/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dawidwys/subscriptions",
                "organizations_url": "https://api.github.com/users/dawidwys/orgs",
                "repos_url": "https://api.github.com/users/dawidwys/repos",
                "events_url": "https://api.github.com/users/dawidwys/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dawidwys/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "7c6b0265e954da45386042bd2ead0102aabe2d1d",
                "url": "https://api.github.com/repos/apache/flink/commits/7c6b0265e954da45386042bd2ead0102aabe2d1d",
                "html_url": "https://github.com/apache/flink/commit/7c6b0265e954da45386042bd2ead0102aabe2d1d"
            }]
        },
        {
            "sha": "7b8621fe37a3feb220d3f8e8f91defdebe7a2d36",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6N2I4NjIxZmUzN2EzZmViMjIwZDNmOGU4ZjkxZGVmZGViZTdhMmQzNg==",
            "commit": {
                "author": {
                    "name": "Dian Fu",
                    "email": "dianfu@apache.org",
                    "date": "2021-07-19T02:56:33Z"
                },
                "committer": {
                    "name": "Dian Fu",
                    "email": "dianfu@apache.org",
                    "date": "2021-07-19T02:57:18Z"
                },
                "message": "[hotfix][python][docs] Correct the docs of interval join",
                "tree": {
                    "sha": "3725142c145173c7d507cde10d43adb382733771",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/3725142c145173c7d507cde10d43adb382733771"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/7b8621fe37a3feb220d3f8e8f91defdebe7a2d36",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/7b8621fe37a3feb220d3f8e8f91defdebe7a2d36",
            "html_url": "https://github.com/apache/flink/commit/7b8621fe37a3feb220d3f8e8f91defdebe7a2d36",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/7b8621fe37a3feb220d3f8e8f91defdebe7a2d36/comments",
            "author": {
                "login": "dianfu",
                "id": 5466492,
                "node_id": "MDQ6VXNlcjU0NjY0OTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5466492?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dianfu",
                "html_url": "https://github.com/dianfu",
                "followers_url": "https://api.github.com/users/dianfu/followers",
                "following_url": "https://api.github.com/users/dianfu/following{/other_user}",
                "gists_url": "https://api.github.com/users/dianfu/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dianfu/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dianfu/subscriptions",
                "organizations_url": "https://api.github.com/users/dianfu/orgs",
                "repos_url": "https://api.github.com/users/dianfu/repos",
                "events_url": "https://api.github.com/users/dianfu/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dianfu/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "dianfu",
                "id": 5466492,
                "node_id": "MDQ6VXNlcjU0NjY0OTI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5466492?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dianfu",
                "html_url": "https://github.com/dianfu",
                "followers_url": "https://api.github.com/users/dianfu/followers",
                "following_url": "https://api.github.com/users/dianfu/following{/other_user}",
                "gists_url": "https://api.github.com/users/dianfu/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dianfu/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dianfu/subscriptions",
                "organizations_url": "https://api.github.com/users/dianfu/orgs",
                "repos_url": "https://api.github.com/users/dianfu/repos",
                "events_url": "https://api.github.com/users/dianfu/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dianfu/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "b6d89fe5d5ed6daefe75657e9c6bf75dfadb07bb",
                "url": "https://api.github.com/repos/apache/flink/commits/b6d89fe5d5ed6daefe75657e9c6bf75dfadb07bb",
                "html_url": "https://github.com/apache/flink/commit/b6d89fe5d5ed6daefe75657e9c6bf75dfadb07bb"
            }]
        },
        {
            "sha": "a6b823498aa77e3de5ff34e191e3a2e3d42f3620",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6YTZiODIzNDk4YWE3N2UzZGU1ZmYzNGUxOTFlM2EyZTNkNDJmMzYyMA==",
            "commit": {
                "author": {
                    "name": "Rui Li",
                    "email": "lirui@apache.org",
                    "date": "2021-07-13T02:52:56Z"
                },
                "committer": {
                    "name": "Rui Li",
                    "email": "lirui@apache.org",
                    "date": "2021-07-19T12:49:26Z"
                },
                "message": "[FLINK-20975][hive][tests] Allow integral partition filter pushdown\n\nThis closes #16475",
                "tree": {
                    "sha": "d7cf256cb101ce01b4387f780830cfdc8d8dc9aa",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/d7cf256cb101ce01b4387f780830cfdc8d8dc9aa"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/a6b823498aa77e3de5ff34e191e3a2e3d42f3620",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/a6b823498aa77e3de5ff34e191e3a2e3d42f3620",
            "html_url": "https://github.com/apache/flink/commit/a6b823498aa77e3de5ff34e191e3a2e3d42f3620",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/a6b823498aa77e3de5ff34e191e3a2e3d42f3620/comments",
            "author": {
                "login": "lirui-apache",
                "id": 5210788,
                "node_id": "MDQ6VXNlcjUyMTA3ODg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5210788?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/lirui-apache",
                "html_url": "https://github.com/lirui-apache",
                "followers_url": "https://api.github.com/users/lirui-apache/followers",
                "following_url": "https://api.github.com/users/lirui-apache/following{/other_user}",
                "gists_url": "https://api.github.com/users/lirui-apache/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/lirui-apache/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/lirui-apache/subscriptions",
                "organizations_url": "https://api.github.com/users/lirui-apache/orgs",
                "repos_url": "https://api.github.com/users/lirui-apache/repos",
                "events_url": "https://api.github.com/users/lirui-apache/events{/privacy}",
                "received_events_url": "https://api.github.com/users/lirui-apache/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "lirui-apache",
                "id": 5210788,
                "node_id": "MDQ6VXNlcjUyMTA3ODg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5210788?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/lirui-apache",
                "html_url": "https://github.com/lirui-apache",
                "followers_url": "https://api.github.com/users/lirui-apache/followers",
                "following_url": "https://api.github.com/users/lirui-apache/following{/other_user}",
                "gists_url": "https://api.github.com/users/lirui-apache/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/lirui-apache/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/lirui-apache/subscriptions",
                "organizations_url": "https://api.github.com/users/lirui-apache/orgs",
                "repos_url": "https://api.github.com/users/lirui-apache/repos",
                "events_url": "https://api.github.com/users/lirui-apache/events{/privacy}",
                "received_events_url": "https://api.github.com/users/lirui-apache/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "7b8621fe37a3feb220d3f8e8f91defdebe7a2d36",
                "url": "https://api.github.com/repos/apache/flink/commits/7b8621fe37a3feb220d3f8e8f91defdebe7a2d36",
                "html_url": "https://github.com/apache/flink/commit/7b8621fe37a3feb220d3f8e8f91defdebe7a2d36"
            }]
        },
        {
            "sha": "bfb55d9c8de63883044529bd99abb69449327b41",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6YmZiNTVkOWM4ZGU2Mzg4MzA0NDUyOWJkOTlhYmI2OTQ0OTMyN2I0MQ==",
            "commit": {
                "author": {
                    "name": "Roman Khachatryan",
                    "email": "khachatryan.roman@gmail.com",
                    "date": "2021-07-14T07:56:45Z"
                },
                "committer": {
                    "name": "Roman Khachatryan",
                    "email": "khachatryan.roman@gmail.com",
                    "date": "2021-07-20T08:45:31Z"
                },
                "message": "[hotfix] Avoid excessive logging in DeclarativeSlotPoolBridge",
                "tree": {
                    "sha": "eb6b401d9236629f4913db035fa5f429ab3fb965",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/eb6b401d9236629f4913db035fa5f429ab3fb965"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/bfb55d9c8de63883044529bd99abb69449327b41",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/bfb55d9c8de63883044529bd99abb69449327b41",
            "html_url": "https://github.com/apache/flink/commit/bfb55d9c8de63883044529bd99abb69449327b41",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/bfb55d9c8de63883044529bd99abb69449327b41/comments",
            "author": {
                "login": "rkhachatryan",
                "id": 3939322,
                "node_id": "MDQ6VXNlcjM5MzkzMjI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3939322?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rkhachatryan",
                "html_url": "https://github.com/rkhachatryan",
                "followers_url": "https://api.github.com/users/rkhachatryan/followers",
                "following_url": "https://api.github.com/users/rkhachatryan/following{/other_user}",
                "gists_url": "https://api.github.com/users/rkhachatryan/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rkhachatryan/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rkhachatryan/subscriptions",
                "organizations_url": "https://api.github.com/users/rkhachatryan/orgs",
                "repos_url": "https://api.github.com/users/rkhachatryan/repos",
                "events_url": "https://api.github.com/users/rkhachatryan/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rkhachatryan/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "rkhachatryan",
                "id": 3939322,
                "node_id": "MDQ6VXNlcjM5MzkzMjI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/3939322?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/rkhachatryan",
                "html_url": "https://github.com/rkhachatryan",
                "followers_url": "https://api.github.com/users/rkhachatryan/followers",
                "following_url": "https://api.github.com/users/rkhachatryan/following{/other_user}",
                "gists_url": "https://api.github.com/users/rkhachatryan/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/rkhachatryan/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/rkhachatryan/subscriptions",
                "organizations_url": "https://api.github.com/users/rkhachatryan/orgs",
                "repos_url": "https://api.github.com/users/rkhachatryan/repos",
                "events_url": "https://api.github.com/users/rkhachatryan/events{/privacy}",
                "received_events_url": "https://api.github.com/users/rkhachatryan/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "a6b823498aa77e3de5ff34e191e3a2e3d42f3620",
                "url": "https://api.github.com/repos/apache/flink/commits/a6b823498aa77e3de5ff34e191e3a2e3d42f3620",
                "html_url": "https://github.com/apache/flink/commit/a6b823498aa77e3de5ff34e191e3a2e3d42f3620"
            }]
        },
        {
            "sha": "9973de3a5e639a5ef850c63a55a9dde9206b5c08",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6OTk3M2RlM2E1ZTYzOWE1ZWY4NTBjNjNhNTVhOWRkZTkyMDZiNWMwOA==",
            "commit": {
                "author": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-07-20T13:23:17Z"
                },
                "committer": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-07-20T13:25:20Z"
                },
                "message": "[hotfix][conf] Correct config option reference in resourcemanager.standalone.start-up-time",
                "tree": {
                    "sha": "72883f8845e500724198672124669db6ae92e4fe",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/72883f8845e500724198672124669db6ae92e4fe"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/9973de3a5e639a5ef850c63a55a9dde9206b5c08",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEEuUmfpp7/Xe7rw8H1un5Bh8b3PYIFAmD2zsAACgkQun5Bh8b3\nPYJMqhAAiaSdo64iZeKRbooJDhd+yEO5V7yJTmbWqAiLVE7/cak2zlP/A0ZiCYmq\n0rrsBqlwFDI9uRSuQmNoEXPNwEETzISTcGolXeJ4hErbsc1QrSCY6uHzGdjEKZij\nmo5oCf9hZvOCxPXTz/j6JbMKi8+sN3e/8W4Yc9MF/G2C62yKXkOK0tRTffpaHXnA\nnHCU1BNUvSPMEOJX4bZlvyzSmezfv24+J8uOVN17PyTNOzTQglc0OnrWFq1iEK55\ng6YWkCmNjV3P/wjLZsNds5dS9Cu+TP5LSJJOJOJYmjjDU3bXsYelM4imOLy7XVc/\nR32XV5rIxLoSfU1GTMwi9tE5IQPN/NRYFOBzF5aiYRifpL3QHj/xML9Nak6ZnloX\nKlU9gVBkRWzEW3LB2uwwGrDFn3Q7AkzEqWBB+yxZ7aefWioxX56Wl0K6Hlu0RSMp\nG99OcIys+EkoR3iBkHBLZpQzsRkJxW4iIScSvvBd1174mNzvziWDGo4e0uQBqk4o\nQWBj1C5cvKuHXewL/oWaKJ8k61z/NlwsT7HM0OLk+0klJ9GriqjuVWbwgxWZdXlD\ncIrzL/W6kzUe42Z7SuKw3LURhoYPYTYNQYW7Vua0hmMowm5B8r6pAEZO/ftfVplj\nc43q+2VAV7lEN2kx4rZ0c7EASlAQTMI7NwWDDrpN/bEHeOYq+KI=\n=uUse\n-----END PGP SIGNATURE-----",
                    "payload": "tree 72883f8845e500724198672124669db6ae92e4fe\nparent bfb55d9c8de63883044529bd99abb69449327b41\nauthor Till Rohrmann <trohrmann@apache.org> 1626787397 +0200\ncommitter Till Rohrmann <trohrmann@apache.org> 1626787520 +0200\n\n[hotfix][conf] Correct config option reference in resourcemanager.standalone.start-up-time\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/9973de3a5e639a5ef850c63a55a9dde9206b5c08",
            "html_url": "https://github.com/apache/flink/commit/9973de3a5e639a5ef850c63a55a9dde9206b5c08",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/9973de3a5e639a5ef850c63a55a9dde9206b5c08/comments",
            "author": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "bfb55d9c8de63883044529bd99abb69449327b41",
                "url": "https://api.github.com/repos/apache/flink/commits/bfb55d9c8de63883044529bd99abb69449327b41",
                "html_url": "https://github.com/apache/flink/commit/bfb55d9c8de63883044529bd99abb69449327b41"
            }]
        },
        {
            "sha": "dd2945d73849a3bedf4f390a5ea8541f9815ce6e",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZGQyOTQ1ZDczODQ5YTNiZWRmNGYzOTBhNWVhODU0MWY5ODE1Y2U2ZQ==",
            "commit": {
                "author": {
                    "name": "Jun Qin",
                    "email": "11677043+qinjunjerry@users.noreply.github.com",
                    "date": "2021-07-21T06:54:52Z"
                },
                "committer": {
                    "name": "Seth Wiesman",
                    "email": "sjwiesman@gmail.com",
                    "date": "2021-07-21T14:08:20Z"
                },
                "message": "[FLINK-23429][state-processor-api] Use Path instead of Path.getPath() to preserve FileSystem info\n\nThis closes #16550",
                "tree": {
                    "sha": "e393f6ef971a6c2f7ff87269870fcb02b47a61f9",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/e393f6ef971a6c2f7ff87269870fcb02b47a61f9"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/dd2945d73849a3bedf4f390a5ea8541f9815ce6e",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/dd2945d73849a3bedf4f390a5ea8541f9815ce6e",
            "html_url": "https://github.com/apache/flink/commit/dd2945d73849a3bedf4f390a5ea8541f9815ce6e",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/dd2945d73849a3bedf4f390a5ea8541f9815ce6e/comments",
            "author": {
                "login": "qinjunjerry",
                "id": 11677043,
                "node_id": "MDQ6VXNlcjExNjc3MDQz",
                "avatar_url": "https://avatars.githubusercontent.com/u/11677043?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/qinjunjerry",
                "html_url": "https://github.com/qinjunjerry",
                "followers_url": "https://api.github.com/users/qinjunjerry/followers",
                "following_url": "https://api.github.com/users/qinjunjerry/following{/other_user}",
                "gists_url": "https://api.github.com/users/qinjunjerry/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/qinjunjerry/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/qinjunjerry/subscriptions",
                "organizations_url": "https://api.github.com/users/qinjunjerry/orgs",
                "repos_url": "https://api.github.com/users/qinjunjerry/repos",
                "events_url": "https://api.github.com/users/qinjunjerry/events{/privacy}",
                "received_events_url": "https://api.github.com/users/qinjunjerry/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "sjwiesman",
                "id": 1891970,
                "node_id": "MDQ6VXNlcjE4OTE5NzA=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1891970?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/sjwiesman",
                "html_url": "https://github.com/sjwiesman",
                "followers_url": "https://api.github.com/users/sjwiesman/followers",
                "following_url": "https://api.github.com/users/sjwiesman/following{/other_user}",
                "gists_url": "https://api.github.com/users/sjwiesman/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/sjwiesman/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/sjwiesman/subscriptions",
                "organizations_url": "https://api.github.com/users/sjwiesman/orgs",
                "repos_url": "https://api.github.com/users/sjwiesman/repos",
                "events_url": "https://api.github.com/users/sjwiesman/events{/privacy}",
                "received_events_url": "https://api.github.com/users/sjwiesman/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "9973de3a5e639a5ef850c63a55a9dde9206b5c08",
                "url": "https://api.github.com/repos/apache/flink/commits/9973de3a5e639a5ef850c63a55a9dde9206b5c08",
                "html_url": "https://github.com/apache/flink/commit/9973de3a5e639a5ef850c63a55a9dde9206b5c08"
            }]
        },
        {
            "sha": "f5bce736ac6138f9b9fd7d36f63578a54e28b23e",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZjViY2U3MzZhYzYxMzhmOWI5ZmQ3ZDM2ZjYzNTc4YTU0ZTI4YjIzZQ==",
            "commit": {
                "author": {
                    "name": "Yun Tang",
                    "email": "myasuka@live.com",
                    "date": "2021-07-22T09:44:24Z"
                },
                "committer": {
                    "name": "Till Rohrmann",
                    "email": "trohrmann@apache.org",
                    "date": "2021-07-22T17:21:21Z"
                },
                "message": "[FLINK-21411][rocksdb] Update FRocksDB to bump bzip2 dependency version\n\nThis closes #16569.",
                "tree": {
                    "sha": "ad5836a5b6fc620435fd7d22d38b08964a43764c",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/ad5836a5b6fc620435fd7d22d38b08964a43764c"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/f5bce736ac6138f9b9fd7d36f63578a54e28b23e",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEEuUmfpp7/Xe7rw8H1un5Bh8b3PYIFAmD5qRwACgkQun5Bh8b3\nPYIkng//b+Kp9MY94TkC4eQFG/mbW6nh4O9PNk3BBHs0+yr1WrDaP1oPFLBg8phi\nv9z9/zXUH9FWn0LsidwJr2ncEEIbnqcMq9GlBU2zh+fpDEbggt73Z+Mfg31wsFkr\nWI+KXcjvM6dsCSd+3/mgPYuK5t5SZpty6XdRAtNOc5YZW2eDeBNhT+yyI+rpMVeZ\nFcagq3NCz0mZBfIyKq2uB3W3KdSjp15b+f0vaNf6eIFG5XplsvAGZMslpyNfMNsW\n81DP8jfEPfCvLs+rbYucY6+9qVCNku3Ty/EgDdywsIYg2We6QAghygVOYwEO/SUA\nqd1KgAd1NRcwSsW4uE1OYbE4oUkaOHCl3qNrSbw9wH+bmHh8njfzHZ+ygqHUUOm5\n1Gfxok839M3KGKF7SCTq+9Zaxo/ooigLx/ejJ4W/QczRJgagkAIXr447KmNWGkHP\n+MMJ2G0mqRtgpXRmkD7ZX16P843C3f0/cdCm0HjsESqdU9iEdkha/oNKQGZGSh0J\nAtkS3WbD8gEJ0OIx7S8qGVFqE2MQUE5dGRNbONRYTol080qXiUFrAhXRJAPnpeKw\naytaN55Re8oN+NIUuzLlZ5w+53NRF1BpugUuQMgnR1yRKhK5jl/kSeuOCNPhZt8y\nq5aJ6gx44+hBDAWsRRMxXRI58OAR1YY4L91+ShB8UyDx7mPUCTQ=\n=THXj\n-----END PGP SIGNATURE-----",
                    "payload": "tree ad5836a5b6fc620435fd7d22d38b08964a43764c\nparent dd2945d73849a3bedf4f390a5ea8541f9815ce6e\nauthor Yun Tang <myasuka@live.com> 1626947064 +0800\ncommitter Till Rohrmann <trohrmann@apache.org> 1626974481 +0200\n\n[FLINK-21411][rocksdb] Update FRocksDB to bump bzip2 dependency version\n\nThis closes #16569.\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/f5bce736ac6138f9b9fd7d36f63578a54e28b23e",
            "html_url": "https://github.com/apache/flink/commit/f5bce736ac6138f9b9fd7d36f63578a54e28b23e",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/f5bce736ac6138f9b9fd7d36f63578a54e28b23e/comments",
            "author": {
                "login": "Myasuka",
                "id": 1709104,
                "node_id": "MDQ6VXNlcjE3MDkxMDQ=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1709104?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/Myasuka",
                "html_url": "https://github.com/Myasuka",
                "followers_url": "https://api.github.com/users/Myasuka/followers",
                "following_url": "https://api.github.com/users/Myasuka/following{/other_user}",
                "gists_url": "https://api.github.com/users/Myasuka/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/Myasuka/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/Myasuka/subscriptions",
                "organizations_url": "https://api.github.com/users/Myasuka/orgs",
                "repos_url": "https://api.github.com/users/Myasuka/repos",
                "events_url": "https://api.github.com/users/Myasuka/events{/privacy}",
                "received_events_url": "https://api.github.com/users/Myasuka/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "tillrohrmann",
                "id": 5756858,
                "node_id": "MDQ6VXNlcjU3NTY4NTg=",
                "avatar_url": "https://avatars.githubusercontent.com/u/5756858?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tillrohrmann",
                "html_url": "https://github.com/tillrohrmann",
                "followers_url": "https://api.github.com/users/tillrohrmann/followers",
                "following_url": "https://api.github.com/users/tillrohrmann/following{/other_user}",
                "gists_url": "https://api.github.com/users/tillrohrmann/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tillrohrmann/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tillrohrmann/subscriptions",
                "organizations_url": "https://api.github.com/users/tillrohrmann/orgs",
                "repos_url": "https://api.github.com/users/tillrohrmann/repos",
                "events_url": "https://api.github.com/users/tillrohrmann/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tillrohrmann/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "dd2945d73849a3bedf4f390a5ea8541f9815ce6e",
                "url": "https://api.github.com/repos/apache/flink/commits/dd2945d73849a3bedf4f390a5ea8541f9815ce6e",
                "html_url": "https://github.com/apache/flink/commit/dd2945d73849a3bedf4f390a5ea8541f9815ce6e"
            }]
        },
        {
            "sha": "c8ad0ec1e5ad21da6b7663944d99f7e413aae0c9",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6YzhhZDBlYzFlNWFkMjFkYTZiNzY2Mzk0NGQ5OWY3ZTQxM2FhZTBjOQ==",
            "commit": {
                "author": {
                    "name": "godfreyhe",
                    "email": "godfreyhe@163.com",
                    "date": "2021-07-20T06:29:20Z"
                },
                "committer": {
                    "name": "godfreyhe",
                    "email": "godfreyhe@163.com",
                    "date": "2021-07-23T08:24:24Z"
                },
                "message": "[FLINK-23434][table-planner-blink] Fix the inconsistent type in IncrementalAggregateRule when the query has one distinct agg function and count star agg function\n\nThis closes #16560",
                "tree": {
                    "sha": "6d2e2e268947579469fc5b8bfc2f50258d5fdf62",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/6d2e2e268947579469fc5b8bfc2f50258d5fdf62"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/c8ad0ec1e5ad21da6b7663944d99f7e413aae0c9",
                "comment_count": 0,
                "verification": {
                    "verified": false,
                    "reason": "unsigned",
                    "signature": null,
                    "payload": null
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/c8ad0ec1e5ad21da6b7663944d99f7e413aae0c9",
            "html_url": "https://github.com/apache/flink/commit/c8ad0ec1e5ad21da6b7663944d99f7e413aae0c9",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/c8ad0ec1e5ad21da6b7663944d99f7e413aae0c9/comments",
            "author": {
                "login": "godfreyhe",
                "id": 8777671,
                "node_id": "MDQ6VXNlcjg3Nzc2NzE=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8777671?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/godfreyhe",
                "html_url": "https://github.com/godfreyhe",
                "followers_url": "https://api.github.com/users/godfreyhe/followers",
                "following_url": "https://api.github.com/users/godfreyhe/following{/other_user}",
                "gists_url": "https://api.github.com/users/godfreyhe/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/godfreyhe/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/godfreyhe/subscriptions",
                "organizations_url": "https://api.github.com/users/godfreyhe/orgs",
                "repos_url": "https://api.github.com/users/godfreyhe/repos",
                "events_url": "https://api.github.com/users/godfreyhe/events{/privacy}",
                "received_events_url": "https://api.github.com/users/godfreyhe/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "godfreyhe",
                "id": 8777671,
                "node_id": "MDQ6VXNlcjg3Nzc2NzE=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8777671?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/godfreyhe",
                "html_url": "https://github.com/godfreyhe",
                "followers_url": "https://api.github.com/users/godfreyhe/followers",
                "following_url": "https://api.github.com/users/godfreyhe/following{/other_user}",
                "gists_url": "https://api.github.com/users/godfreyhe/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/godfreyhe/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/godfreyhe/subscriptions",
                "organizations_url": "https://api.github.com/users/godfreyhe/orgs",
                "repos_url": "https://api.github.com/users/godfreyhe/repos",
                "events_url": "https://api.github.com/users/godfreyhe/events{/privacy}",
                "received_events_url": "https://api.github.com/users/godfreyhe/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "f5bce736ac6138f9b9fd7d36f63578a54e28b23e",
                "url": "https://api.github.com/repos/apache/flink/commits/f5bce736ac6138f9b9fd7d36f63578a54e28b23e",
                "html_url": "https://github.com/apache/flink/commit/f5bce736ac6138f9b9fd7d36f63578a54e28b23e"
            }]
        },
        {
            "sha": "ea2bddc8e82ab4b9797f40534b1e5637eef4c5b5",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6ZWEyYmRkYzhlODJhYjRiOTc5N2Y0MDUzNGIxZTU2MzdlZWY0YzViNQ==",
            "commit": {
                "author": {
                    "name": "Dawid Wysakowicz",
                    "email": "dwysakowicz@apache.org",
                    "date": "2021-07-23T15:04:51Z"
                },
                "committer": {
                    "name": "Dawid Wysakowicz",
                    "email": "dwysakowicz@apache.org",
                    "date": "2021-07-23T15:04:51Z"
                },
                "message": "Revert \"[FLINK-23434][table-planner-blink] Fix the inconsistent type in IncrementalAggregateRule when the query has one distinct agg function and count star agg function\"\n\nThis reverts commit c8ad0ec1e5ad21da6b7663944d99f7e413aae0c9.",
                "tree": {
                    "sha": "ad5836a5b6fc620435fd7d22d38b08964a43764c",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/ad5836a5b6fc620435fd7d22d38b08964a43764c"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/ea2bddc8e82ab4b9797f40534b1e5637eef4c5b5",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEE6pOkNbTiybTJ9TP2MdLdEL/BWi0FAmD62pUACgkQMdLdEL/B\nWi27gg//Ut2x1J145ov5oAp8zoZvS03+6xoWlDsagjnHSU7TWTKy9ohN3mdtfxqq\ncn0+wOBA1gDtOo7B7WAFpPjmb6bSCoZ+eCde0TWANnnhBL7e8Q+I2dYPIB8qUGFH\nlfixiuY0T+yNCgZNG/wa2ApE7HeXcOyQ/TaLMee54Nb3rwxky72kWqrn264zyl6f\nBXlAYekEYnA12MHhU31D6knKPmBlgnaxua+QV2+exvh+C8eWufLX94vvoD6rdbxD\nMlgsOafkD0ARBggCHSCEtk6xukVAJOYsd0pLFRGROb8crjytoDlJ28PnfDiu3hyA\nc+aJSOH8J7DIgPH+ja0WKScGEmge4FuTTWHCXcz7mEmDbjg2Z7R3ZXShPTk5E0bP\nAB2+Bevw5qEDxbMTTViJnAzvlVDgA24VcJTk9Nd2BfpZMXcQHvMxvbH9HXX5d4bP\nwZwWq6txgWoIpwApRHYHhR6FD+HZEmDJTGSEDzCyX9xydZtImdPhmjsCfHxTdB9c\nY5SUZ4S16lrWCrwrOUhRloqqLaGBANQD/7k/KNhV23Xw6yzyKE5WMIpJ+REOS7tt\ngrWZBVxQTs9swZUEeCrqnWanC+zuqfkiHuILPypHZsEn2MzaVhI+t48iw4OZE0Ob\ny9uCj6nrAqFkp4L53squljshenFPi97lGAiePkEStAgqJL6prNs=\n=SZ9W\n-----END PGP SIGNATURE-----",
                    "payload": "tree ad5836a5b6fc620435fd7d22d38b08964a43764c\nparent c8ad0ec1e5ad21da6b7663944d99f7e413aae0c9\nauthor Dawid Wysakowicz <dwysakowicz@apache.org> 1627052691 +0200\ncommitter Dawid Wysakowicz <dwysakowicz@apache.org> 1627052691 +0200\n\nRevert \"[FLINK-23434][table-planner-blink] Fix the inconsistent type in IncrementalAggregateRule when the query has one distinct agg function and count star agg function\"\n\nThis reverts commit c8ad0ec1e5ad21da6b7663944d99f7e413aae0c9.\n"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/ea2bddc8e82ab4b9797f40534b1e5637eef4c5b5",
            "html_url": "https://github.com/apache/flink/commit/ea2bddc8e82ab4b9797f40534b1e5637eef4c5b5",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/ea2bddc8e82ab4b9797f40534b1e5637eef4c5b5/comments",
            "author": {
                "login": "dawidwys",
                "id": 6242259,
                "node_id": "MDQ6VXNlcjYyNDIyNTk=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6242259?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dawidwys",
                "html_url": "https://github.com/dawidwys",
                "followers_url": "https://api.github.com/users/dawidwys/followers",
                "following_url": "https://api.github.com/users/dawidwys/following{/other_user}",
                "gists_url": "https://api.github.com/users/dawidwys/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dawidwys/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dawidwys/subscriptions",
                "organizations_url": "https://api.github.com/users/dawidwys/orgs",
                "repos_url": "https://api.github.com/users/dawidwys/repos",
                "events_url": "https://api.github.com/users/dawidwys/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dawidwys/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "dawidwys",
                "id": 6242259,
                "node_id": "MDQ6VXNlcjYyNDIyNTk=",
                "avatar_url": "https://avatars.githubusercontent.com/u/6242259?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/dawidwys",
                "html_url": "https://github.com/dawidwys",
                "followers_url": "https://api.github.com/users/dawidwys/followers",
                "following_url": "https://api.github.com/users/dawidwys/following{/other_user}",
                "gists_url": "https://api.github.com/users/dawidwys/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/dawidwys/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/dawidwys/subscriptions",
                "organizations_url": "https://api.github.com/users/dawidwys/orgs",
                "repos_url": "https://api.github.com/users/dawidwys/repos",
                "events_url": "https://api.github.com/users/dawidwys/events{/privacy}",
                "received_events_url": "https://api.github.com/users/dawidwys/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "c8ad0ec1e5ad21da6b7663944d99f7e413aae0c9",
                "url": "https://api.github.com/repos/apache/flink/commits/c8ad0ec1e5ad21da6b7663944d99f7e413aae0c9",
                "html_url": "https://github.com/apache/flink/commit/c8ad0ec1e5ad21da6b7663944d99f7e413aae0c9"
            }]
        },
        {
            "sha": "09f868827166da872cb8d683c3c959231e96ae40",
            "node_id": "MDY6Q29tbWl0MjA1ODc1OTk6MDlmODY4ODI3MTY2ZGE4NzJjYjhkNjgzYzNjOTU5MjMxZTk2YWU0MA==",
            "commit": {
                "author": {
                    "name": "tsreaper",
                    "email": "tsreaper96@gmail.com",
                    "date": "2021-07-26T02:18:36Z"
                },
                "committer": {
                    "name": "GitHub",
                    "email": "noreply@github.com",
                    "date": "2021-07-26T02:18:36Z"
                },
                "message": "[FLINK-22861][table-planner-blink] Fix return value deduction of TIMESTAMPADD function\n\nThis closes #16577",
                "tree": {
                    "sha": "9f6c306594bcbfc999a9de9cf754e30215df9ad3",
                    "url": "https://api.github.com/repos/apache/flink/git/trees/9f6c306594bcbfc999a9de9cf754e30215df9ad3"
                },
                "url": "https://api.github.com/repos/apache/flink/git/commits/09f868827166da872cb8d683c3c959231e96ae40",
                "comment_count": 0,
                "verification": {
                    "verified": true,
                    "reason": "valid",
                    "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJg/ht8CRBK7hj4Ov3rIwAAMSIIAHyiPSqMLrHL4HLj/AVa5tyY\naDHa3MwP8oOjeegfUIWHxeNtqrLNbP1+QSifQoYzJGN89jPTPwW4CDrROH5BrSw8\nZJWur8B6pHBPyf8c4JI1KcmKdexTPPjc6NOYNCojFCCQMHkoCWK5hvQd2LA+s05Z\n1r0QnTso9yykMmtRsJX7dUHvn18/riycYeMNJCaTGViiKefqxdfL3lwJ9jH9cyYO\naomLvV+75HaqNLNDcEfDTwVo7n4zi7GX5gBStRHtypbmZsyO/xSBj2PJIurHfd94\nf721DUzKzzeSZ5bj6JRqyhkD9VbrRIihMwBZQ6p68i0w+njRfKFV958EV44UT04=\n=94vF\n-----END PGP SIGNATURE-----\n",
                    "payload": "tree 9f6c306594bcbfc999a9de9cf754e30215df9ad3\nparent ea2bddc8e82ab4b9797f40534b1e5637eef4c5b5\nauthor tsreaper <tsreaper96@gmail.com> 1627265916 +0800\ncommitter GitHub <noreply@github.com> 1627265916 +0800\n\n[FLINK-22861][table-planner-blink] Fix return value deduction of TIMESTAMPADD function\n\nThis closes #16577"
                }
            },
            "url": "https://api.github.com/repos/apache/flink/commits/09f868827166da872cb8d683c3c959231e96ae40",
            "html_url": "https://github.com/apache/flink/commit/09f868827166da872cb8d683c3c959231e96ae40",
            "comments_url": "https://api.github.com/repos/apache/flink/commits/09f868827166da872cb8d683c3c959231e96ae40/comments",
            "author": {
                "login": "tsreaper",
                "id": 19909549,
                "node_id": "MDQ6VXNlcjE5OTA5NTQ5",
                "avatar_url": "https://avatars.githubusercontent.com/u/19909549?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/tsreaper",
                "html_url": "https://github.com/tsreaper",
                "followers_url": "https://api.github.com/users/tsreaper/followers",
                "following_url": "https://api.github.com/users/tsreaper/following{/other_user}",
                "gists_url": "https://api.github.com/users/tsreaper/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/tsreaper/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/tsreaper/subscriptions",
                "organizations_url": "https://api.github.com/users/tsreaper/orgs",
                "repos_url": "https://api.github.com/users/tsreaper/repos",
                "events_url": "https://api.github.com/users/tsreaper/events{/privacy}",
                "received_events_url": "https://api.github.com/users/tsreaper/received_events",
                "type": "User",
                "site_admin": false
            },
            "committer": {
                "login": "web-flow",
                "id": 19864447,
                "node_id": "MDQ6VXNlcjE5ODY0NDQ3",
                "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/web-flow",
                "html_url": "https://github.com/web-flow",
                "followers_url": "https://api.github.com/users/web-flow/followers",
                "following_url": "https://api.github.com/users/web-flow/following{/other_user}",
                "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions",
                "organizations_url": "https://api.github.com/users/web-flow/orgs",
                "repos_url": "https://api.github.com/users/web-flow/repos",
                "events_url": "https://api.github.com/users/web-flow/events{/privacy}",
                "received_events_url": "https://api.github.com/users/web-flow/received_events",
                "type": "User",
                "site_admin": false
            },
            "parents": [{
                "sha": "ea2bddc8e82ab4b9797f40534b1e5637eef4c5b5",
                "url": "https://api.github.com/repos/apache/flink/commits/ea2bddc8e82ab4b9797f40534b1e5637eef4c5b5",
                "html_url": "https://github.com/apache/flink/commit/ea2bddc8e82ab4b9797f40534b1e5637eef4c5b5"
            }]
        }
    ],
    "files": [{
            "sha": "2e260749d2647a7d8f1a4f3e487cb0ec29433714",
            "filename": ".editorconfig",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/.editorconfig",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/.editorconfig",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/.editorconfig?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -3,19 +3,19 @@ root = true\n [*]\n charset = utf-8\n end_of_line = lf\n-indent_size = 4\n-indent_style = tab\n insert_final_newline = true\n max_line_length = 100\n-tab_width = 4\n-ij_continuation_indent_size = 4\n # ij_formatter_off_tag = @formatter:off\n # ij_formatter_on_tag = @formatter:on\n # ij_formatter_tags_enabled = false\n # ij_smart_tabs = false\n # ij_wrap_on_typing = false\n \n [*.java]\n+indent_size = 4\n+indent_style = space\n+tab_width = 4\n+ij_continuation_indent_size = 8\n # ij_java_align_consecutive_assignments = false\n # ij_java_align_consecutive_variable_declarations = false\n # ij_java_align_group_field_declarations = false"
        },
        {
            "sha": "0823d5d0426b31ce4c017d156e473e5b649daa41",
            "filename": ".git-blame-ignore-revs",
            "status": "added",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/.git-blame-ignore-revs",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/.git-blame-ignore-revs",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/.git-blame-ignore-revs?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,2 @@\n+c6997c97c575d334679915c328792b8a3067cfb5\n+481ccff04f647505721541f45d0f99b1f67f11f4"
        },
        {
            "sha": "a3578a69d20fa08f0a346780232acba13cf8f8bd",
            "filename": ".gitignore",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/.gitignore",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/.gitignore",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/.gitignore?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -19,16 +19,16 @@ tmp\n *.pyc\n .DS_Store\n build-target\n-flink-end-to-end-tests/flink-datastream-allround-test/src/main/java/org/apache/flink/streaming/tests/avro/\n-flink-formats/flink-avro/src/test/java/org/apache/flink/formats/avro/generated/\n-flink-formats/flink-parquet/src/test/java/org/apache/flink/formats/parquet/generated/\n flink-runtime-web/web-dashboard/node/\n flink-runtime-web/web-dashboard/node_modules/\n flink-runtime-web/web-dashboard/web/\n flink-python/dist/\n+flink-python/apache-flink-libraries/dist/\n flink-python/build/\n+flink-python/apache-flink-libraries/build\n flink-python/pyflink.egg-info/\n flink-python/apache_flink.egg-info/\n+flink-python/apache-flink-libraries/apache_flink_libraries.egg-info/\n flink-python/docs/_build\n flink-python/.tox/\n flink-python/dev/download\n@@ -37,12 +37,12 @@ flink-python/dev/log/\n flink-python/dev/.stage.txt\n flink-python/.eggs/\n flink-python/apache-flink-*.dev0/\n+flink-python/apache-flink-libraries/apache_flink_libraries-*.dev0/\n flink-python/**/*.c\n flink-python/**/*.so\n atlassian-ide-plugin.xml\n out/\n /docs/api\n-/docs/content\n /docs/.bundle\n /docs/.rubydeps\n /docs/ruby2/.bundle"
        },
        {
            "sha": "6cb7e5ce6530592243838eabe64be0bc164641f4",
            "filename": ".gitmodules",
            "status": "added",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/.gitmodules",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/.gitmodules",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/.gitmodules?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,3 @@\n+[submodule \"docs/themes/book\"]\n+\tpath = docs/themes/book\n+\turl = https://github.com/alex-shpak/hugo-book"
        },
        {
            "sha": "8c61b68d45ec41ce1a34b1e90c78d67627afcde2",
            "filename": "NOTICE",
            "status": "modified",
            "additions": 9,
            "deletions": 6,
            "changes": 15,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/NOTICE",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/NOTICE",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/NOTICE?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -1,14 +1,18 @@\n Apache Flink\n-Copyright 2014-2020 The Apache Software Foundation\n+Copyright 2014-2021 The Apache Software Foundation\n \n This product includes software developed at\n The Apache Software Foundation (http://www.apache.org/).\n \n This project bundles the following dependencies under the MIT license.\n See bundled license files for details.\n \n-- jQuery v3.5.1 | (c) JS Foundation and other contributors\n-\t-> in \"docs/page/js/jquery.min.js\"\n+- AnchorJS v3.1.0 (https://github.com/bryanbraun/anchorjs) Copyright (c) 2016 Bryan Braun\n+    -> in \"docs/static/js/anchor.min.js\"\n+- font-awesome:4.6.3 (css) (https://fontawesome.com/) - Created by Dave Gandy\n+    -> css in \"docs/static/font-awesome/css\"\n+- chroma (css generated by Hugo) (https://github.com/alecthomas/chroma) Copyright (C) 2017 Alec Thomas\n+    -> in \"docs/assets/github.css\"\n \n This project bundles the following dependencies under the BSD license.\n See bundled license files for details.\n@@ -19,8 +23,8 @@ See bundled license files for details.\n This project bundles the following dependencies under SIL OFL 1.1 license (https://opensource.org/licenses/OFL-1.1).\n See bundled license files for details.\n \n-- font-awesome:4.5.0 (Font) (http://fortawesome.github.io/Font-Awesome/) - Created by Dave Gandy\n-    -> fonts in \"docs/page/font-awesome/fonts\"\n+- font-awesome:4.6.3 (Font) (https://fontawesome.com/) - Created by Dave Gandy\n+    -> fonts in \"docs/static/font-awesome/fonts\"\n \n The Apache Flink project contains or reuses code that is licensed under the ISC license from the following projects.\n \n@@ -39,4 +43,3 @@ The Apache Flink project contains or reuses code that is licensed under the Apac\n - Google Cloud Client Library for Java (https://github.com/googleapis/google-cloud-java) Copyright 2017 Google LLC\n \n   See: flink-end-to-end-tests/flink-connector-gcp-pubsub-emulator-tests/src/test/java/org/apache/flink/streaming/connectors/gcp/pubsub/emulator/PubsubHelper.java\n-"
        },
        {
            "sha": "d50663e57ead6d458404e02d1d6abe1ddf695121",
            "filename": "azure-pipelines.yml",
            "status": "modified",
            "additions": 12,
            "deletions": 4,
            "changes": 16,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/azure-pipelines.yml",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/azure-pipelines.yml",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/azure-pipelines.yml?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -38,7 +38,7 @@ resources:\n   containers:\n   # Container with Maven 3.2.5, SSL to have the same environment everywhere.\n   - container: flink-build-container\n-    image: rmetzger/flink-ci:ubuntu-amd64-f009d96\n+    image: rmetzger/flink-ci:ubuntu-amd64-7ac4e28\n     # On AZP provided machines, set this flag to allow writing coredumps in docker\n     options: --privileged\n \n@@ -49,13 +49,16 @@ resources:\n variables:\n   MAVEN_CACHE_FOLDER: $(Pipeline.Workspace)/.m2/repository\n   E2E_CACHE_FOLDER: $(Pipeline.Workspace)/e2e_cache\n+  E2E_TARBALL_CACHE: $(Pipeline.Workspace)/e2e_artifact_cache\n   MAVEN_OPTS: '-Dmaven.repo.local=$(MAVEN_CACHE_FOLDER)'\n   CACHE_KEY: maven | $(Agent.OS) | **/pom.xml, !**/target/**\n   CACHE_FALLBACK_KEY: maven | $(Agent.OS)\n   FLINK_ARTIFACT_DIR: $(Pipeline.Workspace)/flink_artifact\n   SECRET_S3_BUCKET: $[variables.IT_CASE_S3_BUCKET]\n   SECRET_S3_ACCESS_KEY: $[variables.IT_CASE_S3_ACCESS_KEY]\n   SECRET_S3_SECRET_KEY: $[variables.IT_CASE_S3_SECRET_KEY]\n+  SECRET_GLUE_SCHEMA_ACCESS_KEY: $[variables.IT_CASE_GLUE_SCHEMA_ACCESS_KEY]\n+  SECRET_GLUE_SCHEMA_SECRET_KEY: $[variables.IT_CASE_GLUE_SCHEMA_SECRET_KEY]\n \n \n stages:\n@@ -68,13 +71,18 @@ stages:\n         parameters: # see template file for a definition of the parameters.\n           stage_name: ci_build\n           test_pool_definition:\n-            vmImage: 'ubuntu-16.04'\n+            vmImage: 'ubuntu-20.04'\n           e2e_pool_definition:\n-            vmImage: 'ubuntu-16.04'\n+            vmImage: 'ubuntu-20.04'\n           environment: PROFILE=\"-Dhadoop.version=2.8.3 -Dinclude_hadoop_aws -Dscala-2.11\"\n           run_end_to_end: false\n           container: flink-build-container\n-          jdk: jdk8\n+          jdk: 8\n+      - job: docs_404_check # run on a MSFT provided machine\n+        pool:\n+          vmImage: 'ubuntu-20.04'\n+        steps:\n+          - script: ./tools/ci/docs.sh\n   # CI / Special stage for release, e.g. building PyFlink wheel packages, etc:\n   - stage: ci_release\n     displayName: \"CI build (release)\""
        },
        {
            "sha": "270dd7f731332e3fbf265631c0f61155a0e1efcf",
            "filename": "docs/.gitignore",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/.gitignore",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/.gitignore",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/.gitignore?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -2,7 +2,7 @@\n .jekyll-metadata\n .jekyll-cache/\n .rubydeps/\n-content/\n-content_*/\n ruby2/.bundle/\n ruby2/.rubydeps/\n+public/\n+resources/"
        },
        {
            "sha": "a752f8d5054a06e1c3a164b832a75032ee5edfbb",
            "filename": "docs/404.md",
            "status": "removed",
            "additions": 0,
            "deletions": 26,
            "changes": 26,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/404.md",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/404.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/404.md?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,26 +0,0 @@\n----\n-title: \"404\"\n-permalink: /404.html\n-layout: 404_base\n----\n-<!--\n-Licensed to the Apache Software Foundation (ASF) under one\n-or more contributor license agreements.  See the NOTICE file\n-distributed with this work for additional information\n-regarding copyright ownership.  The ASF licenses this file\n-to you under the Apache License, Version 2.0 (the\n-\"License\"); you may not use this file except in compliance\n-with the License.  You may obtain a copy of the License at\n-\n-  http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing,\n-software distributed under the License is distributed on an\n-\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-KIND, either express or implied.  See the License for the\n-specific language governing permissions and limitations\n-under the License.\n--->\n-\n-The page you are looking for has been moved. This could be because of a recent reorganization of the\n-documentation. Redirecting to [Documentation Home Page]({{ site.baseurl }}/) in 5 seconds."
        },
        {
            "sha": "7dfc2ae0e3a4c60047595e1081968a4289f7f72a",
            "filename": "docs/Gemfile",
            "status": "removed",
            "additions": 0,
            "deletions": 35,
            "changes": 35,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/Gemfile",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/Gemfile",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/Gemfile?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,35 +0,0 @@\n-################################################################################\n-#  Licensed to the Apache Software Foundation (ASF) under one\n-#  or more contributor license agreements.  See the NOTICE file\n-#  distributed with this work for additional information\n-#  regarding copyright ownership.  The ASF licenses this file\n-#  to you under the Apache License, Version 2.0 (the\n-#  \"License\"); you may not use this file except in compliance\n-#  with the License.  You may obtain a copy of the License at\n-#\n-#      http://www.apache.org/licenses/LICENSE-2.0\n-#\n-#  Unless required by applicable law or agreed to in writing, software\n-#  distributed under the License is distributed on an \"AS IS\" BASIS,\n-#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-#  See the License for the specific language governing permissions and\n-# limitations under the License.\n-################################################################################\n-\n-source 'https://rubygems.org'\n-\n-ruby '>= 2.4.0'\n-\n-gem 'jekyll', '4.0.1'\n-gem 'addressable', '2.7.0'\n-gem 'octokit', '4.14.0'\n-gem 'therubyracer', '0.12.3'\n-gem 'json', '2.2.0'\n-gem 'jekyll-multiple-languages', '2.0.3'\n-gem 'jekyll-paginate', '1.1.0'\n-gem 'liquid-c', '4.0.0' # speed-up site generation\n-gem 'sassc', '2.2.1' # speed-up site generation\n-\n-# group :jekyll_plugins do\n-#   gem 'hawkins'\n-# end"
        },
        {
            "sha": "7d55d5cc6d63c9078772d86a188fea3366e1f041",
            "filename": "docs/Gemfile.lock",
            "status": "removed",
            "additions": 0,
            "deletions": 96,
            "changes": 96,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/Gemfile.lock",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/Gemfile.lock",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/Gemfile.lock?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,96 +0,0 @@\n-GEM\n-  remote: https://rubygems.org/\n-  specs:\n-    addressable (2.7.0)\n-      public_suffix (>= 2.0.2, < 5.0)\n-    colorator (1.1.0)\n-    concurrent-ruby (1.1.6)\n-    em-websocket (0.5.1)\n-      eventmachine (>= 0.12.9)\n-      http_parser.rb (~> 0.6.0)\n-    eventmachine (1.2.7)\n-    faraday (0.17.0)\n-      multipart-post (>= 1.2, < 3)\n-    ffi (1.11.2)\n-    forwardable-extended (2.6.0)\n-    http_parser.rb (0.6.0)\n-    i18n (1.8.3)\n-      concurrent-ruby (~> 1.0)\n-    jekyll (4.0.1)\n-      addressable (~> 2.4)\n-      colorator (~> 1.0)\n-      em-websocket (~> 0.5)\n-      i18n (>= 0.9.5, < 2)\n-      jekyll-sass-converter (~> 2.0)\n-      jekyll-watch (~> 2.0)\n-      kramdown (~> 2.1)\n-      kramdown-parser-gfm (~> 1.0)\n-      liquid (~> 4.0)\n-      mercenary (~> 0.3.3)\n-      pathutil (~> 0.9)\n-      rouge (~> 3.0)\n-      safe_yaml (~> 1.0)\n-      terminal-table (~> 1.8)\n-    jekyll-multiple-languages (2.0.3)\n-    jekyll-paginate (1.1.0)\n-    jekyll-sass-converter (2.1.0)\n-      sassc (> 2.0.1, < 3.0)\n-    jekyll-watch (2.2.1)\n-      listen (~> 3.0)\n-    json (2.2.0)\n-    kramdown (2.2.1)\n-      rexml\n-    kramdown-parser-gfm (1.1.0)\n-      kramdown (~> 2.0)\n-    libv8 (3.16.14.19)\n-    liquid (4.0.3)\n-    liquid-c (4.0.0)\n-      liquid (>= 3.0.0)\n-    listen (3.2.1)\n-      rb-fsevent (~> 0.10, >= 0.10.3)\n-      rb-inotify (~> 0.9, >= 0.9.10)\n-    mercenary (0.3.6)\n-    multipart-post (2.1.1)\n-    octokit (4.14.0)\n-      sawyer (~> 0.8.0, >= 0.5.3)\n-    pathutil (0.16.2)\n-      forwardable-extended (~> 2.6)\n-    public_suffix (4.0.1)\n-    rb-fsevent (0.10.4)\n-    rb-inotify (0.10.1)\n-      ffi (~> 1.0)\n-    ref (2.0.0)\n-    rexml (3.2.4)\n-    rouge (3.20.0)\n-    safe_yaml (1.0.5)\n-    sassc (2.2.1)\n-      ffi (~> 1.9)\n-    sawyer (0.8.2)\n-      addressable (>= 2.3.5)\n-      faraday (> 0.8, < 2.0)\n-    terminal-table (1.8.0)\n-      unicode-display_width (~> 1.1, >= 1.1.1)\n-    therubyracer (0.12.3)\n-      libv8 (~> 3.16.14.15)\n-      ref\n-    unicode-display_width (1.7.0)\n-\n-PLATFORMS\n-  ruby\n-\n-DEPENDENCIES\n-  addressable (= 2.7.0)\n-  jekyll (= 4.0.1)\n-  jekyll-multiple-languages (= 2.0.3)\n-  jekyll-paginate (= 1.1.0)\n-  json (= 2.2.0)\n-  liquid-c (= 4.0.0)\n-  octokit (= 4.14.0)\n-  sassc (= 2.2.1)\n-  therubyracer (= 0.12.3)\n-\n-RUBY VERSION\n-   ruby 2.6.3p62\n-\n-BUNDLED WITH\n-   1.17.2"
        },
        {
            "sha": "7aab7b52b84521358c137035007445a4ca573df5",
            "filename": "docs/README.md",
            "status": "modified",
            "additions": 148,
            "deletions": 76,
            "changes": 224,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/README.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/README.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/README.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -6,55 +6,23 @@ https://flink.apache.org/ is also generated from the files found here.\n \n # Requirements\n \n-The dependencies are declared in the Gemfile in this directory. We use Markdown\n-to write and Jekyll to translate the documentation to static HTML. All required\n-dependencies are installed locally when you build the documentation through the\n-`build_docs.sh` script. If you want to install the software manually, use Ruby's\n-Bundler Gem to install all dependencies:\n+### Build the site locally\n \n-    gem install bundler -v 1.16.1\n-    bundle install\n+Make sure you have installed [Hugo](https://gohugo.io/getting-started/installing/) on your\n+system. To build the Flink docs, you need the *extended version* of Hugo with Sass/SCSS support.\n \n-Note that in Ubuntu based systems, it may be necessary to install the following\n-packages: `rubygems ruby-dev libssl-dev build-essential`.\n+From this directory:\n \n-# Using Dockerized Jekyll\n+  * Fetch the theme submodule\n+\t```sh\n+\tgit submodule update --init --recursive\n+\t```\n+  * Start local server\n+\t```sh\n+\thugo -b \"\" serve\n+\t```\n \n-We dockerized the jekyll environment above. If you have [docker](https://docs.docker.com/),\n-you can run the following command to start the container.\n-\n-```\n-cd flink/docs/docker\n-./run.sh\n-```\n-\n-It takes a few moments to build the image for the first time but will be a second from the second time.\n-The run.sh command brings you in a bash session where you run the `./build_docs.sh` script mentioned above.\n-\n-\n-# Build\n-\n-The `docs/build_docs.sh` script installs dependencies locally, calls Jekyll, and\n-generates the documentation in `docs/content`. You can then point your browser\n-to `docs/content/index.html` and start reading.\n-\n-If you call the script with the preview flag `build_docs.sh -p`, Jekyll will\n-start a web server at `localhost:4000` and watch the docs directory for\n-updates. Use this mode to preview changes locally. \n-\n-You can call the script with the incremental flag `build_docs.sh -i`.\n-Jekyll will then serve a live preview at `localhost:4000`,\n-and it will be much faster because it will only rebuild the pages corresponding\n-to files that are modified. Note that if you are making changes that affect\n-the sidebar navigation, you'll have to build the entire site to see\n-those changes reflected on every page.\n-\n-| Flag | Action | \n-| -----| -------| \n-| -p   | Run interactive preview | \n-| -i   | Incremental builds | \n-| -e   | Build only English docs |\n-| -z   | Build only Chinese docs |\n+The site can be viewed at http://localhost:1313/\n \n ## Generate configuration tables\n \n@@ -64,11 +32,11 @@ Configuration descriptions are auto generated from code. To trigger the generati\n mvn -Pgenerate-config-docs install\n ```\n \n-The resulting html files will be written to `_includes/generated`. Tables are regenerated each time the command is invoked.\n+The resulting html files will be written to `layouts/shortcodes/generated`. Tables are regenerated each time the command is invoked.\n These tables can be directly included into the documentation:\n \n ```\n-{% include generated/file_name.html %}\n+{{< generated/file_name >}}\n ```\n \n # Contribute\n@@ -85,11 +53,13 @@ In addition to Markdown, every page contains a Jekyll front matter, which specif\n     title: \"Title of the Page\"\n     ---\n \n-Furthermore, you can access the variables found in `docs/_config.yml` as follows:\n-\n-    {{ site.NAME }}\n-\n-This will be replaced with the value of the variable called `NAME` when generating the docs.\n+    ---\n+    title: \"Title of the Page\" <-- Title rendered in the side nave\n+    weight: 1 <-- Weight controls the ordering of pages in the side nav. \n+    type: docs <-- required\n+    aliases:  <-- Alias to setup redirect from removed page to this one\n+      - /alias/to/removed/page.html\n+    ---\n \n ## Structure\n \n@@ -100,8 +70,8 @@ This will be replaced with the value of the variable called `NAME` when generati\n All documents are structured with headings. From these headings, you can automatically generate a page table of contents (see below).\n \n ```\n-# Level-1 Heading  <- Used for the title of the page (don't use this)\n-## Level-2 Heading <- Start with this one\n+# Level-1 Heading  <- Used for the title of the page \n+## Level-2 Heading <- Start with this one for content\n ### Level-3 heading\n #### Level-4 heading\n ##### Level-5 heading\n@@ -111,47 +81,149 @@ Please stick to the \"logical order\" when using the headlines, e.g. start with le\n \n #### Table of Contents\n \n-    * This will be replaced by the TOC\n-    {:toc}\n+Table of contents are added automatically to every page, based on heading levels 2 - 4. \n+The ToC can be ommitted by adding the following to the front matter of the page:\n+\n+    ---\n+    bookToc: false\n+    ---\n+\n+### ShortCodes \n+\n+Flink uses [shortcodes](https://gohugo.io/content-management/shortcodes/) to add custom functionality\n+to its documentation markdown. The following are available for use:  \n \n+#### Flink Artifact\n \n-Add this markup (both lines) to the document in order to generate a table of contents for the page. Headings until level 3 headings are included.\n+    {{< artfiact flink-streaming-java withScalaVersion >}}\n \n-You can exclude a heading from the table of contents:\n+This will be replaced by the maven artifact for flink-streaming-java that users should copy into their pom.xml file. It will render out to:\n \n-    # Excluded heading\n-    {:.no_toc}\n+```xml\n+<dependency>\n+    <groupdId>org.apache.flink</groupId>\n+    <artifactId>flink-streaming-java_2.11</artifactId>\n+    <version><!-- current flink version --></version>\n+</dependency>\n+```\n+\n+It includes a number of optional flags:\n+\n+* withScalaVersion: Includes the scala version suffix to the artifact id\n+* withTestScope: Includes `<scope>test</scope>` to the module. Useful for marking test dependencies.\n+* withTestClassifier: Includes `<classifier>tests</classifier>`. Useful when users should be pulling in Flinks tests dependencies. This is mostly for the test harnesses and probably not what you want. \n \n #### Back to Top\n \n-\t{% top %}\n+\t{{< top >}}\n \n This will be replaced by a back to top link. It is recommended to use these links at least at the end of each level-2 section.\n \n-#### Labels\n+#### Info Hints\n+\n+\t{{< hint info >}}\n+\tSome interesting information\n+\t{{< /hint >}}\n+\t\n+The hint will be rendered in a blue box. This hint is useful when providing \n+additional information for the user that does not fit into the flow of the documentation.\n+\n+#### Info Warning \n+\n+    {{< hint warning >}}\n+    Something to watch out for. \n+    {{< /hint >}}\n+\n+The hint will be rendered in a yellow box. This hint is useful when highlighting\n+information users should watch out for to prevent errors. \n+\n+#### Info Danger\n+\n+    {{< hint danger >}}\n+    Something to avoid\n+    {{< /hint >}}\n+\n+The hint will be rendered in a red box. This hint is useful when highlighting\n+information users need to know to avoid data loss or to point out broken\n+functionality. \n+\n+#### Label\n+\n+    {{< label \"My Label\" >}}\n+    \n+The label will be rendered in an inlined blue box. This is useful for labeling functionality\n+such as whether a SQL feature works for only batch or streaming execution. \n+\n+#### Flink version \n+\n+    {{< version >}}\n+    \n+Interpolates the current Flink version\n+\n+#### Scala Version\n+\n+    {{< scala_verison >}}\n+    \n+Interpolates the default scala version\n+\n+#### Stable\n+\n+    {{< stable >}}\n+     Some content\n+    {{< /stable >}}\n+    \n+This shortcode will only render its content if the site is marked as stable. \n+\n+#### Unstable \n \n-\t{% info %}\n-\t{% warn %}\n+    {{< unstable >}}\n+    Some content \n+    {{< /unstable >}}\n+    \n+This shortcode will only render its content if the site is marked as unstable. \n \n-These will be replaced by an info or warning label. You can change the text of the label by providing an argument:\n+#### Query State Warning\n \n-    {% info Recommendation %}\n+    {{< query_state_warning >}}\n+    \n+Will render a warning the current SQL feature may have unbounded state requirements.\n \n-### Documentation\n+#### tab\n \n-#### Navigation\n+    {{< tabs \"sometab\" >}}\n+    {{< tab \"Java\" >}}\n+    ```java\n+    System.out.println(\"Hello World!\");\n+    ```\n+    {{< /tab >}}\n+    {{< tab \"Scala\" >}}\n+    ```scala\n+    println(\"Hello World!\");\n+    ```\n+    {< /tab >}}\n+    {{< /tabs }}\n+    \n+Prints the content in tabs. IMPORTANT: The label in the outermost \"tabs\" shortcode must\n+be unique for the page. \n \n-The navigation on the left side of the docs is automatically generated when building the docs. You can modify the markup in `_include/sidenav.html`.\n+#### Github Repo\n \n-The structure of the navigation is determined by the front matter of all pages. The fields used to determine the structure are:\n+    {{< github_repo >}}\n+    \n+Renders a link to the apache flink repo. \n \n-- `nav-id` => ID of this page. Other pages can use this ID as their parent ID.\n-- `nav-parent_id` => ID of the parent. This page will be listed under the page with id `nav-parent_id`.\n+#### Github Link\n \n-Level 0 is made up of all pages, which have nav-parent_id set to `root`. There is no limitation on how many levels you can nest.\n+    {{< gh_link file=\"/some/file.java\" name=\"Some file\" >}}\n+    \n+Renders a link to a file in the Apache Flink repo with a given name. \n+ \n+#### JavaDocs Link\n+    {{< javadoc file=\"some/file\" name=\"Some file\" >}}\n \n-The `title` of the page is used as the default link text. You can override this via `nav-title`. The relative position per navigational level is determined by `nav-pos`.\n+Renders a link to a file in the Apache Flink Java Documentation. \n \n-If you have a page with sub pages, the link target will be used to expand the sub level navigation. If you want to actually add a link to the page as well, you can add the `nav-show_overview: true` field to the front matter. This will then add an `Overview` sub page to the expanded list.\n+#### PythonDocs Link\n+    {< pythondoc file=\"some/file\" name=\"Some file\" >}}\n \n-The nesting is also used for the breadcrumbs like `Application Development > Libraries > Machine Learning > Optimization`.\n+Renders a link to a file in the Apache Flink Python Documentation. "
        },
        {
            "sha": "9bda2e18251ad03209ac6a10f294b6fc28b40e64",
            "filename": "docs/_config.yml",
            "status": "removed",
            "additions": 0,
            "deletions": 110,
            "changes": 110,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_config.yml",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_config.yml",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_config.yml?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,110 +0,0 @@\n-# Licensed to the Apache Software Foundation (ASF) under one\n-# or more contributor license agreements.  See the NOTICE file\n-# distributed with this work for additional information\n-# regarding copyright ownership.  The ASF licenses this file\n-# to you under the Apache License, Version 2.0 (the\n-# \"License\"); you may not use this file except in compliance\n-# with the License.  You may obtain a copy of the License at\n-#\n-# http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing,\n-# software distributed under the License is distributed on an\n-# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-# KIND, either express or implied.  See the License for the\n-# specific language governing permissions and limitations\n-# under the License.\n-\n-#------------------------------------------------------------------------------\n-# VARIABLES\n-#------------------------------------------------------------------------------\n-# Variables specified in this file can be used in the documentation via:\n-#     {{ site.CONFIG_KEY }}\n-#------------------------------------------------------------------------------\n-\n-# This are the version referenced in the docs. Please only use these variables\n-# to reference a specific Flink version, because this is the only place where\n-# we change the version for the complete docs when forking of a release branch\n-# etc.\n-# The full version string as referenced in Maven (e.g. 1.2.1)\n-version: \"1.12-SNAPSHOT\"\n-# For stable releases, leave the bugfix version out (e.g. 1.2). For snapshot\n-# release this should be the same as the regular version\n-version_title: \"1.12-SNAPSHOT\"\n-# Branch on Github for this version\n-github_branch: \"master\"\n-\n-# Plain Scala version is needed for e.g. the Gradle quickstart.\n-scala_version: \"2.11\"\n-# This suffix is appended to the Scala-dependent Maven artifact names\n-scala_version_suffix: \"_2.11\"\n-\n-# Some commonly linked pages (this was more important to have as a variable\n-# during incubator; by now it should also be fine to hardcode these.)\n-website_url: \"https://flink.apache.org\"\n-jira_url: \"https://issues.apache.org/jira/browse/FLINK\"\n-github_url: \"https://github.com/apache/flink\"\n-download_url: \"https://flink.apache.org/downloads.html\"\n-zh_download_url: \"https://flink.apache.org/zh/downloads.html\"\n-\n-# please use a protocol relative URL here\n-baseurl: //ci.apache.org/projects/flink/flink-docs-master\n-stable_baseurl: //ci.apache.org/projects/flink/flink-docs-stable\n-\n-javadocs_baseurl: //ci.apache.org/projects/flink/flink-docs-master\n-pythondocs_baseurl: //ci.apache.org/projects/flink/flink-docs-master\n-\n-statefundocs_baseurl: //ci.apache.org/projects/flink/flink-statefun-docs-master\n-statefundocs_stable_baseurl: //ci.apache.org/projects/flink/flink-statefun-docs-stable\n-\n-# Flag whether this is a stable version or not. Used for the quickstart page.\n-is_stable: false\n-\n-# Flag to indicate whether an outdated warning should be shown.\n-show_outdated_warning: false\n-\n-previous_docs:\n-  '1.11': http://ci.apache.org/projects/flink/flink-docs-release-1.11\n-  '1.10': http://ci.apache.org/projects/flink/flink-docs-release-1.10\n-  '1.9': http://ci.apache.org/projects/flink/flink-docs-release-1.9\n-  '1.8': http://ci.apache.org/projects/flink/flink-docs-release-1.8\n-  '1.7': http://ci.apache.org/projects/flink/flink-docs-release-1.7\n-  '1.6': http://ci.apache.org/projects/flink/flink-docs-release-1.6\n-  '1.5': http://ci.apache.org/projects/flink/flink-docs-release-1.5\n-  '1.4': http://ci.apache.org/projects/flink/flink-docs-release-1.4\n-  '1.3': http://ci.apache.org/projects/flink/flink-docs-release-1.3\n-  '1.2': http://ci.apache.org/projects/flink/flink-docs-release-1.2\n-  '1.1': http://ci.apache.org/projects/flink/flink-docs-release-1.1\n-  '1.0': http://ci.apache.org/projects/flink/flink-docs-release-1.0\n-\n-#------------------------------------------------------------------------------\n-# BUILD CONFIG\n-#------------------------------------------------------------------------------\n-# These variables configure the jekyll build (./build_docs.sh). You don't need\n-# to change anything here.\n-#------------------------------------------------------------------------------\n-\n-exclude:\n-  - \"build_docs.sh\"\n-  - \"check_links.sh\"\n-\n-# Used in some documents to initialize arrays. Don't delete.\n-array: []\n-\n-defaults:\n-  -\n-    scope:\n-      path: \"\"\n-    values:\n-      layout: plain\n-      nav-pos: 99999 # Move to end if no pos specified\n-\n-host: 0.0.0.0\n-\n-kramdown:\n-  toc_levels: 1..3 # Include h1-h3 for ToC\n-\n-# The all languages used\n-languages: ['en', 'zh']\n-\n-plugins: ['jekyll-paginate', 'jekyll-multiple-languages']"
        },
        {
            "sha": "eb11fbf39f3192b89559ed5e9d287eaa7506a134",
            "filename": "docs/_config_dev_en.yml",
            "status": "removed",
            "additions": 0,
            "deletions": 24,
            "changes": 24,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_config_dev_en.yml",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_config_dev_en.yml",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_config_dev_en.yml?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,24 +0,0 @@\n-# Licensed to the Apache Software Foundation (ASF) under one\n-# or more contributor license agreements.  See the NOTICE file\n-# distributed with this work for additional information\n-# regarding copyright ownership.  The ASF licenses this file\n-# to you under the Apache License, Version 2.0 (the\n-# \"License\"); you may not use this file except in compliance\n-# with the License.  You may obtain a copy of the License at\n-#\n-# http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing,\n-# software distributed under the License is distributed on an\n-# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-# KIND, either express or implied.  See the License for the\n-# specific language governing permissions and limitations\n-# under the License\n-\n-exclude:\n-  - \"*.zh.md\"\n-  - \"build_docs.sh\"\n-  - \"check_links.sh\"\n-  - \"content\"\n-  - \"content_en\"\n-  - \"content_zh\""
        },
        {
            "sha": "8b9ddeb88caaf51df11433564eeb3f546318e3c0",
            "filename": "docs/_config_dev_zh.yml",
            "status": "removed",
            "additions": 0,
            "deletions": 27,
            "changes": 27,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_config_dev_zh.yml",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_config_dev_zh.yml",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_config_dev_zh.yml?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,27 +0,0 @@\n-# Licensed to the Apache Software Foundation (ASF) under one\n-# or more contributor license agreements.  See the NOTICE file\n-# distributed with this work for additional information\n-# regarding copyright ownership.  The ASF licenses this file\n-# to you under the Apache License, Version 2.0 (the\n-# \"License\"); you may not use this file except in compliance\n-# with the License.  You may obtain a copy of the License at\n-#\n-# http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing,\n-# software distributed under the License is distributed on an\n-# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-# KIND, either express or implied.  See the License for the\n-# specific language governing permissions and limitations\n-# under the License\n-\n-exclude:\n-  - \"*.md\"\n-  - \"build_docs.sh\"\n-  - \"check_links.sh\"\n-  - \"content\"\n-  - \"content_en\"\n-  - \"content_zh\"\n-\n-include:\n-  - \"*.zh.md\""
        },
        {
            "sha": "2683cda79f503697f52759a4d03d0b65bc399bf6",
            "filename": "docs/_data/sql-connectors.yml",
            "status": "removed",
            "additions": 0,
            "deletions": 148,
            "changes": 148,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_data/sql-connectors.yml",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_data/sql-connectors.yml",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_data/sql-connectors.yml?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,148 +0,0 @@\n-# Licensed to the Apache Software Foundation (ASF) under one\n-# or more contributor license agreements.  See the NOTICE file\n-# distributed with this work for additional information\n-# regarding copyright ownership.  The ASF licenses this file\n-# to you under the Apache License, Version 2.0 (the\n-# \"License\"); you may not use this file except in compliance\n-# with the License.  You may obtain a copy of the License at\n-#\n-# http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing,\n-# software distributed under the License is distributed on an\n-# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-# KIND, either express or implied.  See the License for the\n-# specific language governing permissions and limitations\n-# under the License\n-\n-# INSTRUCTIONS:\n-#\n-# In order to add a new connector/format add a new entry to this file.\n-# You need specify a name that will be used in e.g. the description of the connector/format and\n-# a category (either \"format\" or \"connector\"). The category determines which table will the entry\n-# end up in on the Download page. The \"maven\" parameter describes the name of the maven module. The\n-# three parameters are required.\n-#\n-# If you specify \"built-in=true\" the corresponding table on the connector/format will not contain\n-# a link, but just a \"Built-in\" entry. If the built-in is set to true you do not need to provide the\n-# sql-url.\n-#\n-# If a connector comes with different versions for the external system, you can put those under a\n-# \"versions\" property. Each entry in the \"versions\" section should have a \"version\", which\n-# determines name for the version and \"maven\" and \"sql-url\" entries for that particular version.\n-# If you use the \"versions\" property, \"maven\" and \"sql-url\" should not be present in the top level\n-# section of the connector. (Multiple versions are supported only for the connector for now. If you\n-# need multiple versions support for formats, please update downloads.md)\n-#\n-# NOTE: You can use liquid variables in \"sql-url\" and \"maven\" properties.\n-\n-avro:\n-    name: Avro\n-    maven: flink-sql-avro\n-    category: format\n-    sql-url: https://repo.maven.apache.org/maven2/org/apache/flink/flink-sql-avro/{{site.version}}/flink-sql-avro-{{site.version}}.jar\n-\n-avro-confluent:\n-    name: Avro Schema Registry\n-    maven: flink-avro-confluent-registry\n-    category: format\n-    sql-url: https://repo.maven.apache.org/maven2/org/apache/flink/flink-sql-avro-confluent-registry/{{site.version}}/flink-sql-avro-confluent-registry-{{site.version}}.jar\n-\n-orc:\n-    name: ORC\n-    maven: flink-orc{{site.scala_version_suffix}}\n-    category: format\n-    sql-url: https://repo.maven.apache.org/maven2/org/apache/flink/flink-sql-orc{{site.scala_version_suffix}}/{{site.version}}/flink-sql-orc{{site.scala_version_suffix}}-{{site.version}}.jar\n-\n-parquet:\n-    name: Parquet\n-    maven: flink-parquet{{site.scala_version_suffix}}\n-    category: format\n-    sql-url: https://repo.maven.apache.org/maven2/org/apache/flink/flink-sql-parquet{{site.scala_version_suffix}}/{{site.version}}/flink-sql-parquet{{site.scala_version_suffix}}-{{site.version}}.jar\n-\n-debezium-avro-confluent:\n-    name: Debezium\n-    maven: flink-avro-confluent-registry\n-    category: format\n-    sql-url: https://repo.maven.apache.org/maven2/org/apache/flink/flink-sql-avro-confluent-registry/{{site.version}}/flink-sql-avro-confluent-registry-{{site.version}}.jar\n-\n-debezium-json:\n-    name: Debezium\n-    maven: flink-json\n-    category: format\n-    built-in: true\n-\n-canal:\n-    name: Canal\n-    maven: flink-json\n-    category: format\n-    built-in: true\n-\n-csv:\n-    name: CSV\n-    maven: flink-csv\n-    category: format\n-    built-in: true\n-\n-json:\n-    name: Json\n-    maven: flink-json\n-    category: format\n-    built-in: true\n-\n-raw:\n-    name: RAW\n-    maven: flink-raw\n-    category: format\n-    built-in: true\n-\n-elastic:\n-    name: Elasticsearch\n-    category: connector\n-    versions:\n-        - version: 6.x\n-          maven: flink-connector-elasticsearch6{{site.scala_version_suffix}}\n-          sql-url: https://repo.maven.apache.org/maven2/org/apache/flink/flink-sql-connector-elasticsearch6{{site.scala_version_suffix}}/{{site.version}}/flink-sql-connector-elasticsearch6{{site.scala_version_suffix}}-{{site.version}}.jar\n-        - version: 7.x and later versions\n-          maven: flink-connector-elasticsearch7{{site.scala_version_suffix}}\n-          sql-url: https://repo.maven.apache.org/maven2/org/apache/flink/flink-sql-connector-elasticsearch7{{site.scala_version_suffix}}/{{site.version}}/flink-sql-connector-elasticsearch7{{site.scala_version_suffix}}-{{site.version}}.jar\n-\n-hbase:\n-    name: HBase\n-    category: connector\n-    versions:\n-        - version: 1.4.x\n-          maven: flink-connector-hbase-1.4{{site.scala_version_suffix}}\n-          sql-url: https://repo.maven.apache.org/maven2/org/apache/flink/flink-sql-connector-hbase-1.4{{site.scala_version_suffix}}/{{site.version}}/flink-sql-connector-hbase-1.4{{site.scala_version_suffix}}-{{site.version}}.jar\n-        - version: 2.2.x\n-          maven: flink-connector-hbase-2.2{{site.scala_version_suffix}}\n-          sql-url: https://repo.maven.apache.org/maven2/org/apache/flink/flink-sql-connector-hbase-2.2{{site.scala_version_suffix}}/{{site.version}}/flink-sql-connector-hbase-2.2{{site.scala_version_suffix}}-{{site.version}}.jar\n-\n-jdbc:\n-    name: JDBC\n-    category: connector\n-    maven: flink-connector-jdbc{{site.scala_version_suffix}}\n-    sql-url: https://repo.maven.apache.org/maven2/org/apache/flink/flink-connector-jdbc{{site.scala_version_suffix}}/{{site.version}}/flink-connector-jdbc{{site.scala_version_suffix}}-{{site.version}}.jar\n-\n-kafka:\n-    name: Kafka\n-    category: connector\n-    versions:\n-        - version: universal\n-          maven: flink-connector-kafka{{site.scala_version_suffix}}\n-          sql-url: https://repo.maven.apache.org/maven2/org/apache/flink/flink-sql-connector-kafka{{site.scala_version_suffix}}/{{site.version}}/flink-sql-connector-kafka{{site.scala_version_suffix}}-{{site.version}}.jar\n-\n-upsert-kafka:\n-    name: Upsert Kafka\n-    category: connector\n-    versions:\n-        - version: universal\n-          maven: flink-connector-kafka{{site.scala_version_suffix}}\n-          sql-url: https://repo.maven.apache.org/maven2/org/apache/flink/flink-sql-connector-kafka{{site.scala_version_suffix}}/{{site.version}}/flink-sql-connector-kafka{{site.scala_version_suffix}}-{{site.version}}.jar\n-\n-kinesis:\n-    name: Kinesis\n-    category: connector\n-    maven: flink-connector-kinesis{{ site.scala_version_suffix }}\n-    sql-url: https://repo.maven.apache.org/maven2/org/apache/flink/flink-sql-connector-kinesis{{site.scala_version_suffix}}/{{site.version}}/flink-sql-connector-kinesis{{site.scala_version_suffix}}-{{site.version}}.jar\n-"
        },
        {
            "sha": "3e59c13ede8ee747f1161bb4116efaef7d2835c9",
            "filename": "docs/_includes/generated/akka_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 150,
            "changes": 150,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/akka_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/akka_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/akka_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,150 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>akka.ask.callstack</h5></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>If true, call stack for asynchronous asks are captured. That way, when an ask fails (for example times out), you get a proper exception, describing to the original method call and call site. Note that in case of having millions of concurrent RPC calls, this may add to the memory footprint.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>akka.ask.timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"10 s\"</td>\n-            <td>String</td>\n-            <td>Timeout used for all futures and blocking Akka calls. If Flink fails due to timeouts then you should try to increase this value. Timeouts can be caused by slow machines or a congested network. The timeout value requires a time-unit specifier (ms/s/min/h/d).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>akka.client-socket-worker-pool.pool-size-factor</h5></td>\n-            <td style=\"word-wrap: break-word;\">1.0</td>\n-            <td>Double</td>\n-            <td>The pool size factor is used to determine thread pool size using the following formula: ceil(available processors * factor). Resulting size is then bounded by the pool-size-min and pool-size-max values.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>akka.client-socket-worker-pool.pool-size-max</h5></td>\n-            <td style=\"word-wrap: break-word;\">2</td>\n-            <td>Integer</td>\n-            <td>Max number of threads to cap factor-based number to.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>akka.client-socket-worker-pool.pool-size-min</h5></td>\n-            <td style=\"word-wrap: break-word;\">1</td>\n-            <td>Integer</td>\n-            <td>Min number of threads to cap factor-based number to.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>akka.fork-join-executor.parallelism-factor</h5></td>\n-            <td style=\"word-wrap: break-word;\">2.0</td>\n-            <td>Double</td>\n-            <td>The parallelism factor is used to determine thread pool size using the following formula: ceil(available processors * factor). Resulting size is then bounded by the parallelism-min and parallelism-max values.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>akka.fork-join-executor.parallelism-max</h5></td>\n-            <td style=\"word-wrap: break-word;\">64</td>\n-            <td>Integer</td>\n-            <td>Max number of threads to cap factor-based parallelism number to.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>akka.fork-join-executor.parallelism-min</h5></td>\n-            <td style=\"word-wrap: break-word;\">8</td>\n-            <td>Integer</td>\n-            <td>Min number of threads to cap factor-based parallelism number to.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>akka.framesize</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"10485760b\"</td>\n-            <td>String</td>\n-            <td>Maximum size of messages which are sent between the JobManager and the TaskManagers. If Flink fails because messages exceed this limit, then you should increase it. The message size requires a size-unit specifier.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>akka.jvm-exit-on-fatal-error</h5></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>Exit JVM on fatal Akka errors.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>akka.log.lifecycle.events</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Turns on the Akka’s remote logging of events. Set this value to 'true' in case of debugging.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>akka.lookup.timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"10 s\"</td>\n-            <td>String</td>\n-            <td>Timeout used for the lookup of the JobManager. The timeout value has to contain a time-unit specifier (ms/s/min/h/d).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>akka.retry-gate-closed-for</h5></td>\n-            <td style=\"word-wrap: break-word;\">50</td>\n-            <td>Long</td>\n-            <td>Milliseconds a gate should be closed for after a remote connection was disconnected.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>akka.server-socket-worker-pool.pool-size-factor</h5></td>\n-            <td style=\"word-wrap: break-word;\">1.0</td>\n-            <td>Double</td>\n-            <td>The pool size factor is used to determine thread pool size using the following formula: ceil(available processors * factor). Resulting size is then bounded by the pool-size-min and pool-size-max values.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>akka.server-socket-worker-pool.pool-size-max</h5></td>\n-            <td style=\"word-wrap: break-word;\">2</td>\n-            <td>Integer</td>\n-            <td>Max number of threads to cap factor-based number to.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>akka.server-socket-worker-pool.pool-size-min</h5></td>\n-            <td style=\"word-wrap: break-word;\">1</td>\n-            <td>Integer</td>\n-            <td>Min number of threads to cap factor-based number to.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>akka.ssl.enabled</h5></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>Turns on SSL for Akka’s remote communication. This is applicable only when the global ssl flag security.ssl.enabled is set to true.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>akka.startup-timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Timeout after which the startup of a remote component is considered being failed.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>akka.tcp.timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"20 s\"</td>\n-            <td>String</td>\n-            <td>Timeout for all outbound connections. If you should experience problems with connecting to a TaskManager due to a slow network, you should increase this value.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>akka.throughput</h5></td>\n-            <td style=\"word-wrap: break-word;\">15</td>\n-            <td>Integer</td>\n-            <td>Number of messages that are processed in a batch before returning the thread to the pool. Low values denote a fair scheduling whereas high values can increase the performance at the cost of unfairness.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>akka.transport.heartbeat.interval</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"1000 s\"</td>\n-            <td>String</td>\n-            <td>Heartbeat interval for Akka’s transport failure detector. Since Flink uses TCP, the detector is not necessary. Therefore, the detector is disabled by setting the interval to a very high value. In case you should need the transport failure detector, set the interval to some reasonable value. The interval value requires a time-unit specifier (ms/s/min/h/d).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>akka.transport.heartbeat.pause</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"6000 s\"</td>\n-            <td>String</td>\n-            <td>Acceptable heartbeat pause for Akka’s transport failure detector. Since Flink uses TCP, the detector is not necessary. Therefore, the detector is disabled by setting the pause to a very high value. In case you should need the transport failure detector, set the pause to some reasonable value. The pause value requires a time-unit specifier (ms/s/min/h/d).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>akka.transport.threshold</h5></td>\n-            <td style=\"word-wrap: break-word;\">300.0</td>\n-            <td>Double</td>\n-            <td>Threshold for the transport failure detector. Since Flink uses TCP, the detector is not necessary and, thus, the threshold is set to a high value.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "8b3fb2e844bce3950938d44b0ef69d13695f9c65",
            "filename": "docs/_includes/generated/algorithm_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 36,
            "changes": 36,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/algorithm_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/algorithm_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/algorithm_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,36 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>taskmanager.runtime.hashjoin-bloom-filters</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Flag to activate/deactivate bloom filters in the hybrid hash join implementation. In cases where the hash join needs to spill to disk (datasets larger than the reserved fraction of memory), these bloom filters can greatly reduce the number of spilled records, at the cost some CPU cycles.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.runtime.large-record-handler</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Whether to use the LargeRecordHandler when spilling. If a record will not fit into the sorting buffer. The record will be spilled on disk and the sorting will continue with only the key. The record itself will be read afterwards when merging.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.runtime.max-fan</h5></td>\n-            <td style=\"word-wrap: break-word;\">128</td>\n-            <td>Integer</td>\n-            <td>The maximal fan-in for external merge joins and fan-out for spilling hash tables. Limits the number of file handles per operator, but may cause intermediate merging/partitioning, if set too small.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.runtime.sort-spilling-threshold</h5></td>\n-            <td style=\"word-wrap: break-word;\">0.8</td>\n-            <td>Float</td>\n-            <td>A sort operation starts spilling when this fraction of its memory budget is full.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "3cf1e6116c14f1d3d7c44d29d23450138a5d78af",
            "filename": "docs/_includes/generated/all_jobmanager_section.html",
            "status": "removed",
            "additions": 0,
            "deletions": 66,
            "changes": 66,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/all_jobmanager_section.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/all_jobmanager_section.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/all_jobmanager_section.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,66 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>jobmanager.archive.fs.dir</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Dictionary for JobManager to store the archives of completed jobs.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobmanager.execution.attempts-history-size</h5></td>\n-            <td style=\"word-wrap: break-word;\">16</td>\n-            <td>Integer</td>\n-            <td>The maximum number of prior execution attempts kept in history.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobmanager.execution.failover-strategy</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"region\"</td>\n-            <td>String</td>\n-            <td>This option specifies how the job computation recovers from task failures. Accepted values are:<ul><li>'full': Restarts all tasks to recover the job.</li><li>'region': Restarts all tasks that could be affected by the task failure. More details can be found <a href=\"../dev/task_failure_recovery.html#restart-pipelined-region-failover-strategy\">here</a>.</li></ul></td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobmanager.retrieve-taskmanager-hostname</h5></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>Flag indicating whether JobManager would retrieve canonical host name of TaskManager during registration. If the option is set to \"false\", TaskManager registration with JobManager could be faster, since no reverse DNS lookup is performed. However, local input split assignment (such as for HDFS files) may be impacted.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobmanager.rpc.address</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The config parameter defining the network address to connect to for communication with the job manager. This value is only interpreted in setups where a single JobManager with static name or address exists (simple standalone setups, or container setups with dynamic service name resolution). It is not used in many high-availability setups, when a leader-election service (like ZooKeeper) is used to elect and discover the JobManager leader from potentially multiple standby JobManagers.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobmanager.rpc.port</h5></td>\n-            <td style=\"word-wrap: break-word;\">6123</td>\n-            <td>Integer</td>\n-            <td>The config parameter defining the network port to connect to for communication with the job manager. Like jobmanager.rpc.address, this value is only interpreted in setups where a single JobManager with static name/address and port exists (simple standalone setups, or container setups with dynamic service name resolution). This config option is not used in many high-availability setups, when a leader-election service (like ZooKeeper) is used to elect and discover the JobManager leader from potentially multiple standby JobManagers.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobstore.cache-size</h5></td>\n-            <td style=\"word-wrap: break-word;\">52428800</td>\n-            <td>Long</td>\n-            <td>The job store cache size in bytes which is used to keep completed jobs in memory.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobstore.expiration-time</h5></td>\n-            <td style=\"word-wrap: break-word;\">3600</td>\n-            <td>Long</td>\n-            <td>The time in seconds after which a completed job expires and is purged from the job store.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobstore.max-capacity</h5></td>\n-            <td style=\"word-wrap: break-word;\">2147483647</td>\n-            <td>Integer</td>\n-            <td>The max number of completed jobs that can be kept in the job store.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "5e5336d62e1c350649c24f40ebbea5f2ff232b16",
            "filename": "docs/_includes/generated/all_taskmanager_network_section.html",
            "status": "removed",
            "additions": 0,
            "deletions": 120,
            "changes": 120,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/all_taskmanager_network_section.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/all_taskmanager_network_section.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/all_taskmanager_network_section.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,120 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>taskmanager.network.blocking-shuffle.compression.enabled</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Boolean flag indicating whether the shuffle data will be compressed for blocking shuffle mode. Note that data is compressed per buffer and compression can incur extra CPU overhead, so it is more effective for IO bounded scenario when data compression ratio is high. Currently, shuffle data compression is an experimental feature and the config option can be changed in the future.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.blocking-shuffle.type</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"file\"</td>\n-            <td>String</td>\n-            <td>The blocking shuffle type, either \"mmap\" or \"file\". The \"auto\" means selecting the property type automatically based on system memory architecture (64 bit for mmap and 32 bit for file). Note that the memory usage of mmap is not accounted by configured memory limits, but some resource frameworks like yarn would track this memory usage and kill the container once memory exceeding some threshold. Also note that this option is experimental and might be changed future.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.detailed-metrics</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Boolean flag to enable/disable more detailed metrics about inbound/outbound network queue lengths.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.memory.buffers-per-channel</h5></td>\n-            <td style=\"word-wrap: break-word;\">2</td>\n-            <td>Integer</td>\n-            <td>Number of exclusive network buffers to use for each outgoing/incoming channel (subpartition/inputchannel) in the credit-based flow control model. It should be configured at least 2 for good performance. 1 buffer is for receiving in-flight data in the subpartition and 1 buffer is for parallel serialization.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.memory.floating-buffers-per-gate</h5></td>\n-            <td style=\"word-wrap: break-word;\">8</td>\n-            <td>Integer</td>\n-            <td>Number of extra network buffers to use for each outgoing/incoming gate (result partition/input gate). In credit-based flow control mode, this indicates how many floating credits are shared among all the input channels. The floating buffers are distributed based on backlog (real-time output buffers in the subpartition) feedback, and can help relieve back-pressure caused by unbalanced data distribution among the subpartitions. This value should be increased in case of higher round trip times between nodes and/or larger number of machines in the cluster.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.memory.max-buffers-per-channel</h5></td>\n-            <td style=\"word-wrap: break-word;\">10</td>\n-            <td>Integer</td>\n-            <td>Number of max buffers that can be used for each channel. If a channel exceeds the number of max buffers, it will make the task become unavailable, cause the back pressure and block the data processing. This might speed up checkpoint alignment by preventing excessive growth of the buffered in-flight data in case of data skew and high number of configured floating buffers. This limit is not strictly guaranteed, and can be ignored by things like flatMap operators, records spanning multiple buffers or single timer producing large amount of data.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.netty.client.connectTimeoutSec</h5></td>\n-            <td style=\"word-wrap: break-word;\">120</td>\n-            <td>Integer</td>\n-            <td>The Netty client connection timeout.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.netty.client.numThreads</h5></td>\n-            <td style=\"word-wrap: break-word;\">-1</td>\n-            <td>Integer</td>\n-            <td>The number of Netty client threads.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.netty.num-arenas</h5></td>\n-            <td style=\"word-wrap: break-word;\">-1</td>\n-            <td>Integer</td>\n-            <td>The number of Netty arenas.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.netty.sendReceiveBufferSize</h5></td>\n-            <td style=\"word-wrap: break-word;\">0</td>\n-            <td>Integer</td>\n-            <td>The Netty send and receive buffer size. This defaults to the system buffer size (cat /proc/sys/net/ipv4/tcp_[rw]mem) and is 4 MiB in modern Linux.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.netty.server.backlog</h5></td>\n-            <td style=\"word-wrap: break-word;\">0</td>\n-            <td>Integer</td>\n-            <td>The netty server connection backlog.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.netty.server.numThreads</h5></td>\n-            <td style=\"word-wrap: break-word;\">-1</td>\n-            <td>Integer</td>\n-            <td>The number of Netty server threads.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.netty.transport</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"auto\"</td>\n-            <td>String</td>\n-            <td>The Netty transport type, either \"nio\" or \"epoll\". The \"auto\" means selecting the property mode automatically based on the platform. Note that the \"epoll\" mode can get better performance, less GC and have more advanced features which are only available on modern Linux.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.request-backoff.initial</h5></td>\n-            <td style=\"word-wrap: break-word;\">100</td>\n-            <td>Integer</td>\n-            <td>Minimum backoff in milliseconds for partition requests of input channels.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.request-backoff.max</h5></td>\n-            <td style=\"word-wrap: break-word;\">10000</td>\n-            <td>Integer</td>\n-            <td>Maximum backoff in milliseconds for partition requests of input channels.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.retries</h5></td>\n-            <td style=\"word-wrap: break-word;\">0</td>\n-            <td>Integer</td>\n-            <td>The number of retry attempts for network communication. Currently it's only used for establishing input/output channel connections</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.sort-shuffle.min-buffers</h5></td>\n-            <td style=\"word-wrap: break-word;\">64</td>\n-            <td>Integer</td>\n-            <td>Minimum number of network buffers required per sort-merge blocking result partition. For large scale batch jobs, it is suggested to increase this config value to improve compression ratio and reduce small network packets. Note: to increase this config value, you may also need to increase the size of total network memory to avoid \"insufficient number of network buffers\" error.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.sort-shuffle.min-parallelism</h5></td>\n-            <td style=\"word-wrap: break-word;\">2147483647</td>\n-            <td>Integer</td>\n-            <td>Parallelism threshold to switch between sort-merge blocking shuffle and the default hash-based blocking shuffle, which means for small parallelism, hash-based blocking shuffle will be used and for large parallelism, sort-merge blocking shuffle will be used. Note: sort-merge blocking shuffle uses unmanaged direct memory for shuffle data writing and reading so just increase the size of direct memory if direct memory OOM error occurs.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "cecde697206bdc15ca42cb20792a595f48c2a9f3",
            "filename": "docs/_includes/generated/all_taskmanager_section.html",
            "status": "removed",
            "additions": 0,
            "deletions": 103,
            "changes": 103,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/all_taskmanager_section.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/all_taskmanager_section.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/all_taskmanager_section.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,103 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>task.cancellation.interval</h5></td>\n-            <td style=\"word-wrap: break-word;\">30000</td>\n-            <td>Long</td>\n-            <td>Time interval between two successive task cancellation attempts in milliseconds.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>task.cancellation.timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">180000</td>\n-            <td>Long</td>\n-            <td>Timeout in milliseconds after which a task cancellation times out and leads to a fatal TaskManager error. A value of 0 deactivates the watch dog.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>task.cancellation.timers.timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">7500</td>\n-            <td>Long</td>\n-            <td>Time we wait for the timers in milliseconds to finish all pending timer threads when the stream task is cancelled.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.data.port</h5></td>\n-            <td style=\"word-wrap: break-word;\">0</td>\n-            <td>Integer</td>\n-            <td>The task manager’s external port used for data exchange operations.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.data.ssl.enabled</h5></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>Enable SSL support for the taskmanager data transport. This is applicable only when the global flag for internal SSL (security.ssl.internal.enabled) is set to true</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.debug.memory.log</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Flag indicating whether to start a thread, which repeatedly logs the memory usage of the JVM.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.debug.memory.log-interval</h5></td>\n-            <td style=\"word-wrap: break-word;\">5000</td>\n-            <td>Long</td>\n-            <td>The interval (in ms) for the log thread to log the current memory usage.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.host</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The external address of the network interface where the TaskManager is exposed. Because different TaskManagers need different values for this option, usually it is specified in an additional non-shared TaskManager-specific config file.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.jvm-exit-on-oom</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Whether to kill the TaskManager when the task thread throws an OutOfMemoryError.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.memory.segment-size</h5></td>\n-            <td style=\"word-wrap: break-word;\">32 kb</td>\n-            <td>MemorySize</td>\n-            <td>Size of memory buffers used by the network stack and the memory manager.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.bind-policy</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"ip\"</td>\n-            <td>String</td>\n-            <td>The automatic address binding policy used by the TaskManager if \"taskmanager.host\" is not set. The value should be one of the following:\n-<ul><li>\"name\" - uses hostname as binding address</li><li>\"ip\" - uses host's ip address as binding address</li></ul></td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.numberOfTaskSlots</h5></td>\n-            <td style=\"word-wrap: break-word;\">1</td>\n-            <td>Integer</td>\n-            <td>The number of parallel operator or user function instances that a single TaskManager can run. If this value is larger than 1, a single TaskManager takes multiple instances of a function or operator. That way, the TaskManager can utilize multiple CPU cores, but at the same time, the available memory is divided between the different operator or function instances. This value is typically proportional to the number of physical CPU cores that the TaskManager's machine has (e.g., equal to the number of cores, or half the number of cores).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.registration.timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">5 min</td>\n-            <td>Duration</td>\n-            <td>Defines the timeout for the TaskManager registration. If the duration is exceeded without a successful registration, then the TaskManager terminates.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.resource-id</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The TaskManager's ResourceID. If not configured, the ResourceID will be generated with the \"RpcAddress:RpcPort\" and a 6-character random string. Notice that this option is not valid in Yarn / Mesos and Native Kubernetes mode.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.rpc.port</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"0\"</td>\n-            <td>String</td>\n-            <td>The external RPC port where the TaskManager is exposed. Accepts a list of ports (“50100,50101”), ranges (“50100-50200”) or a combination of both. It is recommended to set a range of ports to avoid collisions when multiple TaskManagers are running on the same machine.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "ee5620a425b852f2498ff5d94dad7d46a376119b",
            "filename": "docs/_includes/generated/blob_server_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 72,
            "changes": 72,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/blob_server_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/blob_server_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/blob_server_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,72 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>blob.client.connect.timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">0</td>\n-            <td>Integer</td>\n-            <td>The connection timeout in milliseconds for the blob client.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>blob.client.socket.timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">300000</td>\n-            <td>Integer</td>\n-            <td>The socket timeout in milliseconds for the blob client.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>blob.fetch.backlog</h5></td>\n-            <td style=\"word-wrap: break-word;\">1000</td>\n-            <td>Integer</td>\n-            <td>The config parameter defining the backlog of BLOB fetches on the JobManager.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>blob.fetch.num-concurrent</h5></td>\n-            <td style=\"word-wrap: break-word;\">50</td>\n-            <td>Integer</td>\n-            <td>The config parameter defining the maximum number of concurrent BLOB fetches that the JobManager serves.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>blob.fetch.retries</h5></td>\n-            <td style=\"word-wrap: break-word;\">5</td>\n-            <td>Integer</td>\n-            <td>The config parameter defining number of retires for failed BLOB fetches.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>blob.offload.minsize</h5></td>\n-            <td style=\"word-wrap: break-word;\">1048576</td>\n-            <td>Integer</td>\n-            <td>The minimum size for messages to be offloaded to the BlobServer.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>blob.server.port</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"0\"</td>\n-            <td>String</td>\n-            <td>The config parameter defining the server port of the blob service.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>blob.service.cleanup.interval</h5></td>\n-            <td style=\"word-wrap: break-word;\">3600</td>\n-            <td>Long</td>\n-            <td>Cleanup interval of the blob caches at the task managers (in seconds).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>blob.service.ssl.enabled</h5></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>Flag to override ssl support for the blob service transport.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>blob.storage.directory</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The config parameter defining the storage directory to be used by the blob server.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "748bdb256cdf3fe1938ff7b28e0c35fae1909531",
            "filename": "docs/_includes/generated/checkpointing_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 72,
            "changes": 72,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/checkpointing_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/checkpointing_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/checkpointing_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,72 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>state.backend</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The state backend to be used to store and checkpoint state.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.async</h5></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>Option whether the state backend should use an asynchronous snapshot method where possible and configurable. Some state backends may not support asynchronous snapshots, or only support asynchronous snapshots, and ignore this option.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.fs.memory-threshold</h5></td>\n-            <td style=\"word-wrap: break-word;\">20 kb</td>\n-            <td>MemorySize</td>\n-            <td>The minimum size of state data files. All state chunks smaller than that are stored inline in the root checkpoint metadata file. The max memory threshold for this configuration is 1MB.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.fs.write-buffer-size</h5></td>\n-            <td style=\"word-wrap: break-word;\">4096</td>\n-            <td>Integer</td>\n-            <td>The default size of the write buffer for the checkpoint streams that write to file systems. The actual write buffer size is determined to be the maximum of the value of this option and option 'state.backend.fs.memory-threshold'.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.incremental</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Option whether the state backend should create incremental checkpoints, if possible. For an incremental checkpoint, only a diff from the previous checkpoint is stored, rather than the complete checkpoint state. Once enabled, the state size shown in web UI or fetched from rest API only represents the delta checkpoint size instead of full checkpoint size. Some state backends may not support incremental checkpoints and ignore this option.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.local-recovery</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>This option configures local recovery for this state backend. By default, local recovery is deactivated. Local recovery currently only covers keyed state backends. Currently, MemoryStateBackend does not support local recovery and ignore this option.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.checkpoints.dir</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The default directory used for storing the data files and meta data of checkpoints in a Flink supported filesystem. The storage path must be accessible from all participating processes/nodes(i.e. all TaskManagers and JobManagers).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.checkpoints.num-retained</h5></td>\n-            <td style=\"word-wrap: break-word;\">1</td>\n-            <td>Integer</td>\n-            <td>The maximum number of completed checkpoints to retain.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.savepoints.dir</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The default directory for savepoints. Used by the state backends that write savepoints to file systems (MemoryStateBackend, FsStateBackend, RocksDBStateBackend).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.state.local.root-dirs</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The config parameter defining the root directories for storing file-based state for local recovery. Local recovery currently only covers keyed state backends. Currently, MemoryStateBackend does not support local recovery and ignore this option</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "c623ddeb3bbad378280a4d2fb6d19d4afe390003",
            "filename": "docs/_includes/generated/client_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 24,
            "changes": 24,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/client_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/client_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/client_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,24 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>client.retry-period</h5></td>\n-            <td style=\"word-wrap: break-word;\">2 s</td>\n-            <td>Duration</td>\n-            <td>The interval (in ms) between consecutive retries of failed attempts to execute commands through the CLI or Flink's clients, wherever retry is supported (default 2sec).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>client.timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">1 min</td>\n-            <td>Duration</td>\n-            <td>Timeout on the client side.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "a08a1cd75da9cb828c0562aa43ceb72e4ab64872",
            "filename": "docs/_includes/generated/cluster_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 60,
            "changes": 60,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/cluster_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/cluster_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/cluster_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,60 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>cluster.evenly-spread-out-slots</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Enable the slot spread out allocation strategy. This strategy tries to spread out the slots evenly across all available <span markdown=\"span\">`TaskExecutors`</span>.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>cluster.io-pool.size</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>Integer</td>\n-            <td>The size of the IO executor pool used by the cluster to execute blocking IO operations (Master as well as TaskManager processes). By default it will use 4 * the number of CPU cores (hardware contexts) that the cluster process has access to. Increasing the pool size allows to run more IO operations concurrently.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>cluster.processes.halt-on-fatal-error</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Whether processes should halt on fatal errors instead of performing a graceful shutdown. In some environments (e.g. Java 8 with the G1 garbage collector), a regular graceful shutdown can lead to a JVM deadlock. See <a href=\"https://issues.apache.org/jira/browse/FLINK-16510\">FLINK-16510</a> for details.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>cluster.registration.error-delay</h5></td>\n-            <td style=\"word-wrap: break-word;\">10000</td>\n-            <td>Long</td>\n-            <td>The pause made after an registration attempt caused an exception (other than timeout) in milliseconds.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>cluster.registration.initial-timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">100</td>\n-            <td>Long</td>\n-            <td>Initial registration timeout between cluster components in milliseconds.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>cluster.registration.max-timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">30000</td>\n-            <td>Long</td>\n-            <td>Maximum registration timeout between cluster components in milliseconds.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>cluster.registration.refused-registration-delay</h5></td>\n-            <td style=\"word-wrap: break-word;\">30000</td>\n-            <td>Long</td>\n-            <td>The pause made after the registration attempt was refused in milliseconds.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>cluster.services.shutdown-timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">30000</td>\n-            <td>Long</td>\n-            <td>The shutdown timeout for cluster services like executors in milliseconds.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "4c06ca778cf2ded408bf5ca0cc8937aaba20704d",
            "filename": "docs/_includes/generated/common_high_availability_section.html",
            "status": "removed",
            "additions": 0,
            "deletions": 30,
            "changes": 30,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/common_high_availability_section.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/common_high_availability_section.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/common_high_availability_section.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,30 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>high-availability</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"NONE\"</td>\n-            <td>String</td>\n-            <td>Defines high-availability mode used for the cluster execution. To enable high-availability, set this mode to \"ZOOKEEPER\" or specify FQN of factory class.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>high-availability.cluster-id</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"/default\"</td>\n-            <td>String</td>\n-            <td>The ID of the Flink cluster, used to separate multiple Flink clusters from each other. Needs to be set for standalone clusters but is automatically inferred in YARN and Mesos.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>high-availability.storageDir</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>File system path (URI) where Flink persists metadata in high-availability setups.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "18175fb7339c96c8145102ed4fae49e480981608",
            "filename": "docs/_includes/generated/common_high_availability_zk_section.html",
            "status": "removed",
            "additions": 0,
            "deletions": 24,
            "changes": 24,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/common_high_availability_zk_section.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/common_high_availability_zk_section.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/common_high_availability_zk_section.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,24 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>high-availability.zookeeper.path.root</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"/flink\"</td>\n-            <td>String</td>\n-            <td>The root path under which Flink stores its entries in ZooKeeper.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>high-availability.zookeeper.quorum</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The ZooKeeper quorum to use, when running Flink in a high-availability mode with ZooKeeper.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "21d793511b9dfa6858c6366c7992ecdb890971ee",
            "filename": "docs/_includes/generated/common_host_port_section.html",
            "status": "removed",
            "additions": 0,
            "deletions": 72,
            "changes": 72,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/common_host_port_section.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/common_host_port_section.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/common_host_port_section.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,72 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>jobmanager.rpc.address</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The config parameter defining the network address to connect to for communication with the job manager. This value is only interpreted in setups where a single JobManager with static name or address exists (simple standalone setups, or container setups with dynamic service name resolution). It is not used in many high-availability setups, when a leader-election service (like ZooKeeper) is used to elect and discover the JobManager leader from potentially multiple standby JobManagers.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobmanager.rpc.port</h5></td>\n-            <td style=\"word-wrap: break-word;\">6123</td>\n-            <td>Integer</td>\n-            <td>The config parameter defining the network port to connect to for communication with the job manager. Like jobmanager.rpc.address, this value is only interpreted in setups where a single JobManager with static name/address and port exists (simple standalone setups, or container setups with dynamic service name resolution). This config option is not used in many high-availability setups, when a leader-election service (like ZooKeeper) is used to elect and discover the JobManager leader from potentially multiple standby JobManagers.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>metrics.internal.query-service.port</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"0\"</td>\n-            <td>String</td>\n-            <td>The port range used for Flink's internal metric query service. Accepts a list of ports (“50100,50101”), ranges(“50100-50200”) or a combination of both. It is recommended to set a range of ports to avoid collisions when multiple Flink components are running on the same machine. Per default Flink will pick a random port.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>rest.address</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The address that should be used by clients to connect to the server. Attention: This option is respected only if the high-availability configuration is NONE.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>rest.bind-address</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The address that the server binds itself.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>rest.bind-port</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"8081\"</td>\n-            <td>String</td>\n-            <td>The port that the server binds itself. Accepts a list of ports (“50100,50101”), ranges (“50100-50200”) or a combination of both. It is recommended to set a range of ports to avoid collisions when multiple Rest servers are running on the same machine.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>rest.port</h5></td>\n-            <td style=\"word-wrap: break-word;\">8081</td>\n-            <td>Integer</td>\n-            <td>The port that the client connects to. If rest.bind-port has not been specified, then the REST server will bind to this port. Attention: This option is respected only if the high-availability configuration is NONE.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.data.port</h5></td>\n-            <td style=\"word-wrap: break-word;\">0</td>\n-            <td>Integer</td>\n-            <td>The task manager’s external port used for data exchange operations.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.host</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The external address of the network interface where the TaskManager is exposed. Because different TaskManagers need different values for this option, usually it is specified in an additional non-shared TaskManager-specific config file.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.rpc.port</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"0\"</td>\n-            <td>String</td>\n-            <td>The external RPC port where the TaskManager is exposed. Accepts a list of ports (“50100,50101”), ranges (“50100-50200”) or a combination of both. It is recommended to set a range of ports to avoid collisions when multiple TaskManagers are running on the same machine.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "c2e016056a1355f7c0ed9a1250284f2a7c34c9ed",
            "filename": "docs/_includes/generated/common_memory_section.html",
            "status": "removed",
            "additions": 0,
            "deletions": 162,
            "changes": 162,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/common_memory_section.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/common_memory_section.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/common_memory_section.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,162 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>jobmanager.memory.enable-jvm-direct-memory-limit</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Whether to enable the JVM direct memory limit of the JobManager process (-XX:MaxDirectMemorySize). The limit will be set to the value of 'jobmanager.memory.off-heap.size' option. </td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobmanager.memory.flink.size</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>MemorySize</td>\n-            <td>Total Flink Memory size for the JobManager. This includes all the memory that a JobManager consumes, except for JVM Metaspace and JVM Overhead. It consists of JVM Heap Memory and Off-heap Memory. See also 'jobmanager.memory.process.size' for total process memory size configuration.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobmanager.memory.heap.size</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>MemorySize</td>\n-            <td>JVM Heap Memory size for JobManager. The minimum recommended JVM Heap size is 128.000mb (134217728 bytes).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobmanager.memory.jvm-metaspace.size</h5></td>\n-            <td style=\"word-wrap: break-word;\">256 mb</td>\n-            <td>MemorySize</td>\n-            <td>JVM Metaspace Size for the JobManager.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobmanager.memory.jvm-overhead.fraction</h5></td>\n-            <td style=\"word-wrap: break-word;\">0.1</td>\n-            <td>Float</td>\n-            <td>Fraction of Total Process Memory to be reserved for JVM Overhead. This is off-heap memory reserved for JVM overhead, such as thread stack space, compile cache, etc. This includes native memory but not direct memory, and will not be counted when Flink calculates JVM max direct memory size parameter. The size of JVM Overhead is derived to make up the configured fraction of the Total Process Memory. If the derived size is less or greater than the configured min or max size, the min or max size will be used. The exact size of JVM Overhead can be explicitly specified by setting the min and max size to the same value.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobmanager.memory.jvm-overhead.max</h5></td>\n-            <td style=\"word-wrap: break-word;\">1 gb</td>\n-            <td>MemorySize</td>\n-            <td>Max JVM Overhead size for the JobManager. This is off-heap memory reserved for JVM overhead, such as thread stack space, compile cache, etc. This includes native memory but not direct memory, and will not be counted when Flink calculates JVM max direct memory size parameter. The size of JVM Overhead is derived to make up the configured fraction of the Total Process Memory. If the derived size is less or greater than the configured min or max size, the min or max size will be used. The exact size of JVM Overhead can be explicitly specified by setting the min and max size to the same value.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobmanager.memory.jvm-overhead.min</h5></td>\n-            <td style=\"word-wrap: break-word;\">192 mb</td>\n-            <td>MemorySize</td>\n-            <td>Min JVM Overhead size for the JobManager. This is off-heap memory reserved for JVM overhead, such as thread stack space, compile cache, etc. This includes native memory but not direct memory, and will not be counted when Flink calculates JVM max direct memory size parameter. The size of JVM Overhead is derived to make up the configured fraction of the Total Process Memory. If the derived size is less or greater than the configured min or max size, the min or max size will be used. The exact size of JVM Overhead can be explicitly specified by setting the min and max size to the same value.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobmanager.memory.off-heap.size</h5></td>\n-            <td style=\"word-wrap: break-word;\">128 mb</td>\n-            <td>MemorySize</td>\n-            <td>Off-heap Memory size for JobManager. This option covers all off-heap memory usage including direct and native memory allocation. The JVM direct memory limit of the JobManager process (-XX:MaxDirectMemorySize) will be set to this value if the limit is enabled by 'jobmanager.memory.enable-jvm-direct-memory-limit'. </td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobmanager.memory.process.size</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>MemorySize</td>\n-            <td>Total Process Memory size for the JobManager. This includes all the memory that a JobManager JVM process consumes, consisting of Total Flink Memory, JVM Metaspace, and JVM Overhead. In containerized setups, this should be set to the container memory. See also 'jobmanager.memory.flink.size' for Total Flink Memory size configuration.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.memory.flink.size</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>MemorySize</td>\n-            <td>Total Flink Memory size for the TaskExecutors. This includes all the memory that a TaskExecutor consumes, except for JVM Metaspace and JVM Overhead. It consists of Framework Heap Memory, Task Heap Memory, Task Off-Heap Memory, Managed Memory, and Network Memory. See also 'taskmanager.memory.process.size' for total process memory size configuration.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.memory.framework.heap.size</h5></td>\n-            <td style=\"word-wrap: break-word;\">128 mb</td>\n-            <td>MemorySize</td>\n-            <td>Framework Heap Memory size for TaskExecutors. This is the size of JVM heap memory reserved for TaskExecutor framework, which will not be allocated to task slots.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.memory.framework.off-heap.size</h5></td>\n-            <td style=\"word-wrap: break-word;\">128 mb</td>\n-            <td>MemorySize</td>\n-            <td>Framework Off-Heap Memory size for TaskExecutors. This is the size of off-heap memory (JVM direct memory and native memory) reserved for TaskExecutor framework, which will not be allocated to task slots. The configured value will be fully counted when Flink calculates the JVM max direct memory size parameter.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.memory.jvm-metaspace.size</h5></td>\n-            <td style=\"word-wrap: break-word;\">256 mb</td>\n-            <td>MemorySize</td>\n-            <td>JVM Metaspace Size for the TaskExecutors.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.memory.jvm-overhead.fraction</h5></td>\n-            <td style=\"word-wrap: break-word;\">0.1</td>\n-            <td>Float</td>\n-            <td>Fraction of Total Process Memory to be reserved for JVM Overhead. This is off-heap memory reserved for JVM overhead, such as thread stack space, compile cache, etc. This includes native memory but not direct memory, and will not be counted when Flink calculates JVM max direct memory size parameter. The size of JVM Overhead is derived to make up the configured fraction of the Total Process Memory. If the derived size is less/greater than the configured min/max size, the min/max size will be used. The exact size of JVM Overhead can be explicitly specified by setting the min/max size to the same value.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.memory.jvm-overhead.max</h5></td>\n-            <td style=\"word-wrap: break-word;\">1 gb</td>\n-            <td>MemorySize</td>\n-            <td>Max JVM Overhead size for the TaskExecutors. This is off-heap memory reserved for JVM overhead, such as thread stack space, compile cache, etc. This includes native memory but not direct memory, and will not be counted when Flink calculates JVM max direct memory size parameter. The size of JVM Overhead is derived to make up the configured fraction of the Total Process Memory. If the derived size is less/greater than the configured min/max size, the min/max size will be used. The exact size of JVM Overhead can be explicitly specified by setting the min/max size to the same value.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.memory.jvm-overhead.min</h5></td>\n-            <td style=\"word-wrap: break-word;\">192 mb</td>\n-            <td>MemorySize</td>\n-            <td>Min JVM Overhead size for the TaskExecutors. This is off-heap memory reserved for JVM overhead, such as thread stack space, compile cache, etc. This includes native memory but not direct memory, and will not be counted when Flink calculates JVM max direct memory size parameter. The size of JVM Overhead is derived to make up the configured fraction of the Total Process Memory. If the derived size is less/greater than the configured min/max size, the min/max size will be used. The exact size of JVM Overhead can be explicitly specified by setting the min/max size to the same value.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.memory.managed.consumer-weights</h5></td>\n-            <td style=\"word-wrap: break-word;\">DATAPROC:70,PYTHON:30</td>\n-            <td>Map</td>\n-            <td>Managed memory weights for different kinds of consumers. A slot’s managed memory is shared by all kinds of consumers it contains, proportionally to the kinds’ weights and regardless of the number of consumers from each kind. Currently supported kinds of consumers are DATAPROC (for RocksDB state backend in streaming and built-in algorithms in batch) and PYTHON (for Python processes).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.memory.managed.fraction</h5></td>\n-            <td style=\"word-wrap: break-word;\">0.4</td>\n-            <td>Float</td>\n-            <td>Fraction of Total Flink Memory to be used as Managed Memory, if Managed Memory size is not explicitly specified.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.memory.managed.size</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>MemorySize</td>\n-            <td>Managed Memory size for TaskExecutors. This is the size of off-heap memory managed by the memory manager, reserved for sorting, hash tables, caching of intermediate results and RocksDB state backend. Memory consumers can either allocate memory from the memory manager in the form of MemorySegments, or reserve bytes from the memory manager and keep their memory usage within that boundary. If unspecified, it will be derived to make up the configured fraction of the Total Flink Memory.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.memory.network.fraction</h5></td>\n-            <td style=\"word-wrap: break-word;\">0.1</td>\n-            <td>Float</td>\n-            <td>Fraction of Total Flink Memory to be used as Network Memory. Network Memory is off-heap memory reserved for ShuffleEnvironment (e.g., network buffers). Network Memory size is derived to make up the configured fraction of the Total Flink Memory. If the derived size is less/greater than the configured min/max size, the min/max size will be used. The exact size of Network Memory can be explicitly specified by setting the min/max size to the same value.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.memory.network.max</h5></td>\n-            <td style=\"word-wrap: break-word;\">1 gb</td>\n-            <td>MemorySize</td>\n-            <td>Max Network Memory size for TaskExecutors. Network Memory is off-heap memory reserved for ShuffleEnvironment (e.g., network buffers). Network Memory size is derived to make up the configured fraction of the Total Flink Memory. If the derived size is less/greater than the configured min/max size, the min/max size will be used. The exact size of Network Memory can be explicitly specified by setting the min/max to the same value.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.memory.network.min</h5></td>\n-            <td style=\"word-wrap: break-word;\">64 mb</td>\n-            <td>MemorySize</td>\n-            <td>Min Network Memory size for TaskExecutors. Network Memory is off-heap memory reserved for ShuffleEnvironment (e.g., network buffers). Network Memory size is derived to make up the configured fraction of the Total Flink Memory. If the derived size is less/greater than the configured min/max size, the min/max size will be used. The exact size of Network Memory can be explicitly specified by setting the min/max to the same value.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.memory.process.size</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>MemorySize</td>\n-            <td>Total Process Memory size for the TaskExecutors. This includes all the memory that a TaskExecutor consumes, consisting of Total Flink Memory, JVM Metaspace, and JVM Overhead. On containerized setups, this should be set to the container memory. See also 'taskmanager.memory.flink.size' for total Flink memory size configuration.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.memory.task.heap.size</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>MemorySize</td>\n-            <td>Task Heap Memory size for TaskExecutors. This is the size of JVM heap memory reserved for tasks. If not specified, it will be derived as Total Flink Memory minus Framework Heap Memory, Task Off-Heap Memory, Managed Memory and Network Memory.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.memory.task.off-heap.size</h5></td>\n-            <td style=\"word-wrap: break-word;\">0 bytes</td>\n-            <td>MemorySize</td>\n-            <td>Task Off-Heap Memory size for TaskExecutors. This is the size of off heap memory (JVM direct memory and native memory) reserved for tasks. The configured value will be fully counted when Flink calculates the JVM max direct memory size parameter.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "547a05b25429e05dfaf638d3d249db18e44c27bc",
            "filename": "docs/_includes/generated/common_miscellaneous_section.html",
            "status": "removed",
            "additions": 0,
            "deletions": 30,
            "changes": 30,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/common_miscellaneous_section.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/common_miscellaneous_section.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/common_miscellaneous_section.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,30 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>fs.allowed-fallback-filesystems</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>A (semicolon-separated) list of file schemes, for which Hadoop can be used instead of an appropriate Flink plugin. (example: s3;wasb)</td>\n-        </tr>\n-        <tr>\n-            <td><h5>fs.default-scheme</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The default filesystem scheme, used for paths that do not declare a scheme explicitly. May contain an authority, e.g. host:port in case of an HDFS NameNode.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>io.tmp.dirs</h5></td>\n-            <td style=\"word-wrap: break-word;\">'LOCAL_DIRS' on Yarn. '_FLINK_TMP_DIR' on Mesos. System.getProperty(\"java.io.tmpdir\") in standalone.</td>\n-            <td>String</td>\n-            <td>Directories for temporary files, separated by\",\", \"|\", or the system's java.io.File.pathSeparator.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "c24b0ceb915da5888810de5f81fbd699569cc01a",
            "filename": "docs/_includes/generated/common_state_backends_section.html",
            "status": "removed",
            "additions": 0,
            "deletions": 54,
            "changes": 54,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/common_state_backends_section.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/common_state_backends_section.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/common_state_backends_section.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,54 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>state.backend</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The state backend to be used to store and checkpoint state.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.checkpoints.dir</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The default directory used for storing the data files and meta data of checkpoints in a Flink supported filesystem. The storage path must be accessible from all participating processes/nodes(i.e. all TaskManagers and JobManagers).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.savepoints.dir</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The default directory for savepoints. Used by the state backends that write savepoints to file systems (MemoryStateBackend, FsStateBackend, RocksDBStateBackend).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.incremental</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Option whether the state backend should create incremental checkpoints, if possible. For an incremental checkpoint, only a diff from the previous checkpoint is stored, rather than the complete checkpoint state. Once enabled, the state size shown in web UI or fetched from rest API only represents the delta checkpoint size instead of full checkpoint size. Some state backends may not support incremental checkpoints and ignore this option.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.local-recovery</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>This option configures local recovery for this state backend. By default, local recovery is deactivated. Local recovery currently only covers keyed state backends. Currently, MemoryStateBackend does not support local recovery and ignore this option.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.checkpoints.num-retained</h5></td>\n-            <td style=\"word-wrap: break-word;\">1</td>\n-            <td>Integer</td>\n-            <td>The maximum number of completed checkpoints to retain.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.state.local.root-dirs</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The config parameter defining the root directories for storing file-based state for local recovery. Local recovery currently only covers keyed state backends. Currently, MemoryStateBackend does not support local recovery and ignore this option</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "d50c975adbfc5563929a764732c6d930fe3e51e4",
            "filename": "docs/_includes/generated/core_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 80,
            "changes": 80,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/core_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/core_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/core_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,80 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>classloader.check-leaked-classloader</h5></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>Fails attempts at loading classes if the user classloader of a job is used after it has terminated.\n-This is usually caused by the classloader being leaked by lingering threads or misbehaving libraries, which may also result in the classloader being used by other jobs.\n-This check should only be disabled if such a leak prevents further jobs from running.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>classloader.fail-on-metaspace-oom-error</h5></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>Fail Flink JVM processes if 'OutOfMemoryError: Metaspace' is thrown while trying to load a user code class.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>classloader.parent-first-patterns.additional</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>A (semicolon-separated) list of patterns that specifies which classes should always be resolved through the parent ClassLoader first. A pattern is a simple prefix that is checked against the fully qualified class name. These patterns are appended to \"classloader.parent-first-patterns.default\".</td>\n-        </tr>\n-        <tr>\n-            <td><h5>classloader.parent-first-patterns.default</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"java.;<wbr>scala.;<wbr>org.apache.flink.;<wbr>com.esotericsoftware.kryo;<wbr>org.apache.hadoop.;<wbr>javax.annotation.;<wbr>org.slf4j;<wbr>org.apache.log4j;<wbr>org.apache.logging;<wbr>org.apache.commons.logging;<wbr>ch.qos.logback;<wbr>org.xml;<wbr>javax.xml;<wbr>org.apache.xerces;<wbr>org.w3c\"</td>\n-            <td>String</td>\n-            <td>A (semicolon-separated) list of patterns that specifies which classes should always be resolved through the parent ClassLoader first. A pattern is a simple prefix that is checked against the fully qualified class name. This setting should generally not be modified. To add another pattern we recommend to use \"classloader.parent-first-patterns.additional\" instead.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>classloader.resolve-order</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"child-first\"</td>\n-            <td>String</td>\n-            <td>Defines the class resolution strategy when loading classes from user code, meaning whether to first check the user code jar (\"child-first\") or the application classpath (\"parent-first\"). The default settings indicate to load classes first from the user code jar, which means that user code jars can include and load different dependencies than Flink uses (transitively).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>fs.allowed-fallback-filesystems</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>A (semicolon-separated) list of file schemes, for which Hadoop can be used instead of an appropriate Flink plugin. (example: s3;wasb)</td>\n-        </tr>\n-        <tr>\n-            <td><h5>fs.default-scheme</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The default filesystem scheme, used for paths that do not declare a scheme explicitly. May contain an authority, e.g. host:port in case of an HDFS NameNode.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>fs.output.always-create-directory</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>File writers running with a parallelism larger than one create a directory for the output file path and put the different result files (one per parallel writer task) into that directory. If this option is set to \"true\", writers with a parallelism of 1 will also create a directory and place a single result file into it. If the option is set to \"false\", the writer will directly create the file directly at the output path, without creating a containing directory.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>fs.overwrite-files</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Specifies whether file output writers should overwrite existing files by default. Set to \"true\" to overwrite by default,\"false\" otherwise.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>io.tmp.dirs</h5></td>\n-            <td style=\"word-wrap: break-word;\">'LOCAL_DIRS' on Yarn. '_FLINK_TMP_DIR' on Mesos. System.getProperty(\"java.io.tmpdir\") in standalone.</td>\n-            <td>String</td>\n-            <td>Directories for temporary files, separated by\",\", \"|\", or the system's java.io.File.pathSeparator.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>parallelism.default</h5></td>\n-            <td style=\"word-wrap: break-word;\">1</td>\n-            <td>Integer</td>\n-            <td>Default parallelism for jobs.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "b404a83090f598a141fbe63fe096687a71b474a6",
            "filename": "docs/_includes/generated/deployment_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 36,
            "changes": 36,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/deployment_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/deployment_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/deployment_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,36 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>execution.attached</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Specifies if the pipeline is submitted in attached or detached mode.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>execution.job-listeners</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>List&lt;String&gt;</td>\n-            <td>Custom JobListeners to be registered with the execution environment. The registered listeners cannot have constructors with arguments.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>execution.shutdown-on-attached-exit</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>If the job is submitted in attached mode, perform a best-effort cluster shutdown when the CLI is terminated abruptly, e.g., in response to a user interrupt, such as typing Ctrl + C.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>execution.target</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The deployment target for the execution. This can take one of the following values:<ul><li>remote</li><li>local</li><li>yarn-per-job</li><li>yarn-session</li><li>kubernetes-session</li></ul>.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "26e3d5385648f582f432e7c76453e63fb0bd21a1",
            "filename": "docs/_includes/generated/deprecated_file_sinks_section.html",
            "status": "removed",
            "additions": 0,
            "deletions": 24,
            "changes": 24,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/deprecated_file_sinks_section.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/deprecated_file_sinks_section.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/deprecated_file_sinks_section.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,24 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>fs.output.always-create-directory</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>File writers running with a parallelism larger than one create a directory for the output file path and put the different result files (one per parallel writer task) into that directory. If this option is set to \"true\", writers with a parallelism of 1 will also create a directory and place a single result file into it. If the option is set to \"false\", the writer will directly create the file directly at the output path, without creating a containing directory.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>fs.overwrite-files</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Specifies whether file output writers should overwrite existing files by default. Set to \"true\" to overwrite by default,\"false\" otherwise.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "0fffb88f7b2fd37a36f627defa30624d4ef116e9",
            "filename": "docs/_includes/generated/environment_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 78,
            "changes": 78,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/environment_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/environment_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/environment_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,78 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>env.hadoop.conf.dir</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Path to hadoop configuration directory. It is required to read HDFS and/or YARN configuration. You can also set it via environment variable.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>env.hbase.conf.dir</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Path to hbase configuration directory. It is required to read HBASE configuration. You can also set it via environment variable.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>env.java.opts</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Java options to start the JVM of all Flink processes with.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>env.java.opts.client</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Java options to start the JVM of the Flink Client with.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>env.java.opts.historyserver</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Java options to start the JVM of the HistoryServer with.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>env.java.opts.jobmanager</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Java options to start the JVM of the JobManager with.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>env.java.opts.taskmanager</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Java options to start the JVM of the TaskManager with.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>env.log.dir</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Defines the directory where the Flink logs are saved. It has to be an absolute path. (Defaults to the log directory under Flink’s home)</td>\n-        </tr>\n-        <tr>\n-            <td><h5>env.log.max</h5></td>\n-            <td style=\"word-wrap: break-word;\">5</td>\n-            <td>Integer</td>\n-            <td>The maximum number of old log files to keep.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>env.ssh.opts</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Additional command line options passed to SSH clients when starting or stopping JobManager, TaskManager, and Zookeeper services (start-cluster.sh, stop-cluster.sh, start-zookeeper-quorum.sh, stop-zookeeper-quorum.sh).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>env.yarn.conf.dir</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Path to yarn configuration directory. It is required to run flink on YARN. You can also set it via environment variable.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "94219b17fbba178e776e4192b911c3338c906c2c",
            "filename": "docs/_includes/generated/execution_checkpointing_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 66,
            "changes": 66,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/execution_checkpointing_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/execution_checkpointing_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/execution_checkpointing_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,66 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>execution.checkpointing.externalized-checkpoint-retention</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td><p>Enum</p>Possible values: [DELETE_ON_CANCELLATION, RETAIN_ON_CANCELLATION]</td>\n-            <td>Externalized checkpoints write their meta data out to persistent storage and are not automatically cleaned up when the owning job fails or is suspended (terminating with job status <span markdown=\"span\">`JobStatus#FAILED`</span> or <span markdown=\"span\">`JobStatus#SUSPENDED`</span>. In this case, you have to manually clean up the checkpoint state, both the meta data and actual program state.<br /><br />The mode defines how an externalized checkpoint should be cleaned up on job cancellation. If you choose to retain externalized checkpoints on cancellation you have to handle checkpoint clean up manually when you cancel the job as well (terminating with job status <span markdown=\"span\">`JobStatus#CANCELED`</span>).<br /><br />The target directory for externalized checkpoints is configured via <span markdown=\"span\">`state.checkpoints.dir`</span>.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>execution.checkpointing.interval</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>Duration</td>\n-            <td>Gets the interval in which checkpoints are periodically scheduled.<br /><br />This setting defines the base interval. Checkpoint triggering may be delayed by the settings <span markdown=\"span\">`execution.checkpointing.max-concurrent-checkpoints`</span> and <span markdown=\"span\">`execution.checkpointing.min-pause`</span></td>\n-        </tr>\n-        <tr>\n-            <td><h5>execution.checkpointing.max-concurrent-checkpoints</h5></td>\n-            <td style=\"word-wrap: break-word;\">1</td>\n-            <td>Integer</td>\n-            <td>The maximum number of checkpoint attempts that may be in progress at the same time. If this value is n, then no checkpoints will be triggered while n checkpoint attempts are currently in flight. For the next checkpoint to be triggered, one checkpoint attempt would need to finish or expire.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>execution.checkpointing.min-pause</h5></td>\n-            <td style=\"word-wrap: break-word;\">0 ms</td>\n-            <td>Duration</td>\n-            <td>The minimal pause between checkpointing attempts. This setting defines how soon thecheckpoint coordinator may trigger another checkpoint after it becomes possible to triggeranother checkpoint with respect to the maximum number of concurrent checkpoints(see <span markdown=\"span\">`execution.checkpointing.max-concurrent-checkpoints`</span>).<br /><br />If the maximum number of concurrent checkpoints is set to one, this setting makes effectively sure that a minimum amount of time passes where no checkpoint is in progress at all.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>execution.checkpointing.mode</h5></td>\n-            <td style=\"word-wrap: break-word;\">EXACTLY_ONCE</td>\n-            <td><p>Enum</p>Possible values: [EXACTLY_ONCE, AT_LEAST_ONCE]</td>\n-            <td>The checkpointing mode (exactly-once vs. at-least-once).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>execution.checkpointing.prefer-checkpoint-for-recovery</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>If enabled, a job recovery should fallback to checkpoint when there is a more recent savepoint.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>execution.checkpointing.timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">10 min</td>\n-            <td>Duration</td>\n-            <td>The maximum time that a checkpoint may take before being discarded.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>execution.checkpointing.tolerable-failed-checkpoints</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>Integer</td>\n-            <td>The tolerable checkpoint failure number. If set to 0, that meanswe do not tolerance any checkpoint failure.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>execution.checkpointing.unaligned</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Enables unaligned checkpoints, which greatly reduce checkpointing times under backpressure.<br /><br />Unaligned checkpoints contain data stored in buffers as part of the checkpoint state, which allows checkpoint barriers to overtake these buffers. Thus, the checkpoint duration becomes independent of the current throughput as checkpoint barriers are effectively not embedded into the stream of data anymore.<br /><br />Unaligned checkpoints can only be enabled if <span markdown=\"span\">`execution.checkpointing.mode`</span> is <span markdown=\"span\">`EXACTLY_ONCE`</span> and if <span markdown=\"span\">`execution.checkpointing.max-concurrent-checkpoints`</span> is 1</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "f6e329af777d1cd1fb3459b9cc61948ad9aa869b",
            "filename": "docs/_includes/generated/execution_config_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 122,
            "changes": 122,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/execution_config_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/execution_config_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/execution_config_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,122 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>table.exec.async-lookup.buffer-capacity</h5><br> <span class=\"label label-primary\">Batch</span> <span class=\"label label-primary\">Streaming</span></td>\n-            <td style=\"word-wrap: break-word;\">100</td>\n-            <td>Integer</td>\n-            <td>The max number of async i/o operation that the async lookup join can trigger.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>table.exec.async-lookup.timeout</h5><br> <span class=\"label label-primary\">Batch</span> <span class=\"label label-primary\">Streaming</span></td>\n-            <td style=\"word-wrap: break-word;\">3 min</td>\n-            <td>Duration</td>\n-            <td>The async timeout for the asynchronous operation to complete.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>table.exec.disabled-operators</h5><br> <span class=\"label label-primary\">Batch</span></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Mainly for testing. A comma-separated list of operator names, each name represents a kind of disabled operator.\n-Operators that can be disabled include \"NestedLoopJoin\", \"ShuffleHashJoin\", \"BroadcastHashJoin\", \"SortMergeJoin\", \"HashAgg\", \"SortAgg\".\n-By default no operator is disabled.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>table.exec.mini-batch.allow-latency</h5><br> <span class=\"label label-primary\">Streaming</span></td>\n-            <td style=\"word-wrap: break-word;\">0 ms</td>\n-            <td>Duration</td>\n-            <td>The maximum latency can be used for MiniBatch to buffer input records. MiniBatch is an optimization to buffer input records to reduce state access. MiniBatch is triggered with the allowed latency interval and when the maximum number of buffered records reached. NOTE: If table.exec.mini-batch.enabled is set true, its value must be greater than zero.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>table.exec.mini-batch.enabled</h5><br> <span class=\"label label-primary\">Streaming</span></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Specifies whether to enable MiniBatch optimization. MiniBatch is an optimization to buffer input records to reduce state access. This is disabled by default. To enable this, users should set this config to true. NOTE: If mini-batch is enabled, 'table.exec.mini-batch.allow-latency' and 'table.exec.mini-batch.size' must be set.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>table.exec.mini-batch.size</h5><br> <span class=\"label label-primary\">Streaming</span></td>\n-            <td style=\"word-wrap: break-word;\">-1</td>\n-            <td>Long</td>\n-            <td>The maximum number of input records can be buffered for MiniBatch. MiniBatch is an optimization to buffer input records to reduce state access. MiniBatch is triggered with the allowed latency interval and when the maximum number of buffered records reached. NOTE: MiniBatch only works for non-windowed aggregations currently. If table.exec.mini-batch.enabled is set true, its value must be positive.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>table.exec.resource.default-parallelism</h5><br> <span class=\"label label-primary\">Batch</span> <span class=\"label label-primary\">Streaming</span></td>\n-            <td style=\"word-wrap: break-word;\">-1</td>\n-            <td>Integer</td>\n-            <td>Sets default parallelism for all operators (such as aggregate, join, filter) to run with parallel instances. This config has a higher priority than parallelism of StreamExecutionEnvironment (actually, this config overrides the parallelism of StreamExecutionEnvironment). A value of -1 indicates that no default parallelism is set, then it will fallback to use the parallelism of StreamExecutionEnvironment.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>table.exec.shuffle-mode</h5><br> <span class=\"label label-primary\">Batch</span></td>\n-            <td style=\"word-wrap: break-word;\">\"ALL_EDGES_BLOCKING\"</td>\n-            <td>String</td>\n-            <td>Sets exec shuffle mode.<br />Accepted values are:<ul><li><span markdown=\"span\">`ALL_EDGES_BLOCKING`</span>: All edges will use blocking shuffle.</li><li><span markdown=\"span\">`FORWARD_EDGES_PIPELINED`</span>: Forward edges will use pipelined shuffle, others blocking.</li><li><span markdown=\"span\">`POINTWISE_EDGES_PIPELINED`</span>: Pointwise edges will use pipelined shuffle, others blocking. Pointwise edges include forward and rescale edges.</li><li><span markdown=\"span\">`ALL_EDGES_PIPELINED`</span>: All edges will use pipelined shuffle.</li><li><span markdown=\"span\">`batch`</span>: the same as <span markdown=\"span\">`ALL_EDGES_BLOCKING`</span>. Deprecated.</li><li><span markdown=\"span\">`pipelined`</span>: the same as <span markdown=\"span\">`ALL_EDGES_PIPELINED`</span>. Deprecated.</li></ul>Note: Blocking shuffle means data will be fully produced before sent to consumer tasks. Pipelined shuffle means data will be sent to consumer tasks once produced.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>table.exec.sink.not-null-enforcer</h5><br> <span class=\"label label-primary\">Batch</span> <span class=\"label label-primary\">Streaming</span></td>\n-            <td style=\"word-wrap: break-word;\">ERROR</td>\n-            <td><p>Enum</p>Possible values: [ERROR, DROP]</td>\n-            <td>The NOT NULL column constraint on a table enforces that null values can't be inserted into the table. Flink supports 'error' (default) and 'drop' enforcement behavior. By default, Flink will check values and throw runtime exception when null values writing into NOT NULL columns. Users can change the behavior to 'drop' to silently drop such records without throwing exception.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>table.exec.sort.async-merge-enabled</h5><br> <span class=\"label label-primary\">Batch</span></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>Whether to asynchronously merge sorted spill files.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>table.exec.sort.default-limit</h5><br> <span class=\"label label-primary\">Batch</span></td>\n-            <td style=\"word-wrap: break-word;\">-1</td>\n-            <td>Integer</td>\n-            <td>Default limit when user don't set a limit after order by. -1 indicates that this configuration is ignored.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>table.exec.sort.max-num-file-handles</h5><br> <span class=\"label label-primary\">Batch</span></td>\n-            <td style=\"word-wrap: break-word;\">128</td>\n-            <td>Integer</td>\n-            <td>The maximal fan-in for external merge sort. It limits the number of file handles per operator. If it is too small, may cause intermediate merging. But if it is too large, it will cause too many files opened at the same time, consume memory and lead to random reading.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>table.exec.source.cdc-events-duplicate</h5><br> <span class=\"label label-primary\">Streaming</span></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Indicates whether the CDC (Change Data Capture) sources in the job will produce duplicate change events that requires the framework to deduplicate and get consistent result. CDC source refers to the source that produces full change events, including INSERT/UPDATE_BEFORE/UPDATE_AFTER/DELETE, for example Kafka source with Debezium format. The value of this configuration is false by default.<br /><br />However, it's a common case that there are duplicate change events. Because usually the CDC tools (e.g. Debezium) work in at-least-once delivery when failover happens. Thus, in the abnormal situations Debezium may deliver duplicate change events to Kafka and Flink will get the duplicate events. This may cause Flink query to get wrong results or unexpected exceptions.<br /><br />Therefore, it is recommended to turn on this configuration if your CDC tool is at-least-once delivery. Enabling this configuration requires to define PRIMARY KEY on the CDC sources. The primary key will be used to deduplicate change events and generate normalized changelog stream at the cost of an additional stateful operator.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>table.exec.source.idle-timeout</h5><br> <span class=\"label label-primary\">Streaming</span></td>\n-            <td style=\"word-wrap: break-word;\">0 ms</td>\n-            <td>Duration</td>\n-            <td>When a source do not receive any elements for the timeout time, it will be marked as temporarily idle. This allows downstream tasks to advance their watermarks without the need to wait for watermarks from this source while it is idle. Default value is 0, which means detecting source idleness is not enabled.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>table.exec.spill-compression.block-size</h5><br> <span class=\"label label-primary\">Batch</span></td>\n-            <td style=\"word-wrap: break-word;\">\"64 kb\"</td>\n-            <td>String</td>\n-            <td>The memory size used to do compress when spilling data. The larger the memory, the higher the compression ratio, but more memory resource will be consumed by the job.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>table.exec.spill-compression.enabled</h5><br> <span class=\"label label-primary\">Batch</span></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>Whether to compress spilled data. Currently we only support compress spilled data for sort and hash-agg and hash-join operators.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>table.exec.state.ttl</h5><br> <span class=\"label label-primary\">Streaming</span></td>\n-            <td style=\"word-wrap: break-word;\">0 ms</td>\n-            <td>Duration</td>\n-            <td>Specifies a minimum time interval for how long idle state (i.e. state which was not updated), will be retained. State will never be cleared until it was idle for less than the minimum time, and will be cleared at some time after it was idle. Default is never clean-up the state. NOTE: Cleaning up state requires additional overhead for bookkeeping. Default value is 0, which means that it will never clean up state.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>table.exec.window-agg.buffer-size-limit</h5><br> <span class=\"label label-primary\">Batch</span></td>\n-            <td style=\"word-wrap: break-word;\">100000</td>\n-            <td>Integer</td>\n-            <td>Sets the window elements buffer size limit used in group window agg operator.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "369530c81fcb437c715e3d31299a4031375e30df",
            "filename": "docs/_includes/generated/execution_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 30,
            "changes": 30,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/execution_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/execution_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/execution_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,30 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>execution.buffer-timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">100 ms</td>\n-            <td>Duration</td>\n-            <td>The maximum time frequency (milliseconds) for the flushing of the output buffers. By default the output buffers flush frequently to provide low latency and to aid smooth developer experience. Setting the parameter can result in three logical modes:<ul><li>A positive value triggers flushing periodically by that interval</li><li>0 triggers flushing after every record thus minimizing latency</li><li>-1 ms triggers flushing only when the output buffer is full thus maximizing throughput</li></ul></td>\n-        </tr>\n-        <tr>\n-            <td><h5>execution.checkpointing.snapshot-compression</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Tells if we should use compression for the state snapshot data or not</td>\n-        </tr>\n-        <tr>\n-            <td><h5>execution.runtime-mode</h5></td>\n-            <td style=\"word-wrap: break-word;\">STREAMING</td>\n-            <td><p>Enum</p>Possible values: [STREAMING, BATCH, AUTOMATIC]</td>\n-            <td>Runtime execution mode of DataStream programs. Among other things, this controls task scheduling, network shuffle behavior, and time semantics.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "97bc7e1cc84850771328628bb60233d700828c7d",
            "filename": "docs/_includes/generated/expert_class_loading_section.html",
            "status": "removed",
            "additions": 0,
            "deletions": 44,
            "changes": 44,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/expert_class_loading_section.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/expert_class_loading_section.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/expert_class_loading_section.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,44 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>classloader.check-leaked-classloader</h5></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>Fails attempts at loading classes if the user classloader of a job is used after it has terminated.\n-This is usually caused by the classloader being leaked by lingering threads or misbehaving libraries, which may also result in the classloader being used by other jobs.\n-This check should only be disabled if such a leak prevents further jobs from running.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>classloader.fail-on-metaspace-oom-error</h5></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>Fail Flink JVM processes if 'OutOfMemoryError: Metaspace' is thrown while trying to load a user code class.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>classloader.parent-first-patterns.additional</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>A (semicolon-separated) list of patterns that specifies which classes should always be resolved through the parent ClassLoader first. A pattern is a simple prefix that is checked against the fully qualified class name. These patterns are appended to \"classloader.parent-first-patterns.default\".</td>\n-        </tr>\n-        <tr>\n-            <td><h5>classloader.parent-first-patterns.default</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"java.;<wbr>scala.;<wbr>org.apache.flink.;<wbr>com.esotericsoftware.kryo;<wbr>org.apache.hadoop.;<wbr>javax.annotation.;<wbr>org.slf4j;<wbr>org.apache.log4j;<wbr>org.apache.logging;<wbr>org.apache.commons.logging;<wbr>ch.qos.logback;<wbr>org.xml;<wbr>javax.xml;<wbr>org.apache.xerces;<wbr>org.w3c\"</td>\n-            <td>String</td>\n-            <td>A (semicolon-separated) list of patterns that specifies which classes should always be resolved through the parent ClassLoader first. A pattern is a simple prefix that is checked against the fully qualified class name. This setting should generally not be modified. To add another pattern we recommend to use \"classloader.parent-first-patterns.additional\" instead.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>classloader.resolve-order</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"child-first\"</td>\n-            <td>String</td>\n-            <td>Defines the class resolution strategy when loading classes from user code, meaning whether to first check the user code jar (\"child-first\") or the application classpath (\"parent-first\"). The default settings indicate to load classes first from the user code jar, which means that user code jars can include and load different dependencies than Flink uses (transitively).</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "c6febd02b7c1d3203c817708c17d93800a26e631",
            "filename": "docs/_includes/generated/expert_cluster_section.html",
            "status": "removed",
            "additions": 0,
            "deletions": 18,
            "changes": 18,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/expert_cluster_section.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/expert_cluster_section.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/expert_cluster_section.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,18 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>cluster.processes.halt-on-fatal-error</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Whether processes should halt on fatal errors instead of performing a graceful shutdown. In some environments (e.g. Java 8 with the G1 garbage collector), a regular graceful shutdown can lead to a JVM deadlock. See <a href=\"https://issues.apache.org/jira/browse/FLINK-16510\">FLINK-16510</a> for details.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "09f39595735f18dd08754e977ae8dfa24c65bac9",
            "filename": "docs/_includes/generated/expert_debugging_and_tuning_section.html",
            "status": "removed",
            "additions": 0,
            "deletions": 18,
            "changes": 18,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/expert_debugging_and_tuning_section.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/expert_debugging_and_tuning_section.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/expert_debugging_and_tuning_section.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,18 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>jmx.server.port</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The port range for the JMX server to start the registry. The port config can be a single port: \"9123\", a range of ports: \"50100-50200\", or a list of ranges and ports: \"50100-50200,50300-50400,51234\". <br />This option overrides metrics.reporter.*.port option.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "8adfebbd754ca73c73edb0200ecc5ea90a1b9f0c",
            "filename": "docs/_includes/generated/expert_fault_tolerance_section.html",
            "status": "removed",
            "additions": 0,
            "deletions": 66,
            "changes": 66,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/expert_fault_tolerance_section.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/expert_fault_tolerance_section.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/expert_fault_tolerance_section.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,66 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>cluster.io-pool.size</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>Integer</td>\n-            <td>The size of the IO executor pool used by the cluster to execute blocking IO operations (Master as well as TaskManager processes). By default it will use 4 * the number of CPU cores (hardware contexts) that the cluster process has access to. Increasing the pool size allows to run more IO operations concurrently.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>cluster.registration.error-delay</h5></td>\n-            <td style=\"word-wrap: break-word;\">10000</td>\n-            <td>Long</td>\n-            <td>The pause made after an registration attempt caused an exception (other than timeout) in milliseconds.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>cluster.registration.initial-timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">100</td>\n-            <td>Long</td>\n-            <td>Initial registration timeout between cluster components in milliseconds.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>cluster.registration.max-timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">30000</td>\n-            <td>Long</td>\n-            <td>Maximum registration timeout between cluster components in milliseconds.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>cluster.registration.refused-registration-delay</h5></td>\n-            <td style=\"word-wrap: break-word;\">30000</td>\n-            <td>Long</td>\n-            <td>The pause made after the registration attempt was refused in milliseconds.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>cluster.services.shutdown-timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">30000</td>\n-            <td>Long</td>\n-            <td>The shutdown timeout for cluster services like executors in milliseconds.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>heartbeat.interval</h5></td>\n-            <td style=\"word-wrap: break-word;\">10000</td>\n-            <td>Long</td>\n-            <td>Time interval for requesting heartbeat from sender side.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>heartbeat.timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">50000</td>\n-            <td>Long</td>\n-            <td>Timeout for requesting and receiving heartbeat for both sender and receiver sides.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobmanager.execution.failover-strategy</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"region\"</td>\n-            <td>String</td>\n-            <td>This option specifies how the job computation recovers from task failures. Accepted values are:<ul><li>'full': Restarts all tasks to recover the job.</li><li>'region': Restarts all tasks that could be affected by the task failure. More details can be found <a href=\"../dev/task_failure_recovery.html#restart-pipelined-region-failover-strategy\">here</a>.</li></ul></td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "60bc077486cb2e98c0d470d6aaa44ca536176a94",
            "filename": "docs/_includes/generated/expert_high_availability_k8s_section.html",
            "status": "removed",
            "additions": 0,
            "deletions": 30,
            "changes": 30,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/expert_high_availability_k8s_section.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/expert_high_availability_k8s_section.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/expert_high_availability_k8s_section.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,30 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>high-availability.kubernetes.leader-election.lease-duration</h5></td>\n-            <td style=\"word-wrap: break-word;\">15 s</td>\n-            <td>Duration</td>\n-            <td>Define the lease duration for the Kubernetes leader election. The leader will continuously renew its lease time to indicate its existence. And the followers will do a lease checking against the current time. \"renewTime + leaseDuration &gt; now\" means the leader is alive.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>high-availability.kubernetes.leader-election.renew-deadline</h5></td>\n-            <td style=\"word-wrap: break-word;\">15 s</td>\n-            <td>Duration</td>\n-            <td>Defines the deadline duration when the leader tries to renew the lease. The leader will give up its leadership if it cannot successfully renew the lease in the given time.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>high-availability.kubernetes.leader-election.retry-period</h5></td>\n-            <td style=\"word-wrap: break-word;\">5 s</td>\n-            <td>Duration</td>\n-            <td>Defines the pause duration between consecutive retries. All the contenders, including the current leader and all other followers, periodically try to acquire/renew the leadership if possible at this interval.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "4a571e70cab789927f5f8cb0c0b0e0f2eaacc3ab",
            "filename": "docs/_includes/generated/expert_high_availability_section.html",
            "status": "removed",
            "additions": 0,
            "deletions": 18,
            "changes": 18,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/expert_high_availability_section.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/expert_high_availability_section.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/expert_high_availability_section.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,18 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>high-availability.jobmanager.port</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"0\"</td>\n-            <td>String</td>\n-            <td>The port (range) used by the Flink Master for its RPC connections in highly-available setups. In highly-available setups, this value is used instead of 'jobmanager.rpc.port'.A value of '0' means that a random free port is chosen. TaskManagers discover this port through the high-availability services (leader election), so a random port or a port range works without requiring any additional means of service discovery.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "d7774e22560e961596615780db107c913f4fd9c1",
            "filename": "docs/_includes/generated/expert_high_availability_zk_section.html",
            "status": "removed",
            "additions": 0,
            "deletions": 84,
            "changes": 84,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/expert_high_availability_zk_section.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/expert_high_availability_zk_section.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/expert_high_availability_zk_section.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,84 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>high-availability.zookeeper.client.acl</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"open\"</td>\n-            <td>String</td>\n-            <td>Defines the ACL (open|creator) to be configured on ZK node. The configuration value can be set to “creator” if the ZooKeeper server configuration has the “authProvider” property mapped to use SASLAuthenticationProvider and the cluster is configured to run in secure mode (Kerberos).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>high-availability.zookeeper.client.connection-timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">15000</td>\n-            <td>Integer</td>\n-            <td>Defines the connection timeout for ZooKeeper in ms.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>high-availability.zookeeper.client.max-retry-attempts</h5></td>\n-            <td style=\"word-wrap: break-word;\">3</td>\n-            <td>Integer</td>\n-            <td>Defines the number of connection retries before the client gives up.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>high-availability.zookeeper.client.retry-wait</h5></td>\n-            <td style=\"word-wrap: break-word;\">5000</td>\n-            <td>Integer</td>\n-            <td>Defines the pause between consecutive retries in ms.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>high-availability.zookeeper.client.session-timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">60000</td>\n-            <td>Integer</td>\n-            <td>Defines the session timeout for the ZooKeeper session in ms.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>high-availability.zookeeper.path.checkpoint-counter</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"/checkpoint-counter\"</td>\n-            <td>String</td>\n-            <td>ZooKeeper root path (ZNode) for checkpoint counters.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>high-availability.zookeeper.path.checkpoints</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"/checkpoints\"</td>\n-            <td>String</td>\n-            <td>ZooKeeper root path (ZNode) for completed checkpoints.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>high-availability.zookeeper.path.jobgraphs</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"/jobgraphs\"</td>\n-            <td>String</td>\n-            <td>ZooKeeper root path (ZNode) for job graphs</td>\n-        </tr>\n-        <tr>\n-            <td><h5>high-availability.zookeeper.path.latch</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"/leaderlatch\"</td>\n-            <td>String</td>\n-            <td>Defines the znode of the leader latch which is used to elect the leader.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>high-availability.zookeeper.path.leader</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"/leader\"</td>\n-            <td>String</td>\n-            <td>Defines the znode of the leader which contains the URL to the leader and the current leader session ID.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>high-availability.zookeeper.path.mesos-workers</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"/mesos-workers\"</td>\n-            <td>String</td>\n-            <td>The ZooKeeper root path for persisting the Mesos worker information.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>high-availability.zookeeper.path.running-registry</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"/running_job_registry/\"</td>\n-            <td>String</td>\n-            <td></td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "ab1a70cb67e992723dd371e3fdc9f68a733ffd57",
            "filename": "docs/_includes/generated/expert_rest_section.html",
            "status": "removed",
            "additions": 0,
            "deletions": 66,
            "changes": 66,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/expert_rest_section.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/expert_rest_section.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/expert_rest_section.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,66 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>rest.await-leader-timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">30000</td>\n-            <td>Long</td>\n-            <td>The time in ms that the client waits for the leader address, e.g., Dispatcher or WebMonitorEndpoint</td>\n-        </tr>\n-        <tr>\n-            <td><h5>rest.client.max-content-length</h5></td>\n-            <td style=\"word-wrap: break-word;\">104857600</td>\n-            <td>Integer</td>\n-            <td>The maximum content length in bytes that the client will handle.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>rest.connection-timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">15000</td>\n-            <td>Long</td>\n-            <td>The maximum time in ms for the client to establish a TCP connection.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>rest.idleness-timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">300000</td>\n-            <td>Long</td>\n-            <td>The maximum time in ms for a connection to stay idle before failing.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>rest.retry.delay</h5></td>\n-            <td style=\"word-wrap: break-word;\">3000</td>\n-            <td>Long</td>\n-            <td>The time in ms that the client waits between retries (See also `rest.retry.max-attempts`).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>rest.retry.max-attempts</h5></td>\n-            <td style=\"word-wrap: break-word;\">20</td>\n-            <td>Integer</td>\n-            <td>The number of retries the client will attempt if a retryable operations fails.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>rest.server.max-content-length</h5></td>\n-            <td style=\"word-wrap: break-word;\">104857600</td>\n-            <td>Integer</td>\n-            <td>The maximum content length in bytes that the server will handle.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>rest.server.numThreads</h5></td>\n-            <td style=\"word-wrap: break-word;\">4</td>\n-            <td>Integer</td>\n-            <td>The number of threads for the asynchronous processing of requests.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>rest.server.thread-priority</h5></td>\n-            <td style=\"word-wrap: break-word;\">5</td>\n-            <td>Integer</td>\n-            <td>Thread priority of the REST server's executor for processing asynchronous requests. Lowering the thread priority will give Flink's main components more CPU time whereas increasing will allocate more time for the REST server's processing.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "b24058daa45584addc9665f524143842b265a031",
            "filename": "docs/_includes/generated/expert_rocksdb_section.html",
            "status": "removed",
            "additions": 0,
            "deletions": 36,
            "changes": 36,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/expert_rocksdb_section.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/expert_rocksdb_section.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/expert_rocksdb_section.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,36 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.checkpoint.transfer.thread.num</h5></td>\n-            <td style=\"word-wrap: break-word;\">1</td>\n-            <td>Integer</td>\n-            <td>The number of threads (per stateful operator) used to transfer (download and upload) files in RocksDBStateBackend.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.localdir</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The local directory (on the TaskManager) where RocksDB puts its files.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.options-factory</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"org.apache.flink.contrib.streaming.state.DefaultConfigurableOptionsFactory\"</td>\n-            <td>String</td>\n-            <td>The options factory class for RocksDB to create DBOptions and ColumnFamilyOptions. The default options factory is org.apache.flink.contrib.streaming.state.DefaultConfigurableOptionsFactory, and it would read the configured options which provided in 'RocksDBConfigurableOptions'.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.predefined-options</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"DEFAULT\"</td>\n-            <td>String</td>\n-            <td>The predefined settings for RocksDB DBOptions and ColumnFamilyOptions by Flink community. Current supported candidate predefined-options are DEFAULT, SPINNING_DISK_OPTIMIZED, SPINNING_DISK_OPTIMIZED_HIGH_MEM or FLASH_SSD_OPTIMIZED. Note that user customized options and options from the RocksDBOptionsFactory are applied on top of these predefined ones.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "9020268e0e869b9ac52fbd3d6a89592650624dab",
            "filename": "docs/_includes/generated/expert_scheduling_section.html",
            "status": "removed",
            "additions": 0,
            "deletions": 36,
            "changes": 36,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/expert_scheduling_section.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/expert_scheduling_section.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/expert_scheduling_section.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,36 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>cluster.evenly-spread-out-slots</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Enable the slot spread out allocation strategy. This strategy tries to spread out the slots evenly across all available <span markdown=\"span\">`TaskExecutors`</span>.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>slot.idle.timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">50000</td>\n-            <td>Long</td>\n-            <td>The timeout in milliseconds for a idle slot in Slot Pool.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>slot.request.timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">300000</td>\n-            <td>Long</td>\n-            <td>The timeout in milliseconds for requesting a slot from Slot Pool.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>slotmanager.number-of-slots.max</h5></td>\n-            <td style=\"word-wrap: break-word;\">2147483647</td>\n-            <td>Integer</td>\n-            <td>Defines the maximum number of slots that the Flink cluster allocates. This configuration option is meant for limiting the resource consumption for batch workloads. It is not recommended to configure this option for streaming workloads, which may fail if there are not enough slots. Note that this configuration option does not take effect for standalone clusters, where how many slots are allocated is not controlled by Flink.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "9e5af5f622449802b14d5f30936646ea5264ae2a",
            "filename": "docs/_includes/generated/expert_security_ssl_section.html",
            "status": "removed",
            "additions": 0,
            "deletions": 42,
            "changes": 42,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/expert_security_ssl_section.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/expert_security_ssl_section.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/expert_security_ssl_section.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,42 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>security.ssl.internal.close-notify-flush-timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">-1</td>\n-            <td>Integer</td>\n-            <td>The timeout (in ms) for flushing the `close_notify` that was triggered by closing a channel. If the `close_notify` was not flushed in the given timeout the channel will be closed forcibly. (-1 = use system default)</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.internal.handshake-timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">-1</td>\n-            <td>Integer</td>\n-            <td>The timeout (in ms) during SSL handshake. (-1 = use system default)</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.internal.session-cache-size</h5></td>\n-            <td style=\"word-wrap: break-word;\">-1</td>\n-            <td>Integer</td>\n-            <td>The size of the cache used for storing SSL session objects. According to https://github.com/netty/netty/issues/832, you should always set this to an appropriate number to not run into a bug with stalling IO threads during garbage collection. (-1 = use system default).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.internal.session-timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">-1</td>\n-            <td>Integer</td>\n-            <td>The timeout (in ms) for the cached SSL session objects. (-1 = use system default)</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.provider</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"JDK\"</td>\n-            <td>String</td>\n-            <td>The SSL engine provider to use for the ssl transport:<ul><li><span markdown=\"span\">`JDK`</span>: default Java-based SSL engine</li><li><span markdown=\"span\">`OPENSSL`</span>: openSSL-based SSL engine using system libraries</li></ul><span markdown=\"span\">`OPENSSL`</span> is based on <a href=\"http://netty.io/wiki/forked-tomcat-native.html#wiki-h2-4\">netty-tcnative</a> and comes in two flavours:<ul><li>dynamically linked: This will use your system's openSSL libraries (if compatible) and requires <span markdown=\"span\">`opt/flink-shaded-netty-tcnative-dynamic-*.jar`</span> to be copied to <span markdown=\"span\">`lib/`</span></li><li>statically linked: Due to potential licensing issues with openSSL (see <a href=\"https://issues.apache.org/jira/browse/LEGAL-393\">LEGAL-393</a>), we cannot ship pre-built libraries. However, you can build the required library yourself and put it into <span markdown=\"span\">`lib/`</span>:<br /><span markdown=\"span\">`git clone https://github.com/apache/flink-shaded.git &amp;&amp; cd flink-shaded &amp;&amp; mvn clean package -Pinclude-netty-tcnative-static -pl flink-shaded-netty-tcnative-static`</span></li></ul></td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "0fed8674dbb679e3f1a8981b009722e12750a9cc",
            "filename": "docs/_includes/generated/expert_state_backends_section.html",
            "status": "removed",
            "additions": 0,
            "deletions": 30,
            "changes": 30,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/expert_state_backends_section.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/expert_state_backends_section.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/expert_state_backends_section.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,30 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>state.backend.async</h5></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>Option whether the state backend should use an asynchronous snapshot method where possible and configurable. Some state backends may not support asynchronous snapshots, or only support asynchronous snapshots, and ignore this option.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.fs.memory-threshold</h5></td>\n-            <td style=\"word-wrap: break-word;\">20 kb</td>\n-            <td>MemorySize</td>\n-            <td>The minimum size of state data files. All state chunks smaller than that are stored inline in the root checkpoint metadata file. The max memory threshold for this configuration is 1MB.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.fs.write-buffer-size</h5></td>\n-            <td style=\"word-wrap: break-word;\">4096</td>\n-            <td>Integer</td>\n-            <td>The default size of the write buffer for the checkpoint streams that write to file systems. The actual write buffer size is determined to be the maximum of the value of this option and option 'state.backend.fs.memory-threshold'.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "f42c4c9471ce8580f5d36a1e806a418111d8ed1f",
            "filename": "docs/_includes/generated/external_resource_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 36,
            "changes": 36,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/external_resource_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/external_resource_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/external_resource_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,36 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>external-resource.&lt;resource_name&gt;.amount</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>Long</td>\n-            <td>The amount for the external resource specified by &lt;resource_name&gt; per TaskExecutor.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>external-resource.&lt;resource_name&gt;.driver-factory.class</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Defines the factory class name for the external resource identified by &lt;resource_name&gt;. The factory will be used to instantiated the ExternalResourceDriver at the TaskExecutor side. For example, org.apache.flink.externalresource.gpu.GPUDriverFactory</td>\n-        </tr>\n-        <tr>\n-            <td><h5>external-resource.&lt;resource_name&gt;.param.&lt;param&gt;</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The naming pattern of custom config options for the external resource specified by &lt;resource_name&gt;. Only the configurations that follow this pattern would be passed into the driver factory of that external resource.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>external-resources</h5></td>\n-            <td style=\"word-wrap: break-word;\"></td>\n-            <td>List&lt;String&gt;</td>\n-            <td>List of the &lt;resource_name&gt; of all external resources with delimiter \";\", e.g. \"gpu;fpga\" for two external resource gpu and fpga. The &lt;resource_name&gt; will be used to splice related config options for external resource. Only the &lt;resource_name&gt; defined here will go into effect by external resource framework.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "93bcd22bbdf009c20365a014a4d74dbff2ca523e",
            "filename": "docs/_includes/generated/failure_rate_restart_strategy_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 30,
            "changes": 30,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/failure_rate_restart_strategy_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/failure_rate_restart_strategy_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/failure_rate_restart_strategy_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,30 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>restart-strategy.failure-rate.delay</h5></td>\n-            <td style=\"word-wrap: break-word;\">1 s</td>\n-            <td>Duration</td>\n-            <td>Delay between two consecutive restart attempts if <span markdown=\"span\">`restart-strategy`</span> has been set to <span markdown=\"span\">`failure-rate`</span>. It can be specified using notation: \"1 min\", \"20 s\"</td>\n-        </tr>\n-        <tr>\n-            <td><h5>restart-strategy.failure-rate.failure-rate-interval</h5></td>\n-            <td style=\"word-wrap: break-word;\">1 min</td>\n-            <td>Duration</td>\n-            <td>Time interval for measuring failure rate if <span markdown=\"span\">`restart-strategy`</span> has been set to <span markdown=\"span\">`failure-rate`</span>. It can be specified using notation: \"1 min\", \"20 s\"</td>\n-        </tr>\n-        <tr>\n-            <td><h5>restart-strategy.failure-rate.max-failures-per-interval</h5></td>\n-            <td style=\"word-wrap: break-word;\">1</td>\n-            <td>Integer</td>\n-            <td>Maximum number of restarts in given time interval before failing a job if <span markdown=\"span\">`restart-strategy`</span> has been set to <span markdown=\"span\">`failure-rate`</span>.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "d4d74fe0701350f7d8ce56cb6c893d06a2821430",
            "filename": "docs/_includes/generated/fixed_delay_restart_strategy_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 24,
            "changes": 24,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/fixed_delay_restart_strategy_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/fixed_delay_restart_strategy_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/fixed_delay_restart_strategy_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,24 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>restart-strategy.fixed-delay.attempts</h5></td>\n-            <td style=\"word-wrap: break-word;\">1</td>\n-            <td>Integer</td>\n-            <td>The number of times that Flink retries the execution before the job is declared as failed if <span markdown=\"span\">`restart-strategy`</span> has been set to <span markdown=\"span\">`fixed-delay`</span>.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>restart-strategy.fixed-delay.delay</h5></td>\n-            <td style=\"word-wrap: break-word;\">1 s</td>\n-            <td>Duration</td>\n-            <td>Delay between two consecutive restart attempts if <span markdown=\"span\">`restart-strategy`</span> has been set to <span markdown=\"span\">`fixed-delay`</span>. Delaying the retries can be helpful when the program interacts with external systems where for example connections or pending transactions should reach a timeout before re-execution is attempted. It can be specified using notation: \"1 min\", \"20 s\"</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "4e6fde60b775d60a66481964104082f319edff27",
            "filename": "docs/_includes/generated/heartbeat_manager_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 24,
            "changes": 24,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/heartbeat_manager_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/heartbeat_manager_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/heartbeat_manager_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,24 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>heartbeat.interval</h5></td>\n-            <td style=\"word-wrap: break-word;\">10000</td>\n-            <td>Long</td>\n-            <td>Time interval for requesting heartbeat from sender side.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>heartbeat.timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">50000</td>\n-            <td>Long</td>\n-            <td>Timeout for requesting and receiving heartbeat for both sender and receiver sides.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "cf61274defd042b332efd0416d58201e4fd1a09a",
            "filename": "docs/_includes/generated/high_availability_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 120,
            "changes": 120,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/high_availability_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/high_availability_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/high_availability_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,120 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>high-availability</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"NONE\"</td>\n-            <td>String</td>\n-            <td>Defines high-availability mode used for the cluster execution. To enable high-availability, set this mode to \"ZOOKEEPER\" or specify FQN of factory class.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>high-availability.cluster-id</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"/default\"</td>\n-            <td>String</td>\n-            <td>The ID of the Flink cluster, used to separate multiple Flink clusters from each other. Needs to be set for standalone clusters but is automatically inferred in YARN and Mesos.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>high-availability.jobmanager.port</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"0\"</td>\n-            <td>String</td>\n-            <td>The port (range) used by the Flink Master for its RPC connections in highly-available setups. In highly-available setups, this value is used instead of 'jobmanager.rpc.port'.A value of '0' means that a random free port is chosen. TaskManagers discover this port through the high-availability services (leader election), so a random port or a port range works without requiring any additional means of service discovery.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>high-availability.storageDir</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>File system path (URI) where Flink persists metadata in high-availability setups.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>high-availability.zookeeper.client.acl</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"open\"</td>\n-            <td>String</td>\n-            <td>Defines the ACL (open|creator) to be configured on ZK node. The configuration value can be set to “creator” if the ZooKeeper server configuration has the “authProvider” property mapped to use SASLAuthenticationProvider and the cluster is configured to run in secure mode (Kerberos).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>high-availability.zookeeper.client.connection-timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">15000</td>\n-            <td>Integer</td>\n-            <td>Defines the connection timeout for ZooKeeper in ms.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>high-availability.zookeeper.client.max-retry-attempts</h5></td>\n-            <td style=\"word-wrap: break-word;\">3</td>\n-            <td>Integer</td>\n-            <td>Defines the number of connection retries before the client gives up.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>high-availability.zookeeper.client.retry-wait</h5></td>\n-            <td style=\"word-wrap: break-word;\">5000</td>\n-            <td>Integer</td>\n-            <td>Defines the pause between consecutive retries in ms.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>high-availability.zookeeper.client.session-timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">60000</td>\n-            <td>Integer</td>\n-            <td>Defines the session timeout for the ZooKeeper session in ms.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>high-availability.zookeeper.path.checkpoint-counter</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"/checkpoint-counter\"</td>\n-            <td>String</td>\n-            <td>ZooKeeper root path (ZNode) for checkpoint counters.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>high-availability.zookeeper.path.checkpoints</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"/checkpoints\"</td>\n-            <td>String</td>\n-            <td>ZooKeeper root path (ZNode) for completed checkpoints.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>high-availability.zookeeper.path.jobgraphs</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"/jobgraphs\"</td>\n-            <td>String</td>\n-            <td>ZooKeeper root path (ZNode) for job graphs</td>\n-        </tr>\n-        <tr>\n-            <td><h5>high-availability.zookeeper.path.latch</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"/leaderlatch\"</td>\n-            <td>String</td>\n-            <td>Defines the znode of the leader latch which is used to elect the leader.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>high-availability.zookeeper.path.leader</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"/leader\"</td>\n-            <td>String</td>\n-            <td>Defines the znode of the leader which contains the URL to the leader and the current leader session ID.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>high-availability.zookeeper.path.mesos-workers</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"/mesos-workers\"</td>\n-            <td>String</td>\n-            <td>The ZooKeeper root path for persisting the Mesos worker information.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>high-availability.zookeeper.path.root</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"/flink\"</td>\n-            <td>String</td>\n-            <td>The root path under which Flink stores its entries in ZooKeeper.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>high-availability.zookeeper.path.running-registry</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"/running_job_registry/\"</td>\n-            <td>String</td>\n-            <td></td>\n-        </tr>\n-        <tr>\n-            <td><h5>high-availability.zookeeper.quorum</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The ZooKeeper quorum to use, when running Flink in a high-availability mode with ZooKeeper.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "79520027652ebefea689707be756af4c28202b47",
            "filename": "docs/_includes/generated/history_server_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 66,
            "changes": 66,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/history_server_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/history_server_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/history_server_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,66 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>historyserver.archive.clean-expired-jobs</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Whether HistoryServer should cleanup jobs that are no longer present `historyserver.archive.fs.dir`.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>historyserver.archive.fs.dir</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Comma separated list of directories to fetch archived jobs from. The history server will monitor these directories for archived jobs. You can configure the JobManager to archive jobs to a directory via `jobmanager.archive.fs.dir`.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>historyserver.archive.fs.refresh-interval</h5></td>\n-            <td style=\"word-wrap: break-word;\">10000</td>\n-            <td>Long</td>\n-            <td>Interval in milliseconds for refreshing the archived job directories.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>historyserver.archive.retained-jobs</h5></td>\n-            <td style=\"word-wrap: break-word;\">-1</td>\n-            <td>Integer</td>\n-            <td>The maximum number of jobs to retain in each archive directory defined by `historyserver.archive.fs.dir`. If set to `-1`(default), there is no limit to the number of archives. If set to `0` or less than `-1` HistoryServer will throw an <span markdown=\"span\">`IllegalConfigurationException`</span>. </td>\n-        </tr>\n-        <tr>\n-            <td><h5>historyserver.web.address</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Address of the HistoryServer's web interface.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>historyserver.web.port</h5></td>\n-            <td style=\"word-wrap: break-word;\">8082</td>\n-            <td>Integer</td>\n-            <td>Port of the HistoryServers's web interface.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>historyserver.web.refresh-interval</h5></td>\n-            <td style=\"word-wrap: break-word;\">10000</td>\n-            <td>Long</td>\n-            <td>The refresh interval for the HistoryServer web-frontend in milliseconds.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>historyserver.web.ssl.enabled</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Enable HTTPs access to the HistoryServer web frontend. This is applicable only when the global SSL flag security.ssl.enabled is set to true.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>historyserver.web.tmpdir</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>This configuration parameter allows defining the Flink web directory to be used by the history server web interface. The web interface will copy its static files into the directory.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "393ff855af37bbd85b52a08ee79d849a8bfc5f29",
            "filename": "docs/_includes/generated/influxdb_reporter_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 72,
            "changes": 72,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/influxdb_reporter_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/influxdb_reporter_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/influxdb_reporter_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,72 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>connectTimeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">10000</td>\n-            <td>Integer</td>\n-            <td>(optional) the InfluxDB connect timeout for metrics</td>\n-        </tr>\n-        <tr>\n-            <td><h5>consistency</h5></td>\n-            <td style=\"word-wrap: break-word;\">ONE</td>\n-            <td><p>Enum</p>Possible values: [ALL, ANY, ONE, QUORUM]</td>\n-            <td>(optional) the InfluxDB consistency level for metrics</td>\n-        </tr>\n-        <tr>\n-            <td><h5>db</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>the InfluxDB database to store metrics</td>\n-        </tr>\n-        <tr>\n-            <td><h5>host</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>the InfluxDB server host</td>\n-        </tr>\n-        <tr>\n-            <td><h5>password</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>(optional) InfluxDB username's password used for authentication</td>\n-        </tr>\n-        <tr>\n-            <td><h5>port</h5></td>\n-            <td style=\"word-wrap: break-word;\">8086</td>\n-            <td>Integer</td>\n-            <td>the InfluxDB server port</td>\n-        </tr>\n-        <tr>\n-            <td><h5>retentionPolicy</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>(optional) the InfluxDB retention policy for metrics</td>\n-        </tr>\n-        <tr>\n-            <td><h5>scheme</h5></td>\n-            <td style=\"word-wrap: break-word;\">http</td>\n-            <td><p>Enum</p>Possible values: [http, https]</td>\n-            <td>the InfluxDB schema</td>\n-        </tr>\n-        <tr>\n-            <td><h5>username</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>(optional) InfluxDB username used for authentication</td>\n-        </tr>\n-        <tr>\n-            <td><h5>writeTimeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">10000</td>\n-            <td>Integer</td>\n-            <td>(optional) the InfluxDB write timeout for metrics</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "09f39595735f18dd08754e977ae8dfa24c65bac9",
            "filename": "docs/_includes/generated/jmx_server_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 18,
            "changes": 18,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/jmx_server_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/jmx_server_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/jmx_server_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,18 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>jmx.server.port</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The port range for the JMX server to start the registry. The port config can be a single port: \"9123\", a range of ports: \"50100-50200\", or a list of ranges and ports: \"50100-50200,50300-50400,51234\". <br />This option overrides metrics.reporter.*.port option.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "793616b1bd784b02fcf8aaa7334f98181bf28c71",
            "filename": "docs/_includes/generated/job_manager_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 144,
            "changes": 144,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/job_manager_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/job_manager_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/job_manager_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,144 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>jobmanager.archive.fs.dir</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Dictionary for JobManager to store the archives of completed jobs.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobmanager.bind-host</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The local address of the network interface that the job manager binds to. If not configured, '0.0.0.0' will be used.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobmanager.execution.attempts-history-size</h5></td>\n-            <td style=\"word-wrap: break-word;\">16</td>\n-            <td>Integer</td>\n-            <td>The maximum number of prior execution attempts kept in history.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobmanager.execution.failover-strategy</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"region\"</td>\n-            <td>String</td>\n-            <td>This option specifies how the job computation recovers from task failures. Accepted values are:<ul><li>'full': Restarts all tasks to recover the job.</li><li>'region': Restarts all tasks that could be affected by the task failure. More details can be found <a href=\"../dev/task_failure_recovery.html#restart-pipelined-region-failover-strategy\">here</a>.</li></ul></td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobmanager.memory.enable-jvm-direct-memory-limit</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Whether to enable the JVM direct memory limit of the JobManager process (-XX:MaxDirectMemorySize). The limit will be set to the value of 'jobmanager.memory.off-heap.size' option. </td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobmanager.memory.flink.size</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>MemorySize</td>\n-            <td>Total Flink Memory size for the JobManager. This includes all the memory that a JobManager consumes, except for JVM Metaspace and JVM Overhead. It consists of JVM Heap Memory and Off-heap Memory. See also 'jobmanager.memory.process.size' for total process memory size configuration.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobmanager.memory.heap.size</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>MemorySize</td>\n-            <td>JVM Heap Memory size for JobManager. The minimum recommended JVM Heap size is 128.000mb (134217728 bytes).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobmanager.memory.jvm-metaspace.size</h5></td>\n-            <td style=\"word-wrap: break-word;\">256 mb</td>\n-            <td>MemorySize</td>\n-            <td>JVM Metaspace Size for the JobManager.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobmanager.memory.jvm-overhead.fraction</h5></td>\n-            <td style=\"word-wrap: break-word;\">0.1</td>\n-            <td>Float</td>\n-            <td>Fraction of Total Process Memory to be reserved for JVM Overhead. This is off-heap memory reserved for JVM overhead, such as thread stack space, compile cache, etc. This includes native memory but not direct memory, and will not be counted when Flink calculates JVM max direct memory size parameter. The size of JVM Overhead is derived to make up the configured fraction of the Total Process Memory. If the derived size is less or greater than the configured min or max size, the min or max size will be used. The exact size of JVM Overhead can be explicitly specified by setting the min and max size to the same value.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobmanager.memory.jvm-overhead.max</h5></td>\n-            <td style=\"word-wrap: break-word;\">1 gb</td>\n-            <td>MemorySize</td>\n-            <td>Max JVM Overhead size for the JobManager. This is off-heap memory reserved for JVM overhead, such as thread stack space, compile cache, etc. This includes native memory but not direct memory, and will not be counted when Flink calculates JVM max direct memory size parameter. The size of JVM Overhead is derived to make up the configured fraction of the Total Process Memory. If the derived size is less or greater than the configured min or max size, the min or max size will be used. The exact size of JVM Overhead can be explicitly specified by setting the min and max size to the same value.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobmanager.memory.jvm-overhead.min</h5></td>\n-            <td style=\"word-wrap: break-word;\">192 mb</td>\n-            <td>MemorySize</td>\n-            <td>Min JVM Overhead size for the JobManager. This is off-heap memory reserved for JVM overhead, such as thread stack space, compile cache, etc. This includes native memory but not direct memory, and will not be counted when Flink calculates JVM max direct memory size parameter. The size of JVM Overhead is derived to make up the configured fraction of the Total Process Memory. If the derived size is less or greater than the configured min or max size, the min or max size will be used. The exact size of JVM Overhead can be explicitly specified by setting the min and max size to the same value.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobmanager.memory.off-heap.size</h5></td>\n-            <td style=\"word-wrap: break-word;\">128 mb</td>\n-            <td>MemorySize</td>\n-            <td>Off-heap Memory size for JobManager. This option covers all off-heap memory usage including direct and native memory allocation. The JVM direct memory limit of the JobManager process (-XX:MaxDirectMemorySize) will be set to this value if the limit is enabled by 'jobmanager.memory.enable-jvm-direct-memory-limit'. </td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobmanager.memory.process.size</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>MemorySize</td>\n-            <td>Total Process Memory size for the JobManager. This includes all the memory that a JobManager JVM process consumes, consisting of Total Flink Memory, JVM Metaspace, and JVM Overhead. In containerized setups, this should be set to the container memory. See also 'jobmanager.memory.flink.size' for Total Flink Memory size configuration.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobmanager.retrieve-taskmanager-hostname</h5></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>Flag indicating whether JobManager would retrieve canonical host name of TaskManager during registration. If the option is set to \"false\", TaskManager registration with JobManager could be faster, since no reverse DNS lookup is performed. However, local input split assignment (such as for HDFS files) may be impacted.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobmanager.rpc.address</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The config parameter defining the network address to connect to for communication with the job manager. This value is only interpreted in setups where a single JobManager with static name or address exists (simple standalone setups, or container setups with dynamic service name resolution). It is not used in many high-availability setups, when a leader-election service (like ZooKeeper) is used to elect and discover the JobManager leader from potentially multiple standby JobManagers.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobmanager.rpc.bind-port</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>Integer</td>\n-            <td>The local RPC port that the JobManager binds to. If not configured, the external port (configured by 'jobmanager.rpc.port') will be used.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobmanager.rpc.port</h5></td>\n-            <td style=\"word-wrap: break-word;\">6123</td>\n-            <td>Integer</td>\n-            <td>The config parameter defining the network port to connect to for communication with the job manager. Like jobmanager.rpc.address, this value is only interpreted in setups where a single JobManager with static name/address and port exists (simple standalone setups, or container setups with dynamic service name resolution). This config option is not used in many high-availability setups, when a leader-election service (like ZooKeeper) is used to elect and discover the JobManager leader from potentially multiple standby JobManagers.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobstore.cache-size</h5></td>\n-            <td style=\"word-wrap: break-word;\">52428800</td>\n-            <td>Long</td>\n-            <td>The job store cache size in bytes which is used to keep completed jobs in memory.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobstore.expiration-time</h5></td>\n-            <td style=\"word-wrap: break-word;\">3600</td>\n-            <td>Long</td>\n-            <td>The time in seconds after which a completed job expires and is purged from the job store.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobstore.max-capacity</h5></td>\n-            <td style=\"word-wrap: break-word;\">2147483647</td>\n-            <td>Integer</td>\n-            <td>The max number of completed jobs that can be kept in the job store.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>slot.idle.timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">50000</td>\n-            <td>Long</td>\n-            <td>The timeout in milliseconds for a idle slot in Slot Pool.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>slot.request.timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">300000</td>\n-            <td>Long</td>\n-            <td>The timeout in milliseconds for requesting a slot from Slot Pool.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "aecaf0cc8be0c72431b59dc744a1a168b14e34c1",
            "filename": "docs/_includes/generated/kubernetes_config_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 186,
            "changes": 186,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/kubernetes_config_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/kubernetes_config_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/kubernetes_config_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,186 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>external-resource.&lt;resource_name&gt;.kubernetes.config-key</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>If configured, Flink will add \"resources.limits.&lt;config-key&gt;\" and \"resources.requests.&lt;config-key&gt;\" to the main container of TaskExecutor and set the value to the value of external-resource.&lt;resource_name&gt;.amount.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>kubernetes.cluster-id</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The cluster-id, which should be no more than 45 characters, is used for identifying a unique Flink cluster. If not set, the client will automatically generate it with a random ID.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>kubernetes.config.file</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The kubernetes config file will be used to create the client. The default is located at ~/.kube/config</td>\n-        </tr>\n-        <tr>\n-            <td><h5>kubernetes.container-start-command-template</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"%java% %classpath% %jvmmem% %jvmopts% %logging% %class% %args%\"</td>\n-            <td>String</td>\n-            <td>Template for the kubernetes jobmanager and taskmanager container start invocation.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>kubernetes.container.image</h5></td>\n-            <td style=\"word-wrap: break-word;\">The default value depends on the actually running version. In general it looks like \"flink:&lt;FLINK_VERSION&gt;-scala_&lt;SCALA_VERSION&gt;\"</td>\n-            <td>String</td>\n-            <td>Image to use for Flink containers. The specified image must be based upon the same Apache Flink and Scala versions as used by the application. Visit https://hub.docker.com/_/flink?tab=tags for the images provided by the Flink project.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>kubernetes.container.image.pull-policy</h5></td>\n-            <td style=\"word-wrap: break-word;\">IfNotPresent</td>\n-            <td><p>Enum</p>Possible values: [IfNotPresent, Always, Never]</td>\n-            <td>The Kubernetes container image pull policy (IfNotPresent or Always or Never). The default policy is IfNotPresent to avoid putting pressure to image repository.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>kubernetes.container.image.pull-secrets</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>List&lt;String&gt;</td>\n-            <td>A semicolon-separated list of the Kubernetes secrets used to access private image registries.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>kubernetes.context</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The desired context from your Kubernetes config file used to configure the Kubernetes client for interacting with the cluster. This could be helpful if one has multiple contexts configured and wants to administrate different Flink clusters on different Kubernetes clusters/contexts.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>kubernetes.entry.path</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"/docker-entrypoint.sh\"</td>\n-            <td>String</td>\n-            <td>The entrypoint script of kubernetes in the image. It will be used as command for jobmanager and taskmanager container.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>kubernetes.env.secretKeyRef</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>List&lt;Map&gt;</td>\n-            <td>The user-specified secrets to set env variables in Flink container. The value should be in the form of <span markdown=\"span\">`env:FOO_ENV,secret:foo_secret,key:foo_key;env:BAR_ENV,secret:bar_secret,key:bar_key`</span>.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>kubernetes.flink.conf.dir</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"/opt/flink/conf\"</td>\n-            <td>String</td>\n-            <td>The flink conf directory that will be mounted in pod. The flink-conf.yaml, log4j.properties, logback.xml in this path will be overwritten from config map.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>kubernetes.flink.log.dir</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"/opt/flink/log\"</td>\n-            <td>String</td>\n-            <td>The directory that logs of jobmanager and taskmanager be saved in the pod.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>kubernetes.hadoop.conf.config-map.name</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Specify the name of an existing ConfigMap that contains custom Hadoop configuration to be mounted on the JobManager(s) and TaskManagers.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>kubernetes.jobmanager.annotations</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>Map</td>\n-            <td>The user-specified annotations that are set to the JobManager pod. The value could be in the form of a1:v1,a2:v2</td>\n-        </tr>\n-        <tr>\n-            <td><h5>kubernetes.jobmanager.cpu</h5></td>\n-            <td style=\"word-wrap: break-word;\">1.0</td>\n-            <td>Double</td>\n-            <td>The number of cpu used by job manager</td>\n-        </tr>\n-        <tr>\n-            <td><h5>kubernetes.jobmanager.labels</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>Map</td>\n-            <td>The labels to be set for JobManager pod. Specified as key:value pairs separated by commas. For example, version:alphav1,deploy:test.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>kubernetes.jobmanager.node-selector</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>Map</td>\n-            <td>The node selector to be set for JobManager pod. Specified as key:value pairs separated by commas. For example, environment:production,disk:ssd.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>kubernetes.jobmanager.service-account</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"default\"</td>\n-            <td>String</td>\n-            <td>Service account that is used by jobmanager within kubernetes cluster. The job manager uses this service account when requesting taskmanager pods from the API server.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>kubernetes.jobmanager.tolerations</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>List&lt;Map&gt;</td>\n-            <td>The user-specified tolerations to be set to the JobManager pod. The value should be in the form of key:key1,operator:Equal,value:value1,effect:NoSchedule;key:key2,operator:Exists,effect:NoExecute,tolerationSeconds:6000</td>\n-        </tr>\n-        <tr>\n-            <td><h5>kubernetes.namespace</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"default\"</td>\n-            <td>String</td>\n-            <td>The namespace that will be used for running the jobmanager and taskmanager pods.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>kubernetes.rest-service.annotations</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>Map</td>\n-            <td>The user-specified annotations that are set to the rest Service. The value should be in the form of a1:v1,a2:v2</td>\n-        </tr>\n-        <tr>\n-            <td><h5>kubernetes.rest-service.exposed.type</h5></td>\n-            <td style=\"word-wrap: break-word;\">LoadBalancer</td>\n-            <td><p>Enum</p>Possible values: [ClusterIP, NodePort, LoadBalancer]</td>\n-            <td>The type of the rest service (ClusterIP or NodePort or LoadBalancer). When set to ClusterIP, the rest service will not be created.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>kubernetes.secrets</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>Map</td>\n-            <td>The user-specified secrets that will be mounted into Flink container. The value should be in the form of <span markdown=\"span\">`foo:/opt/secrets-foo,bar:/opt/secrets-bar`</span>.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>kubernetes.taskmanager.annotations</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>Map</td>\n-            <td>The user-specified annotations that are set to the TaskManager pod. The value could be in the form of a1:v1,a2:v2</td>\n-        </tr>\n-        <tr>\n-            <td><h5>kubernetes.taskmanager.cpu</h5></td>\n-            <td style=\"word-wrap: break-word;\">-1.0</td>\n-            <td>Double</td>\n-            <td>The number of cpu used by task manager. By default, the cpu is set to the number of slots per TaskManager</td>\n-        </tr>\n-        <tr>\n-            <td><h5>kubernetes.taskmanager.labels</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>Map</td>\n-            <td>The labels to be set for TaskManager pods. Specified as key:value pairs separated by commas. For example, version:alphav1,deploy:test.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>kubernetes.taskmanager.node-selector</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>Map</td>\n-            <td>The node selector to be set for TaskManager pods. Specified as key:value pairs separated by commas. For example, environment:production,disk:ssd.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>kubernetes.taskmanager.tolerations</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>List&lt;Map&gt;</td>\n-            <td>The user-specified tolerations to be set to the TaskManager pod. The value should be in the form of key:key1,operator:Equal,value:value1,effect:NoSchedule;key:key2,operator:Exists,effect:NoExecute,tolerationSeconds:6000</td>\n-        </tr>\n-        <tr>\n-            <td><h5>kubernetes.transactional-operation.max-retries</h5></td>\n-            <td style=\"word-wrap: break-word;\">5</td>\n-            <td>Integer</td>\n-            <td>Defines the number of Kubernetes transactional operation retries before the client gives up. For example, <span markdown=\"span\">`FlinkKubeClient#checkAndUpdateConfigMap`</span>.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "60bc077486cb2e98c0d470d6aaa44ca536176a94",
            "filename": "docs/_includes/generated/kubernetes_high_availability_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 30,
            "changes": 30,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/kubernetes_high_availability_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/kubernetes_high_availability_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/kubernetes_high_availability_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,30 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>high-availability.kubernetes.leader-election.lease-duration</h5></td>\n-            <td style=\"word-wrap: break-word;\">15 s</td>\n-            <td>Duration</td>\n-            <td>Define the lease duration for the Kubernetes leader election. The leader will continuously renew its lease time to indicate its existence. And the followers will do a lease checking against the current time. \"renewTime + leaseDuration &gt; now\" means the leader is alive.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>high-availability.kubernetes.leader-election.renew-deadline</h5></td>\n-            <td style=\"word-wrap: break-word;\">15 s</td>\n-            <td>Duration</td>\n-            <td>Defines the deadline duration when the leader tries to renew the lease. The leader will give up its leadership if it cannot successfully renew the lease in the given time.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>high-availability.kubernetes.leader-election.retry-period</h5></td>\n-            <td style=\"word-wrap: break-word;\">5 s</td>\n-            <td>Duration</td>\n-            <td>Defines the pause duration between consecutive retries. All the contenders, including the current leader and all other followers, periodically try to acquire/renew the leadership if possible at this interval.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "db8c6f46670f7bbfa2cab7a0265816024ef5ba91",
            "filename": "docs/_includes/generated/mesos_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 84,
            "changes": 84,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/mesos_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/mesos_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/mesos_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,84 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>mesos.failover-timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">604800</td>\n-            <td>Integer</td>\n-            <td>The failover timeout in seconds for the Mesos scheduler, after which running tasks are automatically shut down.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>mesos.master</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The Mesos master URL. The value should be in one of the following forms: <ul><li>host:port</li><li>zk://host1:port1,host2:port2,.../path</li><li>zk://username:password@host1:port1,host2:port2,.../path</li><li>file:///path/to/file</li></ul></td>\n-        </tr>\n-        <tr>\n-            <td><h5>mesos.resourcemanager.artifactserver.port</h5></td>\n-            <td style=\"word-wrap: break-word;\">0</td>\n-            <td>Integer</td>\n-            <td>The config parameter defining the Mesos artifact server port to use. Setting the port to 0 will let the OS choose an available port.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>mesos.resourcemanager.artifactserver.ssl.enabled</h5></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>Enables SSL for the Flink artifact server. Note that security.ssl.enabled also needs to be set to true encryption to enable encryption.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>mesos.resourcemanager.declined-offer-refuse-duration</h5></td>\n-            <td style=\"word-wrap: break-word;\">5000</td>\n-            <td>Long</td>\n-            <td>Amount of time to ask the Mesos master to not resend a declined resource offer again. This ensures a declined resource offer isn't resent immediately after being declined</td>\n-        </tr>\n-        <tr>\n-            <td><h5>mesos.resourcemanager.framework.name</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"Flink\"</td>\n-            <td>String</td>\n-            <td>Mesos framework name</td>\n-        </tr>\n-        <tr>\n-            <td><h5>mesos.resourcemanager.framework.principal</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Mesos framework principal</td>\n-        </tr>\n-        <tr>\n-            <td><h5>mesos.resourcemanager.framework.role</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"*\"</td>\n-            <td>String</td>\n-            <td>Mesos framework role definition</td>\n-        </tr>\n-        <tr>\n-            <td><h5>mesos.resourcemanager.framework.secret</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Mesos framework secret</td>\n-        </tr>\n-        <tr>\n-            <td><h5>mesos.resourcemanager.framework.user</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Mesos framework user</td>\n-        </tr>\n-        <tr>\n-            <td><h5>mesos.resourcemanager.tasks.port-assignments</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Comma-separated list of configuration keys which represent a configurable port. All port keys will dynamically get a port assigned through Mesos.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>mesos.resourcemanager.unused-offer-expiration</h5></td>\n-            <td style=\"word-wrap: break-word;\">120000</td>\n-            <td>Long</td>\n-            <td>Amount of time to wait for unused expired offers before declining them. This ensures your scheduler will not hoard unuseful offers.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "c6bfbc0553a405d70665f42e25f77212f3896e1a",
            "filename": "docs/_includes/generated/mesos_task_manager_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 102,
            "changes": 102,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/mesos_task_manager_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/mesos_task_manager_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/mesos_task_manager_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,102 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>mesos.constraints.hard.hostattribute</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Constraints for task placement on Mesos based on agent attributes. Takes a comma-separated list of key:value pairs corresponding to the attributes exposed by the target mesos agents. Example: az:eu-west-1a,series:t2</td>\n-        </tr>\n-        <tr>\n-            <td><h5>mesos.resourcemanager.network.resource.name</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"network\"</td>\n-            <td>String</td>\n-            <td>Network resource name on Mesos cluster.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>mesos.resourcemanager.tasks.bootstrap-cmd</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>A command which is executed before the TaskManager is started.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>mesos.resourcemanager.tasks.container.docker.force-pull-image</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Instruct the docker containerizer to forcefully pull the image rather than reuse a cached version.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>mesos.resourcemanager.tasks.container.docker.parameters</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Custom parameters to be passed into docker run command when using the docker containerizer. Comma separated list of \"key=value\" pairs. The \"value\" may contain '='.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>mesos.resourcemanager.tasks.container.image.name</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Image name to use for the container.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>mesos.resourcemanager.tasks.container.type</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"mesos\"</td>\n-            <td>String</td>\n-            <td>Type of the containerization used: “mesos” or “docker”.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>mesos.resourcemanager.tasks.container.volumes</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>A comma separated list of [host_path:]container_path[:RO|RW]. This allows for mounting additional volumes into your container.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>mesos.resourcemanager.tasks.cpus</h5></td>\n-            <td style=\"word-wrap: break-word;\">0.0</td>\n-            <td>Double</td>\n-            <td>CPUs to assign to the Mesos workers.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>mesos.resourcemanager.tasks.disk</h5></td>\n-            <td style=\"word-wrap: break-word;\">0</td>\n-            <td>Integer</td>\n-            <td>Disk space to assign to the Mesos workers in MB.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>mesos.resourcemanager.tasks.gpus</h5></td>\n-            <td style=\"word-wrap: break-word;\">0</td>\n-            <td>Integer</td>\n-            <td>GPUs to assign to the Mesos workers.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>mesos.resourcemanager.tasks.hostname</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Optional value to define the TaskManager’s hostname. The pattern _TASK_ is replaced by the actual id of the Mesos task. This can be used to configure the TaskManager to use Mesos DNS (e.g. _TASK_.flink-service.mesos) for name lookups.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>mesos.resourcemanager.tasks.network.bandwidth</h5></td>\n-            <td style=\"word-wrap: break-word;\">0</td>\n-            <td>Integer</td>\n-            <td>Network bandwidth to assign to the Mesos workers in MB per sec.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>mesos.resourcemanager.tasks.taskmanager-cmd</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"$FLINK_HOME/bin/mesos-taskmanager.sh\"</td>\n-            <td>String</td>\n-            <td></td>\n-        </tr>\n-        <tr>\n-            <td><h5>mesos.resourcemanager.tasks.uris</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>A comma separated list of URIs of custom artifacts to be downloaded into the sandbox of Mesos workers.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "49ae31478a06168aad6eea1773c222a1b5847723",
            "filename": "docs/_includes/generated/metric_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 126,
            "changes": 126,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/metric_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/metric_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/metric_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,126 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>metrics.fetcher.update-interval</h5></td>\n-            <td style=\"word-wrap: break-word;\">10000</td>\n-            <td>Long</td>\n-            <td>Update interval for the metric fetcher used by the web UI in milliseconds. Decrease this value for faster updating metrics. Increase this value if the metric fetcher causes too much load. Setting this value to 0 disables the metric fetching completely.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>metrics.internal.query-service.port</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"0\"</td>\n-            <td>String</td>\n-            <td>The port range used for Flink's internal metric query service. Accepts a list of ports (“50100,50101”), ranges(“50100-50200”) or a combination of both. It is recommended to set a range of ports to avoid collisions when multiple Flink components are running on the same machine. Per default Flink will pick a random port.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>metrics.internal.query-service.thread-priority</h5></td>\n-            <td style=\"word-wrap: break-word;\">1</td>\n-            <td>Integer</td>\n-            <td>The thread priority used for Flink's internal metric query service. The thread is created by Akka's thread pool executor. The range of the priority is from 1 (MIN_PRIORITY) to 10 (MAX_PRIORITY). Warning, increasing this value may bring the main Flink components down.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>metrics.latency.granularity</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"operator\"</td>\n-            <td>String</td>\n-            <td>Defines the granularity of latency metrics. Accepted values are:<ul><li>single - Track latency without differentiating between sources and subtasks.</li><li>operator - Track latency while differentiating between sources, but not subtasks.</li><li>subtask - Track latency while differentiating between sources and subtasks.</li></ul></td>\n-        </tr>\n-        <tr>\n-            <td><h5>metrics.latency.history-size</h5></td>\n-            <td style=\"word-wrap: break-word;\">128</td>\n-            <td>Integer</td>\n-            <td>Defines the number of measured latencies to maintain at each operator.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>metrics.latency.interval</h5></td>\n-            <td style=\"word-wrap: break-word;\">0</td>\n-            <td>Long</td>\n-            <td>Defines the interval at which latency tracking marks are emitted from the sources. Disables latency tracking if set to 0 or a negative value. Enabling this feature can significantly impact the performance of the cluster.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>metrics.reporter.&lt;name&gt;.&lt;parameter&gt;</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Configures the parameter &lt;parameter&gt; for the reporter named &lt;name&gt;.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>metrics.reporter.&lt;name&gt;.class</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The reporter class to use for the reporter named &lt;name&gt;.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>metrics.reporter.&lt;name&gt;.interval</h5></td>\n-            <td style=\"word-wrap: break-word;\">10 s</td>\n-            <td>Duration</td>\n-            <td>The reporter interval to use for the reporter named &lt;name&gt;.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>metrics.reporters</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>An optional list of reporter names. If configured, only reporters whose name matches any of the names in the list will be started. Otherwise, all reporters that could be found in the configuration will be started.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>metrics.scope.delimiter</h5></td>\n-            <td style=\"word-wrap: break-word;\">\".\"</td>\n-            <td>String</td>\n-            <td>Delimiter used to assemble the metric identifier.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>metrics.scope.jm</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"&lt;host&gt;.jobmanager\"</td>\n-            <td>String</td>\n-            <td>Defines the scope format string that is applied to all metrics scoped to a JobManager.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>metrics.scope.jm.job</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"&lt;host&gt;.jobmanager.&lt;job_name&gt;\"</td>\n-            <td>String</td>\n-            <td>Defines the scope format string that is applied to all metrics scoped to a job on a JobManager.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>metrics.scope.operator</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"&lt;host&gt;.taskmanager.&lt;tm_id&gt;.&lt;job_name&gt;.&lt;operator_name&gt;.&lt;subtask_index&gt;\"</td>\n-            <td>String</td>\n-            <td>Defines the scope format string that is applied to all metrics scoped to an operator.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>metrics.scope.task</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"&lt;host&gt;.taskmanager.&lt;tm_id&gt;.&lt;job_name&gt;.&lt;task_name&gt;.&lt;subtask_index&gt;\"</td>\n-            <td>String</td>\n-            <td>Defines the scope format string that is applied to all metrics scoped to a task.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>metrics.scope.tm</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"&lt;host&gt;.taskmanager.&lt;tm_id&gt;\"</td>\n-            <td>String</td>\n-            <td>Defines the scope format string that is applied to all metrics scoped to a TaskManager.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>metrics.scope.tm.job</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"&lt;host&gt;.taskmanager.&lt;tm_id&gt;.&lt;job_name&gt;\"</td>\n-            <td>String</td>\n-            <td>Defines the scope format string that is applied to all metrics scoped to a job on a TaskManager.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>metrics.system-resource</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Flag indicating whether Flink should report system resource metrics such as machine's CPU, memory or network usage.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>metrics.system-resource-probing-interval</h5></td>\n-            <td style=\"word-wrap: break-word;\">5000</td>\n-            <td>Long</td>\n-            <td>Interval between probing of system resource metrics specified in milliseconds. Has an effect only when 'metrics.system-resource' is enabled.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "9d54dcaa12467a0a846e64974783eed5657a01a9",
            "filename": "docs/_includes/generated/netty_shuffle_environment_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 138,
            "changes": 138,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/netty_shuffle_environment_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/netty_shuffle_environment_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/netty_shuffle_environment_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,138 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>taskmanager.data.bind-port</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>Integer</td>\n-            <td>The task manager's bind port used for data exchange operations. If not configured, 'taskmanager.data.port' will be used.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.data.port</h5></td>\n-            <td style=\"word-wrap: break-word;\">0</td>\n-            <td>Integer</td>\n-            <td>The task manager’s external port used for data exchange operations.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.data.ssl.enabled</h5></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>Enable SSL support for the taskmanager data transport. This is applicable only when the global flag for internal SSL (security.ssl.internal.enabled) is set to true</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.blocking-shuffle.compression.enabled</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Boolean flag indicating whether the shuffle data will be compressed for blocking shuffle mode. Note that data is compressed per buffer and compression can incur extra CPU overhead, so it is more effective for IO bounded scenario when data compression ratio is high. Currently, shuffle data compression is an experimental feature and the config option can be changed in the future.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.blocking-shuffle.type</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"file\"</td>\n-            <td>String</td>\n-            <td>The blocking shuffle type, either \"mmap\" or \"file\". The \"auto\" means selecting the property type automatically based on system memory architecture (64 bit for mmap and 32 bit for file). Note that the memory usage of mmap is not accounted by configured memory limits, but some resource frameworks like yarn would track this memory usage and kill the container once memory exceeding some threshold. Also note that this option is experimental and might be changed future.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.detailed-metrics</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Boolean flag to enable/disable more detailed metrics about inbound/outbound network queue lengths.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.memory.buffers-per-channel</h5></td>\n-            <td style=\"word-wrap: break-word;\">2</td>\n-            <td>Integer</td>\n-            <td>Number of exclusive network buffers to use for each outgoing/incoming channel (subpartition/inputchannel) in the credit-based flow control model. It should be configured at least 2 for good performance. 1 buffer is for receiving in-flight data in the subpartition and 1 buffer is for parallel serialization.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.memory.floating-buffers-per-gate</h5></td>\n-            <td style=\"word-wrap: break-word;\">8</td>\n-            <td>Integer</td>\n-            <td>Number of extra network buffers to use for each outgoing/incoming gate (result partition/input gate). In credit-based flow control mode, this indicates how many floating credits are shared among all the input channels. The floating buffers are distributed based on backlog (real-time output buffers in the subpartition) feedback, and can help relieve back-pressure caused by unbalanced data distribution among the subpartitions. This value should be increased in case of higher round trip times between nodes and/or larger number of machines in the cluster.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.memory.max-buffers-per-channel</h5></td>\n-            <td style=\"word-wrap: break-word;\">10</td>\n-            <td>Integer</td>\n-            <td>Number of max buffers that can be used for each channel. If a channel exceeds the number of max buffers, it will make the task become unavailable, cause the back pressure and block the data processing. This might speed up checkpoint alignment by preventing excessive growth of the buffered in-flight data in case of data skew and high number of configured floating buffers. This limit is not strictly guaranteed, and can be ignored by things like flatMap operators, records spanning multiple buffers or single timer producing large amount of data.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.netty.client.connectTimeoutSec</h5></td>\n-            <td style=\"word-wrap: break-word;\">120</td>\n-            <td>Integer</td>\n-            <td>The Netty client connection timeout.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.netty.client.numThreads</h5></td>\n-            <td style=\"word-wrap: break-word;\">-1</td>\n-            <td>Integer</td>\n-            <td>The number of Netty client threads.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.netty.num-arenas</h5></td>\n-            <td style=\"word-wrap: break-word;\">-1</td>\n-            <td>Integer</td>\n-            <td>The number of Netty arenas.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.netty.sendReceiveBufferSize</h5></td>\n-            <td style=\"word-wrap: break-word;\">0</td>\n-            <td>Integer</td>\n-            <td>The Netty send and receive buffer size. This defaults to the system buffer size (cat /proc/sys/net/ipv4/tcp_[rw]mem) and is 4 MiB in modern Linux.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.netty.server.backlog</h5></td>\n-            <td style=\"word-wrap: break-word;\">0</td>\n-            <td>Integer</td>\n-            <td>The netty server connection backlog.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.netty.server.numThreads</h5></td>\n-            <td style=\"word-wrap: break-word;\">-1</td>\n-            <td>Integer</td>\n-            <td>The number of Netty server threads.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.netty.transport</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"auto\"</td>\n-            <td>String</td>\n-            <td>The Netty transport type, either \"nio\" or \"epoll\". The \"auto\" means selecting the property mode automatically based on the platform. Note that the \"epoll\" mode can get better performance, less GC and have more advanced features which are only available on modern Linux.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.request-backoff.initial</h5></td>\n-            <td style=\"word-wrap: break-word;\">100</td>\n-            <td>Integer</td>\n-            <td>Minimum backoff in milliseconds for partition requests of input channels.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.request-backoff.max</h5></td>\n-            <td style=\"word-wrap: break-word;\">10000</td>\n-            <td>Integer</td>\n-            <td>Maximum backoff in milliseconds for partition requests of input channels.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.retries</h5></td>\n-            <td style=\"word-wrap: break-word;\">0</td>\n-            <td>Integer</td>\n-            <td>The number of retry attempts for network communication. Currently it's only used for establishing input/output channel connections</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.sort-shuffle.min-buffers</h5></td>\n-            <td style=\"word-wrap: break-word;\">64</td>\n-            <td>Integer</td>\n-            <td>Minimum number of network buffers required per sort-merge blocking result partition. For large scale batch jobs, it is suggested to increase this config value to improve compression ratio and reduce small network packets. Note: to increase this config value, you may also need to increase the size of total network memory to avoid \"insufficient number of network buffers\" error.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.sort-shuffle.min-parallelism</h5></td>\n-            <td style=\"word-wrap: break-word;\">2147483647</td>\n-            <td>Integer</td>\n-            <td>Parallelism threshold to switch between sort-merge blocking shuffle and the default hash-based blocking shuffle, which means for small parallelism, hash-based blocking shuffle will be used and for large parallelism, sort-merge blocking shuffle will be used. Note: sort-merge blocking shuffle uses unmanaged direct memory for shuffle data writing and reading so just increase the size of direct memory if direct memory OOM error occurs.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "7efa6c0145638f595027302eba5245e4bbc3c0f6",
            "filename": "docs/_includes/generated/optimizer_config_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 69,
            "changes": 69,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/optimizer_config_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/optimizer_config_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/optimizer_config_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,69 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>table.optimizer.agg-phase-strategy</h5><br> <span class=\"label label-primary\">Batch</span> <span class=\"label label-primary\">Streaming</span></td>\n-            <td style=\"word-wrap: break-word;\">\"AUTO\"</td>\n-            <td>String</td>\n-            <td>Strategy for aggregate phase. Only AUTO, TWO_PHASE or ONE_PHASE can be set.\n-AUTO: No special enforcer for aggregate stage. Whether to choose two stage aggregate or one stage aggregate depends on cost. \n-TWO_PHASE: Enforce to use two stage aggregate which has localAggregate and globalAggregate. Note that if aggregate call does not support optimize into two phase, we will still use one stage aggregate.\n-ONE_PHASE: Enforce to use one stage aggregate which only has CompleteGlobalAggregate.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>table.optimizer.distinct-agg.split.bucket-num</h5><br> <span class=\"label label-primary\">Streaming</span></td>\n-            <td style=\"word-wrap: break-word;\">1024</td>\n-            <td>Integer</td>\n-            <td>Configure the number of buckets when splitting distinct aggregation. The number is used in the first level aggregation to calculate a bucket key 'hash_code(distinct_key) % BUCKET_NUM' which is used as an additional group key after splitting.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>table.optimizer.distinct-agg.split.enabled</h5><br> <span class=\"label label-primary\">Streaming</span></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Tells the optimizer whether to split distinct aggregation (e.g. COUNT(DISTINCT col), SUM(DISTINCT col)) into two level. The first aggregation is shuffled by an additional key which is calculated using the hashcode of distinct_key and number of buckets. This optimization is very useful when there is data skew in distinct aggregation and gives the ability to scale-up the job. Default is false.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>table.optimizer.join-reorder-enabled</h5><br> <span class=\"label label-primary\">Batch</span> <span class=\"label label-primary\">Streaming</span></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Enables join reorder in optimizer. Default is disabled.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>table.optimizer.join.broadcast-threshold</h5><br> <span class=\"label label-primary\">Batch</span></td>\n-            <td style=\"word-wrap: break-word;\">1048576</td>\n-            <td>Long</td>\n-            <td>Configures the maximum size in bytes for a table that will be broadcast to all worker nodes when performing a join. By setting this value to -1 to disable broadcasting.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>table.optimizer.multiple-input-enabled</h5><br> <span class=\"label label-primary\">Batch</span></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>When it is true, the optimizer will merge the operators with pipelined shuffling into a multiple input operator to reduce shuffling and improve performance. Default value is true.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>table.optimizer.reuse-source-enabled</h5><br> <span class=\"label label-primary\">Batch</span> <span class=\"label label-primary\">Streaming</span></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>When it is true, the optimizer will try to find out duplicated table sources and reuse them. This works only when table.optimizer.reuse-sub-plan-enabled is true.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>table.optimizer.reuse-sub-plan-enabled</h5><br> <span class=\"label label-primary\">Batch</span> <span class=\"label label-primary\">Streaming</span></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>When it is true, the optimizer will try to find out duplicated sub-plans and reuse them.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>table.optimizer.source.predicate-pushdown-enabled</h5><br> <span class=\"label label-primary\">Batch</span> <span class=\"label label-primary\">Streaming</span></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>When it is true, the optimizer will push down predicates into the FilterableTableSource. Default value is true.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "7095a3619997ffbfefc2d1a5f3133980fd407072",
            "filename": "docs/_includes/generated/optimizer_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 30,
            "changes": 30,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/optimizer_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/optimizer_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/optimizer_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,30 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>compiler.delimited-informat.max-line-samples</h5></td>\n-            <td style=\"word-wrap: break-word;\">10</td>\n-            <td>Integer</td>\n-            <td>The maximum number of line samples taken by the compiler for delimited inputs. The samples are used to estimate the number of records. This value can be overridden for a specific input with the input format’s parameters.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>compiler.delimited-informat.max-sample-len</h5></td>\n-            <td style=\"word-wrap: break-word;\">2097152</td>\n-            <td>Integer</td>\n-            <td>The maximal length of a line sample that the compiler takes for delimited inputs. If the length of a single sample exceeds this value (possible because of misconfiguration of the parser), the sampling aborts. This value can be overridden for a specific input with the input format’s parameters.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>compiler.delimited-informat.min-line-samples</h5></td>\n-            <td style=\"word-wrap: break-word;\">2</td>\n-            <td>Integer</td>\n-            <td>The minimum number of line samples taken by the compiler for delimited inputs. The samples are used to estimate the number of records. This value can be overridden for a specific input with the input format’s parameters</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "f3fc216ddeaefa467e5e1968b8930096d3dbd2f9",
            "filename": "docs/_includes/generated/pipeline_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 114,
            "changes": 114,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/pipeline_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/pipeline_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/pipeline_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,114 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>pipeline.auto-generate-uids</h5></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>When auto-generated UIDs are disabled, users are forced to manually specify UIDs on DataStream applications.<br /><br />It is highly recommended that users specify UIDs before deploying to production since they are used to match state in savepoints to operators in a job. Because auto-generated ID's are likely to change when modifying a job, specifying custom IDs allow an application to evolve over time without discarding state.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>pipeline.auto-type-registration</h5></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>Controls whether Flink is automatically registering all types in the user programs with Kryo.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>pipeline.auto-watermark-interval</h5></td>\n-            <td style=\"word-wrap: break-word;\">0 ms</td>\n-            <td>Duration</td>\n-            <td>The interval of the automatic watermark emission. Watermarks are used throughout the streaming system to keep track of the progress of time. They are used, for example, for time based windowing.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>pipeline.cached-files</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>List&lt;String&gt;</td>\n-            <td>Files to be registered at the distributed cache under the given name. The files will be accessible from any user-defined function in the (distributed) runtime under a local path. Files may be local files (which will be distributed via BlobServer), or files in a distributed file system. The runtime will copy the files temporarily to a local cache, if needed.<br /><br />Example:<br /><span markdown=\"span\">`name:file1,path:`file:///tmp/file1`;name:file2,path:`hdfs:///tmp/file2``</span></td>\n-        </tr>\n-        <tr>\n-            <td><h5>pipeline.classpaths</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>List&lt;String&gt;</td>\n-            <td>A semicolon-separated list of the classpaths to package with the job jars to be sent to the cluster. These have to be valid URLs.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>pipeline.closure-cleaner-level</h5></td>\n-            <td style=\"word-wrap: break-word;\">RECURSIVE</td>\n-            <td><p>Enum</p>Possible values: [NONE, TOP_LEVEL, RECURSIVE]</td>\n-            <td>Configures the mode in which the closure cleaner works<ul><li><span markdown=\"span\">`NONE`</span> - disables the closure cleaner completely</li><li><span markdown=\"span\">`TOP_LEVEL`</span> - cleans only the top-level class without recursing into fields</li><li><span markdown=\"span\">`RECURSIVE`</span> - cleans all the fields recursively</li></ul></td>\n-        </tr>\n-        <tr>\n-            <td><h5>pipeline.default-kryo-serializers</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>List&lt;String&gt;</td>\n-            <td>Semicolon separated list of pairs of class names and Kryo serializers class names to be used as Kryo default serializers<br /><br />Example:<br /><span markdown=\"span\">`class:org.example.ExampleClass,serializer:org.example.ExampleSerializer1; class:org.example.ExampleClass2,serializer:org.example.ExampleSerializer2`</span></td>\n-        </tr>\n-        <tr>\n-            <td><h5>pipeline.force-avro</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Forces Flink to use the Apache Avro serializer for POJOs.<br /><br />Important: Make sure to include the <span markdown=\"span\">`flink-avro`</span> module.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>pipeline.force-kryo</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>If enabled, forces TypeExtractor to use Kryo serializer for POJOS even though we could analyze as POJO. In some cases this might be preferable. For example, when using interfaces with subclasses that cannot be analyzed as POJO.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>pipeline.generic-types</h5></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>If the use of generic types is disabled, Flink will throw an <span markdown=\"span\">`UnsupportedOperationException`</span> whenever it encounters a data type that would go through Kryo for serialization.<br /><br />Disabling generic types can be helpful to eagerly find and eliminate the use of types that would go through Kryo serialization during runtime. Rather than checking types individually, using this option will throw exceptions eagerly in the places where generic types are used.<br /><br />We recommend to use this option only during development and pre-production phases, not during actual production use. The application program and/or the input data may be such that new, previously unseen, types occur at some point. In that case, setting this option would cause the program to fail.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>pipeline.global-job-parameters</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>Map</td>\n-            <td>Register a custom, serializable user configuration object. The configuration can be  accessed in operators</td>\n-        </tr>\n-        <tr>\n-            <td><h5>pipeline.jars</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>List&lt;String&gt;</td>\n-            <td>A semicolon-separated list of the jars to package with the job jars to be sent to the cluster. These have to be valid paths.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>pipeline.max-parallelism</h5></td>\n-            <td style=\"word-wrap: break-word;\">-1</td>\n-            <td>Integer</td>\n-            <td>The program-wide maximum parallelism used for operators which haven't specified a maximum parallelism. The maximum parallelism specifies the upper limit for dynamic scaling and the number of key groups used for partitioned state.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>pipeline.object-reuse</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>When enabled objects that Flink internally uses for deserialization and passing data to user-code functions will be reused. Keep in mind that this can lead to bugs when the user-code function of an operation is not aware of this behaviour.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>pipeline.operator-chaining</h5></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>Operator chaining allows non-shuffle operations to be co-located in the same thread fully avoiding serialization and de-serialization.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>pipeline.registered-kryo-types</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>List&lt;String&gt;</td>\n-            <td>Semicolon separated list of types to be registered with the serialization stack. If the type is eventually serialized as a POJO, then the type is registered with the POJO serializer. If the type ends up being serialized with Kryo, then it will be registered at Kryo to make sure that only tags are written.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>pipeline.registered-pojo-types</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>List&lt;String&gt;</td>\n-            <td>Semicolon separated list of types to be registered with the serialization stack. If the type is eventually serialized as a POJO, then the type is registered with the POJO serializer. If the type ends up being serialized with Kryo, then it will be registered at Kryo to make sure that only tags are written.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "8128bf8ea480191c71e7f0548ccbbb8959bff669",
            "filename": "docs/_includes/generated/prometheus_push_gateway_reporter_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 54,
            "changes": 54,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/prometheus_push_gateway_reporter_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/prometheus_push_gateway_reporter_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/prometheus_push_gateway_reporter_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,54 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>deleteOnShutdown</h5></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>Specifies whether to delete metrics from the PushGateway on shutdown.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>filterLabelValueCharacters</h5></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>Specifies whether to filter label value characters. If enabled, all characters not matching [a-zA-Z0-9:_] will be removed, otherwise no characters will be removed. Before disabling this option please ensure that your label values meet the <a href=\"https://prometheus.io/docs/concepts/data_model/#metric-names-and-labels\">Prometheus requirements</a>.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>groupingKey</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Specifies the grouping key which is the group and global labels of all metrics. The label name and value are separated by '=', and labels are separated by ';', e.g., <span markdown=\"span\">`k1=v1;k2=v2`</span>. Please ensure that your grouping key meets the <a href=\"https://prometheus.io/docs/concepts/data_model/#metric-names-and-labels\">Prometheus requirements</a>.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>host</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The PushGateway server host.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>jobName</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The job name under which metrics will be pushed</td>\n-        </tr>\n-        <tr>\n-            <td><h5>port</h5></td>\n-            <td style=\"word-wrap: break-word;\">-1</td>\n-            <td>Integer</td>\n-            <td>The PushGateway server port.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>randomJobNameSuffix</h5></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>Specifies whether a random suffix should be appended to the job name.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "16b76e26211c313c69b6589238d7d6f8a328b77a",
            "filename": "docs/_includes/generated/python_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 96,
            "changes": 96,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/python_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/python_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/python_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,96 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>python.archives</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Add python archive files for job. The archive files will be extracted to the working directory of python UDF worker. Currently only zip-format is supported. For each archive file, a target directory is specified. If the target directory name is specified, the archive file will be extracted to a name can directory with the specified name. Otherwise, the archive file will be extracted to a directory with the same name of the archive file. The files uploaded via this option are accessible via relative path. '#' could be used as the separator of the archive file path and the target directory name. Comma (',') could be used as the separator to specify multiple archive files. This option can be used to upload the virtual environment, the data files used in Python UDF. The data files could be accessed in Python UDF, e.g.: f = open('data/data.txt', 'r'). The option is equivalent to the command line option \"-pyarch\".</td>\n-        </tr>\n-        <tr>\n-            <td><h5>python.client.executable</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"python\"</td>\n-            <td>String</td>\n-            <td>The path of the Python interpreter used to launch the Python process when submitting the Python jobs via \"flink run\" or compiling the Java/Scala jobs containing Python UDFs. Equivalent to the environment variable PYFLINK_CLIENT_EXECUTABLE. The priority is as following: <br />1. the configuration 'python.client.executable' defined in the source code;<br />2. the environment variable PYFLINK_CLIENT_EXECUTABLE;<br />3. the configuration 'python.client.executable' defined in flink-conf.yaml</td>\n-        </tr>\n-        <tr>\n-            <td><h5>python.executable</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"python\"</td>\n-            <td>String</td>\n-            <td>Specify the path of the python interpreter used to execute the python UDF worker. The python UDF worker depends on Python 3.5+, Apache Beam (version == 2.23.0), Pip (version &gt;= 7.1.0) and SetupTools (version &gt;= 37.0.0). Please ensure that the specified environment meets the above requirements. The option is equivalent to the command line option \"-pyexec\".</td>\n-        </tr>\n-        <tr>\n-            <td><h5>python.files</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Attach custom python files for job. These files will be added to the PYTHONPATH of both the local client and the remote python UDF worker. The standard python resource file suffixes such as .py/.egg/.zip or directory are all supported. Comma (',') could be used as the separator to specify multiple files. The option is equivalent to the command line option \"-pyfs\". </td>\n-        </tr>\n-        <tr>\n-            <td><h5>python.fn-execution.arrow.batch.size</h5></td>\n-            <td style=\"word-wrap: break-word;\">10000</td>\n-            <td>Integer</td>\n-            <td>The maximum number of elements to include in an arrow batch for Python user-defined function execution. The arrow batch size should not exceed the bundle size. Otherwise, the bundle size will be used as the arrow batch size.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>python.fn-execution.bundle.size</h5></td>\n-            <td style=\"word-wrap: break-word;\">100000</td>\n-            <td>Integer</td>\n-            <td>The maximum number of elements to include in a bundle for Python user-defined function execution. The elements are processed asynchronously. One bundle of elements are processed before processing the next bundle of elements. A larger value can improve the throughput, but at the cost of more memory usage and higher latency.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>python.fn-execution.bundle.time</h5></td>\n-            <td style=\"word-wrap: break-word;\">1000</td>\n-            <td>Long</td>\n-            <td>Sets the waiting timeout(in milliseconds) before processing a bundle for Python user-defined function execution. The timeout defines how long the elements of a bundle will be buffered before being processed. Lower timeouts lead to lower tail latencies, but may affect throughput.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>python.fn-execution.memory.managed</h5></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>If set, the Python worker will configure itself to use the managed memory budget of the task slot. Otherwise, it will use the Off-Heap Memory of the task slot. In this case, users should set the Task Off-Heap Memory using the configuration key taskmanager.memory.task.off-heap.size.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>python.map-state.iterate-response-batch-size</h5></td>\n-            <td style=\"word-wrap: break-word;\">1000</td>\n-            <td>Integer</td>\n-            <td>The maximum number of the MapState keys/entries sent to Python UDF worker in each batch when iterating a Python MapState. Note that this is an experimental flag and might not be available in future releases.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>python.map-state.read-cache-size</h5></td>\n-            <td style=\"word-wrap: break-word;\">1000</td>\n-            <td>Integer</td>\n-            <td>The maximum number of cached entries for a single Python MapState. Note that this is an experimental flag and might not be available in future releases.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>python.map-state.write-cache-size</h5></td>\n-            <td style=\"word-wrap: break-word;\">1000</td>\n-            <td>Integer</td>\n-            <td>The maximum number of cached write requests for a single Python MapState. The write requests will be flushed to the state backend (managed in the Java operator) when the number of cached write requests exceed this limit. Note that this is an experimental flag and might not be available in future releases.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>python.metric.enabled</h5></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>When it is false, metric for Python will be disabled. You can disable the metric to achieve better performance at some circumstance.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>python.requirements</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Specify a requirements.txt file which defines the third-party dependencies. These dependencies will be installed and added to the PYTHONPATH of the python UDF worker. A directory which contains the installation packages of these dependencies could be specified optionally. Use '#' as the separator if the optional parameter exists. The option is equivalent to the command line option \"-pyreq\".</td>\n-        </tr>\n-        <tr>\n-            <td><h5>python.state.cache-size</h5></td>\n-            <td style=\"word-wrap: break-word;\">1000</td>\n-            <td>Integer</td>\n-            <td>The maximum number of states cached in a Python UDF worker. Note that this is an experimental flag and might not be available in future releases.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "b0e7dc53155510c8a8d39467455670c6abc73c92",
            "filename": "docs/_includes/generated/queryable_state_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 60,
            "changes": 60,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/queryable_state_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/queryable_state_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/queryable_state_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,60 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>queryable-state.client.network-threads</h5></td>\n-            <td style=\"word-wrap: break-word;\">0</td>\n-            <td>Integer</td>\n-            <td>Number of network (Netty's event loop) Threads for queryable state client.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>queryable-state.enable</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Option whether the queryable state proxy and server should be enabled where possible and configurable.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>queryable-state.proxy.network-threads</h5></td>\n-            <td style=\"word-wrap: break-word;\">0</td>\n-            <td>Integer</td>\n-            <td>Number of network (Netty's event loop) Threads for queryable state proxy.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>queryable-state.proxy.ports</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"9069\"</td>\n-            <td>String</td>\n-            <td>The port range of the queryable state proxy. The specified range can be a single port: \"9123\", a range of ports: \"50100-50200\", or a list of ranges and ports: \"50100-50200,50300-50400,51234\".</td>\n-        </tr>\n-        <tr>\n-            <td><h5>queryable-state.proxy.query-threads</h5></td>\n-            <td style=\"word-wrap: break-word;\">0</td>\n-            <td>Integer</td>\n-            <td>Number of query Threads for queryable state proxy. Uses the number of slots if set to 0.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>queryable-state.server.network-threads</h5></td>\n-            <td style=\"word-wrap: break-word;\">0</td>\n-            <td>Integer</td>\n-            <td>Number of network (Netty's event loop) Threads for queryable state server.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>queryable-state.server.ports</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"9067\"</td>\n-            <td>String</td>\n-            <td>The port range of the queryable state server. The specified range can be a single port: \"9123\", a range of ports: \"50100-50200\", or a list of ranges and ports: \"50100-50200,50300-50400,51234\".</td>\n-        </tr>\n-        <tr>\n-            <td><h5>queryable-state.server.query-threads</h5></td>\n-            <td style=\"word-wrap: break-word;\">0</td>\n-            <td>Integer</td>\n-            <td>Number of query Threads for queryable state server. Uses the number of slots if set to 0.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "7cfcec69e1b1365c2f6c9c6b68baa09845b18fc0",
            "filename": "docs/_includes/generated/resource_manager_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 48,
            "changes": 48,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/resource_manager_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/resource_manager_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/resource_manager_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,48 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>resourcemanager.job.timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"5 minutes\"</td>\n-            <td>String</td>\n-            <td>Timeout for jobs which don't have a job manager as leader assigned.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>resourcemanager.rpc.port</h5></td>\n-            <td style=\"word-wrap: break-word;\">0</td>\n-            <td>Integer</td>\n-            <td>Defines the network port to connect to for communication with the resource manager. By default, the port of the JobManager, because the same ActorSystem is used. Its not possible to use this configuration key to define port ranges.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>resourcemanager.standalone.start-up-time</h5></td>\n-            <td style=\"word-wrap: break-word;\">-1</td>\n-            <td>Long</td>\n-            <td>Time in milliseconds of the start-up period of a standalone cluster. During this time, resource manager of the standalone cluster expects new task executors to be registered, and will not fail slot requests that can not be satisfied by any current registered slots. After this time, it will fail pending and new coming requests immediately that can not be satisfied by registered slots. If not set, 'slotmanager.request-timeout' will be used by default.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>resourcemanager.taskmanager-timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">30000</td>\n-            <td>Long</td>\n-            <td>The timeout for an idle task manager to be released.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>slotmanager.number-of-slots.max</h5></td>\n-            <td style=\"word-wrap: break-word;\">2147483647</td>\n-            <td>Integer</td>\n-            <td>Defines the maximum number of slots that the Flink cluster allocates. This configuration option is meant for limiting the resource consumption for batch workloads. It is not recommended to configure this option for streaming workloads, which may fail if there are not enough slots. Note that this configuration option does not take effect for standalone clusters, where how many slots are allocated is not controlled by Flink.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>slotmanager.redundant-taskmanager-num</h5></td>\n-            <td style=\"word-wrap: break-word;\">0</td>\n-            <td>Integer</td>\n-            <td>The number of redundant task managers. Redundant task managers are extra task managers started by Flink, in order to speed up job recovery in case of failures due to task manager lost. Note that this feature is available only to the active deployments (native K8s, Yarn and Mesos).</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "bcef4f6a8ae022ce589ba73dfe1d309383974a0d",
            "filename": "docs/_includes/generated/rest_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 90,
            "changes": 90,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/rest_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/rest_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/rest_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,90 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>rest.address</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The address that should be used by clients to connect to the server. Attention: This option is respected only if the high-availability configuration is NONE.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>rest.await-leader-timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">30000</td>\n-            <td>Long</td>\n-            <td>The time in ms that the client waits for the leader address, e.g., Dispatcher or WebMonitorEndpoint</td>\n-        </tr>\n-        <tr>\n-            <td><h5>rest.bind-address</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The address that the server binds itself.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>rest.bind-port</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"8081\"</td>\n-            <td>String</td>\n-            <td>The port that the server binds itself. Accepts a list of ports (“50100,50101”), ranges (“50100-50200”) or a combination of both. It is recommended to set a range of ports to avoid collisions when multiple Rest servers are running on the same machine.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>rest.client.max-content-length</h5></td>\n-            <td style=\"word-wrap: break-word;\">104857600</td>\n-            <td>Integer</td>\n-            <td>The maximum content length in bytes that the client will handle.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>rest.connection-timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">15000</td>\n-            <td>Long</td>\n-            <td>The maximum time in ms for the client to establish a TCP connection.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>rest.idleness-timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">300000</td>\n-            <td>Long</td>\n-            <td>The maximum time in ms for a connection to stay idle before failing.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>rest.port</h5></td>\n-            <td style=\"word-wrap: break-word;\">8081</td>\n-            <td>Integer</td>\n-            <td>The port that the client connects to. If rest.bind-port has not been specified, then the REST server will bind to this port. Attention: This option is respected only if the high-availability configuration is NONE.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>rest.retry.delay</h5></td>\n-            <td style=\"word-wrap: break-word;\">3000</td>\n-            <td>Long</td>\n-            <td>The time in ms that the client waits between retries (See also `rest.retry.max-attempts`).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>rest.retry.max-attempts</h5></td>\n-            <td style=\"word-wrap: break-word;\">20</td>\n-            <td>Integer</td>\n-            <td>The number of retries the client will attempt if a retryable operations fails.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>rest.server.max-content-length</h5></td>\n-            <td style=\"word-wrap: break-word;\">104857600</td>\n-            <td>Integer</td>\n-            <td>The maximum content length in bytes that the server will handle.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>rest.server.numThreads</h5></td>\n-            <td style=\"word-wrap: break-word;\">4</td>\n-            <td>Integer</td>\n-            <td>The number of threads for the asynchronous processing of requests.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>rest.server.thread-priority</h5></td>\n-            <td style=\"word-wrap: break-word;\">5</td>\n-            <td>Integer</td>\n-            <td>Thread priority of the REST server's executor for processing asynchronous requests. Lowering the thread priority will give Flink's main components more CPU time whereas increasing will allocate more time for the REST server's processing.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "a494e9bef25c70c87f9d45217f77cc5c2bc52976",
            "filename": "docs/_includes/generated/rest_v1_dispatcher.html",
            "status": "removed",
            "additions": 0,
            "deletions": 4755,
            "changes": 4755,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/rest_v1_dispatcher.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/rest_v1_dispatcher.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/rest_v1_dispatcher.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141"
        },
        {
            "sha": "f8a0748003358c8624cf72b359d2a45adafe77a7",
            "filename": "docs/_includes/generated/restart_strategy_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 18,
            "changes": 18,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/restart_strategy_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/restart_strategy_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/restart_strategy_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,18 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>restart-strategy</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Defines the restart strategy to use in case of job failures.<br />Accepted values are:<ul><li><span markdown=\"span\">`none`</span>, <span markdown=\"span\">`off`</span>, <span markdown=\"span\">`disable`</span>: No restart strategy.</li><li><span markdown=\"span\">`fixeddelay`</span>, <span markdown=\"span\">`fixed-delay`</span>: Fixed delay restart strategy. More details can be found <a href=\"../dev/task_failure_recovery.html#fixed-delay-restart-strategy\">here</a>.</li><li><span markdown=\"span\">`failurerate`</span>, <span markdown=\"span\">`failure-rate`</span>: Failure rate restart strategy. More details can be found <a href=\"../dev/task_failure_recovery.html#failure-rate-restart-strategy\">here</a>.</li></ul>If checkpointing is disabled, the default value is <span markdown=\"span\">`none`</span>. If checkpointing is enabled, the default value is <span markdown=\"span\">`fixed-delay`</span> with <span markdown=\"span\">`Integer.MAX_VALUE`</span> restart attempts and '<span markdown=\"span\">`1 s`</span>' delay.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "a22f5d26595db84113244e1e82e6d6e0c1def040",
            "filename": "docs/_includes/generated/rocksdb_configurable_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 84,
            "changes": 84,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/rocksdb_configurable_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/rocksdb_configurable_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/rocksdb_configurable_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,84 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.block.blocksize</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>MemorySize</td>\n-            <td>The approximate size (in bytes) of user data packed per block. RocksDB has default blocksize as '4KB'.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.block.cache-size</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>MemorySize</td>\n-            <td>The amount of the cache for data blocks in RocksDB. RocksDB has default block-cache size as '8MB'.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.compaction.level.max-size-level-base</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>MemorySize</td>\n-            <td>The upper-bound of the total size of level base files in bytes. RocksDB has default configuration as '256MB'.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.compaction.level.target-file-size-base</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>MemorySize</td>\n-            <td>The target file size for compaction, which determines a level-1 file size. RocksDB has default configuration as '64MB'.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.compaction.level.use-dynamic-size</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>Boolean</td>\n-            <td>If true, RocksDB will pick target size of each level dynamically. From an empty DB, RocksDB would make last level the base level, which means merging L0 data into the last level, until it exceeds max_bytes_for_level_base. And then repeat this process for second last level and so on. RocksDB has default configuration as 'false'. For more information, please refer to <a href=\"https://github.com/facebook/rocksdb/wiki/Leveled-Compaction#level_compaction_dynamic_level_bytes-is-true\">RocksDB's doc.</a></td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.compaction.style</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td><p>Enum</p>Possible values: [LEVEL, UNIVERSAL, FIFO]</td>\n-            <td>The specified compaction style for DB. Candidate compaction style is LEVEL, FIFO or UNIVERSAL, and RocksDB choose 'LEVEL' as default style.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.files.open</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>Integer</td>\n-            <td>The maximum number of open files (per TaskManager) that can be used by the DB, '-1' means no limit. RocksDB has default configuration as '-1'.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.thread.num</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>Integer</td>\n-            <td>The maximum number of concurrent background flush and compaction jobs (per TaskManager). RocksDB has default configuration as '1'.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.write-batch-size</h5></td>\n-            <td style=\"word-wrap: break-word;\">2 mb</td>\n-            <td>MemorySize</td>\n-            <td>The max size of the consumed memory for RocksDB batch write, will flush just based on item count if this config set to 0.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.writebuffer.count</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>Integer</td>\n-            <td>The maximum number of write buffers that are built up in memory. RocksDB has default configuration as '2'.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.writebuffer.number-to-merge</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>Integer</td>\n-            <td>The minimum number of write buffers that will be merged together before writing to storage. RocksDB has default configuration as '1'.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.writebuffer.size</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>MemorySize</td>\n-            <td>The amount of data built up in memory (backed by an unsorted log on disk) before converting to a sorted on-disk files. RocksDB has default writebuffer size as '64MB'.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "44ccc96ac3d642e386007a3ca8dfdf6c4ef8eadf",
            "filename": "docs/_includes/generated/rocksdb_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 66,
            "changes": 66,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/rocksdb_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/rocksdb_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/rocksdb_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,66 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.checkpoint.transfer.thread.num</h5></td>\n-            <td style=\"word-wrap: break-word;\">1</td>\n-            <td>Integer</td>\n-            <td>The number of threads (per stateful operator) used to transfer (download and upload) files in RocksDBStateBackend.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.localdir</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The local directory (on the TaskManager) where RocksDB puts its files.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.memory.fixed-per-slot</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>MemorySize</td>\n-            <td>The fixed total amount of memory, shared among all RocksDB instances per slot. This option overrides the 'state.backend.rocksdb.memory.managed' option when configured. If neither this option, nor the 'state.backend.rocksdb.memory.managed' optionare set, then each RocksDB column family state has its own memory caches (as controlled by the column family options).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.memory.high-prio-pool-ratio</h5></td>\n-            <td style=\"word-wrap: break-word;\">0.1</td>\n-            <td>Double</td>\n-            <td>The fraction of cache memory that is reserved for high-priority data like index, filter, and compression dictionary blocks. This option only has an effect when 'state.backend.rocksdb.memory.managed' or 'state.backend.rocksdb.memory.fixed-per-slot' are configured.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.memory.managed</h5></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>If set, the RocksDB state backend will automatically configure itself to use the managed memory budget of the task slot, and divide the memory over write buffers, indexes, block caches, etc. That way, the three major uses of memory of RocksDB will be capped.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.memory.write-buffer-ratio</h5></td>\n-            <td style=\"word-wrap: break-word;\">0.5</td>\n-            <td>Double</td>\n-            <td>The maximum amount of memory that write buffers may take, as a fraction of the total shared memory. This option only has an effect when 'state.backend.rocksdb.memory.managed' or 'state.backend.rocksdb.memory.fixed-per-slot' are configured.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.options-factory</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"org.apache.flink.contrib.streaming.state.DefaultConfigurableOptionsFactory\"</td>\n-            <td>String</td>\n-            <td>The options factory class for RocksDB to create DBOptions and ColumnFamilyOptions. The default options factory is org.apache.flink.contrib.streaming.state.DefaultConfigurableOptionsFactory, and it would read the configured options which provided in 'RocksDBConfigurableOptions'.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.predefined-options</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"DEFAULT\"</td>\n-            <td>String</td>\n-            <td>The predefined settings for RocksDB DBOptions and ColumnFamilyOptions by Flink community. Current supported candidate predefined-options are DEFAULT, SPINNING_DISK_OPTIMIZED, SPINNING_DISK_OPTIMIZED_HIGH_MEM or FLASH_SSD_OPTIMIZED. Note that user customized options and options from the RocksDBOptionsFactory are applied on top of these predefined ones.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.timer-service.factory</h5></td>\n-            <td style=\"word-wrap: break-word;\">ROCKSDB</td>\n-            <td><p>Enum</p>Possible values: [HEAP, ROCKSDB]</td>\n-            <td>This determines the factory for timer service state implementation. Options are either HEAP (heap-based) or ROCKSDB for an implementation based on RocksDB.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "82c573811a71dfafd23a32c746ab567212e528df",
            "filename": "docs/_includes/generated/rocksdb_native_metric_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 168,
            "changes": 168,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/rocksdb_native_metric_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/rocksdb_native_metric_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/rocksdb_native_metric_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,168 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.metrics.actual-delayed-write-rate</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Monitor the current actual delayed write rate. 0 means no delay.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.metrics.background-errors</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Monitor the number of background errors in RocksDB.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.metrics.block-cache-capacity</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Monitor block cache capacity.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.metrics.block-cache-pinned-usage</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Monitor the memory size for the entries being pinned in block cache.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.metrics.block-cache-usage</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Monitor the memory size for the entries residing in block cache.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.metrics.column-family-as-variable</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Whether to expose the column family as a variable.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.metrics.compaction-pending</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Track pending compactions in RocksDB. Returns 1 if a compaction is pending, 0 otherwise.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.metrics.cur-size-active-mem-table</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Monitor the approximate size of the active memtable in bytes.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.metrics.cur-size-all-mem-tables</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Monitor the approximate size of the active and unflushed immutable memtables in bytes.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.metrics.estimate-live-data-size</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Estimate of the amount of live data in bytes.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.metrics.estimate-num-keys</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Estimate the number of keys in RocksDB.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.metrics.estimate-pending-compaction-bytes</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Estimated total number of bytes compaction needs to rewrite to get all levels down to under target size. Not valid for other compactions than level-based.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.metrics.estimate-table-readers-mem</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Estimate the memory used for reading SST tables, excluding memory used in block cache (e.g.,filter and index blocks) in bytes.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.metrics.is-write-stopped</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Track whether write has been stopped in RocksDB. Returns 1 if write has been stopped, 0 otherwise.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.metrics.mem-table-flush-pending</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Monitor the number of pending memtable flushes in RocksDB.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.metrics.num-deletes-active-mem-table</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Monitor the total number of delete entries in the active memtable.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.metrics.num-deletes-imm-mem-tables</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Monitor the total number of delete entries in the unflushed immutable memtables.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.metrics.num-entries-active-mem-table</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Monitor the total number of entries in the active memtable.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.metrics.num-entries-imm-mem-tables</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Monitor the total number of entries in the unflushed immutable memtables.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.metrics.num-immutable-mem-table</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Monitor the number of immutable memtables in RocksDB.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.metrics.num-live-versions</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Monitor number of live versions. Version is an internal data structure. See RocksDB file version_set.h for details. More live versions often mean more SST files are held from being deleted, by iterators or unfinished compactions.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.metrics.num-running-compactions</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Monitor the number of currently running compactions.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.metrics.num-running-flushes</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Monitor the number of currently running flushes.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.metrics.num-snapshots</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Monitor the number of unreleased snapshots of the database.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.metrics.size-all-mem-tables</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Monitor the approximate size of the active, unflushed immutable, and pinned immutable memtables in bytes.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.metrics.total-sst-files-size</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Monitor the total size (bytes) of all SST files.WARNING: may slow down online queries if there are too many files.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "2f9b464e593cb315baa3ca689b3de3854df60098",
            "filename": "docs/_includes/generated/savepoint_config_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 24,
            "changes": 24,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/savepoint_config_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/savepoint_config_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/savepoint_config_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,24 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>execution.savepoint.ignore-unclaimed-state</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Allow to skip savepoint state that cannot be restored. Allow this if you removed an operator from your pipeline after the savepoint was triggered.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>execution.savepoint.path</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Path to a savepoint to restore the job from (for example hdfs:///flink/savepoint-1537).</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "cf279171a54c9317a7cf86c064d7010062c54b49",
            "filename": "docs/_includes/generated/security_auth_kerberos_section.html",
            "status": "removed",
            "additions": 0,
            "deletions": 36,
            "changes": 36,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/security_auth_kerberos_section.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/security_auth_kerberos_section.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/security_auth_kerberos_section.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,36 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>security.kerberos.login.contexts</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>A comma-separated list of login contexts to provide the Kerberos credentials to (for example, `Client,KafkaClient` to use the credentials for ZooKeeper authentication and for Kafka authentication)</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.kerberos.login.keytab</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Absolute path to a Kerberos keytab file that contains the user credentials.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.kerberos.login.principal</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Kerberos principal name associated with the keytab.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.kerberos.login.use-ticket-cache</h5></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>Indicates whether to read from your Kerberos ticket cache.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "7aaaaff20d78b8bbe3bcacf9cc01c3f0fa2997f1",
            "filename": "docs/_includes/generated/security_auth_zk_section.html",
            "status": "removed",
            "additions": 0,
            "deletions": 30,
            "changes": 30,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/security_auth_zk_section.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/security_auth_zk_section.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/security_auth_zk_section.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,30 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>zookeeper.sasl.disable</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td></td>\n-        </tr>\n-        <tr>\n-            <td><h5>zookeeper.sasl.login-context-name</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"Client\"</td>\n-            <td>String</td>\n-            <td></td>\n-        </tr>\n-        <tr>\n-            <td><h5>zookeeper.sasl.service-name</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"zookeeper\"</td>\n-            <td>String</td>\n-            <td></td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "e286b362cd71b17fa72c7b38af28e865a88bd18b",
            "filename": "docs/_includes/generated/security_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 210,
            "changes": 210,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/security_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/security_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/security_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,210 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>security.context.factory.classes</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"org.apache.flink.runtime.security.contexts.HadoopSecurityContextFactory\";<wbr>\"org.apache.flink.runtime.security.contexts.NoOpSecurityContextFactory\"</td>\n-            <td>List&lt;String&gt;</td>\n-            <td>List of factories that should be used to instantiate a security context. If multiple are configured, Flink will use the first compatible factory. You should have a NoOpSecurityContextFactory in this list as a fallback.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.kerberos.krb5-conf.path</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Specify the local location of the krb5.conf file. If defined, this conf would be mounted on the JobManager and TaskManager pods for Kubernetes. Note: The KDC defined needs to be visible from inside the containers.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.kerberos.login.contexts</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>A comma-separated list of login contexts to provide the Kerberos credentials to (for example, `Client,KafkaClient` to use the credentials for ZooKeeper authentication and for Kafka authentication)</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.kerberos.login.keytab</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Absolute path to a Kerberos keytab file that contains the user credentials.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.kerberos.login.principal</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Kerberos principal name associated with the keytab.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.kerberos.login.use-ticket-cache</h5></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>Indicates whether to read from your Kerberos ticket cache.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.module.factory.classes</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"org.apache.flink.runtime.security.modules.HadoopModuleFactory\";<wbr>\"org.apache.flink.runtime.security.modules.JaasModuleFactory\";<wbr>\"org.apache.flink.runtime.security.modules.ZookeeperModuleFactory\"</td>\n-            <td>List&lt;String&gt;</td>\n-            <td>List of factories that should be used to instantiate security modules. All listed modules will be installed. Keep in mind that the configured security context might rely on some modules being present.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.algorithms</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"TLS_RSA_WITH_AES_128_CBC_SHA\"</td>\n-            <td>String</td>\n-            <td>The comma separated list of standard SSL algorithms to be supported. Read more <a href=\"http://docs.oracle.com/javase/8/docs/technotes/guides/security/StandardNames.html#ciphersuites\">here</a></td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.internal.cert.fingerprint</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The sha1 fingerprint of the internal certificate. This further protects the internal communication to present the exact certificate used by Flink.This is necessary where one cannot use private CA(self signed) or there is internal firm wide CA is required</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.internal.close-notify-flush-timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">-1</td>\n-            <td>Integer</td>\n-            <td>The timeout (in ms) for flushing the `close_notify` that was triggered by closing a channel. If the `close_notify` was not flushed in the given timeout the channel will be closed forcibly. (-1 = use system default)</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.internal.enabled</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Turns on SSL for internal network communication. Optionally, specific components may override this through their own settings (rpc, data transport, REST, etc).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.internal.handshake-timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">-1</td>\n-            <td>Integer</td>\n-            <td>The timeout (in ms) during SSL handshake. (-1 = use system default)</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.internal.key-password</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The secret to decrypt the key in the keystore for Flink's internal endpoints (rpc, data transport, blob server).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.internal.keystore</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The Java keystore file with SSL Key and Certificate, to be used Flink's internal endpoints (rpc, data transport, blob server).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.internal.keystore-password</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The secret to decrypt the keystore file for Flink's for Flink's internal endpoints (rpc, data transport, blob server).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.internal.session-cache-size</h5></td>\n-            <td style=\"word-wrap: break-word;\">-1</td>\n-            <td>Integer</td>\n-            <td>The size of the cache used for storing SSL session objects. According to https://github.com/netty/netty/issues/832, you should always set this to an appropriate number to not run into a bug with stalling IO threads during garbage collection. (-1 = use system default).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.internal.session-timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">-1</td>\n-            <td>Integer</td>\n-            <td>The timeout (in ms) for the cached SSL session objects. (-1 = use system default)</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.internal.truststore</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The truststore file containing the public CA certificates to verify the peer for Flink's internal endpoints (rpc, data transport, blob server).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.internal.truststore-password</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The password to decrypt the truststore for Flink's internal endpoints (rpc, data transport, blob server).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.protocol</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"TLSv1.2\"</td>\n-            <td>String</td>\n-            <td>The SSL protocol version to be supported for the ssl transport. Note that it doesn’t support comma separated list.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.provider</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"JDK\"</td>\n-            <td>String</td>\n-            <td>The SSL engine provider to use for the ssl transport:<ul><li><span markdown=\"span\">`JDK`</span>: default Java-based SSL engine</li><li><span markdown=\"span\">`OPENSSL`</span>: openSSL-based SSL engine using system libraries</li></ul><span markdown=\"span\">`OPENSSL`</span> is based on <a href=\"http://netty.io/wiki/forked-tomcat-native.html#wiki-h2-4\">netty-tcnative</a> and comes in two flavours:<ul><li>dynamically linked: This will use your system's openSSL libraries (if compatible) and requires <span markdown=\"span\">`opt/flink-shaded-netty-tcnative-dynamic-*.jar`</span> to be copied to <span markdown=\"span\">`lib/`</span></li><li>statically linked: Due to potential licensing issues with openSSL (see <a href=\"https://issues.apache.org/jira/browse/LEGAL-393\">LEGAL-393</a>), we cannot ship pre-built libraries. However, you can build the required library yourself and put it into <span markdown=\"span\">`lib/`</span>:<br /><span markdown=\"span\">`git clone https://github.com/apache/flink-shaded.git &amp;&amp; cd flink-shaded &amp;&amp; mvn clean package -Pinclude-netty-tcnative-static -pl flink-shaded-netty-tcnative-static`</span></li></ul></td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.rest.authentication-enabled</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Turns on mutual SSL authentication for external communication via the REST endpoints.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.rest.cert.fingerprint</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The sha1 fingerprint of the rest certificate. This further protects the rest REST endpoints to present certificate which is only used by proxy serverThis is necessary where once uses public CA or internal firm wide CA</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.rest.enabled</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Turns on SSL for external communication via the REST endpoints.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.rest.key-password</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The secret to decrypt the key in the keystore for Flink's external REST endpoints.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.rest.keystore</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The Java keystore file with SSL Key and Certificate, to be used Flink's external REST endpoints.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.rest.keystore-password</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The secret to decrypt the keystore file for Flink's for Flink's external REST endpoints.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.rest.truststore</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The truststore file containing the public CA certificates to verify the peer for Flink's external REST endpoints.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.rest.truststore-password</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The password to decrypt the truststore for Flink's external REST endpoints.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.verify-hostname</h5></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>Flag to enable peer’s hostname verification during ssl handshake.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>zookeeper.sasl.disable</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td></td>\n-        </tr>\n-        <tr>\n-            <td><h5>zookeeper.sasl.login-context-name</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"Client\"</td>\n-            <td>String</td>\n-            <td></td>\n-        </tr>\n-        <tr>\n-            <td><h5>zookeeper.sasl.service-name</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"zookeeper\"</td>\n-            <td>String</td>\n-            <td></td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "ae345d8e4c320bcf592d4a66895b90d35cf51e94",
            "filename": "docs/_includes/generated/security_ssl_section.html",
            "status": "removed",
            "additions": 0,
            "deletions": 120,
            "changes": 120,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/security_ssl_section.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/security_ssl_section.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/security_ssl_section.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,120 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>security.ssl.algorithms</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"TLS_RSA_WITH_AES_128_CBC_SHA\"</td>\n-            <td>String</td>\n-            <td>The comma separated list of standard SSL algorithms to be supported. Read more <a href=\"http://docs.oracle.com/javase/8/docs/technotes/guides/security/StandardNames.html#ciphersuites\">here</a></td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.internal.cert.fingerprint</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The sha1 fingerprint of the internal certificate. This further protects the internal communication to present the exact certificate used by Flink.This is necessary where one cannot use private CA(self signed) or there is internal firm wide CA is required</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.internal.enabled</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Turns on SSL for internal network communication. Optionally, specific components may override this through their own settings (rpc, data transport, REST, etc).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.internal.key-password</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The secret to decrypt the key in the keystore for Flink's internal endpoints (rpc, data transport, blob server).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.internal.keystore</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The Java keystore file with SSL Key and Certificate, to be used Flink's internal endpoints (rpc, data transport, blob server).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.internal.keystore-password</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The secret to decrypt the keystore file for Flink's for Flink's internal endpoints (rpc, data transport, blob server).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.internal.truststore</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The truststore file containing the public CA certificates to verify the peer for Flink's internal endpoints (rpc, data transport, blob server).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.internal.truststore-password</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The password to decrypt the truststore for Flink's internal endpoints (rpc, data transport, blob server).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.protocol</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"TLSv1.2\"</td>\n-            <td>String</td>\n-            <td>The SSL protocol version to be supported for the ssl transport. Note that it doesn’t support comma separated list.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.rest.authentication-enabled</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Turns on mutual SSL authentication for external communication via the REST endpoints.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.rest.cert.fingerprint</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The sha1 fingerprint of the rest certificate. This further protects the rest REST endpoints to present certificate which is only used by proxy serverThis is necessary where once uses public CA or internal firm wide CA</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.rest.enabled</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Turns on SSL for external communication via the REST endpoints.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.rest.key-password</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The secret to decrypt the key in the keystore for Flink's external REST endpoints.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.rest.keystore</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The Java keystore file with SSL Key and Certificate, to be used Flink's external REST endpoints.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.rest.keystore-password</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The secret to decrypt the keystore file for Flink's for Flink's external REST endpoints.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.rest.truststore</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The truststore file containing the public CA certificates to verify the peer for Flink's external REST endpoints.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.rest.truststore-password</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The password to decrypt the truststore for Flink's external REST endpoints.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>security.ssl.verify-hostname</h5></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>Flag to enable peer’s hostname verification during ssl handshake.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "bf7d0bb328169fb4256f78dcda06585136d821fb",
            "filename": "docs/_includes/generated/shuffle_service_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 18,
            "changes": 18,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/shuffle_service_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/shuffle_service_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/shuffle_service_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,18 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>shuffle-service-factory.class</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"org.apache.flink.runtime.io.network.NettyShuffleServiceFactory\"</td>\n-            <td>String</td>\n-            <td>The full class name of the shuffle service factory implementation to be used by the cluster. The default implementation uses Netty for network communication and local memory as well disk space to store results on a TaskExecutor.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "03c10b61084e06473ac44a71e73d43ffb7e55319",
            "filename": "docs/_includes/generated/state_backend_rocksdb_section.html",
            "status": "removed",
            "additions": 0,
            "deletions": 42,
            "changes": 42,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/state_backend_rocksdb_section.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/state_backend_rocksdb_section.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/state_backend_rocksdb_section.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,42 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.memory.fixed-per-slot</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>MemorySize</td>\n-            <td>The fixed total amount of memory, shared among all RocksDB instances per slot. This option overrides the 'state.backend.rocksdb.memory.managed' option when configured. If neither this option, nor the 'state.backend.rocksdb.memory.managed' optionare set, then each RocksDB column family state has its own memory caches (as controlled by the column family options).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.memory.high-prio-pool-ratio</h5></td>\n-            <td style=\"word-wrap: break-word;\">0.1</td>\n-            <td>Double</td>\n-            <td>The fraction of cache memory that is reserved for high-priority data like index, filter, and compression dictionary blocks. This option only has an effect when 'state.backend.rocksdb.memory.managed' or 'state.backend.rocksdb.memory.fixed-per-slot' are configured.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.memory.managed</h5></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>If set, the RocksDB state backend will automatically configure itself to use the managed memory budget of the task slot, and divide the memory over write buffers, indexes, block caches, etc. That way, the three major uses of memory of RocksDB will be capped.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.memory.write-buffer-ratio</h5></td>\n-            <td style=\"word-wrap: break-word;\">0.5</td>\n-            <td>Double</td>\n-            <td>The maximum amount of memory that write buffers may take, as a fraction of the total shared memory. This option only has an effect when 'state.backend.rocksdb.memory.managed' or 'state.backend.rocksdb.memory.fixed-per-slot' are configured.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>state.backend.rocksdb.timer-service.factory</h5></td>\n-            <td style=\"word-wrap: break-word;\">ROCKSDB</td>\n-            <td><p>Enum</p>Possible values: [HEAP, ROCKSDB]</td>\n-            <td>This determines the factory for timer service state implementation. Options are either HEAP (heap-based) or ROCKSDB for an implementation based on RocksDB.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "0fdefe9c4f17a06129e936232d909e3ee1ca5fe0",
            "filename": "docs/_includes/generated/stream_pipeline_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 18,
            "changes": 18,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/stream_pipeline_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/stream_pipeline_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/stream_pipeline_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,18 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>pipeline.time-characteristic</h5></td>\n-            <td style=\"word-wrap: break-word;\">ProcessingTime</td>\n-            <td><p>Enum</p>Possible values: [ProcessingTime, IngestionTime, EventTime]</td>\n-            <td>The time characteristic for all created streams, e.g., processingtime, event time, or ingestion time.<br /><br />If you set the characteristic to IngestionTime or EventTime this will set a default watermark update interval of 200 ms. If this is not applicable for your application you should change it using <span markdown=\"span\">`pipeline.auto-watermark-interval`</span>.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "d530df816f0c37242f15c708b0701c993f8a03ff",
            "filename": "docs/_includes/generated/table_config_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 36,
            "changes": 36,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/table_config_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/table_config_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/table_config_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,36 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>table.dynamic-table-options.enabled</h5><br> <span class=\"label label-primary\">Batch</span> <span class=\"label label-primary\">Streaming</span></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Enable or disable the OPTIONS hint used to specify table options dynamically, if disabled, an exception would be thrown if any OPTIONS hint is specified</td>\n-        </tr>\n-        <tr>\n-            <td><h5>table.generated-code.max-length</h5><br> <span class=\"label label-primary\">Batch</span> <span class=\"label label-primary\">Streaming</span></td>\n-            <td style=\"word-wrap: break-word;\">64000</td>\n-            <td>Integer</td>\n-            <td>Specifies a threshold where generated code will be split into sub-function calls. Java has a maximum method length of 64 KB. This setting allows for finer granularity if necessary.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>table.local-time-zone</h5><br> <span class=\"label label-primary\">Batch</span> <span class=\"label label-primary\">Streaming</span></td>\n-            <td style=\"word-wrap: break-word;\">\"default\"</td>\n-            <td>String</td>\n-            <td>The local time zone defines current session time zone id. It is used when converting to/from &lt;code&gt;TIMESTAMP WITH LOCAL TIME ZONE&lt;/code&gt;. Internally, timestamps with local time zone are always represented in the UTC time zone. However, when converting to data types that don't include a time zone (e.g. TIMESTAMP, TIME, or simply STRING), the session time zone is used during conversion. The input of option is either an abbreviation such as \"PST\", a full name such as \"America/Los_Angeles\", or a custom timezone id such as \"GMT-8:00\".</td>\n-        </tr>\n-        <tr>\n-            <td><h5>table.sql-dialect</h5><br> <span class=\"label label-primary\">Batch</span> <span class=\"label label-primary\">Streaming</span></td>\n-            <td style=\"word-wrap: break-word;\">\"default\"</td>\n-            <td>String</td>\n-            <td>The SQL dialect defines how to parse a SQL query. A different SQL dialect may support different SQL grammar. Currently supported dialects are: default and hive</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "84f11732652c5bbc3a3efc3cb18a81487b686dfe",
            "filename": "docs/_includes/generated/task_manager_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 97,
            "changes": 97,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/task_manager_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/task_manager_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/task_manager_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,97 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>task.cancellation.interval</h5></td>\n-            <td style=\"word-wrap: break-word;\">30000</td>\n-            <td>Long</td>\n-            <td>Time interval between two successive task cancellation attempts in milliseconds.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>task.cancellation.timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">180000</td>\n-            <td>Long</td>\n-            <td>Timeout in milliseconds after which a task cancellation times out and leads to a fatal TaskManager error. A value of 0 deactivates the watch dog.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>task.cancellation.timers.timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">7500</td>\n-            <td>Long</td>\n-            <td>Time we wait for the timers in milliseconds to finish all pending timer threads when the stream task is cancelled.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.bind-host</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The local address of the network interface that the task manager binds to. If not configured, '0.0.0.0' will be used.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.debug.memory.log</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Flag indicating whether to start a thread, which repeatedly logs the memory usage of the JVM.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.debug.memory.log-interval</h5></td>\n-            <td style=\"word-wrap: break-word;\">5000</td>\n-            <td>Long</td>\n-            <td>The interval (in ms) for the log thread to log the current memory usage.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.host</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The external address of the network interface where the TaskManager is exposed. Because different TaskManagers need different values for this option, usually it is specified in an additional non-shared TaskManager-specific config file.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.jvm-exit-on-oom</h5></td>\n-            <td style=\"word-wrap: break-word;\">false</td>\n-            <td>Boolean</td>\n-            <td>Whether to kill the TaskManager when the task thread throws an OutOfMemoryError.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.network.bind-policy</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"ip\"</td>\n-            <td>String</td>\n-            <td>The automatic address binding policy used by the TaskManager if \"taskmanager.host\" is not set. The value should be one of the following:\n-<ul><li>\"name\" - uses hostname as binding address</li><li>\"ip\" - uses host's ip address as binding address</li></ul></td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.numberOfTaskSlots</h5></td>\n-            <td style=\"word-wrap: break-word;\">1</td>\n-            <td>Integer</td>\n-            <td>The number of parallel operator or user function instances that a single TaskManager can run. If this value is larger than 1, a single TaskManager takes multiple instances of a function or operator. That way, the TaskManager can utilize multiple CPU cores, but at the same time, the available memory is divided between the different operator or function instances. This value is typically proportional to the number of physical CPU cores that the TaskManager's machine has (e.g., equal to the number of cores, or half the number of cores).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.registration.timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">5 min</td>\n-            <td>Duration</td>\n-            <td>Defines the timeout for the TaskManager registration. If the duration is exceeded without a successful registration, then the TaskManager terminates.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.resource-id</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The TaskManager's ResourceID. If not configured, the ResourceID will be generated with the \"RpcAddress:RpcPort\" and a 6-character random string. Notice that this option is not valid in Yarn / Mesos and Native Kubernetes mode.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.rpc.bind-port</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>Integer</td>\n-            <td>The local RPC port that the TaskManager binds to. If not configured, the external port (configured by 'taskmanager.rpc.port') will be used.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.rpc.port</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"0\"</td>\n-            <td>String</td>\n-            <td>The external RPC port where the TaskManager is exposed. Accepts a list of ports (“50100,50101”), ranges (“50100-50200”) or a combination of both. It is recommended to set a range of ports to avoid collisions when multiple TaskManagers are running on the same machine.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "d23b267bc1f45abc468cda3ed2f7cf7ee8dc5f4d",
            "filename": "docs/_includes/generated/task_manager_memory_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 114,
            "changes": 114,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/task_manager_memory_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/task_manager_memory_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/task_manager_memory_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,114 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>taskmanager.memory.flink.size</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>MemorySize</td>\n-            <td>Total Flink Memory size for the TaskExecutors. This includes all the memory that a TaskExecutor consumes, except for JVM Metaspace and JVM Overhead. It consists of Framework Heap Memory, Task Heap Memory, Task Off-Heap Memory, Managed Memory, and Network Memory. See also 'taskmanager.memory.process.size' for total process memory size configuration.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.memory.framework.heap.size</h5></td>\n-            <td style=\"word-wrap: break-word;\">128 mb</td>\n-            <td>MemorySize</td>\n-            <td>Framework Heap Memory size for TaskExecutors. This is the size of JVM heap memory reserved for TaskExecutor framework, which will not be allocated to task slots.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.memory.framework.off-heap.size</h5></td>\n-            <td style=\"word-wrap: break-word;\">128 mb</td>\n-            <td>MemorySize</td>\n-            <td>Framework Off-Heap Memory size for TaskExecutors. This is the size of off-heap memory (JVM direct memory and native memory) reserved for TaskExecutor framework, which will not be allocated to task slots. The configured value will be fully counted when Flink calculates the JVM max direct memory size parameter.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.memory.jvm-metaspace.size</h5></td>\n-            <td style=\"word-wrap: break-word;\">256 mb</td>\n-            <td>MemorySize</td>\n-            <td>JVM Metaspace Size for the TaskExecutors.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.memory.jvm-overhead.fraction</h5></td>\n-            <td style=\"word-wrap: break-word;\">0.1</td>\n-            <td>Float</td>\n-            <td>Fraction of Total Process Memory to be reserved for JVM Overhead. This is off-heap memory reserved for JVM overhead, such as thread stack space, compile cache, etc. This includes native memory but not direct memory, and will not be counted when Flink calculates JVM max direct memory size parameter. The size of JVM Overhead is derived to make up the configured fraction of the Total Process Memory. If the derived size is less/greater than the configured min/max size, the min/max size will be used. The exact size of JVM Overhead can be explicitly specified by setting the min/max size to the same value.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.memory.jvm-overhead.max</h5></td>\n-            <td style=\"word-wrap: break-word;\">1 gb</td>\n-            <td>MemorySize</td>\n-            <td>Max JVM Overhead size for the TaskExecutors. This is off-heap memory reserved for JVM overhead, such as thread stack space, compile cache, etc. This includes native memory but not direct memory, and will not be counted when Flink calculates JVM max direct memory size parameter. The size of JVM Overhead is derived to make up the configured fraction of the Total Process Memory. If the derived size is less/greater than the configured min/max size, the min/max size will be used. The exact size of JVM Overhead can be explicitly specified by setting the min/max size to the same value.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.memory.jvm-overhead.min</h5></td>\n-            <td style=\"word-wrap: break-word;\">192 mb</td>\n-            <td>MemorySize</td>\n-            <td>Min JVM Overhead size for the TaskExecutors. This is off-heap memory reserved for JVM overhead, such as thread stack space, compile cache, etc. This includes native memory but not direct memory, and will not be counted when Flink calculates JVM max direct memory size parameter. The size of JVM Overhead is derived to make up the configured fraction of the Total Process Memory. If the derived size is less/greater than the configured min/max size, the min/max size will be used. The exact size of JVM Overhead can be explicitly specified by setting the min/max size to the same value.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.memory.managed.consumer-weights</h5></td>\n-            <td style=\"word-wrap: break-word;\">DATAPROC:70,PYTHON:30</td>\n-            <td>Map</td>\n-            <td>Managed memory weights for different kinds of consumers. A slot’s managed memory is shared by all kinds of consumers it contains, proportionally to the kinds’ weights and regardless of the number of consumers from each kind. Currently supported kinds of consumers are DATAPROC (for RocksDB state backend in streaming and built-in algorithms in batch) and PYTHON (for Python processes).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.memory.managed.fraction</h5></td>\n-            <td style=\"word-wrap: break-word;\">0.4</td>\n-            <td>Float</td>\n-            <td>Fraction of Total Flink Memory to be used as Managed Memory, if Managed Memory size is not explicitly specified.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.memory.managed.size</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>MemorySize</td>\n-            <td>Managed Memory size for TaskExecutors. This is the size of off-heap memory managed by the memory manager, reserved for sorting, hash tables, caching of intermediate results and RocksDB state backend. Memory consumers can either allocate memory from the memory manager in the form of MemorySegments, or reserve bytes from the memory manager and keep their memory usage within that boundary. If unspecified, it will be derived to make up the configured fraction of the Total Flink Memory.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.memory.network.fraction</h5></td>\n-            <td style=\"word-wrap: break-word;\">0.1</td>\n-            <td>Float</td>\n-            <td>Fraction of Total Flink Memory to be used as Network Memory. Network Memory is off-heap memory reserved for ShuffleEnvironment (e.g., network buffers). Network Memory size is derived to make up the configured fraction of the Total Flink Memory. If the derived size is less/greater than the configured min/max size, the min/max size will be used. The exact size of Network Memory can be explicitly specified by setting the min/max size to the same value.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.memory.network.max</h5></td>\n-            <td style=\"word-wrap: break-word;\">1 gb</td>\n-            <td>MemorySize</td>\n-            <td>Max Network Memory size for TaskExecutors. Network Memory is off-heap memory reserved for ShuffleEnvironment (e.g., network buffers). Network Memory size is derived to make up the configured fraction of the Total Flink Memory. If the derived size is less/greater than the configured min/max size, the min/max size will be used. The exact size of Network Memory can be explicitly specified by setting the min/max to the same value.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.memory.network.min</h5></td>\n-            <td style=\"word-wrap: break-word;\">64 mb</td>\n-            <td>MemorySize</td>\n-            <td>Min Network Memory size for TaskExecutors. Network Memory is off-heap memory reserved for ShuffleEnvironment (e.g., network buffers). Network Memory size is derived to make up the configured fraction of the Total Flink Memory. If the derived size is less/greater than the configured min/max size, the min/max size will be used. The exact size of Network Memory can be explicitly specified by setting the min/max to the same value.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.memory.process.size</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>MemorySize</td>\n-            <td>Total Process Memory size for the TaskExecutors. This includes all the memory that a TaskExecutor consumes, consisting of Total Flink Memory, JVM Metaspace, and JVM Overhead. On containerized setups, this should be set to the container memory. See also 'taskmanager.memory.flink.size' for total Flink memory size configuration.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.memory.segment-size</h5></td>\n-            <td style=\"word-wrap: break-word;\">32 kb</td>\n-            <td>MemorySize</td>\n-            <td>Size of memory buffers used by the network stack and the memory manager.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.memory.task.heap.size</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>MemorySize</td>\n-            <td>Task Heap Memory size for TaskExecutors. This is the size of JVM heap memory reserved for tasks. If not specified, it will be derived as Total Flink Memory minus Framework Heap Memory, Task Off-Heap Memory, Managed Memory and Network Memory.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>taskmanager.memory.task.off-heap.size</h5></td>\n-            <td style=\"word-wrap: break-word;\">0 bytes</td>\n-            <td>MemorySize</td>\n-            <td>Task Off-Heap Memory size for TaskExecutors. This is the size of off heap memory (JVM direct memory and native memory) reserved for tasks. The configured value will be fully counted when Flink calculates the JVM max direct memory size parameter.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "4b5a98d45af0572ee51cd07a3351cebd21e0d8f3",
            "filename": "docs/_includes/generated/web_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 90,
            "changes": 90,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/web_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/web_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/web_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,90 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>web.access-control-allow-origin</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"*\"</td>\n-            <td>String</td>\n-            <td>Access-Control-Allow-Origin header for all responses from the web-frontend.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>web.backpressure.cleanup-interval</h5></td>\n-            <td style=\"word-wrap: break-word;\">600000</td>\n-            <td>Integer</td>\n-            <td>Time, in milliseconds, after which cached stats are cleaned up if not accessed.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>web.backpressure.delay-between-samples</h5></td>\n-            <td style=\"word-wrap: break-word;\">50</td>\n-            <td>Integer</td>\n-            <td>Delay between samples to determine back pressure in milliseconds.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>web.backpressure.num-samples</h5></td>\n-            <td style=\"word-wrap: break-word;\">100</td>\n-            <td>Integer</td>\n-            <td>Number of samples to take to determine back pressure.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>web.backpressure.refresh-interval</h5></td>\n-            <td style=\"word-wrap: break-word;\">60000</td>\n-            <td>Integer</td>\n-            <td>Time, in milliseconds, after which available stats are deprecated and need to be refreshed (by resampling).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>web.checkpoints.history</h5></td>\n-            <td style=\"word-wrap: break-word;\">10</td>\n-            <td>Integer</td>\n-            <td>Number of checkpoints to remember for recent history.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>web.history</h5></td>\n-            <td style=\"word-wrap: break-word;\">5</td>\n-            <td>Integer</td>\n-            <td>Number of archived jobs for the JobManager.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>web.log.path</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Path to the log file (may be in /log for standalone but under log directory when using YARN).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>web.refresh-interval</h5></td>\n-            <td style=\"word-wrap: break-word;\">3000</td>\n-            <td>Long</td>\n-            <td>Refresh interval for the web-frontend in milliseconds.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>web.submit.enable</h5></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>Flag indicating whether jobs can be uploaded and run from the web-frontend.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>web.timeout</h5></td>\n-            <td style=\"word-wrap: break-word;\">600000</td>\n-            <td>Long</td>\n-            <td>Timeout for asynchronous operations by the web monitor in milliseconds.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>web.tmpdir</h5></td>\n-            <td style=\"word-wrap: break-word;\">System.getProperty(\"java.io.tmpdir\")</td>\n-            <td>String</td>\n-            <td>Flink web directory which is used by the webmonitor.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>web.upload.dir</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Directory for uploading the job jars. If not specified a dynamic directory will be used under the directory specified by JOB_MANAGER_WEB_TMPDIR_KEY.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "74b5457a19d59997f76c38130f170f34230a7705",
            "filename": "docs/_includes/generated/yarn_config_configuration.html",
            "status": "removed",
            "additions": 0,
            "deletions": 168,
            "changes": 168,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/yarn_config_configuration.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/generated/yarn_config_configuration.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/yarn_config_configuration.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,168 +0,0 @@\n-<table class=\"table table-bordered\">\n-    <thead>\n-        <tr>\n-            <th class=\"text-left\" style=\"width: 20%\">Key</th>\n-            <th class=\"text-left\" style=\"width: 15%\">Default</th>\n-            <th class=\"text-left\" style=\"width: 10%\">Type</th>\n-            <th class=\"text-left\" style=\"width: 55%\">Description</th>\n-        </tr>\n-    </thead>\n-    <tbody>\n-        <tr>\n-            <td><h5>external-resource.&lt;resource_name&gt;.yarn.config-key</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>If configured, Flink will add this key to the resource profile of container request to Yarn. The value will be set to the value of external-resource.&lt;resource_name&gt;.amount.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>yarn.application-attempt-failures-validity-interval</h5></td>\n-            <td style=\"word-wrap: break-word;\">10000</td>\n-            <td>Long</td>\n-            <td>Time window in milliseconds which defines the number of application attempt failures when restarting the AM. Failures which fall outside of this window are not being considered. Set this value to -1 in order to count globally. See <a href=\"https://hortonworks.com/blog/apache-hadoop-yarn-hdp-2-2-fault-tolerance-features-long-running-services/\">here</a> for more information.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>yarn.application-attempts</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Number of ApplicationMaster restarts. By default, the value will be set to 1. If high availability is enabled, then the default value will be 2. The restart number is also limited by YARN (configured via <a href=\"https://hadoop.apache.org/docs/r2.4.1/hadoop-yarn/hadoop-yarn-common/yarn-default.xml\">yarn.resourcemanager.am.max-attempts</a>). Note that that the entire Flink cluster will restart and the YARN Client will lose the connection.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>yarn.application-master.port</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"0\"</td>\n-            <td>String</td>\n-            <td>With this configuration option, users can specify a port, a range of ports or a list of ports for the Application Master (and JobManager) RPC port. By default we recommend using the default value (0) to let the operating system choose an appropriate port. In particular when multiple AMs are running on the same physical host, fixed port assignments prevent the AM from starting. For example when running Flink on YARN on an environment with a restrictive firewall, this option allows specifying a range of allowed ports.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>yarn.application.id</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The YARN application id of the running yarn cluster. This is the YARN cluster where the pipeline is going to be executed.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>yarn.application.name</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>A custom name for your YARN application.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>yarn.application.node-label</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Specify YARN node label for the YARN application.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>yarn.application.priority</h5></td>\n-            <td style=\"word-wrap: break-word;\">-1</td>\n-            <td>Integer</td>\n-            <td>A non-negative integer indicating the priority for submitting a Flink YARN application. It will only take effect if YARN priority scheduling setting is enabled. Larger integer corresponds with higher priority. If priority is negative or set to '-1'(default), Flink will unset yarn priority setting and use cluster default priority. Please refer to YARN's official documentation for specific settings required to enable priority scheduling for the targeted YARN version.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>yarn.application.queue</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The YARN queue on which to put the current pipeline.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>yarn.application.type</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>A custom type for your YARN application..</td>\n-        </tr>\n-        <tr>\n-            <td><h5>yarn.appmaster.vcores</h5></td>\n-            <td style=\"word-wrap: break-word;\">1</td>\n-            <td>Integer</td>\n-            <td>The number of virtual cores (vcores) used by YARN application master.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>yarn.containers.vcores</h5></td>\n-            <td style=\"word-wrap: break-word;\">-1</td>\n-            <td>Integer</td>\n-            <td>The number of virtual cores (vcores) per YARN container. By default, the number of vcores is set to the number of slots per TaskManager, if set, or to 1, otherwise. In order for this parameter to be used your cluster must have CPU scheduling enabled. You can do this by setting the <span markdown=\"span\">`org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler`</span>.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>yarn.file-replication</h5></td>\n-            <td style=\"word-wrap: break-word;\">-1</td>\n-            <td>Integer</td>\n-            <td>Number of file replication of each local resource file. If it is not configured, Flink will use the default replication value in hadoop configuration.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>yarn.flink-dist-jar</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>The location of the Flink dist jar.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>yarn.heartbeat.container-request-interval</h5></td>\n-            <td style=\"word-wrap: break-word;\">500</td>\n-            <td>Integer</td>\n-            <td>Time between heartbeats with the ResourceManager in milliseconds if Flink requests containers:<ul><li>The lower this value is, the faster Flink will get notified about container allocations since requests and allocations are transmitted via heartbeats.</li><li>The lower this value is, the more excessive containers might get allocated which will eventually be released but put pressure on Yarn.</li></ul>If you observe too many container allocations on the ResourceManager, then it is recommended to increase this value. See <a href=\"https://issues.apache.org/jira/browse/YARN-1902\">this link</a> for more information.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>yarn.heartbeat.interval</h5></td>\n-            <td style=\"word-wrap: break-word;\">5</td>\n-            <td>Integer</td>\n-            <td>Time between heartbeats with the ResourceManager in seconds.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>yarn.per-job-cluster.include-user-jar</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"ORDER\"</td>\n-            <td>String</td>\n-            <td>Defines whether user-jars are included in the system class path for per-job-clusters as well as their positioning in the path. They can be positioned at the beginning (\"FIRST\"), at the end (\"LAST\"), or be positioned based on their name (\"ORDER\"). \"DISABLED\" means the user-jars are excluded from the system class path.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>yarn.properties-file.location</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>When a Flink job is submitted to YARN, the JobManager’s host and the number of available processing slots is written into a properties file, so that the Flink client is able to pick those details up. This configuration parameter allows changing the default location of that file (for example for environments sharing a Flink installation between users).</td>\n-        </tr>\n-        <tr>\n-            <td><h5>yarn.provided.lib.dirs</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>List&lt;String&gt;</td>\n-            <td>A semicolon-separated list of provided lib directories. They should be pre-uploaded and world-readable. Flink will use them to exclude the local Flink jars(e.g. flink-dist, lib/, plugins/)uploading to accelerate the job submission process. Also YARN will cache them on the nodes so that they doesn't need to be downloaded every time for each application. An example could be hdfs://$namenode_address/path/of/flink/lib</td>\n-        </tr>\n-        <tr>\n-            <td><h5>yarn.security.kerberos.additionalFileSystems</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>List&lt;String&gt;</td>\n-            <td>A comma-separated list of additional Kerberos-secured Hadoop filesystems Flink is going to access. For example, yarn.security.kerberos.additionalFileSystems=hdfs://namenode2:9002,hdfs://namenode3:9003. The client submitting to YARN needs to have access to these file systems to retrieve the security tokens.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>yarn.security.kerberos.localized-keytab-path</h5></td>\n-            <td style=\"word-wrap: break-word;\">\"krb5.keytab\"</td>\n-            <td>String</td>\n-            <td>Local (on NodeManager) path where kerberos keytab file will be localized to. If yarn.security.kerberos.ship-local-keytab set to true, Flink willl ship the keytab file as a YARN local resource. In this case, the path is relative to the local resource directory. If set to false, Flink will try to directly locate the keytab from the path itself.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>yarn.security.kerberos.ship-local-keytab</h5></td>\n-            <td style=\"word-wrap: break-word;\">true</td>\n-            <td>Boolean</td>\n-            <td>When this is true Flink will ship the keytab file configured via security.kerberos.login.keytab as a localized YARN resource.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>yarn.ship-archives</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>List&lt;String&gt;</td>\n-            <td>A semicolon-separated list of archives to be shipped to the YARN cluster. These archives will be un-packed when localizing and they can be any of the following types: \".tar.gz\", \".tar\", \".tgz\", \".dst\", \".jar\", \".zip\".</td>\n-        </tr>\n-        <tr>\n-            <td><h5>yarn.ship-files</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>List&lt;String&gt;</td>\n-            <td>A semicolon-separated list of files and/or directories to be shipped to the YARN cluster.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>yarn.staging-directory</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>Staging directory used to store YARN files while submitting applications. Per default, it uses the home directory of the configured file system.</td>\n-        </tr>\n-        <tr>\n-            <td><h5>yarn.tags</h5></td>\n-            <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>String</td>\n-            <td>A comma-separated list of tags to apply to the Flink YARN application.</td>\n-        </tr>\n-    </tbody>\n-</table>"
        },
        {
            "sha": "b2f8f08f2b5a4a7960e09b5811894a92983b0f9a",
            "filename": "docs/_includes/latex_commands.html",
            "status": "removed",
            "additions": 0,
            "deletions": 38,
            "changes": 38,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/latex_commands.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/latex_commands.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/latex_commands.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,38 +0,0 @@\n-<!--\n-Licensed to the Apache Software Foundation (ASF) under one\n-or more contributor license agreements.  See the NOTICE file\n-distributed with this work for additional information\n-regarding copyright ownership.  The ASF licenses this file\n-to you under the Apache License, Version 2.0 (the\n-\"License\"); you may not use this file except in compliance\n-with the License.  You may obtain a copy of the License at\n-\n-  http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing,\n-software distributed under the License is distributed on an\n-\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-KIND, either express or implied.  See the License for the\n-specific language governing permissions and limitations\n-under the License.\n--->\n-\n-<!--Some of the Latex math notation has been adapted from Apache Spark MLlib's documentation-->\n-$$\n-\\newcommand{\\R}{\\mathbb{R}}\n-\\newcommand{\\E}{\\mathbb{E}}\n-\\newcommand{\\x}{\\mathbf{x}}\n-\\newcommand{\\y}{\\mathbf{y}}\n-\\newcommand{\\wv}{\\mathbf{w}}\n-\\newcommand{\\av}{\\mathbf{\\alpha}}\n-\\newcommand{\\bv}{\\mathbf{b}}\n-\\newcommand{\\N}{\\mathbb{N}}\n-\\newcommand{\\id}{\\mathbf{I}}\n-\\newcommand{\\ind}{\\mathbf{1}}\n-\\newcommand{\\0}{\\mathbf{0}}\n-\\newcommand{\\unit}{\\mathbf{e}}\n-\\newcommand{\\one}{\\mathbf{1}}\n-\\newcommand{\\zero}{\\mathbf{0}}\n-\\newcommand\\rfrac[2]{^{#1}\\!/_{#2}}\n-\\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert}\n-$$\n\\ No newline at end of file"
        },
        {
            "sha": "a0ac41357bcbbc729d7554a83ebaa3229de42af8",
            "filename": "docs/_includes/note.html",
            "status": "removed",
            "additions": 0,
            "deletions": 23,
            "changes": 23,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/note.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/note.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/note.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,23 +0,0 @@\n-<!--\n-Licensed to the Apache Software Foundation (ASF) under one\n-or more contributor license agreements.  See the NOTICE file\n-distributed with this work for additional information\n-regarding copyright ownership.  The ASF licenses this file\n-to you under the Apache License, Version 2.0 (the\n-\"License\"); you may not use this file except in compliance\n-with the License.  You may obtain a copy of the License at\n-\n-  http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing,\n-software distributed under the License is distributed on an\n-\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-KIND, either express or implied.  See the License for the\n-specific language governing permissions and limitations\n-under the License.\n--->\n-\n-<div markdown=\"span\" class=\"alert alert-info\" role=\"alert\">\n-\t<i class=\"fa fa-info-circle\"></i> <b>Note:</b>\n-\t{{ include.content }}\n-</div>"
        },
        {
            "sha": "ed767f23a0f8cb82912bea4c35b701fbc01db1c2",
            "filename": "docs/_includes/sidenav.html",
            "status": "removed",
            "additions": 0,
            "deletions": 184,
            "changes": 184,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/sidenav.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/sidenav.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/sidenav.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,184 +0,0 @@\n-<!--\n-Licensed to the Apache Software Foundation (ASF) under one\n-or more contributor license agreements.  See the NOTICE file\n-distributed with this work for additional information\n-regarding copyright ownership.  The ASF licenses this file\n-to you under the Apache License, Version 2.0 (the\n-\"License\"); you may not use this file except in compliance\n-with the License.  You may obtain a copy of the License at\n-\n-  http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing,\n-software distributed under the License is distributed on an\n-\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-KIND, either express or implied.  See the License for the\n-specific language governing permissions and limitations\n-under the License.\n--->\n-\n-{%- comment -%}\n-==============================================================================\n-Extract the active nav IDs.\n-==============================================================================\n-{%- endcomment -%}\n-\n-{%- assign active_nav_ids = site.array -%}\n-{%- assign parent_id = page.nav-parent_id -%}\n-\n-{%- for i in (1..10) -%}\n-  {%- if parent_id -%}\n-    {%- assign active_nav_ids = active_nav_ids | push: parent_id -%}\n-    {%- assign current = (site.pages_by_language[page.language] | where: \"nav-id\" , parent_id | sort: \"nav-pos\") -%}\n-    {%- if current.size > 0 -%}\n-      {%- assign parent_id = current[0].nav-parent_id -%}\n-    {%- else -%}\n-      {%- break -%}\n-    {%- endif -%}\n-  {%- else -%}\n-    {%- break -%}\n-  {%- endif -%}\n-{%- endfor -%}\n-\n-{%- if page.language == \"en\" -%}\n-  {%- capture baseurl_i18n -%}{{ site.baseurl }}{%- endcapture -%}\n-{%- else if page.language == \"zh\" -%}\n-  {%- capture baseurl_i18n -%}{{ site.baseurl }}/{{ page.language }}{%- endcapture -%}\n-{%- endif -%}\n-\n-{%- comment -%}\n-==============================================================================\n-Build the nested list from nav-id and nav-parent_id relations.\n-==============================================================================\n-This builds a nested list from all pages. The fields used to determine the\n-structure are:\n-\n-- 'nav-id' => ID of this page. Other pages can use this ID as their\n-  parent ID.\n-- 'nav-parent_id' => ID of the parent. This page will be listed under\n-  the page with id 'nav-parent_id'.\n-\n-Level 0 is made up of all pages, which have nav-parent_id set to 'root'.\n-\n-The 'title' of the page is used as the default link text. You can\n-override this via 'nav-title'. The relative position per navigational\n-level is determined by 'nav-pos'.\n-{%- endcomment -%}\n-\n-{%- assign elementsPosStack = site.array -%}\n-{%- assign posStack = site.array -%}\n-\n-{%- assign elements = site.array -%}\n-{%- assign all_pages_by_nav_parent = (site.pages_by_language[page.language] | where_exp: \"item\", \"item.nav-parent_id != nil\" | group_by: \"nav-parent_id\") -%}\n-{%- assign children = (all_pages_by_nav_parent | where: \"name\" , \"root\") -%}\n-{%- assign children = (children[0].items | sort: \"nav-pos\") -%}\n-{%- if children.size > 0 -%}\n-  {%- assign elements = elements | push: children -%}\n-{%- endif -%}\n-\n-{%- assign elementsPos = 0 -%}\n-{%- assign pos = 0 -%}\n-\n-<div class=\"sidenav-logo\">\n-  <p><a href=\"{{ baseurl_i18n }}/\"><img class=\"bottom\" alt=\"Apache Flink\" src=\"{{ site.baseurl }}/page/img/navbar-brand-logo.jpg\"></a> v{{ site.version_title }}</p>\n-</div>\n-<ul id=\"sidenav\">\n-{%- for i in (1..10000) -%}\n-  {%- if pos >= elements[elementsPos].size -%}\n-    {%- if elementsPos == 0 -%}\n-      {%- break -%}\n-    {%- else -%}\n-      {%- assign elementsPos = elementsPosStack | last -%}\n-      {%- assign pos = posStack | last %}\n-</ul></div></li>\n-      {%- assign elementsPosStack = elementsPosStack | pop -%}\n-      {%- assign posStack = posStack | pop -%}\n-    {%- endif -%}\n-  {%- else -%}\n-    {%- assign this = elements[elementsPos][pos] -%}\n-\n-    {%- if this.url == page.url -%}\n-      {%- assign active = true -%}\n-    {%- elsif this.nav-id and active_nav_ids contains this.nav-id -%}\n-      {%- assign active = true -%}\n-    {%- else -%}\n-      {%- assign active = false -%}\n-    {%- endif -%}\n-\n-    {%- capture title -%}{%- if this.nav-title -%}{{ this.nav-title }}{%- else -%}{{ this.title }}{%- endif -%}{%- endcapture -%}\n-    {%- capture target -%}\"{{ site.baseurl }}{{ this.url }}\"{%- if active %} class=\"active\"{%- endif -%}{%- endcapture -%}\n-    {%- capture overview_target -%}\"{{ site.baseurl }}{{ this.url }}\"{%- if this.url == page.url -%} class=\"active\"{%- endif -%}{%- endcapture -%}\n-\n-    {% if this.section-break %}<hr class=\"section-break\"></hr>{% endif -%}\n-\n-    {%- assign pos = pos | plus: 1 -%}\n-    {%- if this.nav-id -%}\n-      {%- assign children = (all_pages_by_nav_parent | where: \"name\" , this.nav-id) -%}\n-      {%- if children.size > 0 -%}\n-        {%- assign children = (children[0].items | sort: \"nav-pos\") -%}\n-        {%- capture collapse_target -%}\"#collapse-{{ i }}\" data-toggle=\"collapse\"{%- if active -%} class=\"active\"{%- endif -%}{%- endcapture -%}\n-        {%- capture expand -%}{%- unless active -%} <i class=\"fa fa-caret-down pull-right\" aria-hidden=\"true\" style=\"padding-top: 4px\"></i>{%- endunless -%}{%- endcapture %}\n-<li><a href={{ collapse_target }}>{{ title }}{{ expand }}</a><div class=\"collapse{% if active %} in{% endif %}\" id=\"collapse-{{ i }}\"><ul>\n-        {%- if this.nav-show_overview %}\n-<li><a href={{ overview_target }}>\n-            {%- if page.is_default_language %}Overview{% else %}概览{% endif %}</a></li>\n-        {%- endif -%}\n-        {%- assign elements = elements | push: children -%}\n-        {%- assign elementsPosStack = elementsPosStack | push: elementsPos -%}\n-        {%- assign posStack = posStack | push: pos -%}\n-\n-        {%- assign elementsPos = elements.size | minus: 1 -%}\n-        {%- assign pos = 0 -%}\n-      {%- else %}\n-<li><a href={{ target }}>{{ title }}</a></li>\n-      {%- endif -%}\n-    {%- else %}\n-<li><a href={{ target }}>{{ title }}</a></li>\n-    {%- endif -%}\n-  {%- endif -%}\n-{%- endfor %}\n-  <li class=\"divider\"></li>\n-  <li><a href=\"{{ site.javadocs_baseurl }}/api/java\"><i class=\"fa fa-external-link title\" aria-hidden=\"true\"></i> Javadocs</a></li>\n-  <li><a href=\"{{ site.javadocs_baseurl }}/api/scala/index.html#org.apache.flink.api.scala.package\"><i class=\"fa fa-external-link title\" aria-hidden=\"true\"></i> Scaladocs</a></li>\n-  <li><a href=\"{{ site.pythondocs_baseurl }}/api/python\"><i class=\"fa fa-external-link title\" aria-hidden=\"true\"></i> Pythondocs</a></li>\n-  <li><a href=\"http://flink.apache.org\"><i class=\"fa fa-external-link title\" aria-hidden=\"true\"></i> Project Page</a></li>\n-</ul>\n-\n-<div class=\"sidenav-search-box\">\n-  <form class=\"navbar-form\" role=\"search\" action=\"{{site.baseurl}}/search-results.html\">\n-    <div class=\"form-group\">\n-      <input type=\"text\" class=\"form-control\" size=\"16px\" name=\"q\" placeholder=\"Search\">\n-    </div>\n-    <button type=\"submit\" class=\"btn btn-default\">Go</button>\n-  </form>\n-</div>\n-\n-<div class=\"sidenav-versions\">\n-  <div class=\"dropdown\">\n-    <button class=\"btn btn-default dropdown-toggle\" type=\"button\" data-toggle=\"dropdown\">\n-      {%- if page.is_default_language -%}\n-        Pick Docs Version\n-      {%- else -%}\n-        选择文档版本\n-      {%- endif -%}\n-    <span class=\"caret\"></span></button>\n-    <ul class=\"dropdown-menu\">\n-      {%- for d in site.previous_docs %}\n-      <li><a href=\"{{ d[1] }}\">v{{ d[0] }}</a></li>\n-      {%- endfor %}\n-    </ul>\n-  </div>\n-</div>\n-\n-<div class=\"sidenav-languages\">\n-  {%- if page.is_default_language -%}\n-    <!-- link to the Chinese home page when current is blog page -->\n-    <a href=\"{{ site.baseurl }}/zh{{ page.url }}\">\n-      <button type=\"submit\" class=\"btn btn-default\">中文版</button>\n-    </a>\n-  {%- else -%}\n-    <a href=\"{{ site.baseurl }}{{ page.url | remove_first: 'zh/' }}\">\n-      <button type=\"submit\" class=\"btn btn-default\">English</button>\n-    </a>\n-  {%- endif %}\n-</div>"
        },
        {
            "sha": "56cc78e16e308ed49cf2cde7e3920f568571fdf3",
            "filename": "docs/_includes/sql-connector-download-table.html",
            "status": "removed",
            "additions": 0,
            "deletions": 84,
            "changes": 84,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/sql-connector-download-table.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_includes/sql-connector-download-table.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/sql-connector-download-table.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,84 +0,0 @@\n-<!--\n-Licensed to the Apache Software Foundation (ASF) under one\n-or more contributor license agreements.  See the NOTICE file\n-distributed with this work for additional information\n-regarding copyright ownership.  The ASF licenses this file\n-to you under the Apache License, Version 2.0 (the\n-\"License\"); you may not use this file except in compliance\n-with the License.  You may obtain a copy of the License at\n-\n-  http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing,\n-software distributed under the License is distributed on an\n-\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-KIND, either express or implied.  See the License for the\n-specific language governing permissions and limitations\n-under the License.\n--->\n-\n-<p>In order to use the {{ include.connector.name }} {{ include.connector.category }} the following\n-dependencies are required for both projects using a build automation tool (such as Maven or SBT)\n-and SQL Client with SQL JAR bundles.</p>\n-\n-\n-{% comment %}\n-\tThe 'liquify' filter makes it possible to include liquid variables such as e.g. site.version.\n-{% endcomment %}\n-\n-{% if include.connector.versions == nil %}\n-<table>\n-\t<thead>\n-\t<tr>\n-\t\t<th style=\"text-align: left\">Maven dependency</th>\n-\t\t<th style=\"text-align: left\">SQL Client JAR</th>\n-\t</tr>\n-\t</thead>\n-\t<tbody>\n-\t<tr>\n-\t\t<td style=\"text-align: left\"><code class=\"highlighter-rouge\">{{ include.connector.maven | liquify }}</code></td>\n-\t\t{% if include.connector.built-in %}\n-\t\t\t<td style=\"text-align: left\">Built-in</td>\n-\t\t{% elsif site.is_stable %}\n-\t\t\t{% if include.connector.sql-url != nil %}\n-\t\t\t\t<td style=\"text-align: left\"><a href=\"{{ include.connector.sql-url | liquify }}\">Download</a></td>\n-\t\t\t{% else %}\n-\t\t\t\t<td style=\"text-align: left\">There is no sql jar available yet.</td>\n-\t\t\t{% endif %}\n-\t\t{% else %}\n-\t\t\t<td style=\"text-align: left\">Only available for stable releases.</td>\n-\t\t{% endif %}\n-\t</tr>\n-\t</tbody>\n-</table>\n-{% else %}\n-<table>\n-\t<thead>\n-\t<tr>\n-\t\t<th style=\"text-align: left\">{{ include.connector.name }} version</th>\n-\t\t<th style=\"text-align: left\">Maven dependency</th>\n-\t\t<th style=\"text-align: left\">SQL Client JAR</th>\n-\t</tr>\n-\t</thead>\n-\t<tbody>\n-\t{% for version in include.connector.versions %}\n-\t<tr>\n-\t\t<td style=\"text-align: left\">{{ version.version | liquify }}</td>\n-\t\t<td style=\"text-align: left\"><code class=\"highlighter-rouge\">{{ version.maven | liquify }}</code></td>\n-\t\t{% if include.connector.built-in %}\n-\t\t<td style=\"text-align: left\">Built-in</td>\n-\t\t{% elsif include.connector.no-sql-jar %}\n-\t\t{% elsif site.is_stable %}\n-\t\t\t{% if version.sql-url != nil %}\n-\t\t\t\t<td style=\"text-align: left\"><a href=\"{{ version.sql-url | liquify }}\">Download</a></td>\n-\t\t\t{% else %}\n-\t\t\t\t<td style=\"text-align: left\">There is no sql jar available yet.</td>\n-\t\t\t{% endif %}\n-\t\t{% else %}\n-\t\t<td style=\"text-align: left\">Only available for stable releases.</td>\n-\t\t{% endif %}\n-\t</tr>\n-\t{% endfor %}\n-\t</tbody>\n-</table>\n-{% endif %}"
        },
        {
            "sha": "9ad29b38a221072d10841ed701750a8ddef38599",
            "filename": "docs/_layouts/404_base.html",
            "status": "removed",
            "additions": 0,
            "deletions": 39,
            "changes": 39,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_layouts/404_base.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_layouts/404_base.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_layouts/404_base.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,39 +0,0 @@\n----\n-layout: base\n----\n-<!--\n-Licensed to the Apache Software Foundation (ASF) under one\n-or more contributor license agreements.  See the NOTICE file\n-distributed with this work for additional information\n-regarding copyright ownership.  The ASF licenses this file\n-to you under the Apache License, Version 2.0 (the\n-\"License\"); you may not use this file except in compliance\n-with the License.  You may obtain a copy of the License at\n-\n-  http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing,\n-software distributed under the License is distributed on an\n-\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-KIND, either express or implied.  See the License for the\n-specific language governing permissions and limitations\n-under the License.\n--->\n-\n-<noscript>\n-  <meta http-equiv=\"refresh\" content=\"5; url=https:{{ site.baseurl }}\">\n-</noscript>\n-<script type=\"text/javascript\">\n-  var documentationRootUrl = \"https:{{ site.baseurl }}\";\n-  var timeout = \"5000\";\n-  window.onload = function() {\n-    setTimeout(doRedirect, timeout);\n-  }\n-  function doRedirect() {\n-    window.location.href = documentationRootUrl;\n-  }\n-</script>\n-\n-<h1>{{ page.title }}</h1>\n-\n-{{ content }}"
        },
        {
            "sha": "b0bf2f4f7ed12680785e9c48c5cb136feaeacacf",
            "filename": "docs/_layouts/base.html",
            "status": "removed",
            "additions": 0,
            "deletions": 121,
            "changes": 121,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_layouts/base.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_layouts/base.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_layouts/base.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,121 +0,0 @@\n-<!DOCTYPE html>\n-<!--\n-Licensed to the Apache Software Foundation (ASF) under one\n-or more contributor license agreements.  See the NOTICE file\n-distributed with this work for additional information\n-regarding copyright ownership.  The ASF licenses this file\n-to you under the Apache License, Version 2.0 (the\n-\"License\"); you may not use this file except in compliance\n-with the License.  You may obtain a copy of the License at\n-\n-  http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing,\n-software distributed under the License is distributed on an\n-\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-KIND, either express or implied.  See the License for the\n-specific language governing permissions and limitations\n-under the License.\n--->\n-<html lang=\"en\">\n-  <head>\n-    <meta charset=\"utf-8\">\n-    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n-    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n-    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->\n-    <title>Apache Flink {{ site.version_title }} Documentation: {{ page.title }}</title>\n-    <link rel=\"shortcut icon\" href=\"{{ site.baseurl }}/page/favicon.ico\" type=\"image/x-icon\">\n-    <link rel=\"icon\" href=\"{{ site.baseurl }}/page/favicon.ico\" type=\"image/x-icon\">\n-    <link rel=\"canonical\" href=\"{{ site.stable_baseurl }}{{ page.url | replace:'index.html',''}}\">\n-\n-    <!-- Bootstrap -->\n-    <link rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap.min.css\">\n-    <link rel=\"stylesheet\" href=\"{{ site.baseurl }}/page/css/flink.css\">\n-    <link rel=\"stylesheet\" href=\"{{ site.baseurl }}/page/css/syntax.css\">\n-    <link rel=\"stylesheet\" href=\"{{ site.baseurl }}/page/css/codetabs.css\">\n-    <link rel=\"stylesheet\" href=\"{{ site.baseurl }}/page/font-awesome/css/font-awesome.min.css\">\n-    {% if page.mathjax %}\n-    <script type=\"text/x-mathjax-config\">\n-        MathJax.Hub.Config({\n-        tex2jax: {\n-          inlineMath: [['$','$'], ['\\\\(','\\\\)']] },\n-        TeX: {\n-          equationNumbers: { autoNumber: \"AMS\" } }\n-        });\n-    </script>\n-    <script type=\"text/javascript\"\n-            src=\"https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\">\n-    </script>\n-    {% endif %}\n-    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->\n-    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->\n-    <!--[if lt IE 9]>\n-      <script src=\"https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js\"></script>\n-      <script src=\"https://oss.maxcdn.com/respond/1.4.2/respond.min.js\"></script>\n-    <![endif]-->\n-  </head>\n-  <body>\n-    {% if site.show_outdated_warning %}\n-    <div style=\"position:fixed; bottom:0; left:0; z-index:99999; width:100%; text-align:center; padding:15px; border-top:5px solid #ECCCD1; background:#F2DEDE; color:#AD433F; font-weight:bold\">\n-      {% if page.language == \"en\" %}\n-        This documentation is for an out-of-date version of Apache Flink. We recommend you use <a href=\"https://ci.apache.org/projects/flink/flink-docs-stable/\">the latest stable version</a>.\n-      {% else if page.language == \"zh\" %}\n-        本文档是 Apache Flink 的旧版本。建议访问 <a href=\"https://ci.apache.org/projects/flink/flink-docs-stable/zh\">最新的稳定版本</a>。\n-      {% endif %}\n-    </div>\n-    {% endif %}\n-\n-    <!-- Main content. -->\n-    <div class=\"container\">\n-      {% comment %}\n-      This is the base for all content. The content from the layouts found in\n-      the _layouts directory goes here.\n-      {% endcomment %}\n-      <div class=\"row\">\n-        <div class=\"col-lg-3\" id=\"sidenavcol\">\n-          {% include sidenav.html %}\n-        </div>\n-        <div class=\"col-lg-9 content\" id=\"contentcol\">\n-          {%- if page.mathjax -%}\n-          {%- include latex_commands.html -%}\n-          {%- endif %}\n-\n-          {{ content }}\n-        </div>\n-      </div>\n-    </div><!-- /.container -->\n-\n-    <!-- default code tab -->\n-    <script>var defaultCodeTab = \"{{ page.code_tab }}\";</script>\n-\n-    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->\n-    <script src=\"{{ site.baseurl }}/page/js/jquery.min.js\"></script>\n-    <!-- Include all compiled plugins (below), or include individual files as needed -->\n-    <script src=\"https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js\"></script>\n-    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/anchor-js/3.1.0/anchor.min.js\"></script>\n-    <script src=\"{{ site.baseurl }}/page/js/flink.js\"></script>\n-\n-    <!-- Google Analytics -->\n-    <script>\n-      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n-      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n-      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n-      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');\n-\n-      ga('create', 'UA-52545728-1', 'auto');\n-      ga('send', 'pageview');\n-    </script>\n-\n-    <!-- Disqus -->\n-    {% comment %}\n-    <script type=\"text/javascript\">\n-    var disqus_shortname = 'stratosphere-eu';\n-    (function() {\n-        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;\n-        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';\n-        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);\n-    })();\n-    </script>\n-    {% endcomment %}\n-  </body>\n-</html>"
        },
        {
            "sha": "e639e55a24b426afb5d7a65526e316806975d285",
            "filename": "docs/_layouts/plain.html",
            "status": "removed",
            "additions": 0,
            "deletions": 78,
            "changes": 78,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_layouts/plain.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_layouts/plain.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_layouts/plain.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,78 +0,0 @@\n----\n-layout: base\n----\n-<!--\n-Licensed to the Apache Software Foundation (ASF) under one\n-or more contributor license agreements.  See the NOTICE file\n-distributed with this work for additional information\n-regarding copyright ownership.  The ASF licenses this file\n-to you under the Apache License, Version 2.0 (the\n-\"License\"); you may not use this file except in compliance\n-with the License.  You may obtain a copy of the License at\n-\n-  http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing,\n-software distributed under the License is distributed on an\n-\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-KIND, either express or implied.  See the License for the\n-specific language governing permissions and limitations\n-under the License.\n--->\n-\n-{%- assign active_pages = site.array -%}\n-{%- assign active = page -%}\n-\n-{%- for i in (1..10) -%}\n-  {%- assign active_pages = active_pages | push: active -%}\n-  {%- if active.nav-parent_id -%}\n-    {%- assign next = site.pages_by_language[page.language] | where: \"nav-id\" , active.nav-parent_id -%}\n-    {%- if next.size > 0 -%}\n-      {%- assign active = next[0] -%}\n-    {%- else -%}\n-      {%- break -%}\n-    {%- endif -%}\n-  {%- else -%}\n-    {%- break -%}\n-  {%- endif -%}\n-{%- endfor -%}\n-\n-{% assign active_pages = active_pages | reverse %}\n-\n-<ol class=\"breadcrumb\">\n-{%- for p in active_pages %}\n-  {% capture title %}{% if p.nav-title %}{{ p.nav-title }}{% else %}{{ p.title }}{% endif %}{% endcapture -%}\n-  {%- if forloop.last == true %}\n-    <li class=\"active\">{{ title }}</li>\n-  {%- elsif p.nav-show_overview %}\n-    <li><a href=\"{{ site.baseurl }}{{ p.url }}\">{{ title }}</a></li>\n-  {%- else %}\n-    <li>{{ title }}</li>\n-  {%- endif -%}\n-{%- endfor %}\n-</ol>\n-\n-<h1>{{ page.title }}{% if page.is_beta %} <span class=\"beta\">Beta</span>{% endif %}</h1>\n-{% if site.show_outdated_warning %}\n-<div class=\"alert alert-danger\" role=\"alert\">\n-  {%- if page.language == \"en\" %}\n-    <strong>This documentation is for an out-of-date version of Apache Flink. We recommend you use <a href=\"https://ci.apache.org/projects/flink/flink-docs-stable/\">the latest stable version</a>.</strong>\n-  {%- else if page.language == \"zh\" %}\n-    <strong>本文档是 Apache Flink 的旧版本。建议访问 <a href=\"https://ci.apache.org/projects/flink/flink-docs-stable/zh\">最新的稳定版本</a>。</strong>\n-  {%- endif %}\n-</div>\n-{%- endif %}\n-\n-{{ content }}\n-\n-\n-<div class=\"footer\">\n-  <a href=\"https://cwiki.apache.org/confluence/display/FLINK/Flink+Translation+Specifications\" target=\"_blank\">\n-    {% if page.language == \"zh\" %}\n-      想参与贡献翻译？\n-    {% else if page.language == \"en\" %}\n-      Want to contribute translation?\n-    {% endif %}\n-  </a>\n-</div>\n-"
        },
        {
            "sha": "700e8aa5286cd3be9db8290c54f6eee436ced4d1",
            "filename": "docs/_layouts/redirect.html",
            "status": "removed",
            "additions": 0,
            "deletions": 39,
            "changes": 39,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_layouts/redirect.html",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_layouts/redirect.html",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_layouts/redirect.html?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,39 +0,0 @@\n----\n-layout: base\n----\n-<!--\n-Licensed to the Apache Software Foundation (ASF) under one\n-or more contributor license agreements.  See the NOTICE file\n-distributed with this work for additional information\n-regarding copyright ownership.  The ASF licenses this file\n-to you under the Apache License, Version 2.0 (the\n-\"License\"); you may not use this file except in compliance\n-with the License.  You may obtain a copy of the License at\n-\n-  http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing,\n-software distributed under the License is distributed on an\n-\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-KIND, either express or implied.  See the License for the\n-specific language governing permissions and limitations\n-under the License.\n--->\n-\n-{% if page.language == \"en\" %}\n-\n-    <meta http-equiv=\"refresh\" content=\"1; url={{ site.baseurl }}{{ page.redirect }}\" />\n-\n-    <h1>Page '{{ page.title }}' Has Moved</h1>\n-\n-    The page <strong>{{ page.title }}</strong> has been moved. Redirecting to <a href=\"{{ site.baseurl }}/{{ page.redirect }}\">{{ site.baseurl }}{{ page.redirect }}</a> in 1 second.\n-\n-{% else if page.language == \"zh\" %}\n-\n-    <meta http-equiv=\"refresh\" content=\"1; url={{ site.baseurl }}/zh{{ page.redirect }}\" />\n-\n-    <h1>'{{ page.title }}' 页面已被移动</h1>\n-\n-    <strong>{{ page.title }}</strong> 页面已经被移动了。将在 1 秒后重定向到 <a href=\"{{ site.baseurl }}/zh{{ page.redirect }}\">{{ site.baseurl }}/zh{{ page.redirect }}</a> 。\n-\n-{% endif %}"
        },
        {
            "sha": "61aa5e83bf682aef4b8bf71b9d2aad88e09dd39f",
            "filename": "docs/_plugins/build_time.rb",
            "status": "removed",
            "additions": 0,
            "deletions": 31,
            "changes": 31,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_plugins/build_time.rb",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_plugins/build_time.rb",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_plugins/build_time.rb?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,31 +0,0 @@\n-# Licensed to the Apache Software Foundation (ASF) under one\n-# or more contributor license agreements.  See the NOTICE file\n-# distributed with this work for additional information\n-# regarding copyright ownership.  The ASF licenses this file\n-# to you under the Apache License, Version 2.0 (the\n-# \"License\"); you may not use this file except in compliance\n-# with the License.  You may obtain a copy of the License at\n-#\n-# http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing,\n-# software distributed under the License is distributed on an\n-# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-# KIND, either express or implied.  See the License for the\n-# specific language governing permissions and limitations\n-# under the License.\n-\n-module Jekyll\n-  class BuildTimeTag < Liquid::Tag\n-\n- \tdef initialize(tag_name, input, tokens)\n-      super\n-    end\n-\n-    def render(context)\n-    \tTime.now.strftime(\"%D, %r %Z\")\n-    end\n-  end\n-end\n-\n-Liquid::Template.register_tag('build_time', Jekyll::BuildTimeTag)\n\\ No newline at end of file"
        },
        {
            "sha": "bdaa2d44ac3b2d2ceb62a2c81a8015d3c7aa75ba",
            "filename": "docs/_plugins/gh_link.rb",
            "status": "removed",
            "additions": 0,
            "deletions": 52,
            "changes": 52,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_plugins/gh_link.rb",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_plugins/gh_link.rb",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_plugins/gh_link.rb?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,52 +0,0 @@\n-# Licensed to the Apache Software Foundation (ASF) under one\n-# or more contributor license agreements.  See the NOTICE file\n-# distributed with this work for additional information\n-# regarding copyright ownership.  The ASF licenses this file\n-# to you under the Apache License, Version 2.0 (the\n-# \"License\"); you may not use this file except in compliance\n-# with the License.  You may obtain a copy of the License at\n-# \n-# http://www.apache.org/licenses/LICENSE-2.0\n-# \n-# Unless required by applicable law or agreed to in writing,\n-# software distributed under the License is distributed on an\n-# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-# KIND, either express or implied.  See the License for the\n-# specific language governing permissions and limitations\n-# under the License.\n-\n-# ---------------------------------------------------------\n-# Expands a github link shortcut into a proper markdown link\n-# ---------------------------------------------------------\n-\n-module Jekyll\n-  class GitHubLinkTag < Liquid::Tag\n-\n-    def initialize(tag_name, input, tokens)\n-      super\n-      @input = input\n-    end\n-\n-    def render(context)\n-      input = @input.sub(/\".*\"/, \"\").split\n-      name = @input.match(/\".*\"/).to_s.gsub(/\"/, \"\")#@input.split.drop(2).join(\" \")\n-      config = context.registers[:site].config\n-\n-      path = input[0]\n-      file = path.split('/').last\n-\n-      page_gh_tag = context[\"page\"][\"gh_link_tag\"]\n-      # tag precendence:\n-      # 1. input[1],\n-      # 2. 'gh_link_tag' of page frontmatter\n-      # 3. \"master\" (default)\n-      gh_tag = input[1].nil? ? (page_gh_tag.nil? ? \"master\" : page_gh_tag) : input[1]\n-      name = name.to_s == '' ? file : name\n-      #refname = input[2].nil? ? file : input[2]\n-\n-      \"[#{name}](#{config[\"github_url\"]}/blob/#{gh_tag}/#{path})\"\n-    end\n-  end\n-end\n-\n-Liquid::Template.register_tag('gh_link', Jekyll::GitHubLinkTag)"
        },
        {
            "sha": "8a7792e3f55573e56a094750bfa472afd72d0f87",
            "filename": "docs/_plugins/include_without_header.rb",
            "status": "removed",
            "additions": 0,
            "deletions": 40,
            "changes": 40,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_plugins/include_without_header.rb",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_plugins/include_without_header.rb",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_plugins/include_without_header.rb?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,40 +0,0 @@\n-# Licensed to the Apache Software Foundation (ASF) under one\n-# or more contributor license agreements.  See the NOTICE file\n-# distributed with this work for additional information\n-# regarding copyright ownership.  The ASF licenses this file\n-# to you under the Apache License, Version 2.0 (the\n-# \"License\"); you may not use this file except in compliance\n-# with the License.  You may obtain a copy of the License at\n-#\n-# http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing,\n-# software distributed under the License is distributed on an\n-# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-# KIND, either express or implied.  See the License for the\n-# specific language governing permissions and limitations\n-# under the License.\n-\n-module Jekyll\n-  module Tags\n-\n-    class IncludeWithoutHeaderTag < Liquid::Tag\n-\n-      def initialize(tag_name, text, tokens)\n-        super\n-        @file = text.strip\n-      end\n-\n-      def render(context)\n-        source = File.expand_path(context.registers[:site].config['source'])\n-        path = File.join(source, @file)\n-        content = File.read(path, :encoding => 'UTF-8')\n-        content = content.split(/<!--[^>]*LICENSE-2.0[^>]*-->/, 2)[1]\n-        partial = Liquid::Template.parse(content)\n-        partial.render!(context)\n-      end\n-    end\n-  end\n-end\n-\n-Liquid::Template.register_tag(\"include_without_header\", Jekyll::Tags::IncludeWithoutHeaderTag)"
        },
        {
            "sha": "ef3c210b92eafe597e341e68bae7b703a4167fcb",
            "filename": "docs/_plugins/info.rb",
            "status": "removed",
            "additions": 0,
            "deletions": 37,
            "changes": 37,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_plugins/info.rb",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_plugins/info.rb",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_plugins/info.rb?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,37 +0,0 @@\n-# Licensed to the Apache Software Foundation (ASF) under one\n-# or more contributor license agreements.  See the NOTICE file\n-# distributed with this work for additional information\n-# regarding copyright ownership.  The ASF licenses this file\n-# to you under the Apache License, Version 2.0 (the\n-# \"License\"); you may not use this file except in compliance\n-# with the License.  You may obtain a copy of the License at\n-#\n-# http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing,\n-# software distributed under the License is distributed on an\n-# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-# KIND, either express or implied.  See the License for the\n-# specific language governing permissions and limitations\n-# under the License.\n-\n-module Jekyll\n-  class InfoTag < Liquid::Tag\n-\n-    def initialize(tag_name, text, tokens)\n-      super\n-      @text = text\n-    end\n-\n-    def render(context)\n-    \tif @text.to_s == ''\n-    \t\t@text = \"Info\"\n-    \tend\n-\n-    \t@text = @text.strip! || @text if !@text.nil?\n-    \t\"<span class=\\\"label label-info\\\">#{@text}</span>\"\n-    end\n-  end\n-end\n-\n-Liquid::Template.register_tag('info', Jekyll::InfoTag)"
        },
        {
            "sha": "57528f6873e05c4d3976c458437565ddcdb09796",
            "filename": "docs/_plugins/liquify.rb",
            "status": "removed",
            "additions": 0,
            "deletions": 31,
            "changes": 31,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_plugins/liquify.rb",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_plugins/liquify.rb",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_plugins/liquify.rb?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,31 +0,0 @@\n-# Licensed to the Apache Software Foundation (ASF) under one\n-# or more contributor license agreements.  See the NOTICE file\n-# distributed with this work for additional information\n-# regarding copyright ownership.  The ASF licenses this file\n-# to you under the Apache License, Version 2.0 (the\n-# \"License\"); you may not use this file except in compliance\n-# with the License.  You may obtain a copy of the License at\n-#\n-# http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing,\n-# software distributed under the License is distributed on an\n-# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-# KIND, either express or implied.  See the License for the\n-# specific language governing permissions and limitations\n-# under the License.\n-\n-# *A Jekyll filter that can parse Liquid in Liquid variables\n-#\n-# Usage:\n-# e.g. Welcome to {{ page.title | liquify }}!\n-\n-module Jekyll\n-  module LiquifyFilter\n-    def liquify(input)\n-      Liquid::Template.parse(input).render(@context)\n-    end\n-  end\n-end\n-\n-Liquid::Template.register_filter(Jekyll::LiquifyFilter)"
        },
        {
            "sha": "1dfef6346ac0cc22ee459d080d3b841a2c1631d1",
            "filename": "docs/_plugins/panel.rb",
            "status": "removed",
            "additions": 0,
            "deletions": 33,
            "changes": 33,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_plugins/panel.rb",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_plugins/panel.rb",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_plugins/panel.rb?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,33 +0,0 @@\n-# Licensed to the Apache Software Foundation (ASF) under one\n-# or more contributor license agreements.  See the NOTICE file\n-# distributed with this work for additional information\n-# regarding copyright ownership.  The ASF licenses this file\n-# to you under the Apache License, Version 2.0 (the\n-# \"License\"); you may not use this file except in compliance\n-# with the License.  You may obtain a copy of the License at\n-#\n-# http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing,\n-# software distributed under the License is distributed on an\n-# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-# KIND, either express or implied.  See the License for the\n-# specific language governing permissions and limitations\n-# under the License.\n-\n-module Jekyll\n-  class PanelTag < Liquid::Tag\n-\n-    def initialize(tag_name, text, tokens)\n-      super\n-      @text = text\n-    end\n-\n-    def render(context)\n-    \t@text = @text.strip! || @text if !@text.nil?\n-      \"<div class=\\\"panel panel-default\\\"><div class=\\\"panel-body\\\" markdown=\\\"span\\\">#{@text}</div></div>\"\n-    end\n-  end\n-end\n-\n-Liquid::Template.register_tag('panel', Jekyll::PanelTag)"
        },
        {
            "sha": "2ac653fb40baee5e60ff563e7a1c32b4e3ceb240",
            "filename": "docs/_plugins/removeDuplicateLicenseHeaders.rb",
            "status": "removed",
            "additions": 0,
            "deletions": 75,
            "changes": 75,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_plugins/removeDuplicateLicenseHeaders.rb",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_plugins/removeDuplicateLicenseHeaders.rb",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_plugins/removeDuplicateLicenseHeaders.rb?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,75 +0,0 @@\n-# Licensed to the Apache Software Foundation (ASF) under one\n-# or more contributor license agreements.  See the NOTICE file\n-# distributed with this work for additional information\n-# regarding copyright ownership.  The ASF licenses this file\n-# to you under the Apache License, Version 2.0 (the\n-# \"License\"); you may not use this file except in compliance\n-# with the License.  You may obtain a copy of the License at\n-\n-# http://www.apache.org/licenses/LICENSE-2.0\n-\n-# Unless required by applicable law or agreed to in writing,\n-# software distributed under the License is distributed on an\n-# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-# KIND, either express or implied.  See the License for the\n-# specific language governing permissions and limitations\n-# under the License.\n-\n-# ---------------------------------------------------------\n-# Ensures that the documentation contains the Apache License\n-# headers once, not repeatedly for each include.\n-# ---------------------------------------------------------\n-\n-module Jekyll\n-\n-  module LicenseRemover\n- \n-    AL2 = \"<!--\\n\"+\n-          \"Licensed to the Apache Software Foundation (ASF) under one\\n\"+\n-          \"or more contributor license agreements.  See the NOTICE file\\n\"+\n-          \"distributed with this work for additional information\\n\"+\n-          \"regarding copyright ownership.  The ASF licenses this file\\n\"+\n-          \"to you under the Apache License, Version 2.0 (the\\n\"+\n-          \"\\\"License\\\"); you may not use this file except in compliance\\n\"+\n-          \"with the License.  You may obtain a copy of the License at\\n\"+\n-          \"\\n\"+\n-          \"http://www.apache.org/licenses/LICENSE-2.0\\n\"+\n-          \"\\n\"+\n-          \"Unless required by applicable law or agreed to in writing,\\n\"+\n-          \"software distributed under the License is distributed on an\\n\"+\n-          \"\\\"AS IS\\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\\n\"+\n-          \"KIND, either express or implied.  See the License for the\\n\"+\n-          \"specific language governing permissions and limitations\\n\"+\n-          \"under the License.\\n\"+\n-          \"-->\\n\"\n-\n-    def writeFile(dest, content)\n-      path = self.destination(dest)\n-      FileUtils.mkdir_p(File.dirname(path))\n-      File.open(path, 'w') do |f|\n-        # remove all Apache Licenses\n-        withoutLicense = content.gsub(/<!--[^>]*LICENSE-2.0[^>]*-->/,'')\n-        # put single Apache License on top\n-        singleLicense = AL2+withoutLicense\n-        # write file out\n-        f.write(singleLicense)\n-      end\n-    end\n-\n-  end\n-\n-  class Post\n-    include LicenseRemover\n-    def write(dest)\n-      self.writeFile(dest, self.output)\n-    end\n-  end\n-\n-  class Page\n-    include LicenseRemover\n-    def write(dest)\n-      self.writeFile(dest, self.output)\n-    end\n-  end\n-\n-end"
        },
        {
            "sha": "b79781c8c95df6cd0370606cca0fab243d2deed2",
            "filename": "docs/_plugins/top.rb",
            "status": "removed",
            "additions": 0,
            "deletions": 31,
            "changes": 31,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_plugins/top.rb",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_plugins/top.rb",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_plugins/top.rb?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,31 +0,0 @@\n-# Licensed to the Apache Software Foundation (ASF) under one\n-# or more contributor license agreements.  See the NOTICE file\n-# distributed with this work for additional information\n-# regarding copyright ownership.  The ASF licenses this file\n-# to you under the Apache License, Version 2.0 (the\n-# \"License\"); you may not use this file except in compliance\n-# with the License.  You may obtain a copy of the License at\n-#\n-# http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing,\n-# software distributed under the License is distributed on an\n-# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-# KIND, either express or implied.  See the License for the\n-# specific language governing permissions and limitations\n-# under the License.\n-\n-module Jekyll\n-  class TopTag < Liquid::Tag\n-\n-    def initialize(tag_name, text, tokens)\n-      super\n-    end\n-\n-    def render(context)\n-    \t\"<a href=\\\"\\#top\\\" class=\\\"top pull-right\\\"><span class=\\\"glyphicon glyphicon-chevron-up\\\"></span> Back to top</a>\"\n-    end\n-  end\n-end\n-\n-Liquid::Template.register_tag('top', Jekyll::TopTag)"
        },
        {
            "sha": "c8bd3af19ce8f7ce59d9b6643d54fb862221bf6f",
            "filename": "docs/_plugins/warn.rb",
            "status": "removed",
            "additions": 0,
            "deletions": 41,
            "changes": 41,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_plugins/warn.rb",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/_plugins/warn.rb",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_plugins/warn.rb?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,41 +0,0 @@\n-# Licensed to the Apache Software Foundation (ASF) under one\n-# or more contributor license agreements.  See the NOTICE file\n-# distributed with this work for additional information\n-# regarding copyright ownership.  The ASF licenses this file\n-# to you under the Apache License, Version 2.0 (the\n-# \"License\"); you may not use this file except in compliance\n-# with the License.  You may obtain a copy of the License at\n-#\n-# http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing,\n-# software distributed under the License is distributed on an\n-# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-# KIND, either express or implied.  See the License for the\n-# specific language governing permissions and limitations\n-# under the License.\n-\n-# ---------------------------------------------------------\n-# Expands a github link shortcut into a proper markdown link\n-# ---------------------------------------------------------\n-\n-module Jekyll\n-  class WarnTag < Liquid::Tag\n-\n-    def initialize(tag_name, text, tokens)\n-      super\n-      @text = text\n-    end\n-\n-    def render(context)\n-    \tif @text.to_s == ''\n-    \t\t@text = \"Warning\"\n-    \tend\n-\n-    \t@text = @text.strip! || @text if !@text.nil?\n-    \t\"<span class=\\\"label label-danger\\\">#{@text}</span>\"\n-    end\n-  end\n-end\n-\n-Liquid::Template.register_tag('warn', Jekyll::WarnTag)"
        },
        {
            "sha": "a857770aa604797a7f071d25d3d78a27d7c272de",
            "filename": "docs/annotations.xml",
            "status": "removed",
            "additions": 0,
            "deletions": 66,
            "changes": 66,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/annotations.xml",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/annotations.xml",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/annotations.xml?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,66 +0,0 @@\n-<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n-\n-<!--\n-Licensed to the Apache Software Foundation (ASF) under one\n-or more contributor license agreements.  See the NOTICE file\n-distributed with this work for additional information\n-regarding copyright ownership.  The ASF licenses this file\n-to you under the Apache License, Version 2.0 (the\n-\"License\"); you may not use this file except in compliance\n-with the License.  You may obtain a copy of the License at\n-\n-http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing,\n-software distributed under the License is distributed on an\n-\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-KIND, either express or implied.  See the License for the\n-specific language governing permissions and limitations\n-under the License.\n--->\n-\n-<?ignore\n-This is the annotations file for the Google Custom Search Engine\n-used by the Apache Flink Documentation after version 1.3.\n-After modifying this file it needs to be uploaded to the Custom Search control panel at\n-https://cse.google.com/cse/setup/advanced?cx=000322205049649384055%3Aqbxxlwnwoqs\n-in order for the changes to take effect.\n-The UI is specified separately in cse.xml.\n-?>\n-\n-<Annotations start=\"0\" num=\"7\" total=\"7\">\n-  <Annotation score=\"1\" about=\"ci.apache.org/projects/flink/flink-docs-master/*\" timestamp=\"0x0005539172a442a2\" href=\"CjBjaS5hcGFjaGUub3JnL3Byb2plY3RzL2ZsaW5rL2ZsaW5rLWRvY3MtbWFzdGVyLyoQooWRlZfy1AI\">\n-    <Label name=\"_cse_qbxxlwnwoqs\" />\n-    <Label name=\"documentation\" />\n-    <AdditionalData attribute=\"original_url\" value=\"https://ci.apache.org/projects/flink/flink-docs-master/\" />\n-  </Annotation>\n-  <Annotation score=\"0.2\" about=\"issues.apache.org/jira/browse/FLINK-*\" timestamp=\"0x000553938050ff8b\" href=\"CiVpc3N1ZXMuYXBhY2hlLm9yZy9qaXJhL2Jyb3dzZS9GTElOSy0qEIv_w4K48tQC\">\n-    <Label name=\"_cse_qbxxlwnwoqs\" />\n-    <Label name=\"jira\" />\n-    <AdditionalData attribute=\"original_url\" value=\"https://issues.apache.org/jira/browse/FLINK-*\" />\n-  </Annotation>\n-  <Annotation score=\"0.5\" about=\"mail-archives.apache.org/mod_mbox/flink-*\" timestamp=\"0x000553917ae594ac\" href=\"Ci1tYWlsLWFyY2hpdmVzLmFwYWNoZS5vcmcvbW9kX21ib3gvZmxpbmstZGV2LyoQrKmW15fy1AI\">\n-    <Label name=\"_cse_qbxxlwnwoqs\" />\n-    <Label name=\"mailing_lists\" />\n-    <AdditionalData attribute=\"original_url\" value=\"https://mail-archives.apache.org/mod_mbox/flink-*\" />\n-  </Annotation>\n-  <Annotation score=\"0.5\" about=\"cwiki.apache.org/confluence/display/FLINK/FLIP-*\">\n-    <Label name=\"_cse_qbxxlwnwoqs\" />\n-    <Label name=\"flips\" />\n-    <AdditionalData attribute=\"original_url\" value=\"https://cwiki.apache.org/confluence/display/FLINK/FLIP-*\" />\n-  </Annotation>\n-  <Annotation score=\"0.5\" about=\"*.flink-forward.org/*\">\n-    <Label name=\"_cse_qbxxlwnwoqs\" />\n-    <Label name=\"FF\" />\n-  </Annotation>\n-  <Annotation score=\"0.001\" about=\"*.stackoverflow.com/*\" timestamp=\"0x000553943f18494c\" href=\"ChUqLnN0YWNrb3ZlcmZsb3cuY29tLyoQzJLh-MPy1AI\">\n-    <Label name=\"_cse_qbxxlwnwoqs\" />\n-    <Label name=\"stack_overflow\" />\n-    <AdditionalData attribute=\"original_url\" value=\"https://stackoverflow.com\" />\n-  </Annotation>\n-  <Annotation about=\"ci.apache.org/projects/flink/flink-docs-master/api/java/*\" timestamp=\"0x0005539459e4638b\" href=\"CjljaS5hcGFjaGUub3JnL3Byb2plY3RzL2ZsaW5rL2ZsaW5rLWRvY3MtbWFzdGVyL2FwaS9qYXZhLyoQi8eRz8Xy1AI\">\n-    <Label name=\"_cse_exclude_qbxxlwnwoqs\" />\n-    <Label name=\"javadocs\" />\n-    <AdditionalData attribute=\"original_url\" value=\"https://ci.apache.org/projects/flink/flink-docs-master/api/java/\" />\n-  </Annotation>\n-</Annotations>"
        },
        {
            "sha": "33ccbb4060a8bc3fe49fc2dc1c9c8c78324d74bb",
            "filename": "docs/assets/_custom.scss",
            "status": "added",
            "additions": 239,
            "deletions": 0,
            "changes": 239,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/assets/_custom.scss",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/assets/_custom.scss",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/assets/_custom.scss?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,239 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+// \n+//   http://www.apache.org/licenses/LICENSE-2.0\n+// \n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+@import \"github\";\n+\n+.link {\n+    padding-bottom: 5px;\n+}\n+\n+.appetizer {\n+\tcolor: #FBB142;\n+}\n+\n+.maindish {\n+\tcolor: #7E4F89;\n+}\n+\n+.dessert {\n+    color: #E6526F;\n+}\n+\n+.book-menu nav {\n+\tbackground: #f8f8f8;\n+}\n+\n+.book-page {\n+\tpadding: 2rem 2rem;\n+}\n+\n+.book-search input {\n+\tbackground: white;\n+}\n+\n+.markdown a {\n+\ttext-decoration: none;\n+\tcolor: #05b;\n+}\n+\n+.markdown a:visited {\n+\ttext-decoration: none;\n+\tcolor: #05b;\n+}\n+\n+.markdown {\n+    line-height: 1.43;\n+\n+    h1,\n+    h2,\n+    h3,\n+    h4,\n+    h5,\n+    h6 {\n+        font-weight: 500;\n+        padding-top: 0;\n+        margin-top: 1em;\n+    }\n+}\n+\n+body {\n+    letter-spacing: normal;\n+    -webkit-font-smoothing: auto;\n+}\n+\n+aside nav ul {\n+  li {\n+    margin: 0.5em 0;\n+  }\n+}\n+\n+.book-search {\n+\tborder: 2px solid #ebebeb;\n+}\n+\n+@media screen and (max-width: 768px) {\n+    .toc {\n+        display: none;\n+    }\n+}\n+\n+aside.book-menu nav {\n+    a:hover {\n+        font-weight: bold;\n+        opacity: 1.0;\n+    }\n+\n+    a.active {\n+        font-weight: bold;\n+        color: var(--body-font-color);\n+    }\n+}\n+\n+aside.book-menu > li {\n+    padding: 10px 5px 5px 5px;\n+}\n+\n+aside.book-toc {\n+    h3 {\n+        margin-top: 0;\n+        padding-top: 0;\n+        font-size: 1.2em;\n+    }\n+}\n+\n+html {\n+    line-height: 1.43;\n+}\n+\n+h1, h2, h3, h4, h5, h6 {\n+    line-height: 1.1;\n+}\n+\n+h1, h2, h3 {\n+    margin-top: 20px;\n+    margin-bottom: 10px;\n+}\n+\n+h2, h3, h4 {\n+    padding-top: 1em;\n+}\n+\n+h1 {\n+    font-size: 36px;\n+}\n+\n+h2 {\n+    font-size: 30px;\n+    border-bottom: 1px solid #e5e5e5;\n+}\n+\n+h3 {\n+    font-size: 24px;\n+}\n+\n+h4 {\n+    font-size: 18px;\n+}\n+\n+.markdown code {\n+    background: white;\n+    padding: 0;\n+    border-radius: 0;\n+}\n+\n+pre.chroma code {\n+    line-height: 1.43;\n+}\n+\n+.book-languages {\n+    border: 2px solid black; \n+}\n+\n+.menu-break {\n+    opacity: 0.1;\n+}\n+\n+#book-search-results {\n+    padding: 2px;\n+    background-color: white;\n+}\n+\n+.label {\n+    display: inline;\n+    padding: .2em .6em .3em;\n+    font-size: 75%;\n+    font-weight: 700;\n+    line-height: 1;\n+    color: #fff;\n+    text-align: center;\n+    white-space: nowrap;\n+    vertical-align: baseline;\n+    border-radius: .25em;\n+    background-color: #337ab7;\n+}\n+\n+.expand-toc {\n+    position: fixed;\n+    top: 2em;\n+    right: 5em;\n+    display: none;\n+}\n+\n+.container {\n+    max-width: 90rem;\n+}\n+\n+#book-search-input:focus {\n+    outline: none;\n+}\n+\n+.rest-api h5 {\n+    margin-top: .5em;\n+    margin-bottom: .5em;\n+    font-size: 1em;\n+}\n+\n+.rest-api tbody {\n+    display: table;\n+    width: 100%;\n+    background: white;\n+}\n+\n+.rest-api td {\n+    background: white;\n+}\n+\n+.rest-api .book-expand label {\n+    padding: 0rem 0rem;\n+    background: white;\n+}\n+\n+.rest-api .book-expand {\n+    background: white;\n+}\n+\n+.rest-api .book-expand .book-expand-head {\n+    background: white;\n+}\n+\n+.configuration td {\n+    background: white;\n+}\n+\n+.markdown table tr:nth-child(2n) {\n+    background: white;\n+} \n\\ No newline at end of file"
        },
        {
            "sha": "dc57189cf04b68c13e9606428ee5e72b61750920",
            "filename": "docs/assets/_fonts.scss",
            "status": "added",
            "additions": 25,
            "deletions": 0,
            "changes": 25,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/assets/_fonts.scss",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/assets/_fonts.scss",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/assets/_fonts.scss?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,25 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+// \n+//   http://www.apache.org/licenses/LICENSE-2.0\n+// \n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+body {\n+    font-family: \"Helvetica Neue\",Helvetica,Arial,sans-serif;\n+    font-size: 14px;\n+}\n+\n+code {\n+    font-family: \"Menlo\", \"Lucida Console\", monospace;\n+}\n\\ No newline at end of file"
        },
        {
            "sha": "25600e34e7103deb748b8542b7602ecb7db85255",
            "filename": "docs/assets/github.css",
            "status": "added",
            "additions": 87,
            "deletions": 0,
            "changes": 87,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/assets/github.css",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/assets/github.css",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/assets/github.css?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,87 @@\n+/**\n+ * Syntax highlighting generated via\n+ * hugo gen chromastyles --style=github > chroma.css\n+ */\n+\n+/* Background */ .chroma { background-color: #ffffff }\n+/* Other */ .chroma .x {  }\n+/* Error */ .chroma .err { color: #a61717; background-color: #e3d2d2 }\n+/* LineTableTD */ .chroma .lntd { vertical-align: top; padding: 0; margin: 0; border: 0; }\n+/* LineTable */ .chroma .lntable { border-spacing: 0; padding: 0; margin: 0; border: 0; width: auto; overflow: auto; display: block; }\n+/* LineHighlight */ .chroma .hl { display: block; width: 100%;background-color: #ffffcc }\n+/* LineNumbersTable */ .chroma .lnt { margin-right: 0.4em; padding: 0 0.4em 0 0.4em;color: #7f7f7f }\n+/* LineNumbers */ .chroma .ln { margin-right: 0.4em; padding: 0 0.4em 0 0.4em;color: #7f7f7f }\n+/* Keyword */ .chroma .k { color: #000000; font-weight: bold }\n+/* KeywordConstant */ .chroma .kc { color: #000000; font-weight: bold }\n+/* KeywordDeclaration */ .chroma .kd { color: #000000; font-weight: bold }\n+/* KeywordNamespace */ .chroma .kn { color: #000000; font-weight: bold }\n+/* KeywordPseudo */ .chroma .kp { color: #000000; font-weight: bold }\n+/* KeywordReserved */ .chroma .kr { color: #000000; font-weight: bold }\n+/* KeywordType */ .chroma .kt { color: #445588; font-weight: bold }\n+/* Name */ .chroma .n {  }\n+/* NameAttribute */ .chroma .na { color: #008080 }\n+/* NameBuiltin */ .chroma .nb { color: #0086b3 }\n+/* NameBuiltinPseudo */ .chroma .bp { color: #999999 }\n+/* NameClass */ .chroma .nc { color: #445588; font-weight: bold }\n+/* NameConstant */ .chroma .no { color: #008080 }\n+/* NameDecorator */ .chroma .nd { color: #3c5d5d; font-weight: bold }\n+/* NameEntity */ .chroma .ni { color: #800080 }\n+/* NameException */ .chroma .ne { color: #990000; font-weight: bold }\n+/* NameFunction */ .chroma .nf { color: #990000; font-weight: bold }\n+/* NameFunctionMagic */ .chroma .fm {  }\n+/* NameLabel */ .chroma .nl { color: #990000; font-weight: bold }\n+/* NameNamespace */ .chroma .nn { color: #555555 }\n+/* NameOther */ .chroma .nx {  }\n+/* NameProperty */ .chroma .py {  }\n+/* NameTag */ .chroma .nt { color: #000080 }\n+/* NameVariable */ .chroma .nv { color: #008080 }\n+/* NameVariableClass */ .chroma .vc { color: #008080 }\n+/* NameVariableGlobal */ .chroma .vg { color: #008080 }\n+/* NameVariableInstance */ .chroma .vi { color: #008080 }\n+/* NameVariableMagic */ .chroma .vm {  }\n+/* Literal */ .chroma .l {  }\n+/* LiteralDate */ .chroma .ld {  }\n+/* LiteralString */ .chroma .s { color: #dd1144 }\n+/* LiteralStringAffix */ .chroma .sa { color: #dd1144 }\n+/* LiteralStringBacktick */ .chroma .sb { color: #dd1144 }\n+/* LiteralStringChar */ .chroma .sc { color: #dd1144 }\n+/* LiteralStringDelimiter */ .chroma .dl { color: #dd1144 }\n+/* LiteralStringDoc */ .chroma .sd { color: #dd1144 }\n+/* LiteralStringDouble */ .chroma .s2 { color: #dd1144 }\n+/* LiteralStringEscape */ .chroma .se { color: #dd1144 }\n+/* LiteralStringHeredoc */ .chroma .sh { color: #dd1144 }\n+/* LiteralStringInterpol */ .chroma .si { color: #dd1144 }\n+/* LiteralStringOther */ .chroma .sx { color: #dd1144 }\n+/* LiteralStringRegex */ .chroma .sr { color: #009926 }\n+/* LiteralStringSingle */ .chroma .s1 { color: #dd1144 }\n+/* LiteralStringSymbol */ .chroma .ss { color: #990073 }\n+/* LiteralNumber */ .chroma .m { color: #009999 }\n+/* LiteralNumberBin */ .chroma .mb { color: #009999 }\n+/* LiteralNumberFloat */ .chroma .mf { color: #009999 }\n+/* LiteralNumberHex */ .chroma .mh { color: #009999 }\n+/* LiteralNumberInteger */ .chroma .mi { color: #009999 }\n+/* LiteralNumberIntegerLong */ .chroma .il { color: #009999 }\n+/* LiteralNumberOct */ .chroma .mo { color: #009999 }\n+/* Operator */ .chroma .o { color: #000000; font-weight: bold }\n+/* OperatorWord */ .chroma .ow { color: #000000; font-weight: bold }\n+/* Punctuation */ .chroma .p {  }\n+/* Comment */ .chroma .c { color: #999988; font-style: italic }\n+/* CommentHashbang */ .chroma .ch { color: #999988; font-style: italic }\n+/* CommentMultiline */ .chroma .cm { color: #999988; font-style: italic }\n+/* CommentSingle */ .chroma .c1 { color: #999988; font-style: italic }\n+/* CommentSpecial */ .chroma .cs { color: #999999; font-weight: bold; font-style: italic }\n+/* CommentPreproc */ .chroma .cp { color: #999999; font-weight: bold; font-style: italic }\n+/* CommentPreprocFile */ .chroma .cpf { color: #999999; font-weight: bold; font-style: italic }\n+/* Generic */ .chroma .g {  }\n+/* GenericDeleted */ .chroma .gd { color: #000000; background-color: #ffdddd }\n+/* GenericEmph */ .chroma .ge { color: #000000; font-style: italic }\n+/* GenericError */ .chroma .gr { color: #aa0000 }\n+/* GenericHeading */ .chroma .gh { color: #999999 }\n+/* GenericInserted */ .chroma .gi { color: #000000; background-color: #ddffdd }\n+/* GenericOutput */ .chroma .go { color: #888888 }\n+/* GenericPrompt */ .chroma .gp { color: #555555 }\n+/* GenericStrong */ .chroma .gs { font-weight: bold }\n+/* GenericSubheading */ .chroma .gu { color: #aaaaaa }\n+/* GenericTraceback */ .chroma .gt { color: #aa0000 }\n+/* GenericUnderline */ .chroma .gl { text-decoration: underline }\n+/* TextWhitespace */ .chroma .w { color: #bbbbbb }"
        },
        {
            "sha": "620fc380cf2b7bbc40165a8915ac88749f0c8e16",
            "filename": "docs/assets/search-data.js",
            "status": "added",
            "additions": 50,
            "deletions": 0,
            "changes": 50,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/assets/search-data.js",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/assets/search-data.js",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/assets/search-data.js?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+'use strict';\n+\n+(function () {\n+  const indexCfg = {{ with i18n \"bookSearchConfig\" }}\n+    {{ . }};\n+  {{ else }}\n+   {};\n+  {{ end }}\n+\n+  indexCfg.doc = {\n+    id: 'id',\n+    field: ['title', 'content'],\n+    store: ['title', 'href', 'section'],\n+  };\n+\n+  const index = FlexSearch.create('balance', indexCfg);\n+  window.bookSearchIndex = index;\n+\n+  {{- $pages := where .Site.Pages \"Kind\" \"in\" (slice \"page\" \"section\") -}}\n+  {{- $pages = where $pages \"Params.booksearchexclude\" \"!=\" true -}}\n+  {{- $pages = where $pages \"Content\" \"not in\" (slice nil \"\") -}}\n+\n+  {{ range $index, $page := $pages }}\n+  index.add({\n+    'id': {{ $index }},\n+    'href': '{{ $page.RelPermalink }}',\n+    'title': {{ (partial \"docs/simple-title\" $page) | jsonify }},\n+    'section': {{ (partial \"docs/simple-title\" $page.Parent) | jsonify }},\n+    'content': {{ $page.Plain | jsonify }}\n+  });\n+  {{- end -}}\n+})();"
        },
        {
            "sha": "36eba0cc2de519ee379ad846de4d37655acc03c9",
            "filename": "docs/build_docs.sh",
            "status": "modified",
            "additions": 7,
            "deletions": 86,
            "changes": 93,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/build_docs.sh",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/build_docs.sh",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/build_docs.sh?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -17,91 +17,12 @@\n # limitations under the License.\n ################################################################################\n \n-RUBY=${RUBY:-ruby}\n-GEM=${GEM:-gem}\n-CACHE_DIR=${CACHE_DIR:-\".rubydeps\"}\n-\n-set -e\n-cd \"$(dirname ${BASH_SOURCE[0]})\"\n-\n-DIR=\"`pwd`\"\n-\n-# We need at least bundler to proceed\n-if [ \"`command -v bundle`\" == \"\" ]; then\n-\tRUBYGEM_BINDIR=\"\"\n-\n-\t# Adjust the PATH to discover locally installed ruby gem binaries\n-\texport PATH=\"$(${RUBY} -e 'puts Gem.user_dir')/bin:$PATH\"\n-\n-\tif [ \"`command -v bundle`\" == \"\" ]; then\n-\t\techo \"WARN: Could not find bundle.\"\n-\t\techo \"Attempting to install locally. If this doesn't work, please install with 'gem install bundler'.\"\n-\n-\t\t# install bundler locally\n-\t\t${GEM} install --user-install --no-format-executable bundler\n-\tfi\n+if ! command -v hugo &> /dev/null\n+then\n+\techo \"Hugo must be installed to run the docs locally\"\n+\techo \"Please see docs/README.md for more details\"\n+\texit 1\n fi\n+git submodule update --init --recursive\n \n-# Install Ruby dependencies locally\n-bundle install --path ${CACHE_DIR}\n-\n-DOCS_SRC=${DIR}\n-DOCS_DST=${DOCS_SRC}/content\n-\n-# default jekyll command is to just build site\n-JEKYLL_CMD=\"build\"\n-\n-JEKYLL_CONFIG=\"\"\n-\n-DOC_LANGUAGES=\"en zh\"\n-\n-# if -p flag is provided, serve site on localhost\n-# -i is like -p, but incremental (only rebuilds the modified file)\n-# -e builds only english documentation\n-# -z builds only chinese documentation \n-while getopts \"piez\" opt; do\n-\tcase $opt in\n-\t\tp)\n-\t\tJEKYLL_CMD=\"serve --baseurl= --watch\"\n-\t\t;;\n-\t\ti)\n-\t\t[[ `${RUBY} -v` =~ 'ruby 1' ]] && echo \"Error: building the docs with the incremental option requires at least ruby 2.0\" && exit 1\n-\t\tJEKYLL_CMD=\"serve --baseurl= --watch --incremental\"\n-\t\t;;\n-\t\te)\n-\t\tJEKYLL_CONFIG=\"--config _config.yml,_config_dev_en.yml\"\n-\t\t;;\n-\t\tz)\n-\t\tJEKYLL_CONFIG=\"--config _config.yml,_config_dev_zh.yml\"\n-\t\t;;\n-\t\t*) echo \"usage: $0 [-e|-z] [-i|-p]\" >&2\n-\t\texit 1 ;;\n-\tesac\n-done\n-\n-# use 'bundle exec' to insert the local Ruby dependencies\n-\n-if [ \"${JEKYLL_CMD}\" = \"build\" ] && [ -z \"${JEKYLL_CONFIG}\" ]; then\n-  # run parallel builds for all languages if not serving or creating a single language only\n-\n-  # run processes and store pids\n-  echo \"Spawning parallel builds for languages: ${DOC_LANGUAGES}...\"\n-  pids=\"\"\n-  for lang in ${DOC_LANGUAGES}; do\n-    bundle exec jekyll ${JEKYLL_CMD} --config _config.yml,_config_dev_${lang}.yml --source \"${DOCS_SRC}\" --destination \"${DOCS_DST}_${lang}\" &\n-    pid=$!\n-    pids=\"${pids} ${pid}\"\n-  done\n-\n-  # wait for all pids (since jekyll returns 0 even in case of failures, we do not parse exit codes)\n-  wait ${pids}\n-  rm -rf \"${DOCS_DST}\"\n-  mkdir -p \"${DOCS_DST}\"\n-  for lang in ${DOC_LANGUAGES}; do\n-    cp -aln \"${DOCS_DST}_${lang}/.\" \"${DOCS_DST}\"\n-    rm -rf \"${DOCS_DST}_${lang}\"\n-  done\n-  exit 0\n-else\n-  bundle exec jekyll ${JEKYLL_CMD} ${JEKYLL_CONFIG} --source \"${DOCS_SRC}\" --destination \"${DOCS_DST}\"\n-fi\n+hugo -b \"\" serve "
        },
        {
            "sha": "5d9f7628c472cff5b190ae70784d1e0a40c4dacf",
            "filename": "docs/check_links.sh",
            "status": "removed",
            "additions": 0,
            "deletions": 39,
            "changes": 39,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/check_links.sh",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/check_links.sh",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/check_links.sh?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,39 +0,0 @@\n-#!/usr/bin/env bash\n-################################################################################\n-#  Licensed to the Apache Software Foundation (ASF) under one\n-#  or more contributor license agreements.  See the NOTICE file\n-#  distributed with this work for additional information\n-#  regarding copyright ownership.  The ASF licenses this file\n-#  to you under the Apache License, Version 2.0 (the\n-#  \"License\"); you may not use this file except in compliance\n-#  with the License.  You may obtain a copy of the License at\n-#\n-#      http://www.apache.org/licenses/LICENSE-2.0\n-#\n-#  Unless required by applicable law or agreed to in writing, software\n-#  distributed under the License is distributed on an \"AS IS\" BASIS,\n-#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-#  See the License for the specific language governing permissions and\n-# limitations under the License.\n-################################################################################\n-\n-target=${1:-\"http://localhost:4000\"}\n-\n-# Crawl the docs, ignoring robots.txt, storing nothing locally\n-wget --spider -r -nd -nv -e robots=off -p -o spider.log \"$target\"\n-\n-# Abort for anything other than 0 and 4 (\"Network failure\")\n-status=$?\n-if [ $status -ne 0 ] && [ $status -ne 4 ]; then\n-    exit $status\n-fi\n-\n-# Fail the build if any broken links are found\n-broken_links_str=$(grep -e 'Found [[:digit:]]\\+ broken links' spider.log)\n-if [ -n \"$broken_links_str\" ]; then\n-    grep -B 1 \"Remote file does not exist -- broken link!!!\" spider.log\n-    echo \"---------------------------------------------------------------------------\"\n-    echo -e \"$broken_links_str\"\n-    echo \"Search for page containing broken link using 'grep -R BROKEN_PATH DOCS_DIR'\"\n-    exit 1\n-fi"
        },
        {
            "sha": "604dfbab9e2947992b86d89bfcf8ee56a780b582",
            "filename": "docs/concepts/flink-architecture.md",
            "status": "removed",
            "additions": 0,
            "deletions": 252,
            "changes": 252,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/concepts/flink-architecture.md",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/concepts/flink-architecture.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/concepts/flink-architecture.md?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,252 +0,0 @@\n----\n-title: Flink Architecture\n-nav-id: flink-architecture\n-nav-pos: 4\n-nav-title: Flink Architecture\n-nav-parent_id: concepts\n----\n-<!--\n-Licensed to the Apache Software Foundation (ASF) under one\n-or more contributor license agreements.  See the NOTICE file\n-distributed with this work for additional information\n-regarding copyright ownership.  The ASF licenses this file\n-to you under the Apache License, Version 2.0 (the\n-\"License\"); you may not use this file except in compliance\n-with the License.  You may obtain a copy of the License at\n-\n-  http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing,\n-software distributed under the License is distributed on an\n-\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-KIND, either express or implied.  See the License for the\n-specific language governing permissions and limitations\n-under the License.\n--->\n-\n-Flink is a distributed system and requires effective allocation and management\n-of compute resources in order to execute streaming applications. It integrates\n-with all common cluster resource managers such as [Hadoop\n-YARN](https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/YARN.html),\n-[Apache Mesos](https://mesos.apache.org/) and\n-[Kubernetes](https://kubernetes.io/), but can also be set up to run as a\n-standalone cluster or even as a library.\n-\n-This section contains an overview of Flink’s architecture and describes how its\n-main components interact to execute applications and recover from failures.\n-\n-* This will be replaced by the TOC\n-{:toc}\n-\n-## Anatomy of a Flink Cluster\n-\n-The Flink runtime consists of two types of processes: a _JobManager_ and one or more _TaskManagers_.\n-\n-<img src=\"{% link /fig/processes.svg %}\" alt=\"The processes involved in executing a Flink dataflow\" class=\"offset\" width=\"70%\" />\n-\n-The *Client* is not part of the runtime and program execution, but is used to\n-prepare and send a dataflow to the JobManager.  After that, the client can\n-disconnect (_detached mode_), or stay connected to receive progress reports\n-(_attached mode_). The client runs either as part of the Java/Scala program\n-that triggers the execution, or in the command line process `./bin/flink run\n-...`.\n-\n-The JobManager and TaskManagers can be started in various ways: directly on\n-the machines as a [standalone cluster]({% link\n-ops/deployment/cluster_setup.md %}), in containers, or managed by resource\n-frameworks like [YARN]({% link ops/deployment/yarn_setup.md\n-%}) or [Mesos]({% link ops/deployment/mesos.md %}).\n-TaskManagers connect to JobManagers, announcing themselves as available, and\n-are assigned work.\n-\n-### JobManager\n-\n-The _JobManager_ has a number of responsibilities related to coordinating the distributed execution of Flink Applications:\n-it decides when to schedule the next task (or set of tasks), reacts to finished\n-tasks or execution failures, coordinates checkpoints, and coordinates recovery on\n-failures, among others. This process consists of three different components:\n-\n-  * **ResourceManager** \n-\n-    The _ResourceManager_ is responsible for resource de-/allocation and\n-    provisioning in a Flink cluster — it manages **task slots**, which are the\n-    unit of resource scheduling in a Flink cluster (see [TaskManagers](#taskmanagers)).\n-    Flink implements multiple ResourceManagers for different environments and\n-    resource providers such as YARN, Mesos, Kubernetes and standalone\n-    deployments. In a standalone setup, the ResourceManager can only distribute\n-    the slots of available TaskManagers and cannot start new TaskManagers on\n-    its own.  \n-\n-  * **Dispatcher** \n-\n-    The _Dispatcher_ provides a REST interface to submit Flink applications for\n-    execution and starts a new JobMaster for each submitted job. It\n-    also runs the Flink WebUI to provide information about job executions.\n-\n-  * **JobMaster** \n-\n-    A _JobMaster_ is responsible for managing the execution of a single\n-    [JobGraph]({% link concepts/glossary.md %}#logical-graph).\n-    Multiple jobs can run simultaneously in a Flink cluster, each having its\n-    own JobMaster.\n-\n-There is always at least one JobManager. A high-availability setup might have\n-multiple JobManagers, one of which is always the *leader*, and the others are\n-*standby* (see [High Availability (HA)]({% link ops/jobmanager_high_availability.md %})).\n-\n-### TaskManagers\n-\n-The *TaskManagers* (also called *workers*) execute the tasks of a dataflow, and buffer and exchange the data\n-streams.\n-\n-There must always be at least one TaskManager. The smallest unit of resource scheduling in a TaskManager is a task _slot_. The number of task slots in a\n-TaskManager indicates the number of concurrent processing tasks. Note that\n-multiple operators may execute in a task slot (see [Tasks and Operator\n-Chains](#tasks-and-operator-chains)).\n-\n-{% top %}\n-\n-## Tasks and Operator Chains\n-\n-For distributed execution, Flink *chains* operator subtasks together into\n-*tasks*. Each task is executed by one thread.  Chaining operators together into\n-tasks is a useful optimization: it reduces the overhead of thread-to-thread\n-handover and buffering, and increases overall throughput while decreasing\n-latency.  The chaining behavior can be configured; see the [chaining docs]({%\n-link dev/stream/operators/index.md %}#task-chaining-and-resource-groups) for details.\n-\n-The sample dataflow in the figure below is executed with five subtasks, and\n-hence with five parallel threads.\n-\n-<img src=\"{% link /fig/tasks_chains.svg %}\" alt=\"Operator chaining into Tasks\" class=\"offset\" width=\"80%\" />\n-\n-{% top %}\n-\n-## Task Slots and Resources\n-\n-Each worker (TaskManager) is a *JVM process*, and may execute one or more\n-subtasks in separate threads.  To control how many tasks a TaskManager accepts, it\n-has so called **task slots** (at least one).\n-\n-Each *task slot* represents a fixed subset of resources of the TaskManager. A\n-TaskManager with three slots, for example, will dedicate 1/3 of its managed\n-memory to each slot. Slotting the resources means that a subtask will not\n-compete with subtasks from other jobs for managed memory, but instead has a\n-certain amount of reserved managed memory. Note that no CPU isolation happens\n-here; currently slots only separate the managed memory of tasks.\n-\n-By adjusting the number of task slots, users can define how subtasks are\n-isolated from each other.  Having one slot per TaskManager means that each task\n-group runs in a separate JVM (which can be started in a separate container, for\n-example). Having multiple slots means more subtasks share the same JVM. Tasks\n-in the same JVM share TCP connections (via multiplexing) and heartbeat\n-messages. They may also share data sets and data structures, thus reducing the\n-per-task overhead.\n-\n-<img src=\"{% link /fig/tasks_slots.svg %}\" alt=\"A TaskManager with Task Slots and Tasks\" class=\"offset\" width=\"80%\" />\n-\n-By default, Flink allows subtasks to share slots even if they are subtasks of\n-different tasks, so long as they are from the same job. The result is that one\n-slot may hold an entire pipeline of the job. Allowing this *slot sharing* has\n-two main benefits:\n-\n-  - A Flink cluster needs exactly as many task slots as the highest parallelism\n-    used in the job.  No need to calculate how many tasks (with varying\n-    parallelism) a program contains in total.\n-\n-  - It is easier to get better resource utilization. Without slot sharing, the\n-    non-intensive *source/map()* subtasks would block as many resources as the\n-    resource intensive *window* subtasks.  With slot sharing, increasing the\n-    base parallelism in our example from two to six yields full utilization of\n-    the slotted resources, while making sure that the heavy subtasks are fairly\n-    distributed among the TaskManagers.\n-\n-<img src=\"{% link /fig/slot_sharing.svg %}\" alt=\"TaskManagers with shared Task Slots\" class=\"offset\" width=\"80%\" />\n-\n-## Flink Application Execution\n-\n-A _Flink Application_ is any user program that spawns one or multiple Flink\n-jobs from its ``main()`` method. The execution of these jobs can happen in a\n-local JVM (``LocalEnvironment``) or on a remote setup of clusters with multiple\n-machines (``RemoteEnvironment``). For each program, the\n-[``ExecutionEnvironment``]({{ site.javadocs_baseurl }}/api/java/) provides methods to\n-control the job execution (e.g. setting the parallelism) and to interact with\n-the outside world (see [Anatomy of a Flink Program]({%\n-link dev/datastream_api.md %}#anatomy-of-a-flink-program)).\n-\n-The jobs of a Flink Application can either be submitted to a long-running\n-[Flink Session Cluster]({%\n-link concepts/glossary.md %}#flink-session-cluster), a dedicated [Flink Job\n-Cluster]({% link concepts/glossary.md %}#flink-job-cluster), or a\n-[Flink Application Cluster]({%\n-link concepts/glossary.md %}#flink-application-cluster). The difference between\n-these options is mainly related to the cluster’s lifecycle and to resource\n-isolation guarantees.\n-\n-### Flink Session Cluster\n-\n-* **Cluster Lifecycle**: in a Flink Session Cluster, the client connects to a\n-  pre-existing, long-running cluster that can accept multiple job submissions.\n-  Even after all jobs are finished, the cluster (and the JobManager) will\n-  keep running until the session is manually stopped. The lifetime of a Flink\n-  Session Cluster is therefore not bound to the lifetime of any Flink Job.\n-\n-* **Resource Isolation**: TaskManager slots are allocated by the\n-  ResourceManager on job submission and released once the job is finished.\n-  Because all jobs are sharing the same cluster, there is some competition for\n-  cluster resources — like network bandwidth in the submit-job phase. One\n-  limitation of this shared setup is that if one TaskManager crashes, then all\n-  jobs that have tasks running on this TaskManager will fail; in a similar way, if\n-  some fatal error occurs on the JobManager, it will affect all jobs running\n-  in the cluster.\n-\n-* **Other considerations**: having a pre-existing cluster saves a considerable\n-  amount of time applying for resources and starting TaskManagers. This is\n-  important in scenarios where the execution time of jobs is very short and a\n-  high startup time would negatively impact the end-to-end user experience — as\n-  is the case with interactive analysis of short queries, where it is desirable\n-  that jobs can quickly perform computations using existing resources.\n-\n-<div class=\"alert alert-info\"> <strong>Note:</strong> Formerly, a Flink Session Cluster was also known as a Flink Cluster in <i>session mode</i>. </div>\n-\n-### Flink Job Cluster\n-\n-* **Cluster Lifecycle**: in a Flink Job Cluster, the available cluster manager\n-  (like YARN or Kubernetes) is used to spin up a cluster for each submitted job\n-  and this cluster is available to that job only. Here, the client first\n-  requests resources from the cluster manager to start the JobManager and\n-  submits the job to the Dispatcher running inside this process. TaskManagers\n-  are then lazily allocated based on the resource requirements of the job. Once\n-  the job is finished, the Flink Job Cluster is torn down.\n-\n-* **Resource Isolation**: a fatal error in the JobManager only affects the one job running in that Flink Job Cluster.\n-\n-* **Other considerations**: because the ResourceManager has to apply and wait\n-  for external resource management components to start the TaskManager\n-  processes and allocate resources, Flink Job Clusters are more suited to large\n-  jobs that are long-running, have high-stability requirements and are not\n-  sensitive to longer startup times.\n-\n-<div class=\"alert alert-info\"> <strong>Note:</strong> Formerly, a Flink Job Cluster was also known as a Flink Cluster in <i>job (or per-job) mode</i>. </div>\n-\n-### Flink Application Cluster\n-\n-* **Cluster Lifecycle**: a Flink Application Cluster is a dedicated Flink\n-  cluster that only executes jobs from one Flink Application and where the\n-  ``main()`` method runs on the cluster rather than the client. The job\n-  submission is a one-step process: you don’t need to start a Flink cluster\n-  first and then submit a job to the existing cluster session; instead, you\n-  package your application logic and dependencies into a executable job JAR and\n-  the cluster entrypoint (``ApplicationClusterEntryPoint``)\n-  is responsible for calling the ``main()`` method to extract the JobGraph.\n-  This allows you to deploy a Flink Application like any other application on\n-  Kubernetes, for example. The lifetime of a Flink Application Cluster is\n-  therefore bound to the lifetime of the Flink Application.\n-\n-* **Resource Isolation**: in a Flink Application Cluster, the ResourceManager\n-  and Dispatcher are scoped to a single Flink Application, which provides a\n-  better separation of concerns than the Flink Session Cluster.\n-\n-<div class=\"alert alert-info\"> <strong>Note:</strong> A Flink Job Cluster can be seen as a “run-on-client” alternative to Flink Application Clusters. </div>\n-\n-{% top %}"
        },
        {
            "sha": "b63fa78e6b2e2be6d4c6d1ba9be6ec2e467576fa",
            "filename": "docs/concepts/flink-architecture.zh.md",
            "status": "removed",
            "additions": 0,
            "deletions": 252,
            "changes": 252,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/concepts/flink-architecture.zh.md",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/concepts/flink-architecture.zh.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/concepts/flink-architecture.zh.md?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,252 +0,0 @@\n----\n-title: Flink 架构\n-nav-id: flink-architecture\n-nav-pos: 4\n-nav-title: Flink 架构\n-nav-parent_id: concepts\n----\n-<!--\n-Licensed to the Apache Software Foundation (ASF) under one\n-or more contributor license agreements.  See the NOTICE file\n-distributed with this work for additional information\n-regarding copyright ownership.  The ASF licenses this file\n-to you under the Apache License, Version 2.0 (the\n-\"License\"); you may not use this file except in compliance\n-with the License.  You may obtain a copy of the License at\n-\n-  http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing,\n-software distributed under the License is distributed on an\n-\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-KIND, either express or implied.  See the License for the\n-specific language governing permissions and limitations\n-under the License.\n--->\n-\n-Flink is a distributed system and requires effective allocation and management\n-of compute resources in order to execute streaming applications. It integrates\n-with all common cluster resource managers such as [Hadoop\n-YARN](https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/YARN.html),\n-[Apache Mesos](https://mesos.apache.org/) and\n-[Kubernetes](https://kubernetes.io/), but can also be set up to run as a\n-standalone cluster or even as a library.\n-\n-This section contains an overview of Flink’s architecture and describes how its\n-main components interact to execute applications and recover from failures.\n-\n-* This will be replaced by the TOC\n-{:toc}\n-\n-## Anatomy of a Flink Cluster\n-\n-The Flink runtime consists of two types of processes: a _JobManager_ and one or more _TaskManagers_.\n-\n-<img src=\"{% link /fig/processes.svg %}\" alt=\"The processes involved in executing a Flink dataflow\" class=\"offset\" width=\"70%\" />\n-\n-The *Client* is not part of the runtime and program execution, but is used to\n-prepare and send a dataflow to the JobManager.  After that, the client can\n-disconnect (_detached mode_), or stay connected to receive progress reports\n-(_attached mode_). The client runs either as part of the Java/Scala program\n-that triggers the execution, or in the command line process `./bin/flink run\n-...`.\n-\n-The JobManager and TaskManagers can be started in various ways: directly on\n-the machines as a [standalone cluster]({% link\n-ops/deployment/cluster_setup.zh.md %}), in containers, or managed by resource\n-frameworks like [YARN]({% link ops/deployment/yarn_setup.zh.md\n-%}) or [Mesos]({% link ops/deployment/mesos.zh.md %}).\n-TaskManagers connect to JobManagers, announcing themselves as available, and\n-are assigned work.\n-\n-### JobManager\n-\n-The _JobManager_ has a number of responsibilities related to coordinating the distributed execution of Flink Applications:\n-it decides when to schedule the next task (or set of tasks), reacts to finished\n-tasks or execution failures, coordinates checkpoints, and coordinates recovery on\n-failures, among others. This process consists of three different components:\n-\n-  * **ResourceManager** \n-\n-    The _ResourceManager_ is responsible for resource de-/allocation and\n-    provisioning in a Flink cluster — it manages **task slots**, which are the\n-    unit of resource scheduling in a Flink cluster (see [TaskManagers](#taskmanagers)).\n-    Flink implements multiple ResourceManagers for different environments and\n-    resource providers such as YARN, Mesos, Kubernetes and standalone\n-    deployments. In a standalone setup, the ResourceManager can only distribute\n-    the slots of available TaskManagers and cannot start new TaskManagers on\n-    its own.  \n-\n-  * **Dispatcher** \n-\n-    The _Dispatcher_ provides a REST interface to submit Flink applications for\n-    execution and starts a new JobMaster for each submitted job. It\n-    also runs the Flink WebUI to provide information about job executions.\n-\n-  * **JobMaster** \n-\n-    A _JobMaster_ is responsible for managing the execution of a single\n-    [JobGraph]({% link concepts/glossary.zh.md %}#logical-graph).\n-    Multiple jobs can run simultaneously in a Flink cluster, each having its\n-    own JobMaster.\n-\n-There is always at least one JobManager. A high-availability setup might have\n-multiple JobManagers, one of which is always the *leader*, and the others are\n-*standby* (see [High Availability (HA)]({% link ops/jobmanager_high_availability.zh.md %})).\n-\n-### TaskManagers\n-\n-The *TaskManagers* (also called *workers*) execute the tasks of a dataflow, and buffer and exchange the data\n-streams.\n-\n-There must always be at least one TaskManager. The smallest unit of resource scheduling in a TaskManager is a task _slot_. The number of task slots in a\n-TaskManager indicates the number of concurrent processing tasks. Note that\n-multiple operators may execute in a task slot (see [Tasks and Operator\n-Chains](#tasks-and-operator-chains)).\n-\n-{% top %}\n-\n-## Tasks and Operator Chains\n-\n-For distributed execution, Flink *chains* operator subtasks together into\n-*tasks*. Each task is executed by one thread.  Chaining operators together into\n-tasks is a useful optimization: it reduces the overhead of thread-to-thread\n-handover and buffering, and increases overall throughput while decreasing\n-latency.  The chaining behavior can be configured; see the [chaining docs]({%\n-link dev/stream/operators/index.zh.md %}#task-chaining-and-resource-groups) for details.\n-\n-The sample dataflow in the figure below is executed with five subtasks, and\n-hence with five parallel threads.\n-\n-<img src=\"{% link /fig/tasks_chains.svg %}\" alt=\"Operator chaining into Tasks\" class=\"offset\" width=\"80%\" />\n-\n-{% top %}\n-\n-## Task Slots and Resources\n-\n-Each worker (TaskManager) is a *JVM process*, and may execute one or more\n-subtasks in separate threads.  To control how many tasks a TaskManager accepts, it\n-has so called **task slots** (at least one).\n-\n-Each *task slot* represents a fixed subset of resources of the TaskManager. A\n-TaskManager with three slots, for example, will dedicate 1/3 of its managed\n-memory to each slot. Slotting the resources means that a subtask will not\n-compete with subtasks from other jobs for managed memory, but instead has a\n-certain amount of reserved managed memory. Note that no CPU isolation happens\n-here; currently slots only separate the managed memory of tasks.\n-\n-By adjusting the number of task slots, users can define how subtasks are\n-isolated from each other.  Having one slot per TaskManager means that each task\n-group runs in a separate JVM (which can be started in a separate container, for\n-example). Having multiple slots means more subtasks share the same JVM. Tasks\n-in the same JVM share TCP connections (via multiplexing) and heartbeat\n-messages. They may also share data sets and data structures, thus reducing the\n-per-task overhead.\n-\n-<img src=\"{% link /fig/tasks_slots.svg %}\" alt=\"A TaskManager with Task Slots and Tasks\" class=\"offset\" width=\"80%\" />\n-\n-By default, Flink allows subtasks to share slots even if they are subtasks of\n-different tasks, so long as they are from the same job. The result is that one\n-slot may hold an entire pipeline of the job. Allowing this *slot sharing* has\n-two main benefits:\n-\n-  - A Flink cluster needs exactly as many task slots as the highest parallelism\n-    used in the job.  No need to calculate how many tasks (with varying\n-    parallelism) a program contains in total.\n-\n-  - It is easier to get better resource utilization. Without slot sharing, the\n-    non-intensive *source/map()* subtasks would block as many resources as the\n-    resource intensive *window* subtasks.  With slot sharing, increasing the\n-    base parallelism in our example from two to six yields full utilization of\n-    the slotted resources, while making sure that the heavy subtasks are fairly\n-    distributed among the TaskManagers.\n-\n-<img src=\"{% link /fig/slot_sharing.svg %}\" alt=\"TaskManagers with shared Task Slots\" class=\"offset\" width=\"80%\" />\n-\n-## Flink Application Execution\n-\n-A _Flink Application_ is any user program that spawns one or multiple Flink\n-jobs from its ``main()`` method. The execution of these jobs can happen in a\n-local JVM (``LocalEnvironment``) or on a remote setup of clusters with multiple\n-machines (``RemoteEnvironment``). For each program, the\n-[``ExecutionEnvironment``]({{ site.javadocs_baseurl }}/api/java/) provides methods to\n-control the job execution (e.g. setting the parallelism) and to interact with\n-the outside world (see [Anatomy of a Flink Program]({%\n-link dev/datastream_api.zh.md %}#anatomy-of-a-flink-program)).\n-\n-The jobs of a Flink Application can either be submitted to a long-running\n-[Flink Session Cluster]({%\n-link concepts/glossary.zh.md %}#flink-session-cluster), a dedicated [Flink Job\n-Cluster]({% link concepts/glossary.zh.md %}#flink-job-cluster), or a\n-[Flink Application Cluster]({%\n-link concepts/glossary.zh.md %}#flink-application-cluster). The difference between\n-these options is mainly related to the cluster’s lifecycle and to resource\n-isolation guarantees.\n-\n-### Flink Session Cluster\n-\n-* **Cluster Lifecycle**: in a Flink Session Cluster, the client connects to a\n-  pre-existing, long-running cluster that can accept multiple job submissions.\n-  Even after all jobs are finished, the cluster (and the JobManager) will\n-  keep running until the session is manually stopped. The lifetime of a Flink\n-  Session Cluster is therefore not bound to the lifetime of any Flink Job.\n-\n-* **Resource Isolation**: TaskManager slots are allocated by the\n-  ResourceManager on job submission and released once the job is finished.\n-  Because all jobs are sharing the same cluster, there is some competition for\n-  cluster resources — like network bandwidth in the submit-job phase. One\n-  limitation of this shared setup is that if one TaskManager crashes, then all\n-  jobs that have tasks running on this TaskManager will fail; in a similar way, if\n-  some fatal error occurs on the JobManager, it will affect all jobs running\n-  in the cluster.\n-\n-* **Other considerations**: having a pre-existing cluster saves a considerable\n-  amount of time applying for resources and starting TaskManagers. This is\n-  important in scenarios where the execution time of jobs is very short and a\n-  high startup time would negatively impact the end-to-end user experience — as\n-  is the case with interactive analysis of short queries, where it is desirable\n-  that jobs can quickly perform computations using existing resources.\n-\n-<div class=\"alert alert-info\"> <strong>Note:</strong> Formerly, a Flink Session Cluster was also known as a Flink Cluster in <i>session mode</i>. </div>\n-\n-### Flink Job Cluster\n-\n-* **Cluster Lifecycle**: in a Flink Job Cluster, the available cluster manager\n-  (like YARN or Kubernetes) is used to spin up a cluster for each submitted job\n-  and this cluster is available to that job only. Here, the client first\n-  requests resources from the cluster manager to start the JobManager and\n-  submits the job to the Dispatcher running inside this process. TaskManagers\n-  are then lazily allocated based on the resource requirements of the job. Once\n-  the job is finished, the Flink Job Cluster is torn down.\n-\n-* **Resource Isolation**: a fatal error in the JobManager only affects the one job running in that Flink Job Cluster.\n-\n-* **Other considerations**: because the ResourceManager has to apply and wait\n-  for external resource management components to start the TaskManager\n-  processes and allocate resources, Flink Job Clusters are more suited to large\n-  jobs that are long-running, have high-stability requirements and are not\n-  sensitive to longer startup times.\n-\n-<div class=\"alert alert-info\"> <strong>Note:</strong> Formerly, a Flink Job Cluster was also known as a Flink Cluster in <i>job (or per-job) mode</i>. </div>\n-\n-### Flink Application Cluster\n-\n-* **Cluster Lifecycle**: a Flink Application Cluster is a dedicated Flink\n-  cluster that only executes jobs from one Flink Application and where the\n-  ``main()`` method runs on the cluster rather than the client. The job\n-  submission is a one-step process: you don’t need to start a Flink cluster\n-  first and then submit a job to the existing cluster session; instead, you\n-  package your application logic and dependencies into a executable job JAR and\n-  the cluster entrypoint (``ApplicationClusterEntryPoint``)\n-  is responsible for calling the ``main()`` method to extract the JobGraph.\n-  This allows you to deploy a Flink Application like any other application on\n-  Kubernetes, for example. The lifetime of a Flink Application Cluster is\n-  therefore bound to the lifetime of the Flink Application.\n-\n-* **Resource Isolation**: in a Flink Application Cluster, the ResourceManager\n-  and Dispatcher are scoped to a single Flink Application, which provides a\n-  better separation of concerns than the Flink Session Cluster.\n-\n-<div class=\"alert alert-info\"> <strong>Note:</strong> A Flink Job Cluster can be seen as a “run-on-client” alternative to Flink Application Clusters. </div>\n-\n-{% top %}"
        },
        {
            "sha": "c45cf1fc052de83a49a7dd62ee63e8041aa2fb6c",
            "filename": "docs/concepts/glossary.md",
            "status": "removed",
            "additions": 0,
            "deletions": 190,
            "changes": 190,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/concepts/glossary.md",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/concepts/glossary.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/concepts/glossary.md?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,190 +0,0 @@\n----\n-title: Glossary\n-nav-pos: 10\n-nav-title: Glossary\n-nav-parent_id: concepts\n----\n-<!--\n-Licensed to the Apache Software Foundation (ASF) under one\n-or more contributor license agreements.  See the NOTICE file\n-distributed with this work for additional information\n-regarding copyright ownership.  The ASF licenses this file\n-to you under the Apache License, Version 2.0 (the\n-\"License\"); you may not use this file except in compliance\n-with the License.  You may obtain a copy of the License at\n-\n-  http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing,\n-software distributed under the License is distributed on an\n-\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-KIND, either express or implied.  See the License for the\n-specific language governing permissions and limitations\n-under the License.\n--->\n-\n-#### Flink Application Cluster\n-\n-A Flink Application Cluster is a dedicated [Flink Cluster](#flink-cluster) that\n-only executes [Flink Jobs](#flink-job) from one [Flink\n-Application](#flink-application). The lifetime of the [Flink\n-Cluster](#flink-cluster) is bound to the lifetime of the Flink Application.\n-\n-#### Flink Job Cluster\n-\n-A Flink Job Cluster is a dedicated [Flink Cluster](#flink-cluster) that only\n-executes a single [Flink Job](#flink-job). The lifetime of the\n-[Flink Cluster](#flink-cluster) is bound to the lifetime of the Flink Job.\n-\n-#### Flink Cluster\n-\n-A distributed system consisting of (typically) one [JobManager](#flink-jobmanager) and one or more\n-[Flink TaskManager](#flink-taskmanager) processes.\n-\n-#### Event\n-\n-An event is a statement about a change of the state of the domain modelled by the\n-application. Events can be input and/or output of a stream or batch processing application.\n-Events are special types of [records](#Record).\n-\n-#### ExecutionGraph\n-\n-see [Physical Graph](#physical-graph)\n-\n-#### Function\n-\n-Functions are implemented by the user and encapsulate the\n-application logic of a Flink program. Most Functions are wrapped by a corresponding\n-[Operator](#operator).\n-\n-#### Instance\n-\n-The term *instance* is used to describe a specific instance of a specific type (usually\n-[Operator](#operator) or [Function](#function)) during runtime. As Apache Flink is mostly written in\n-Java, this corresponds to the definition of *Instance* or *Object* in Java. In the context of Apache\n-Flink, the term *parallel instance* is also frequently used to emphasize that multiple instances of\n-the same [Operator](#operator) or [Function](#function) type are running in parallel.\n-\n-#### Flink Application\n-\n-A Flink application is a Java Application that submits one or multiple [Flink\n-Jobs](#flink-job) from the `main()` method (or by some other means). Submitting\n-jobs is usually done by calling `execute()` on an execution environment.\n-\n-The jobs of an application can either be submitted to a long running [Flink\n-Session Cluster](#flink-session-cluster), to a dedicated [Flink Application\n-Cluster](#flink-application-cluster), or to a [Flink Job\n-Cluster](#flink-job-cluster).\n-\n-#### Flink Job\n-\n-A Flink Job is the runtime representation of a [logical graph](#logical-graph)\n-(also often called dataflow graph) that is created and submitted by calling\n-`execute()` in a [Flink Application](#flink-application).\n-\n-#### JobGraph\n-\n-see [Logical Graph](#logical-graph)\n-\n-#### Flink JobManager\n-\n-The JobManager is the orchestrator of a [Flink Cluster](#flink-cluster). It contains three distinct\n-components: Flink Resource Manager, Flink Dispatcher and one [Flink JobMaster](#flink-jobmaster)\n-per running [Flink Job](#flink-job).\n-\n-#### Flink JobMaster\n-\n-JobMasters are one of the components running in the [JobManager](#flink-jobmanager). A JobMaster is\n-responsible for supervising the execution of the [Tasks](#task) of a single job.\n-\n-#### Logical Graph\n-\n-A logical graph is a directed graph where the nodes are  [Operators](#operator)\n-and the edges define input/output-relationships of the operators and correspond\n-to data streams or data sets. A logical graph is created by submitting jobs\n-from a [Flink Application](#flink-application).\n-\n-Logical graphs are also often referred to as *dataflow graphs*.\n-\n-#### Managed State\n-\n-Managed State describes application state which has been registered with the framework. For\n-Managed State, Apache Flink will take care about persistence and rescaling among other things.\n-\n-#### Operator\n-\n-Node of a [Logical Graph](#logical-graph). An Operator performs a certain operation, which is\n-usually executed by a [Function](#function). Sources and Sinks are special Operators for data\n-ingestion and data egress.\n-\n-#### Operator Chain\n-\n-An Operator Chain consists of two or more consecutive [Operators](#operator) without any\n-repartitioning in between. Operators within the same Operator Chain forward records to each other\n-directly without going through serialization or Flink's network stack.\n-\n-#### Partition\n-\n-A partition is an independent subset of the overall data stream or data set. A data stream or\n-data set is divided into partitions by assigning each [record](#Record) to one or more partitions.\n-Partitions of data streams or data sets are consumed by [Tasks](#task) during runtime. A\n-transformation which changes the way a data stream or data set is partitioned is often called\n-repartitioning.\n-\n-#### Physical Graph\n-\n-A physical graph is the result of translating a [Logical Graph](#logical-graph) for execution in a\n-distributed runtime. The nodes are [Tasks](#task) and the edges indicate input/output-relationships\n-or [partitions](#partition) of data streams or data sets.\n-\n-#### Record\n-\n-Records are the constituent elements of a data set or data stream. [Operators](#operator) and\n-[Functions](#Function) receive records as input and emit records as output.\n-\n-#### (Runtime) Execution Mode\n-\n-DataStream API programs can be executed in one of two execution modes: `BATCH`\n-or `STREAMING`. See [Execution Mode]({% link dev/datastream_execution_mode.md\n-%}) for more details.\n-\n-#### Flink Session Cluster\n-\n-A long-running [Flink Cluster](#flink-cluster) which accepts multiple [Flink Jobs](#flink-job) for\n-execution. The lifetime of this Flink Cluster is not bound to the lifetime of any Flink Job.\n-Formerly, a Flink Session Cluster was also known as a Flink Cluster in *session mode*. Compare to\n-[Flink Application Cluster](#flink-application-cluster).\n-\n-#### State Backend\n-\n-For stream processing programs, the State Backend of a [Flink Job](#flink-job) determines how its\n-[state](#managed-state) is stored on each TaskManager (Java Heap of TaskManager or (embedded)\n-RocksDB) as well as where it is written upon a checkpoint (Java Heap of\n-[JobManager](#flink-jobmanager) or Filesystem).\n-\n-#### Sub-Task\n-\n-A Sub-Task is a [Task](#task) responsible for processing a [partition](#partition) of\n-the data stream. The term \"Sub-Task\" emphasizes that there are multiple parallel Tasks for the same\n-[Operator](#operator) or [Operator Chain](#operator-chain).\n-\n-#### Task\n-\n-Node of a [Physical Graph](#physical-graph). A task is the basic unit of work, which is executed by\n-Flink's runtime. Tasks encapsulate exactly one parallel instance of an\n-[Operator](#operator) or [Operator Chain](#operator-chain).\n-\n-#### Flink TaskManager\n-\n-TaskManagers are the worker processes of a [Flink Cluster](#flink-cluster). [Tasks](#task) are\n-scheduled to TaskManagers for execution. They communicate with each other to exchange data between\n-subsequent Tasks.\n-\n-#### Transformation\n-\n-A Transformation is applied on one or more data streams or data sets and results in one or more\n-output data streams or data sets. A transformation might change a data stream or data set on a\n-per-record basis, but might also only change its partitioning or perform an aggregation. While\n-[Operators](#operator) and [Functions](#function) are the \"physical\" parts of Flink's API,\n-Transformations are only an API concept. Specifically, most transformations are\n-implemented by certain [Operators](#operator)."
        },
        {
            "sha": "dc78acaeb0ec810d903ac5e02e35293b8ae469c3",
            "filename": "docs/concepts/glossary.zh.md",
            "status": "removed",
            "additions": 0,
            "deletions": 144,
            "changes": 144,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/concepts/glossary.zh.md",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/concepts/glossary.zh.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/concepts/glossary.zh.md?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,144 +0,0 @@\n----\n-title: 词汇表\n-nav-pos: 10\n-nav-title: 词汇表\n-nav-parent_id: concepts\n----\n-<!--\n-Licensed to the Apache Software Foundation (ASF) under one\n-or more contributor license agreements.  See the NOTICE file\n-distributed with this work for additional information\n-regarding copyright ownership.  The ASF licenses this file\n-to you under the Apache License, Version 2.0 (the\n-\"License\"); you may not use this file except in compliance\n-with the License.  You may obtain a copy of the License at\n-\n-  http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing,\n-software distributed under the License is distributed on an\n-\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-KIND, either express or implied.  See the License for the\n-specific language governing permissions and limitations\n-under the License.\n--->\n-\n-#### Flink Application Cluster\n-\n-A Flink Application Cluster is a dedicated [Flink Cluster](#flink-cluster) that\n-only executes [Flink Jobs](#flink-job) from one [Flink\n-Application](#flink-application). The lifetime of the [Flink\n-Cluster](#flink-cluster) is bound to the lifetime of the Flink Application.\n-\n-#### Flink Job Cluster\n-\n-A Flink Job Cluster is a dedicated [Flink Cluster](#flink-cluster) that only\n-executes a single [Flink Job](#flink-job). The lifetime of the\n-[Flink Cluster](#flink-cluster) is bound to the lifetime of the Flink Job.\n-\n-#### Flink Cluster\n-\n-一般情况下，Flink 集群是由一个 [Flink JobManager](#flink-jobmanager) 和一个或多个 [Flink TaskManager](#flink-taskmanager) 进程组成的分布式系统。\n-\n-#### Event\n-\n-Event 是对应用程序建模的域的状态更改的声明。它可以同时为流或批处理应用程序的 input 和 output，也可以单独是 input 或者 output 中的一种。Event 是特殊类型的 [Record](#record)。\n-\n-#### ExecutionGraph\n-\n-见 [Physical Graph](#physical-graph)。\n-\n-#### Function\n-\n-Function 是由用户实现的，并封装了 Flink 程序的应用程序逻辑。大多数 Function 都由相应的 [Operator](#operator) 封装。\n-\n-#### Instance\n-\n-Instance 常用于描述运行时的特定类型(通常是 [Operator](#operator) 或者 [Function](#function))的一个具体实例。由于 Apache Flink 主要是用 Java 编写的，所以，这与 Java 中的 *Instance* 或 *Object* 的定义相对应。在 Apache Flink 的上下文中，*parallel instance* 也常用于强调同一 [Operator](#operator) 或者 [Function](#function) 的多个 instance 以并行的方式运行。\n-\n-#### Flink Application\n-\n-A Flink application is a Java Application that submits one or multiple [Flink\n-Jobs](#flink-job) from the `main()` method (or by some other means). Submitting\n-jobs is usually done by calling `execute()` on an execution environment.\n-\n-The jobs of an application can either be submitted to a long running [Flink\n-Session Cluster](#flink-session-cluster), to a dedicated [Flink Application\n-Cluster](#flink-application-cluster), or to a [Flink Job\n-Cluster](#flink-job-cluster).\n-\n-#### Flink Job\n-\n-A Flink Job is the runtime representation of a [logical graph](#logical-graph)\n-(also often called dataflow graph) that is created and submitted by calling\n-`execute()` in a [Flink Application](#flink-application).\n-\n-#### JobGraph\n-\n-见 [Logical Graph](#logical-graph)。\n-\n-#### Flink JobManager\n-\n-Flink JobManager 是 [Flink Cluster](#flink-cluster) 的主节点。它包含三个不同的组件：Flink Resource Manager、Flink Dispatcher、运行每个 [Flink Job](#flink-job) 的 [Flink JobMaster](#flink-jobmaster)。 \n-\n-\n-#### Flink JobMaster\n-\n-JobMaster 是在 [Flink JobManager](#flink-jobmanager) 运行中的组件之一。JobManager 负责监督单个作业 [Task](#task) 的执行。以前，整个 [Flink JobManager](#flink-jobmanager) 都叫做 JobManager。\n-\n-#### Logical Graph\n-\n-A logical graph is a directed graph where the nodes are  [Operators](#operator)\n-and the edges define input/output-relationships of the operators and correspond\n-to data streams or data sets. A logical graph is created by submitting jobs\n-from a [Flink Application](#flink-application).\n-\n-Logical graphs are also often referred to as *dataflow graphs*.\n-\n-#### Managed State\n-\n-Managed State 描述了已在框架中注册的应用程序的托管状态。对于托管状态，Apache Flink 会负责持久化和重伸缩等事宜。\n-\n-#### Operator\n-\n-[Logical Graph](#logical-graph) 的节点。算子执行某种操作，该操作通常由 [Function](#function) 执行。Source 和 Sink 是数据输入和数据输出的特殊算子。\n-\n-#### Operator Chain\n-\n-算子链由两个或多个连续的 [Operator](#operator) 组成，两者之间没有任何的重新分区。同一算子链内的算子可以彼此直接传递 record，而无需通过序列化或 Flink 的网络栈。\n-\n-#### Partition\n-\n-分区是整个数据流或数据集的独立子集。通过将每个 [Record](#record) 分配给一个或多个分区，来把数据流或数据集划分为多个分区。在运行期间，[Task](#task) 会消费数据流或数据集的分区。改变数据流或数据集分区方式的转换通常称为重分区。\n-\n-#### Physical Graph\n-\n-Physical graph 是一个在分布式运行时，把 [Logical Graph](#logical-graph) 转换为可执行的结果。节点是 [Task](#task)，边表示数据流或数据集的输入/输出关系或 [partition](#partition)。\n-\n-#### Record\n-\n-Record 是数据集或数据流的组成元素。[Operator](#operator) 和 [Function](#Function)接收 record 作为输入，并将 record 作为输出发出。\n-\n-#### Flink Session Cluster\n-\n-长时间运行的 [Flink Cluster](#flink-cluster)，它可以接受多个 [Flink Job](#flink-job) 的执行。此 [Flink Cluster](#flink-cluster) 的生命周期不受任何 [Flink Job](#flink-job) 生命周期的约束限制。以前，Flink Session Cluster 也称为 *session mode* 的 [Flink Cluster](#flink-cluster)，和 [Flink Application Cluster](#flink-application-cluster) 相对应。\n-\n-#### State Backend\n-\n-对于流处理程序，[Flink Job](#flink-job) 的 State Backend 决定了其 [state](#managed-state) 是如何存储在每个 TaskManager 上的（ TaskManager 的 Java 堆栈或嵌入式 RocksDB），以及它在 checkpoint 时的写入位置（ [Flink JobManager](#flink-jobmanager) 的 Java 堆或者 Filesystem）。\n-\n-#### Sub-Task\n-\n-Sub-Task 是负责处理数据流 [Partition](#partition) 的 [Task](#task)。\"Sub-Task\"强调的是同一个 [Operator](#operator) 或者 [Operator Chain](#operator-chain) 具有多个并行的 Task 。\n-\n-#### Task\n-\n-Task 是 [Physical Graph](#physical-graph) 的节点。它是基本的工作单元，由 Flink 的 runtime 来执行。Task 正好封装了一个 [Operator](#operator) 或者 [Operator Chain](#operator-chain) 的 *parallel instance*。 \n-\n-#### Flink TaskManager\n-\n-TaskManager 是 [Flink Cluster](#flink-cluster) 的工作进程。[Task](#task) 被调度到 TaskManager 上执行。TaskManager 相互通信，只为在后续的 Task 之间交换数据。\n-\n-#### Transformation\n-\n-Transformation 应用于一个或多个数据流或数据集，并产生一个或多个输出数据流或数据集。Transformation 可能会在每个记录的基础上更改数据流或数据集，但也可以只更改其分区或执行聚合。虽然 [Operator](#operator) 和 [Function](#function) 是 Flink API 的“物理”部分，但 Transformation 只是一个 API 概念。具体来说，大多数（但不是全部）Transformation 是由某些 [Operator](#operator) 实现的。"
        },
        {
            "sha": "c17113d8fb0c1b45ccc278b81efc68998017facf",
            "filename": "docs/concepts/index.md",
            "status": "removed",
            "additions": 0,
            "deletions": 89,
            "changes": 89,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/concepts/index.md",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/concepts/index.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/concepts/index.md?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,89 +0,0 @@\n----\n-title: Concepts\n-nav-id: concepts\n-nav-pos: 3\n-nav-title: '<i class=\"fa fa-map-o title appetizer\" aria-hidden=\"true\"></i> Concepts'\n-nav-parent_id: root\n-nav-show_overview: true\n-permalink: /concepts/index.html\n----\n-<!--\n-Licensed to the Apache Software Foundation (ASF) under one\n-or more contributor license agreements.  See the NOTICE file\n-distributed with this work for additional information\n-regarding copyright ownership.  The ASF licenses this file\n-to you under the Apache License, Version 2.0 (the\n-\"License\"); you may not use this file except in compliance\n-with the License.  You may obtain a copy of the License at\n-\n-  http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing,\n-software distributed under the License is distributed on an\n-\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-KIND, either express or implied.  See the License for the\n-specific language governing permissions and limitations\n-under the License.\n--->\n-\n-The [Hands-on Training]({% link learn-flink/index.md %}) explains the basic concepts\n-of stateful and timely stream processing that underlie Flink's APIs, and provides examples of how\n-these mechanisms are used in applications. Stateful stream processing is introduced in the context\n-of [Data Pipelines & ETL]({% link learn-flink/etl.md %}#stateful-transformations)\n-and is further developed in the section on [Fault Tolerance]({% link learn-flink/fault_tolerance.md %}). Timely stream processing is introduced in the section on\n-[Streaming Analytics]({% link learn-flink/streaming_analytics.md %}).\n-\n-This _Concepts in Depth_ section provides a deeper understanding of how Flink's architecture and runtime \n-implement these concepts.\n-\n-## Flink's APIs\n-\n-Flink offers different levels of abstraction for developing streaming/batch applications.\n-\n-<img src=\"{% link /fig/levels_of_abstraction.svg %}\" alt=\"Programming levels of abstraction\" class=\"offset\" width=\"80%\" />\n-\n-  - The lowest level abstraction simply offers **stateful and timely stream processing**. It is\n-    embedded into the [DataStream API]({% link dev/datastream_api.md %}) via the [Process\n-    Function]({% link dev/stream/operators/process_function.md %}). It allows\n-    users to freely process events from one or more streams, and provides consistent, fault tolerant\n-    *state*. In addition, users can register event time and processing time callbacks, allowing\n-    programs to realize sophisticated computations.\n-\n-  - In practice, many applications do not need the low-level\n-    abstractions described above, and can instead program against the **Core APIs**: the\n-    [DataStream API]({% link dev/datastream_api.md %})\n-    (bounded/unbounded streams) and the [DataSet API]({% link\n-    dev/batch/index.md %}) (bounded data sets). These fluent APIs offer the\n-    common building blocks for data processing, like various forms of\n-    user-specified transformations, joins, aggregations, windows, state, etc.\n-    Data types processed in these APIs are represented as classes in the\n-    respective programming languages.\n-\n-    The low level *Process Function* integrates with the *DataStream API*,\n-    making it possible to use the lower-level abstraction on an as-needed basis. \n-    The *DataSet API* offers additional primitives on bounded data sets,\n-    like loops/iterations.\n-\n-  - The **Table API** is a declarative DSL centered around *tables*, which may\n-    be dynamically changing tables (when representing streams).  The [Table\n-    API]({% link dev/table/index.md %}) follows the\n-    (extended) relational model: Tables have a schema attached (similar to\n-    tables in relational databases) and the API offers comparable operations,\n-    such as select, project, join, group-by, aggregate, etc.  Table API\n-    programs declaratively define *what logical operation should be done*\n-    rather than specifying exactly *how the code for the operation looks*.\n-    Though the Table API is extensible by various types of user-defined\n-    functions, it is less expressive than the *Core APIs*, and more concise to\n-    use (less code to write).  In addition, Table API programs also go through\n-    an optimizer that applies optimization rules before execution.\n-\n-    One can seamlessly convert between tables and *DataStream*/*DataSet*,\n-    allowing programs to mix the *Table API* with the *DataStream* and\n-    *DataSet* APIs.\n-\n-  - The highest level abstraction offered by Flink is **SQL**. This abstraction\n-    is similar to the *Table API* both in semantics and expressiveness, but\n-    represents programs as SQL query expressions.  The [SQL](\n-    {% link dev/table/index.md %}#sql) abstraction closely interacts with the\n-    Table API, and SQL queries can be executed over tables defined in the\n-    *Table API*."
        },
        {
            "sha": "a6efcf294e49d0002a9362b28a985280491721f7",
            "filename": "docs/concepts/index.zh.md",
            "status": "removed",
            "additions": 0,
            "deletions": 49,
            "changes": 49,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/concepts/index.zh.md",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/concepts/index.zh.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/concepts/index.zh.md?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,49 +0,0 @@\n----\n-title: 概念透析\n-nav-id: concepts\n-nav-pos: 3\n-nav-title: '<i class=\"fa fa-map-o title appetizer\" aria-hidden=\"true\"></i> 概念透析'\n-nav-parent_id: root\n-nav-show_overview: true\n-permalink: /concepts/index.html\n----\n-<!--\n-Licensed to the Apache Software Foundation (ASF) under one\n-or more contributor license agreements.  See the NOTICE file\n-distributed with this work for additional information\n-regarding copyright ownership.  The ASF licenses this file\n-to you under the Apache License, Version 2.0 (the\n-\"License\"); you may not use this file except in compliance\n-with the License.  You may obtain a copy of the License at\n-\n-  http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing,\n-software distributed under the License is distributed on an\n-\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-KIND, either express or implied.  See the License for the\n-specific language governing permissions and limitations\n-under the License.\n--->\n-\n-[实践练习]({% link learn-flink/index.zh.md %})章节介绍了作为 Flink API 根基的有状态实时流处理的基本概念，并且举例说明了如何在 Flink 应用中使用这些机制。其中 [Data Pipelines & ETL]({% link learn-flink/etl.zh.md %}#stateful-transformations) 小节介绍了有状态流处理的概念，并且在 [Fault Tolerance]({% link learn-flink/fault_tolerance.zh.md %}) 小节中进行了深入介绍。[Streaming Analytics]({% link learn-flink/streaming_analytics.zh.md %}) 小节介绍了实时流处理的概念。\n-\n-本章将深入分析 Flink 分布式运行时架构如何实现这些概念。\n-\n-## Flink 中的 API\n-\n-Flink 为流式/批式处理应用程序的开发提供了不同级别的抽象。\n-\n-<img src=\"{% link /fig/levels_of_abstraction.svg %}\" alt=\"Programming levels of abstraction\" class=\"offset\" width=\"80%\" />\n-\n-  - Flink API 最底层的抽象为**有状态实时流处理**。其抽象实现是 [Process Function]({% link dev/stream/operators/process_function.zh.md %})，并且 **Process Function** 被 Flink 框架集成到了 [DataStream API]({% link dev/datastream_api.zh.md %}) 中来为我们使用。它允许用户在应用程序中自由地处理来自单流或多流的事件（数据），并提供具有全局一致性和容错保障的*状态*。此外，用户可以在此层抽象中注册事件时间（event time）和处理时间（processing time）回调方法，从而允许程序可以实现复杂计算。\n-\n-  - Flink API 第二层抽象是 **Core APIs**。实际上，许多应用程序不需要使用到上述最底层抽象的 API，而是可以使用 **Core APIs** 进行编程：其中包含 [DataStream API]({% link dev/datastream_api.zh.md %})（应用于有界/无界数据流场景）和 [DataSet API]({% link dev/batch/index.zh.md %})（应用于有界数据集场景）两部分。Core APIs 提供的流式 API（Fluent API）为数据处理提供了通用的模块组件，例如各种形式的用户自定义转换（transformations）、联接（joins）、聚合（aggregations）、窗口（windows）和状态（state）操作等。此层 API 中处理的数据类型在每种编程语言中都有其对应的类。\n-\n-    *Process Function* 这类底层抽象和 *DataStream API* 的相互集成使得用户可以选择使用更底层的抽象 API 来实现自己的需求。*DataSet API* 还额外提供了一些原语，比如循环/迭代（loop/iteration）操作。\n-\n-  - Flink API 第三层抽象是 **Table API**。**Table API** 是以表（Table）为中心的声明式编程（DSL）API，例如在流式数据场景下，它可以表示一张正在动态改变的表。[Table API]({% link dev/table/index.zh.md %}) 遵循（扩展）关系模型：即表拥有 schema（类似于关系型数据库中的 schema），并且 Table API 也提供了类似于关系模型中的操作，比如 select、project、join、group-by 和 aggregate 等。Table API 程序是以声明的方式定义*应执行的逻辑操作*，而不是确切地指定程序*应该执行的代码*。尽管 Table API 使用起来很简洁并且可以由各种类型的用户自定义函数扩展功能，但还是比 Core API 的表达能力差。此外，Table API 程序在执行之前还会使用优化器中的优化规则对用户编写的表达式进行优化。\n-\n-    表和 *DataStream*/*DataSet* 可以进行无缝切换，Flink 允许用户在编写应用程序时将 *Table API* 与 *DataStream*/*DataSet* API 混合使用。\n-\n-  - Flink API 最顶层抽象是 **SQL**。这层抽象在语义和程序表达式上都类似于 *Table API*，但是其程序实现都是 SQL 查询表达式。[SQL]({% link dev/table/index.zh.md %}#sql) 抽象与 Table API 抽象之间的关联是非常紧密的，并且 SQL 查询语句可以在 *Table API* 中定义的表上执行。"
        },
        {
            "sha": "875bb0d69569fa0344c48911f766d80007023e08",
            "filename": "docs/concepts/stateful-stream-processing.md",
            "status": "removed",
            "additions": 0,
            "deletions": 370,
            "changes": 370,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/concepts/stateful-stream-processing.md",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/concepts/stateful-stream-processing.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/concepts/stateful-stream-processing.md?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,370 +0,0 @@\n----\n-title: Stateful Stream Processing\n-nav-id: stateful-stream-processing\n-nav-pos: 2\n-nav-title: Stateful Stream Processing\n-nav-parent_id: concepts\n----\n-<!--\n-Licensed to the Apache Software Foundation (ASF) under one\n-or more contributor license agreements.  See the NOTICE file\n-distributed with this work for additional information\n-regarding copyright ownership.  The ASF licenses this file\n-to you under the Apache License, Version 2.0 (the\n-\"License\"); you may not use this file except in compliance\n-with the License.  You may obtain a copy of the License at\n-\n-  http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing,\n-software distributed under the License is distributed on an\n-\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-KIND, either express or implied.  See the License for the\n-specific language governing permissions and limitations\n-under the License.\n--->\n-\n-* This will be replaced by the TOC\n-{:toc}\n-\n-## What is State?\n-\n-While many operations in a dataflow simply look at one individual *event at a\n-time* (for example an event parser), some operations remember information\n-across multiple events (for example window operators). These operations are\n-called **stateful**.\n-\n-Some examples of stateful operations:\n-\n-  - When an application searches for certain event patterns, the state will\n-    store the sequence of events encountered so far.\n-  - When aggregating events per minute/hour/day, the state holds the pending\n-    aggregates.\n-  - When training a machine learning model over a stream of data points, the\n-    state holds the current version of the model parameters.\n-  - When historic data needs to be managed, the state allows efficient access\n-    to events that occurred in the past.\n-\n-Flink needs to be aware of the state in order to make it fault tolerant using\n-[checkpoints]({% link dev/stream/state/checkpointing.md %})\n-and [savepoints]({%link ops/state/savepoints.md %}).\n-\n-Knowledge about the state also allows for rescaling Flink applications, meaning\n-that Flink takes care of redistributing state across parallel instances.\n-\n-[Queryable state]({% link dev/stream/state/queryable_state.md\n-%}) allows you to access state from outside of Flink during runtime.\n-\n-When working with state, it might also be useful to read about [Flink's state\n-backends]({% link ops/state/state_backends.md %}). Flink\n-provides different state backends that specify how and where state is stored.\n-\n-{% top %}\n-\n-## Keyed State\n-\n-Keyed state is maintained in what can be thought of as an embedded key/value\n-store.  The state is partitioned and distributed strictly together with the\n-streams that are read by the stateful operators. Hence, access to the key/value\n-state is only possible on *keyed streams*, i.e. after a keyed/partitioned data\n-exchange, and is restricted to the values associated with the current event's\n-key. Aligning the keys of streams and state makes sure that all state updates\n-are local operations, guaranteeing consistency without transaction overhead.\n-This alignment also allows Flink to redistribute the state and adjust the\n-stream partitioning transparently.\n-\n-<img src=\"{% link /fig/state_partitioning.svg %}\" alt=\"State and Partitioning\" class=\"offset\" width=\"50%\" />\n-\n-Keyed State is further organized into so-called *Key Groups*. Key Groups are\n-the atomic unit by which Flink can redistribute Keyed State; there are exactly\n-as many Key Groups as the defined maximum parallelism.  During execution each\n-parallel instance of a keyed operator works with the keys for one or more Key\n-Groups.\n-\n-## State Persistence\n-\n-Flink implements fault tolerance using a combination of **stream replay** and\n-**checkpointing**. A checkpoint marks a specific point in each of the\n-input streams along with the corresponding state for each of the operators. A\n-streaming dataflow can be resumed from a checkpoint while maintaining\n-consistency *(exactly-once processing semantics)* by restoring the state of the\n-operators and replaying the records from the point of the checkpoint.\n-\n-The checkpoint interval is a means of trading off the overhead of fault\n-tolerance during execution with the recovery time (the number of records that\n-need to be replayed).\n-\n-The fault tolerance mechanism continuously draws snapshots of the distributed\n-streaming data flow. For streaming applications with small state, these\n-snapshots are very light-weight and can be drawn frequently without much impact\n-on performance.  The state of the streaming applications is stored at a\n-configurable place, usually in a distributed file system.\n-\n-In case of a program failure (due to machine-, network-, or software failure),\n-Flink stops the distributed streaming dataflow.  The system then restarts the\n-operators and resets them to the latest successful checkpoint. The input\n-streams are reset to the point of the state snapshot. Any records that are\n-processed as part of the restarted parallel dataflow are guaranteed to not have\n-affected the previously checkpointed state.\n-\n-{% info Note %} By default, checkpointing is disabled. See [Checkpointing]({%\n-link dev/stream/state/checkpointing.md %}) for details on how to enable and\n-configure checkpointing.\n-\n-{% info Note %} For this mechanism to realize its full guarantees, the data\n-stream source (such as message queue or broker) needs to be able to rewind the\n-stream to a defined recent point. [Apache Kafka](http://kafka.apache.org) has\n-this ability and Flink's connector to Kafka exploits this. See [Fault\n-Tolerance Guarantees of Data Sources and Sinks]({% link\n-dev/connectors/guarantees.md %}) for more information about the guarantees\n-provided by Flink's connectors.\n-\n-{% info Note %} Because Flink's checkpoints are realized through distributed\n-snapshots, we use the words *snapshot* and *checkpoint* interchangeably. Often\n-we also use the term *snapshot* to mean either *checkpoint* or *savepoint*.\n-\n-### Checkpointing\n-\n-The central part of Flink's fault tolerance mechanism is drawing consistent\n-snapshots of the distributed data stream and operator state.  These snapshots\n-act as consistent checkpoints to which the system can fall back in case of a\n-failure. Flink's mechanism for drawing these snapshots is described in\n-\"[Lightweight Asynchronous Snapshots for Distributed\n-Dataflows](http://arxiv.org/abs/1506.08603)\". It is inspired by the standard\n-[Chandy-Lamport\n-algorithm](http://research.microsoft.com/en-us/um/people/lamport/pubs/chandy.pdf)\n-for distributed snapshots and is specifically tailored to Flink's execution\n-model.\n-\n-Keep in mind that everything to do with checkpointing can be done\n-asynchronously. The checkpoint barriers don't travel in lock step and\n-operations can asynchronously snapshot their state.\n-\n-Since Flink 1.11, checkpoints can be taken with or without alignment. In this \n-section, we describe aligned checkpoints first.\n-\n-#### Barriers\n-\n-A core element in Flink's distributed snapshotting are the *stream barriers*.\n-These barriers are injected into the data stream and flow with the records as\n-part of the data stream. Barriers never overtake records, they flow strictly in\n-line.  A barrier separates the records in the data stream into the set of\n-records that goes into the current snapshot, and the records that go into the\n-next snapshot. Each barrier carries the ID of the snapshot whose records it\n-pushed in front of it. Barriers do not interrupt the flow of the stream and are\n-hence very lightweight. Multiple barriers from different snapshots can be in\n-the stream at the same time, which means that various snapshots may happen\n-concurrently.\n-\n-<div style=\"text-align: center\">\n-  <img src=\"{% link /fig/stream_barriers.svg %}\" alt=\"Checkpoint barriers in data streams\" style=\"width:60%; padding-top:10px; padding-bottom:10px;\" />\n-</div>\n-\n-Stream barriers are injected into the parallel data flow at the stream sources.\n-The point where the barriers for snapshot *n* are injected (let's call it\n-<i>S<sub>n</sub></i>) is the position in the source stream up to which the\n-snapshot covers the data. For example, in Apache Kafka, this position would be\n-the last record's offset in the partition. This position <i>S<sub>n</sub></i>\n-is reported to the *checkpoint coordinator* (Flink's JobManager).\n-\n-The barriers then flow downstream. When an intermediate operator has received a\n-barrier for snapshot *n* from all of its input streams, it emits a barrier for\n-snapshot *n* into all of its outgoing streams. Once a sink operator (the end of\n-a streaming DAG) has received the barrier *n* from all of its input streams, it\n-acknowledges that snapshot *n* to the checkpoint coordinator. After all sinks\n-have acknowledged a snapshot, it is considered completed.\n-\n-Once snapshot *n* has been completed, the job will never again ask the source\n-for records from before <i>S<sub>n</sub></i>, since at that point these records\n-(and their descendant records) will have passed through the entire data flow\n-topology.\n-\n-<div style=\"text-align: center\">\n-  <img src=\"{% link /fig/stream_aligning.svg %}\" alt=\"Aligning data streams at operators with multiple inputs\" style=\"width:100%; padding-top:10px; padding-bottom:10px;\" />\n-</div>\n-\n-Operators that receive more than one input stream need to *align* the input\n-streams on the snapshot barriers. The figure above illustrates this:\n-\n-  - As soon as the operator receives snapshot barrier *n* from an incoming\n-    stream, it cannot process any further records from that stream until it has\n-    received the barrier *n* from the other inputs as well. Otherwise, it would\n-    mix records that belong to snapshot *n* and with records that belong to\n-    snapshot *n+1*.\n-  - Once the last stream has received barrier *n*, the operator emits all\n-    pending outgoing records, and then emits snapshot *n* barriers itself.\n-  - It snapshots the state and resumes processing records from all input streams,\n-    processing records from the input buffers before processing the records\n-    from the streams.\n-  - Finally, the operator writes the state asynchronously to the state backend.\n-  \n-Note that the alignment is needed for all operators with multiple inputs and for \n-operators after a shuffle when they consume output streams of multiple upstream \n-subtasks.\n-\n-#### Snapshotting Operator State\n-\n-When operators contain any form of *state*, this state must be part of the\n-snapshots as well.\n-\n-Operators snapshot their state at the point in time when they have received all\n-snapshot barriers from their input streams, and before emitting the barriers to\n-their output streams. At that point, all updates to the state from records\n-before the barriers have been made, and no updates that depend on records\n-from after the barriers have been applied. Because the state of a snapshot may\n-be large, it is stored in a configurable *[state backend]({%\n-link ops/state/state_backends.md %})*. By default, this is the JobManager's\n-memory, but for production use a distributed reliable storage should be\n-configured (such as HDFS). After the state has been stored, the operator\n-acknowledges the checkpoint, emits the snapshot barrier into the output\n-streams, and proceeds.\n-\n-The resulting snapshot now contains:\n-\n-  - For each parallel stream data source, the offset/position in the stream\n-    when the snapshot was started\n-  - For each operator, a pointer to the state that was stored as part of the\n-    snapshot\n-\n-<div style=\"text-align: center\">\n-  <img src=\"{% link /fig/checkpointing.svg %}\" alt=\"Illustration of the Checkpointing Mechanism\" style=\"width:100%; padding-top:10px; padding-bottom:10px;\" />\n-</div>\n-\n-#### Recovery\n-\n-Recovery under this mechanism is straightforward: Upon a failure, Flink selects\n-the latest completed checkpoint *k*. The system then re-deploys the entire\n-distributed dataflow, and gives each operator the state that was snapshotted as\n-part of checkpoint *k*. The sources are set to start reading the stream from\n-position <i>S<sub>k</sub></i>. For example in Apache Kafka, that means telling\n-the consumer to start fetching from offset <i>S<sub>k</sub></i>.\n-\n-If state was snapshotted incrementally, the operators start with the state of\n-the latest full snapshot and then apply a series of incremental snapshot\n-updates to that state.\n-\n-See [Restart Strategies]({% link dev/task_failure_recovery.md\n-%}#restart-strategies) for more information.\n-\n-### Unaligned Checkpointing\n-\n-Starting with Flink 1.11, checkpointing can also be performed unaligned.\n-The basic idea is that checkpoints can overtake all in-flight data as long as \n-the in-flight data becomes part of the operator state.\n-\n-Note that this approach is actually closer to the [Chandy-Lamport algorithm\n-](http://research.microsoft.com/en-us/um/people/lamport/pubs/chandy.pdf), but\n-Flink still inserts the barrier in the sources to avoid overloading the\n-checkpoint coordinator.\n-\n-<div style=\"text-align: center\">\n-  <img src=\"{% link fig/stream_unaligning.svg %}\" alt=\"Unaligned checkpointing\" style=\"width:100%; padding-top:10px; padding-bottom:10px;\" />\n-</div>\n-\n-The figure depicts how an operator handles unaligned checkpoint barriers:\n-\n-- The operator reacts on the first barrier that is stored in its input buffers.\n-- It immediately forwards the barrier to the downstream operator by adding it \n-  to the end of the output buffers.\n-- The operator marks all overtaken records to be stored asynchronously and \n-  creates a snapshot of its own state.\n- \n-Consequently, the operator only briefly stops the processing of input to mark\n-the buffers, forwards the barrier, and creates the snapshot of the other state.\n-  \n-Unaligned checkpointing ensures that barriers are arriving at the sink as fast \n-as possible. It's especially suited for applications with at least one slow \n-moving data path, where alignment times can reach hours. However, since it's\n-adding additional I/O pressure, it doesn't help when the I/O to the state \n-backends is the bottleneck. See the more in-depth discussion in \n-[ops]({% link ops/state/checkpoints.md %}#unaligned-checkpoints)\n-for other limitations.\n-\n-Note that savepoints will always be aligned.\n-\n-#### Unaligned Recovery\n-\n-Operators first recover the in-flight data before starting processing any data\n-from upstream operators in unaligned checkpointing. Aside from that, it \n-performs the same steps as during [recovery of aligned checkpoints](#recovery).\n-\n-### State Backends\n-\n-The exact data structures in which the key/values indexes are stored depends on\n-the chosen [state backend]({% link\n-ops/state/state_backends.md %}). One state backend stores data in an in-memory\n-hash map, another state backend uses [RocksDB](http://rocksdb.org) as the\n-key/value store.  In addition to defining the data structure that holds the\n-state, the state backends also implement the logic to take a point-in-time\n-snapshot of the key/value state and store that snapshot as part of a\n-checkpoint. State backends can be configured without changing your application\n-logic.\n-\n-<img src=\"{% link /fig/checkpoints.svg %}\" alt=\"checkpoints and snapshots\" class=\"offset\" width=\"60%\" />\n-\n-{% top %}\n-\n-### Savepoints\n-\n-All programs that use checkpointing can resume execution from a **savepoint**.\n-Savepoints allow both updating your programs and your Flink cluster without\n-losing any state.\n-\n-[Savepoints]({% link ops/state/savepoints.md %}) are\n-**manually triggered checkpoints**, which take a snapshot of the program and\n-write it out to a state backend. They rely on the regular checkpointing\n-mechanism for this.\n-\n-Savepoints are similar to checkpoints except that they are\n-**triggered by the user** and **don't automatically expire** when newer\n-checkpoints are completed.\n-\n-{% top %}\n-\n-### Exactly Once vs. At Least Once\n-\n-The alignment step may add latency to the streaming program. Usually, this\n-extra latency is on the order of a few milliseconds, but we have seen cases\n-where the latency of some outliers increased noticeably. For applications that\n-require consistently super low latencies (few milliseconds) for all records,\n-Flink has a switch to skip the stream alignment during a checkpoint. Checkpoint\n-snapshots are still drawn as soon as an operator has seen the checkpoint\n-barrier from each input.\n-\n-When the alignment is skipped, an operator keeps processing all inputs, even\n-after some checkpoint barriers for checkpoint *n* arrived. That way, the\n-operator also processes elements that belong to checkpoint *n+1* before the\n-state snapshot for checkpoint *n* was taken.  On a restore, these records will\n-occur as duplicates, because they are both included in the state snapshot of\n-checkpoint *n*, and will be replayed as part of the data after checkpoint *n*.\n-\n-{% info Note %} Alignment happens only for operators with multiple predecessors\n-(joins) as well as operators with multiple senders (after a stream\n-repartitioning/shuffle).  Because of that, dataflows with only embarrassingly\n-parallel streaming operations (`map()`, `flatMap()`, `filter()`, ...) actually\n-give *exactly once* guarantees even in *at least once* mode.\n-\n-{% top %}\n-\n-## State and Fault Tolerance in Batch Programs\n-\n-Flink executes [batch programs]({% link dev/batch/index.md %}) as a special case of\n-streaming programs, where the streams are bounded (finite number of elements).\n-A *DataSet* is treated internally as a stream of data. The concepts above thus\n-apply to batch programs in the same way as well as they apply to streaming\n-programs, with minor exceptions:\n-\n-  - [Fault tolerance for batch programs](../dev/batch/fault_tolerance.html)\n-    does not use checkpointing.  Recovery happens by fully replaying the\n-    streams.  That is possible, because inputs are bounded. This pushes the\n-    cost more towards the recovery, but makes the regular processing cheaper,\n-    because it avoids checkpoints.\n-\n-  - Stateful operations in the DataSet API use simplified in-memory/out-of-core\n-    data structures, rather than key/value indexes.\n-\n-  - The DataSet API introduces special synchronized (superstep-based)\n-    iterations, which are only possible on bounded streams. For details, check\n-    out the [iteration docs]({% link dev/batch/iterations.md %}).\n-\n-{% top %}"
        },
        {
            "sha": "88b3056689271d3e0187fd2a1df2c27bf0bf77b1",
            "filename": "docs/concepts/stateful-stream-processing.zh.md",
            "status": "removed",
            "additions": 0,
            "deletions": 324,
            "changes": 324,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/concepts/stateful-stream-processing.zh.md",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/concepts/stateful-stream-processing.zh.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/concepts/stateful-stream-processing.zh.md?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,324 +0,0 @@\n----\n-title: 有状态流处理\n-nav-id: stateful-stream-processing\n-nav-pos: 2\n-nav-title: 有状态流处理\n-nav-parent_id: concepts\n----\n-<!--\n-Licensed to the Apache Software Foundation (ASF) under one\n-or more contributor license agreements.  See the NOTICE file\n-distributed with this work for additional information\n-regarding copyright ownership.  The ASF licenses this file\n-to you under the Apache License, Version 2.0 (the\n-\"License\"); you may not use this file except in compliance\n-with the License.  You may obtain a copy of the License at\n-\n-  http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing,\n-software distributed under the License is distributed on an\n-\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-KIND, either express or implied.  See the License for the\n-specific language governing permissions and limitations\n-under the License.\n--->\n-\n-* This will be replaced by the TOC\n-{:toc}\n-\n-## What is State?\n-\n-While many operations in a dataflow simply look at one individual *event at a\n-time* (for example an event parser), some operations remember information\n-across multiple events (for example window operators). These operations are\n-called **stateful**.\n-\n-Some examples of stateful operations:\n-\n-  - When an application searches for certain event patterns, the state will\n-    store the sequence of events encountered so far.\n-  - When aggregating events per minute/hour/day, the state holds the pending\n-    aggregates.\n-  - When training a machine learning model over a stream of data points, the\n-    state holds the current version of the model parameters.\n-  - When historic data needs to be managed, the state allows efficient access\n-    to events that occurred in the past.\n-\n-Flink needs to be aware of the state in order to make it fault tolerant using\n-[checkpoints]({% link dev/stream/state/checkpointing.zh.md %})\n-and [savepoints]({%link ops/state/savepoints.zh.md %}).\n-\n-Knowledge about the state also allows for rescaling Flink applications, meaning\n-that Flink takes care of redistributing state across parallel instances.\n-\n-[Queryable state]({% link dev/stream/state/queryable_state.zh.md\n-%}) allows you to access state from outside of Flink during runtime.\n-\n-When working with state, it might also be useful to read about [Flink's state\n-backends]({% link ops/state/state_backends.zh.md %}). Flink\n-provides different state backends that specify how and where state is stored.\n-\n-{% top %}\n-\n-## Keyed State\n-\n-Keyed state is maintained in what can be thought of as an embedded key/value\n-store.  The state is partitioned and distributed strictly together with the\n-streams that are read by the stateful operators. Hence, access to the key/value\n-state is only possible on *keyed streams*, i.e. after a keyed/partitioned data\n-exchange, and is restricted to the values associated with the current event's\n-key. Aligning the keys of streams and state makes sure that all state updates\n-are local operations, guaranteeing consistency without transaction overhead.\n-This alignment also allows Flink to redistribute the state and adjust the\n-stream partitioning transparently.\n-\n-<img src=\"{% link /fig/state_partitioning.svg %}\" alt=\"State and Partitioning\" class=\"offset\" width=\"50%\" />\n-\n-Keyed State is further organized into so-called *Key Groups*. Key Groups are\n-the atomic unit by which Flink can redistribute Keyed State; there are exactly\n-as many Key Groups as the defined maximum parallelism.  During execution each\n-parallel instance of a keyed operator works with the keys for one or more Key\n-Groups.\n-\n-## State Persistence\n-\n-Flink implements fault tolerance using a combination of **stream replay** and\n-**checkpointing**. A checkpoint marks a specific point in each of the\n-input streams along with the corresponding state for each of the operators. A\n-streaming dataflow can be resumed from a checkpoint while maintaining\n-consistency *(exactly-once processing semantics)* by restoring the state of the\n-operators and replaying the records from the point of the checkpoint.\n-\n-The checkpoint interval is a means of trading off the overhead of fault\n-tolerance during execution with the recovery time (the number of records that\n-need to be replayed).\n-\n-The fault tolerance mechanism continuously draws snapshots of the distributed\n-streaming data flow. For streaming applications with small state, these\n-snapshots are very light-weight and can be drawn frequently without much impact\n-on performance.  The state of the streaming applications is stored at a\n-configurable place, usually in a distributed file system.\n-\n-In case of a program failure (due to machine-, network-, or software failure),\n-Flink stops the distributed streaming dataflow.  The system then restarts the\n-operators and resets them to the latest successful checkpoint. The input\n-streams are reset to the point of the state snapshot. Any records that are\n-processed as part of the restarted parallel dataflow are guaranteed to not have\n-affected the previously checkpointed state.\n-\n-{% info Note %} By default, checkpointing is disabled. See [Checkpointing]({%\n-link dev/stream/state/checkpointing.zh.md %}) for details on how to enable and\n-configure checkpointing.\n-\n-{% info Note %} For this mechanism to realize its full guarantees, the data\n-stream source (such as message queue or broker) needs to be able to rewind the\n-stream to a defined recent point. [Apache Kafka](http://kafka.apache.org) has\n-this ability and Flink's connector to Kafka exploits this. See [Fault\n-Tolerance Guarantees of Data Sources and Sinks]({% link\n-dev/connectors/guarantees.zh.md %}) for more information about the guarantees\n-provided by Flink's connectors.\n-\n-{% info Note %} Because Flink's checkpoints are realized through distributed\n-snapshots, we use the words *snapshot* and *checkpoint* interchangeably. Often\n-we also use the term *snapshot* to mean either *checkpoint* or *savepoint*.\n-\n-### Checkpointing\n-\n-The central part of Flink's fault tolerance mechanism is drawing consistent\n-snapshots of the distributed data stream and operator state.  These snapshots\n-act as consistent checkpoints to which the system can fall back in case of a\n-failure. Flink's mechanism for drawing these snapshots is described in\n-\"[Lightweight Asynchronous Snapshots for Distributed\n-Dataflows](http://arxiv.org/abs/1506.08603)\". It is inspired by the standard\n-[Chandy-Lamport\n-algorithm](http://research.microsoft.com/en-us/um/people/lamport/pubs/chandy.pdf)\n-for distributed snapshots and is specifically tailored to Flink's execution\n-model.\n-\n-Keep in mind that everything to do with checkpointing can be done\n-asynchronously. The checkpoint barriers don't travel in lock step and\n-operations can asynchronously snapshot their state.\n-\n-\n-#### Barriers\n-\n-A core element in Flink's distributed snapshotting are the *stream barriers*.\n-These barriers are injected into the data stream and flow with the records as\n-part of the data stream. Barriers never overtake records, they flow strictly in\n-line.  A barrier separates the records in the data stream into the set of\n-records that goes into the current snapshot, and the records that go into the\n-next snapshot. Each barrier carries the ID of the snapshot whose records it\n-pushed in front of it. Barriers do not interrupt the flow of the stream and are\n-hence very lightweight. Multiple barriers from different snapshots can be in\n-the stream at the same time, which means that various snapshots may happen\n-concurrently.\n-\n-<div style=\"text-align: center\">\n-  <img src=\"{% link /fig/stream_barriers.svg %}\" alt=\"Checkpoint barriers in data streams\" style=\"width:60%; padding-top:10px; padding-bottom:10px;\" />\n-</div>\n-\n-Stream barriers are injected into the parallel data flow at the stream sources.\n-The point where the barriers for snapshot *n* are injected (let's call it\n-<i>S<sub>n</sub></i>) is the position in the source stream up to which the\n-snapshot covers the data. For example, in Apache Kafka, this position would be\n-the last record's offset in the partition. This position <i>S<sub>n</sub></i>\n-is reported to the *checkpoint coordinator* (Flink's JobManager).\n-\n-The barriers then flow downstream. When an intermediate operator has received a\n-barrier for snapshot *n* from all of its input streams, it emits a barrier for\n-snapshot *n* into all of its outgoing streams. Once a sink operator (the end of\n-a streaming DAG) has received the barrier *n* from all of its input streams, it\n-acknowledges that snapshot *n* to the checkpoint coordinator. After all sinks\n-have acknowledged a snapshot, it is considered completed.\n-\n-Once snapshot *n* has been completed, the job will never again ask the source\n-for records from before <i>S<sub>n</sub></i>, since at that point these records\n-(and their descendant records) will have passed through the entire data flow\n-topology.\n-\n-<div style=\"text-align: center\">\n-  <img src=\"{% link /fig/stream_aligning.svg %}\" alt=\"Aligning data streams at operators with multiple inputs\" style=\"width:100%; padding-top:10px; padding-bottom:10px;\" />\n-</div>\n-\n-Operators that receive more than one input stream need to *align* the input\n-streams on the snapshot barriers. The figure above illustrates this:\n-\n-  - As soon as the operator receives snapshot barrier *n* from an incoming\n-    stream, it cannot process any further records from that stream until it has\n-    received the barrier *n* from the other inputs as well. Otherwise, it would\n-    mix records that belong to snapshot *n* and with records that belong to\n-    snapshot *n+1*.\n-  - Streams that report barrier *n* are temporarily set aside. Records that are\n-    received from these streams are not processed, but put into an input\n-    buffer.\n-  - Once the last stream has received barrier *n*, the operator emits all\n-    pending outgoing records, and then emits snapshot *n* barriers itself.\n-  - After that, it resumes processing records from all input streams,\n-    processing records from the input buffers before processing the records\n-    from the streams.\n-\n-#### Snapshotting Operator State\n-\n-When operators contain any form of *state*, this state must be part of the\n-snapshots as well.\n-\n-Operators snapshot their state at the point in time when they have received all\n-snapshot barriers from their input streams, and before emitting the barriers to\n-their output streams. At that point, all updates to the state from records\n-before the barriers will have been made, and no updates that depend on records\n-from after the barriers have been applied. Because the state of a snapshot may\n-be large, it is stored in a configurable *[state backend]({%\n-link ops/state/state_backends.zh.md %})*. By default, this is the JobManager's\n-memory, but for production use a distributed reliable storage should be\n-configured (such as HDFS). After the state has been stored, the operator\n-acknowledges the checkpoint, emits the snapshot barrier into the output\n-streams, and proceeds.\n-\n-The resulting snapshot now contains:\n-\n-  - For each parallel stream data source, the offset/position in the stream\n-    when the snapshot was started\n-  - For each operator, a pointer to the state that was stored as part of the\n-    snapshot\n-\n-<div style=\"text-align: center\">\n-  <img src=\"{% link /fig/checkpointing.svg %}\" alt=\"Illustration of the Checkpointing Mechanism\" style=\"width:100%; padding-top:10px; padding-bottom:10px;\" />\n-</div>\n-\n-#### Recovery\n-\n-Recovery under this mechanism is straightforward: Upon a failure, Flink selects\n-the latest completed checkpoint *k*. The system then re-deploys the entire\n-distributed dataflow, and gives each operator the state that was snapshotted as\n-part of checkpoint *k*. The sources are set to start reading the stream from\n-position <i>S<sub>k</sub></i>. For example in Apache Kafka, that means telling\n-the consumer to start fetching from offset <i>S<sub>k</sub></i>.\n-\n-If state was snapshotted incrementally, the operators start with the state of\n-the latest full snapshot and then apply a series of incremental snapshot\n-updates to that state.\n-\n-See [Restart Strategies]({% link dev/task_failure_recovery.zh.md\n-%}#restart-strategies) for more information.\n-\n-### State Backends\n-\n-The exact data structures in which the key/values indexes are stored depends on\n-the chosen [state backend]({% link\n-ops/state/state_backends.zh.md %}). One state backend stores data in an in-memory\n-hash map, another state backend uses [RocksDB](http://rocksdb.org) as the\n-key/value store.  In addition to defining the data structure that holds the\n-state, the state backends also implement the logic to take a point-in-time\n-snapshot of the key/value state and store that snapshot as part of a\n-checkpoint. State backends can be configured without changing your application\n-logic.\n-\n-<img src=\"{% link /fig/checkpoints.svg %}\" alt=\"checkpoints and snapshots\" class=\"offset\" width=\"60%\" />\n-\n-{% top %}\n-\n-### Savepoints\n-\n-All programs that use checkpointing can resume execution from a **savepoint**.\n-Savepoints allow both updating your programs and your Flink cluster without\n-losing any state.\n-\n-[Savepoints]({% link ops/state/savepoints.zh.md %}) are\n-**manually triggered checkpoints**, which take a snapshot of the program and\n-write it out to a state backend. They rely on the regular checkpointing\n-mechanism for this.\n-\n-Savepoints are similar to checkpoints except that they are\n-**triggered by the user** and **don't automatically expire** when newer\n-checkpoints are completed.\n-\n-{% top %}\n-\n-### Exactly Once vs. At Least Once\n-\n-The alignment step may add latency to the streaming program. Usually, this\n-extra latency is on the order of a few milliseconds, but we have seen cases\n-where the latency of some outliers increased noticeably. For applications that\n-require consistently super low latencies (few milliseconds) for all records,\n-Flink has a switch to skip the stream alignment during a checkpoint. Checkpoint\n-snapshots are still drawn as soon as an operator has seen the checkpoint\n-barrier from each input.\n-\n-When the alignment is skipped, an operator keeps processing all inputs, even\n-after some checkpoint barriers for checkpoint *n* arrived. That way, the\n-operator also processes elements that belong to checkpoint *n+1* before the\n-state snapshot for checkpoint *n* was taken.  On a restore, these records will\n-occur as duplicates, because they are both included in the state snapshot of\n-checkpoint *n*, and will be replayed as part of the data after checkpoint *n*.\n-\n-{% info Note %} Alignment happens only for operators with multiple predecessors\n-(joins) as well as operators with multiple senders (after a stream\n-repartitioning/shuffle).  Because of that, dataflows with only embarrassingly\n-parallel streaming operations (`map()`, `flatMap()`, `filter()`, ...) actually\n-give *exactly once* guarantees even in *at least once* mode.\n-\n-{% top %}\n-\n-## State and Fault Tolerance in Batch Programs\n-\n-Flink executes [batch programs]({% link dev/batch/index.zh.md %}) as a special case of\n-streaming programs, where the streams are bounded (finite number of elements).\n-A *DataSet* is treated internally as a stream of data. The concepts above thus\n-apply to batch programs in the same way as well as they apply to streaming\n-programs, with minor exceptions:\n-\n-  - [Fault tolerance for batch programs](../dev/batch/fault_tolerance.html)\n-    does not use checkpointing.  Recovery happens by fully replaying the\n-    streams.  That is possible, because inputs are bounded. This pushes the\n-    cost more towards the recovery, but makes the regular processing cheaper,\n-    because it avoids checkpoints.\n-\n-  - Stateful operations in the DataSet API use simplified in-memory/out-of-core\n-    data structures, rather than key/value indexes.\n-\n-  - The DataSet API introduces special synchronized (superstep-based)\n-    iterations, which are only possible on bounded streams. For details, check\n-    out the [iteration docs]({% link dev/batch/iterations.zh.md %}).\n-\n-{% top %}"
        },
        {
            "sha": "f8a5b8dfa5435e8431bf39587dbf2538017dd332",
            "filename": "docs/concepts/timely-stream-processing.md",
            "status": "removed",
            "additions": 0,
            "deletions": 214,
            "changes": 214,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/concepts/timely-stream-processing.md",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/concepts/timely-stream-processing.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/concepts/timely-stream-processing.md?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,214 +0,0 @@\n----\n-title: Timely Stream Processing\n-nav-id: timely-stream-processing\n-nav-pos: 3\n-nav-title: Timely Stream Processing\n-nav-parent_id: concepts\n----\n-<!--\n-Licensed to the Apache Software Foundation (ASF) under one\n-or more contributor license agreements.  See the NOTICE file\n-distributed with this work for additional information\n-regarding copyright ownership.  The ASF licenses this file\n-to you under the Apache License, Version 2.0 (the\n-\"License\"); you may not use this file except in compliance\n-with the License.  You may obtain a copy of the License at\n-\n-  http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing,\n-software distributed under the License is distributed on an\n-\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-KIND, either express or implied.  See the License for the\n-specific language governing permissions and limitations\n-under the License.\n--->\n-\n-* This will be replaced by the TOC\n-{:toc}\n-\n-## Introduction\n-\n-Timely stream processing is an extension of [stateful stream processing]({% link\n-concepts/stateful-stream-processing.md %}) in which time plays some role in the\n-computation. Among other things, this is the case when you do time series\n-analysis, when doing aggregations based on certain time periods (typically\n-called windows), or when you do event processing where the time when an event\n-occurred is important.\n-\n-In the following sections we will highlight some of the topics that you should\n-consider when working with timely Flink Applications.\n-\n-{% top %}\n-\n-## Notions of Time: Event Time and Processing Time\n-\n-When referring to time in a streaming program (for example to define windows),\n-one can refer to different notions of *time*:\n-\n-- **Processing time:** Processing time refers to the system time of the machine\n-  that is executing the respective operation.\n-\n-  When a streaming program runs on processing time, all time-based operations\n-  (like time windows) will use the system clock of the machines that run the\n-  respective operator. An hourly processing time window will include all\n-  records that arrived at a specific operator between the times when the system\n-  clock indicated the full hour. For example, if an application begins running\n-  at 9:15am, the first hourly processing time window will include events\n-  processed between 9:15am and 10:00am, the next window will include events\n-  processed between 10:00am and 11:00am, and so on.\n-\n-  Processing time is the simplest notion of time and requires no coordination\n-  between streams and machines.  It provides the best performance and the\n-  lowest latency. However, in distributed and asynchronous environments\n-  processing time does not provide determinism, because it is susceptible to\n-  the speed at which records arrive in the system (for example from the message\n-  queue), to the speed at which the records flow between operators inside the\n-  system, and to outages (scheduled, or otherwise).\n-\n-- **Event time:** Event time is the time that each individual event occurred on\n-  its producing device.  This time is typically embedded within the records\n-  before they enter Flink, and that *event timestamp* can be extracted from\n-  each record. In event time, the progress of time depends on the data, not on\n-  any wall clocks. Event time programs must specify how to generate *Event Time\n-  Watermarks*, which is the mechanism that signals progress in event time. This\n-  watermarking mechanism is described in a later section,\n-  [below](#event-time-and-watermarks).\n-\n-  In a perfect world, event time processing would yield completely consistent\n-  and deterministic results, regardless of when events arrive, or their\n-  ordering.  However, unless the events are known to arrive in-order (by\n-  timestamp), event time processing incurs some latency while waiting for\n-  out-of-order events. As it is only possible to wait for a finite period of\n-  time, this places a limit on how deterministic event time applications can\n-  be.\n-\n-  Assuming all of the data has arrived, event time operations will behave as\n-  expected, and produce correct and consistent results even when working with\n-  out-of-order or late events, or when reprocessing historic data. For example,\n-  an hourly event time window will contain all records that carry an event\n-  timestamp that falls into that hour, regardless of the order in which they\n-  arrive, or when they are processed. (See the section on [late\n-  events](#late-elements) for more information.)\n-\n-  Note that sometimes when event time programs are processing live data in\n-  real-time, they will use some *processing time* operations in order to\n-  guarantee that they are progressing in a timely fashion.\n-\n-<img src=\"{% link /fig/event_processing_time.svg %}\" alt=\"Event Time and Processing Time\" class=\"offset\" width=\"80%\" />\n-\n-{% top %}\n-\n-## Event Time and Watermarks\n-\n-*Note: Flink implements many techniques from the Dataflow Model. For a good\n-introduction to event time and watermarks, have a look at the articles below.*\n-\n-  - [Streaming\n-    101](https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-101) by\n-    Tyler Akidau\n-  - The [Dataflow Model\n-    paper](https://research.google.com/pubs/archive/43864.pdf)\n-\n-\n-A stream processor that supports *event time* needs a way to measure the\n-progress of event time.  For example, a window operator that builds hourly\n-windows needs to be notified when event time has passed beyond the end of an\n-hour, so that the operator can close the window in progress.\n-\n-*Event time* can progress independently of *processing time* (measured by wall\n-clocks).  For example, in one program the current *event time* of an operator\n-may trail slightly behind the *processing time* (accounting for a delay in\n-receiving the events), while both proceed at the same speed.  On the other\n-hand, another streaming program might progress through weeks of event time with\n-only a few seconds of processing, by fast-forwarding through some historic data\n-already buffered in a Kafka topic (or another message queue).\n-\n-------\n-\n-The mechanism in Flink to measure progress in event time is **watermarks**.\n-Watermarks flow as part of the data stream and carry a timestamp *t*. A\n-*Watermark(t)* declares that event time has reached time *t* in that stream,\n-meaning that there should be no more elements from the stream with a timestamp\n-*t' <= t* (i.e. events with timestamps older or equal to the watermark).\n-\n-The figure below shows a stream of events with (logical) timestamps, and\n-watermarks flowing inline. In this example the events are in order (with\n-respect to their timestamps), meaning that the watermarks are simply periodic\n-markers in the stream.\n-\n-<img src=\"{% link /fig/stream_watermark_in_order.svg %}\" alt=\"A data stream with events (in order) and watermarks\" class=\"center\" width=\"65%\" />\n-\n-Watermarks are crucial for *out-of-order* streams, as illustrated below, where\n-the events are not ordered by their timestamps.  In general a watermark is a\n-declaration that by that point in the stream, all events up to a certain\n-timestamp should have arrived.  Once a watermark reaches an operator, the\n-operator can advance its internal *event time clock* to the value of the\n-watermark.\n-\n-<img src=\"{% link /fig/stream_watermark_out_of_order.svg %}\" alt=\"A data stream with events (out of order) and watermarks\" class=\"center\" width=\"65%\" />\n-\n-Note that event time is inherited by a freshly created stream element (or\n-elements) from either the event that produced them or from watermark that\n-triggered creation of those elements.\n-\n-### Watermarks in Parallel Streams\n-\n-Watermarks are generated at, or directly after, source functions. Each parallel\n-subtask of a source function usually generates its watermarks independently.\n-These watermarks define the event time at that particular parallel source.\n-\n-As the watermarks flow through the streaming program, they advance the event\n-time at the operators where they arrive. Whenever an operator advances its\n-event time, it generates a new watermark downstream for its successor\n-operators.\n-\n-Some operators consume multiple input streams; a union, for example, or\n-operators following a *keyBy(...)* or *partition(...)* function.  Such an\n-operator's current event time is the minimum of its input streams' event times.\n-As its input streams update their event times, so does the operator.\n-\n-The figure below shows an example of events and watermarks flowing through\n-parallel streams, and operators tracking event time.\n-\n-<img src=\"{% link /fig/parallel_streams_watermarks.svg %}\" alt=\"Parallel data streams and operators with events and watermarks\" class=\"center\" width=\"80%\" />\n-\n-## Lateness\n-\n-It is possible that certain elements will violate the watermark condition,\n-meaning that even after the *Watermark(t)* has occurred, more elements with\n-timestamp *t' <= t* will occur. In fact, in many real world setups, certain\n-elements can be arbitrarily delayed, making it impossible to specify a time by\n-which all elements of a certain event timestamp will have occurred.\n-Furthermore, even if the lateness can be bounded, delaying the watermarks by\n-too much is often not desirable, because it causes too much delay in the\n-evaluation of event time windows.\n-\n-For this reason, streaming programs may explicitly expect some *late* elements.\n-Late elements are elements that arrive after the system's event time clock (as\n-signaled by the watermarks) has already passed the time of the late element's\n-timestamp. See [Allowed Lateness]({% link\n-dev/stream/operators/windows.md %}#allowed-lateness) for more information on\n-how to work with late elements in event time windows.\n-\n-## Windowing\n-\n-Aggregating events (e.g., counts, sums) works differently on streams than in\n-batch processing.  For example, it is impossible to count all elements in a\n-stream, because streams are in general infinite (unbounded). Instead,\n-aggregates on streams (counts, sums, etc), are scoped by **windows**, such as\n-*\"count over the last 5 minutes\"*, or *\"sum of the last 100 elements\"*.\n-\n-Windows can be *time driven* (example: every 30 seconds) or *data driven*\n-(example: every 100 elements).  One typically distinguishes different types of\n-windows, such as *tumbling windows* (no overlap), *sliding windows* (with\n-overlap), and *session windows* (punctuated by a gap of inactivity).\n-\n-<img src=\"{% link /fig/windows.svg %}\" alt=\"Time- and Count Windows\" class=\"offset\" width=\"80%\" />\n-\n-Please check out this [blog\n-post](https://flink.apache.org/news/2015/12/04/Introducing-windows.html) for\n-additional examples of windows or take a look a [window documentation]({% link\n-dev/stream/operators/windows.md %}) of the DataStream API.\n-\n-{% top %}"
        },
        {
            "sha": "54fcf1bea32fee9da44676b386de69bc24eec4f1",
            "filename": "docs/concepts/timely-stream-processing.zh.md",
            "status": "removed",
            "additions": 0,
            "deletions": 214,
            "changes": 214,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/concepts/timely-stream-processing.zh.md",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/concepts/timely-stream-processing.zh.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/concepts/timely-stream-processing.zh.md?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,214 +0,0 @@\n----\n-title: 及时流处理\n-nav-id: timely-stream-processing\n-nav-pos: 3\n-nav-title: 及时流处理\n-nav-parent_id: concepts\n----\n-<!--\n-Licensed to the Apache Software Foundation (ASF) under one\n-or more contributor license agreements.  See the NOTICE file\n-distributed with this work for additional information\n-regarding copyright ownership.  The ASF licenses this file\n-to you under the Apache License, Version 2.0 (the\n-\"License\"); you may not use this file except in compliance\n-with the License.  You may obtain a copy of the License at\n-\n-  http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing,\n-software distributed under the License is distributed on an\n-\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-KIND, either express or implied.  See the License for the\n-specific language governing permissions and limitations\n-under the License.\n--->\n-\n-* This will be replaced by the TOC\n-{:toc}\n-\n-## Introduction\n-\n-Timely steam processing is an extension of [stateful stream processing]({% link\n-concepts/stateful-stream-processing.zh.md %}) in which time plays some role in the\n-computation. Among other things, this is the case when you do time series\n-analysis, when doing aggregations based on certain time periods (typically\n-called windows), or when you do event processing where the time when an event\n-occurred is important.\n-\n-In the following sections we will highlight some of the topics that you should\n-consider when working with timely Flink Applications.\n-\n-{% top %}\n-\n-## Notions of Time: Event Time and Processing Time\n-\n-When referring to time in a streaming program (for example to define windows),\n-one can refer to different notions of *time*:\n-\n-- **Processing time:** Processing time refers to the system time of the machine\n-  that is executing the respective operation.\n-\n-  When a streaming program runs on processing time, all time-based operations\n-  (like time windows) will use the system clock of the machines that run the\n-  respective operator. An hourly processing time window will include all\n-  records that arrived at a specific operator between the times when the system\n-  clock indicated the full hour. For example, if an application begins running\n-  at 9:15am, the first hourly processing time window will include events\n-  processed between 9:15am and 10:00am, the next window will include events\n-  processed between 10:00am and 11:00am, and so on.\n-\n-  Processing time is the simplest notion of time and requires no coordination\n-  between streams and machines.  It provides the best performance and the\n-  lowest latency. However, in distributed and asynchronous environments\n-  processing time does not provide determinism, because it is susceptible to\n-  the speed at which records arrive in the system (for example from the message\n-  queue), to the speed at which the records flow between operators inside the\n-  system, and to outages (scheduled, or otherwise).\n-\n-- **Event time:** Event time is the time that each individual event occurred on\n-  its producing device.  This time is typically embedded within the records\n-  before they enter Flink, and that *event timestamp* can be extracted from\n-  each record. In event time, the progress of time depends on the data, not on\n-  any wall clocks. Event time programs must specify how to generate *Event Time\n-  Watermarks*, which is the mechanism that signals progress in event time. This\n-  watermarking mechanism is described in a later section,\n-  [below](#event-time-and-watermarks).\n-\n-  In a perfect world, event time processing would yield completely consistent\n-  and deterministic results, regardless of when events arrive, or their\n-  ordering.  However, unless the events are known to arrive in-order (by\n-  timestamp), event time processing incurs some latency while waiting for\n-  out-of-order events. As it is only possible to wait for a finite period of\n-  time, this places a limit on how deterministic event time applications can\n-  be.\n-\n-  Assuming all of the data has arrived, event time operations will behave as\n-  expected, and produce correct and consistent results even when working with\n-  out-of-order or late events, or when reprocessing historic data. For example,\n-  an hourly event time window will contain all records that carry an event\n-  timestamp that falls into that hour, regardless of the order in which they\n-  arrive, or when they are processed. (See the section on [late\n-  events](#late-elements) for more information.)\n-\n-  Note that sometimes when event time programs are processing live data in\n-  real-time, they will use some *processing time* operations in order to\n-  guarantee that they are progressing in a timely fashion.\n-\n-<img src=\"{% link /fig/event_processing_time.svg %}\" alt=\"Event Time and Processing Time\" class=\"offset\" width=\"80%\" />\n-\n-{% top %}\n-\n-## Event Time and Watermarks\n-\n-*Note: Flink implements many techniques from the Dataflow Model. For a good\n-introduction to event time and watermarks, have a look at the articles below.*\n-\n-  - [Streaming\n-    101](https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-101) by\n-    Tyler Akidau\n-  - The [Dataflow Model\n-    paper](https://research.google.com/pubs/archive/43864.pdf)\n-\n-\n-A stream processor that supports *event time* needs a way to measure the\n-progress of event time.  For example, a window operator that builds hourly\n-windows needs to be notified when event time has passed beyond the end of an\n-hour, so that the operator can close the window in progress.\n-\n-*Event time* can progress independently of *processing time* (measured by wall\n-clocks).  For example, in one program the current *event time* of an operator\n-may trail slightly behind the *processing time* (accounting for a delay in\n-receiving the events), while both proceed at the same speed.  On the other\n-hand, another streaming program might progress through weeks of event time with\n-only a few seconds of processing, by fast-forwarding through some historic data\n-already buffered in a Kafka topic (or another message queue).\n-\n-------\n-\n-The mechanism in Flink to measure progress in event time is **watermarks**.\n-Watermarks flow as part of the data stream and carry a timestamp *t*. A\n-*Watermark(t)* declares that event time has reached time *t* in that stream,\n-meaning that there should be no more elements from the stream with a timestamp\n-*t' <= t* (i.e. events with timestamps older or equal to the watermark).\n-\n-The figure below shows a stream of events with (logical) timestamps, and\n-watermarks flowing inline. In this example the events are in order (with\n-respect to their timestamps), meaning that the watermarks are simply periodic\n-markers in the stream.\n-\n-<img src=\"{% link /fig/stream_watermark_in_order.svg %}\" alt=\"A data stream with events (in order) and watermarks\" class=\"center\" width=\"65%\" />\n-\n-Watermarks are crucial for *out-of-order* streams, as illustrated below, where\n-the events are not ordered by their timestamps.  In general a watermark is a\n-declaration that by that point in the stream, all events up to a certain\n-timestamp should have arrived.  Once a watermark reaches an operator, the\n-operator can advance its internal *event time clock* to the value of the\n-watermark.\n-\n-<img src=\"{% link /fig/stream_watermark_out_of_order.svg %}\" alt=\"A data stream with events (out of order) and watermarks\" class=\"center\" width=\"65%\" />\n-\n-Note that event time is inherited by a freshly created stream element (or\n-elements) from either the event that produced them or from watermark that\n-triggered creation of those elements.\n-\n-### Watermarks in Parallel Streams\n-\n-Watermarks are generated at, or directly after, source functions. Each parallel\n-subtask of a source function usually generates its watermarks independently.\n-These watermarks define the event time at that particular parallel source.\n-\n-As the watermarks flow through the streaming program, they advance the event\n-time at the operators where they arrive. Whenever an operator advances its\n-event time, it generates a new watermark downstream for its successor\n-operators.\n-\n-Some operators consume multiple input streams; a union, for example, or\n-operators following a *keyBy(...)* or *partition(...)* function.  Such an\n-operator's current event time is the minimum of its input streams' event times.\n-As its input streams update their event times, so does the operator.\n-\n-The figure below shows an example of events and watermarks flowing through\n-parallel streams, and operators tracking event time.\n-\n-<img src=\"{% link /fig/parallel_streams_watermarks.svg %}\" alt=\"Parallel data streams and operators with events and watermarks\" class=\"center\" width=\"80%\" />\n-\n-## Lateness\n-\n-It is possible that certain elements will violate the watermark condition,\n-meaning that even after the *Watermark(t)* has occurred, more elements with\n-timestamp *t' <= t* will occur. In fact, in many real world setups, certain\n-elements can be arbitrarily delayed, making it impossible to specify a time by\n-which all elements of a certain event timestamp will have occurred.\n-Furthermore, even if the lateness can be bounded, delaying the watermarks by\n-too much is often not desirable, because it causes too much delay in the\n-evaluation of event time windows.\n-\n-For this reason, streaming programs may explicitly expect some *late* elements.\n-Late elements are elements that arrive after the system's event time clock (as\n-signaled by the watermarks) has already passed the time of the late element's\n-timestamp. See [Allowed Lateness]({% link\n-dev/stream/operators/windows.zh.md %}#allowed-lateness) for more information on\n-how to work with late elements in event time windows.\n-\n-## Windowing\n-\n-Aggregating events (e.g., counts, sums) works differently on streams than in\n-batch processing.  For example, it is impossible to count all elements in a\n-stream, because streams are in general infinite (unbounded). Instead,\n-aggregates on streams (counts, sums, etc), are scoped by **windows**, such as\n-*\"count over the last 5 minutes\"*, or *\"sum of the last 100 elements\"*.\n-\n-Windows can be *time driven* (example: every 30 seconds) or *data driven*\n-(example: every 100 elements).  One typically distinguishes different types of\n-windows, such as *tumbling windows* (no overlap), *sliding windows* (with\n-overlap), and *session windows* (punctuated by a gap of inactivity).\n-\n-<img src=\"{% link /fig/windows.svg %}\" alt=\"Time- and Count Windows\" class=\"offset\" width=\"80%\" />\n-\n-Please check out this [blog\n-post](https://flink.apache.org/news/2015/12/04/Introducing-windows.html) for\n-additional examples of windows or take a look a [window documentation]({% link\n-dev/stream/operators/windows.zh.md %}) of the DataStream API.\n-\n-{% top %}"
        },
        {
            "sha": "e9b123b6ee173cd14f98aab2eb66afef8df5adcd",
            "filename": "docs/config.toml",
            "status": "added",
            "additions": 103,
            "deletions": 0,
            "changes": 103,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/config.toml",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/config.toml",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/config.toml?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,103 @@\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+baseURL = '//ci.apache.org/projects/flink/flink-docs-release-1.13'\n+languageCode = \"en-us\"\n+title = \"Apache Flink\"\n+enableGitInfo = false\n+theme = \"book\"\n+pygmentsUseClasses = true\n+\n+[params]\n+  # Flag whether this is a stable version or not.\n+  # Used for the quickstart page.\n+  IsStable = true\n+  \n+  # Flag to indicate whether an outdated warning should be shown.\n+  ShowOutDatedWarning = false\n+\n+  # This are the version referenced in the docs. Please only use these variables\n+  # to reference a specific Flink version, because this is the only place where\n+  # we change the version for the complete docs when forking of a release branch\n+  # etc.\n+  # The full version string as referenced in Maven (e.g. 1.2.1)\n+  Version = \"1.13.0\"\n+\n+  # For stable releases, leave the bugfix version out (e.g. 1.2). For snapshot\n+  # release this should be the same as the regular version\n+  VersionTitle = \"1.13\"\n+\n+  # The branch for this version of Apache Flink\n+  Branch = \"release-1.13\"\n+\n+  # The github repository for Apache Flink\n+  Repo = \"//github.com/apache/flink\"\n+\n+  GithubRepo = \"https://github.com/apache/flink.git\"\n+\n+  # Flink training exercises \n+  TrainingExercises = \"//github.com/apache/flink-training\"\n+\n+  # This suffix is appended to the Scala-dependent Maven artifact names\n+  ScalaVersion = \"_2.11\"\n+\n+  ProjectHomepage = \"//flink.apache.org\"\n+\n+  JavaDocs = \"//ci.apache.org/projects/flink/flink-docs-release-1.13/api/java/\"\n+\n+  ScalaDocs = \"//ci.apache.org/projects/flink/flink-docs-release-1.13/api/scala/index.html#org.apache.flink.api.scala.package\"\n+\n+  PyDocs = \"//ci.apache.org/projects/flink/flink-docs-release-1.13/api/python/\"\n+\n+  # External links at the bottom\n+  # of the menu\n+  MenuLinks = [\n+    [\"Project Homepage\", \"//flink.apache.org\"],\n+    [\"JavaDocs\", \"//ci.apache.org/projects/flink/flink-docs-release-1.13/api/java/\"],\n+    [\"ScalaDocs\", \"//ci.apache.org/projects/flink/flink-docs-release-1.13/api/scala/index.html#org.apache.flink.api.scala.package/\"],\n+    [\"PyDocs\", \"//ci.apache.org/projects/flink/flink-docs-release-1.13/api/python/\"]\n+  ]\n+\n+  PreviousDocs = [\n+    [\"1.12\", \"http://ci.apache.org/projects/flink/flink-docs-release-1.12\"],\n+    [\"1.11\", \"http://ci.apache.org/projects/flink/flink-docs-release-1.11\"],\n+    [\"1.10\", \"http://ci.apache.org/projects/flink/flink-docs-release-1.10\"],\n+    [\"1.9\", \"http://ci.apache.org/projects/flink/flink-docs-release-1.9\"],\n+    [\"1.8\", \"http://ci.apache.org/projects/flink/flink-docs-release-1.8\"],\n+    [\"1.7\", \"http://ci.apache.org/projects/flink/flink-docs-release-1.7\"],\n+    [\"1.6\", \"http://ci.apache.org/projects/flink/flink-docs-release-1.6\"],\n+    [\"1.5\", \"http://ci.apache.org/projects/flink/flink-docs-release-1.5\"],\n+    [\"1.4\", \"http://ci.apache.org/projects/flink/flink-docs-release-1.4\"],\n+    [\"1.3\", \"http://ci.apache.org/projects/flink/flink-docs-release-1.3\"],\n+    [\"1.2\", \"http://ci.apache.org/projects/flink/flink-docs-release-1.2\"],\n+    [\"1.1\", \"http://ci.apache.org/projects/flink/flink-docs-release-1.1\"],\n+    [\"1.0\", \"http://ci.apache.org/projects/flink/flink-docs-release-1.0\"]\n+  ]\n+\n+[markup]\n+[markup.goldmark.renderer]\n+  unsafe = true\n+\n+[languages]\n+[languages.en]\n+  languageName = 'English'\n+  contentDir = 'content'\n+  weight = 1\n+\n+[languages.zh]\n+  languageName = '中文版'\n+  contentDir = 'content.zh'\n+  weight = 2"
        },
        {
            "sha": "5a744166b3ccce0a74c2b63cfc37d8446d8bc4aa",
            "filename": "docs/connectors/index.md",
            "status": "removed",
            "additions": 0,
            "deletions": 28,
            "changes": 28,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/connectors/index.md",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/connectors/index.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/connectors/index.md?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,28 +0,0 @@\n----\n-title: \"Connectors\"\n-nav-id: connectors-root\n-nav-title: '<i class=\"fa fa-random title maindish\" aria-hidden=\"true\"></i> Connectors'\n-nav-parent_id: root\n-nav-pos: 7\n----\n-<!--\n-Licensed to the Apache Software Foundation (ASF) under one\n-or more contributor license agreements.  See the NOTICE file\n-distributed with this work for additional information\n-regarding copyright ownership.  The ASF licenses this file\n-to you under the Apache License, Version 2.0 (the\n-\"License\"); you may not use this file except in compliance\n-with the License.  You may obtain a copy of the License at\n-\n-  http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing,\n-software distributed under the License is distributed on an\n-\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-KIND, either express or implied.  See the License for the\n-specific language governing permissions and limitations\n-under the License.\n--->\n-\n-* toc\n-{:toc}"
        },
        {
            "sha": "5a744166b3ccce0a74c2b63cfc37d8446d8bc4aa",
            "filename": "docs/connectors/index.zh.md",
            "status": "removed",
            "additions": 0,
            "deletions": 28,
            "changes": 28,
            "blob_url": "https://github.com/apache/flink/blob/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/connectors/index.zh.md",
            "raw_url": "https://github.com/apache/flink/raw/c008907d2a629449c8d0ad9725d13b0604fc2141/docs/connectors/index.zh.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/connectors/index.zh.md?ref=c008907d2a629449c8d0ad9725d13b0604fc2141",
            "patch": "@@ -1,28 +0,0 @@\n----\n-title: \"Connectors\"\n-nav-id: connectors-root\n-nav-title: '<i class=\"fa fa-random title maindish\" aria-hidden=\"true\"></i> Connectors'\n-nav-parent_id: root\n-nav-pos: 7\n----\n-<!--\n-Licensed to the Apache Software Foundation (ASF) under one\n-or more contributor license agreements.  See the NOTICE file\n-distributed with this work for additional information\n-regarding copyright ownership.  The ASF licenses this file\n-to you under the Apache License, Version 2.0 (the\n-\"License\"); you may not use this file except in compliance\n-with the License.  You may obtain a copy of the License at\n-\n-  http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing,\n-software distributed under the License is distributed on an\n-\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-KIND, either express or implied.  See the License for the\n-specific language governing permissions and limitations\n-under the License.\n--->\n-\n-* toc\n-{:toc}"
        },
        {
            "sha": "c1e782d1fdcaf42ea05760637a5a8506a0159ff7",
            "filename": "docs/content.zh/_index.md",
            "status": "added",
            "additions": 88,
            "deletions": 0,
            "changes": 88,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/_index.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/_index.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/_index.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,88 @@\n+---\n+title: Apache Flink Documentation \n+type: docs\n+bookToc: false\n+aliases:\n+  - /zh/examples/index.html\n+  - /zh/getting-started/examples/index.html\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Apache Flink Documentation\n+\n+{{< center >}}\n+**Apache Flink** is a framework and distributed processing engine for stateful computations over *unbounded* and *bounded* data streams. Flink has been designed to run in *all common cluster environments* perform computations at *in-memory* speed and at *any scale*.\n+{{< /center >}}\n+\n+{{< columns >}}\n+\n+### Try Flink\n+\n+If you’re interested in playing around with Flink, try one of our tutorials:\n+\n+* [Fraud Detection with the DataStream API]({{< ref \"docs/try-flink/datastream\" >}})\n+* [Real Time Reporting with the Table API]({{< ref \"docs/try-flink/table_api\" >}})\n+* [Intro to PyFlink]({{< ref \"docs/dev/python/overview\" >}})\n+* [Flink Operations Playground]({{< ref \"docs/try-flink/flink-operations-playground\" >}})\n+\n+### Learn Flink\n+\n+* To dive in deeper, the [Hands-on Training]({{< ref \"docs/learn-flink/overview\" >}}) includes a set of lessons and exercises that provide a step-by-step introduction to Flink.\n+\n+* The [Concepts]({{< ref \"docs/concepts/overview\" >}}) section explains what you need to know about Flink before exploring the reference documentation.\n+\n+### Get Help with Flink\n+\n+If you get stuck, check out our [community support resources](https://flink.apache.org/community.html). In particular, Apache Flink’s user mailing list is consistently ranked as one of the most active of any Apache project, and is a great way to get help quickly.\n+\n+<--->\n+\n+### Explore Flink\n+\n+The reference documentation covers all the details. Some starting points:\n+\n+{{< columns >}}\n+* [DataStream API]({{< ref \"docs/dev/datastream/overview\" >}})\n+* [Table API & SQL]({{< ref \"docs/dev/table/overview\" >}})\n+* [Stateful Functions](https://ci.apache.org/projects/flink/flink-statefun-docs-stable/)\n+\n+<--->\n+\n+* [Configuration]({{< ref \"docs/deployment/config\" >}})\n+* [Rest API]({{< ref \"docs/ops/rest_api\" >}})\n+* [CLI]({{< ref \"docs/deployment/cli\" >}})\n+{{< /columns >}}\n+\n+### Deploy Flink\n+\n+Before putting your Flink job into production, read the [Production Readiness Checklist]({{< ref \"docs/ops/production_ready\" >}}).\n+For an overview of possible deployment targets, see [Clusters and Deployments]({{< ref \"docs/deployment/overview\" >}}).\n+\n+### Upgrade Flink\n+\n+Release notes cover important changes between Flink versions. Please read them carefully if you plan to upgrade your Flink setup.\n+\n+<!--\n+For some reason Hugo will only allow linking to the \n+release notes if there is a leading '/' and file extension.\n+-->\n+See the release notes for [Flink 1.12]({{< ref \"/release-notes/flink-1.12.md\" >}}), [Flink 1.11]({{< ref \"/release-notes/flink-1.11.md\" >}}), [Flink 1.10]({{< ref \"/release-notes/flink-1.10.md\" >}}), [Flink 1.9]({{< ref \"/release-notes/flink-1.9.md\" >}}), [Flink 1.8]({{< ref \"/release-notes/flink-1.8.md\" >}}), or [Flink 1.7]({{< ref \"/release-notes/flink-1.7.md\" >}}).\n+\n+{{< /columns >}}\n\\ No newline at end of file"
        },
        {
            "sha": "040815aa98e63760cf6fbd46325561d59ff3c6ca",
            "filename": "docs/content.zh/docs/concepts/_index.md",
            "status": "added",
            "additions": 25,
            "deletions": 0,
            "changes": 25,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/concepts/_index.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/concepts/_index.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/concepts/_index.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,25 @@\n+---\n+title: 概念透析\n+icon: <i class=\"fa fa-map-o title appetizer\" aria-hidden=\"true\"></i>\n+bold: true\n+bookCollapseSection: true\n+weight: 3\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n\\ No newline at end of file"
        },
        {
            "sha": "e4c7b0f5174a47462f97ca6462707987655da66c",
            "filename": "docs/content.zh/docs/concepts/flink-architecture.md",
            "status": "added",
            "additions": 139,
            "deletions": 0,
            "changes": 139,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/concepts/flink-architecture.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/concepts/flink-architecture.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/concepts/flink-architecture.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,139 @@\n+---\n+title: Flink 架构\n+weight: 4\n+type: docs\n+nav-title: Flink 架构\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Flink 架构\n+\n+Flink 是一个分布式系统，需要有效分配和管理计算资源才能执行流应用程序。它集成了所有常见的集群资源管理器，例如[Hadoop YARN](https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/YARN.html)、[Apache Mesos](https://mesos.apache.org/)和[Kubernetes](https://kubernetes.io/)，但也可以设置作为独立集群甚至库运行。\n+\n+本节概述了 Flink 架构，并且描述了其主要组件如何交互以执行应用程序和从故障中恢复。\n+\n+## Flink 集群剖析\n+\n+Flink 运行时由两种类型的进程组成：一个 _JobManager_ 和一个或者多个 _TaskManager_。\n+\n+{{< img src=\"/fig/processes.svg\" alt=\"The processes involved in executing a Flink dataflow\" class=\"offset\" width=\"70%\" >}}\n+\n+*Client* 不是运行时和程序执行的一部分，而是用于准备数据流并将其发送给 JobManager。之后，客户端可以断开连接（_分离模式_），或保持连接来接收进程报告（_附加模式_）。客户端可以作为触发执行 Java/Scala 程序的一部分运行，也可以在命令行进程`./bin/flink run ...`中运行。\n+\n+可以通过多种方式启动 JobManager 和 TaskManager：直接在机器上作为[standalone 集群]({{< ref \"docs/deployment/resource-providers/standalone/overview\" >}})启动、在容器中启动、或者通过[YARN]({{< ref \"docs/deployment/resource-providers/yarn\" >}})或[Mesos]({{< ref \"docs/deployment/resource-providers/mesos\" >}})等资源框架管理并启动。TaskManager 连接到 JobManagers，宣布自己可用，并被分配工作。\n+\n+### JobManager\n+\n+_JobManager_ 具有许多与协调 Flink 应用程序的分布式执行有关的职责：它决定何时调度下一个 task（或一组 task）、对完成的 task 或执行失败做出反应、协调 checkpoint、并且协调从失败中恢复等等。这个进程由三个不同的组件组成：\n+\n+  * **ResourceManager** \n+\n+    _ResourceManager_ 负责 Flink 集群中的资源提供、回收、分配 - 它管理 **task slots**，这是 Flink 集群中资源调度的单位（请参考[TaskManagers](#taskmanagers)）。Flink 为不同的环境和资源提供者（例如 YARN、Mesos、Kubernetes 和 standalone 部署）实现了对应的 ResourceManager。在 standalone 设置中，ResourceManager 只能分配可用 TaskManager 的 slots，而不能自行启动新的 TaskManager。\n+\n+  * **Dispatcher** \n+\n+    _Dispatcher_ 提供了一个 REST 接口，用来提交 Flink 应用程序执行，并为每个提交的作业启动一个新的 JobMaster。它还运行 Flink WebUI 用来提供作业执行信息。\n+\n+  * **JobMaster** \n+\n+    _JobMaster_ 负责管理单个[JobGraph]({{< ref \"docs/concepts/glossary\" >}}#logical-graph)的执行。Flink 集群中可以同时运行多个作业，每个作业都有自己的 JobMaster。\n+\n+始终至少有一个 JobManager。高可用（HA）设置中可能有多个 JobManager，其中一个始终是 *leader*，其他的则是 *standby*（请参考 [高可用（HA）]({{< ref \"docs/deployment/ha/overview\" >}})）。\n+\n+### TaskManagers\n+\n+*TaskManager*（也称为 *worker*）执行作业流的 task，并且缓存和交换数据流。\n+\n+必须始终至少有一个 TaskManager。在 TaskManager 中资源调度的最小单位是 task _slot_。TaskManager 中 task slot 的数量表示并发处理 task 的数量。请注意一个 task slot 中可以执行多个算子（请参考[Tasks 和算子链](#tasks-and-operator-chains)）。\n+\n+{{< top >}}\n+\n+## Tasks 和算子链\n+\n+对于分布式执行，Flink 将算子的 subtasks *链接*成 *tasks*。每个 task 由一个线程执行。将算子链接成 task 是个有用的优化：它减少线程间切换、缓冲的开销，并且减少延迟的同时增加整体吞吐量。链行为是可以配置的；请参考[链文档]({{< ref \"docs/dev/datastream/operators/overview\" >}}#task-chaining-and-resource-groups)以获取详细信息。\n+\n+下图中样例数据流用 5 个 subtask 执行，因此有 5 个并行线程。\n+\n+{{< img src=\"/fig/tasks_chains.svg\" alt=\"Operator chaining into Tasks\" class=\"offset\" width=\"80%\" >}}\n+\n+{{< top >}}\n+\n+## Task Slots 和资源\n+\n+每个 worker（TaskManager）都是一个 *JVM 进程*，可以在单独的线程中执行一个或多个 subtask。为了控制一个 TaskManager 中接受多少个 task，就有了所谓的 **task slots**（至少一个）。\n+\n+每个 *task slot* 代表 TaskManager 中资源的固定子集。例如，具有 3 个 slot 的 TaskManager，会将其托管内存 1/3 用于每个 slot。分配资源意味着 subtask 不会与其他作业的 subtask 竞争托管内存，而是具有一定数量的保留托管内存。注意此处没有 CPU 隔离；当前 slot 仅分离 task 的托管内存。\n+\n+通过调整 task slot 的数量，用户可以定义 subtask 如何互相隔离。每个 TaskManager 有一个 slot，这意味着每个 task 组都在单独的 JVM 中运行（例如，可以在单独的容器中启动）。具有多个 slot 意味着更多 subtask 共享同一 JVM。同一 JVM 中的 task 共享 TCP 连接（通过多路复用）和心跳信息。它们还可以共享数据集和数据结构，从而减少了每个 task 的开销。\n+\n+{{< img src=\"/fig/tasks_slots.svg\" alt=\"A TaskManager with Task Slots and Tasks\" class=\"offset\" width=\"80%\" >}}\n+\n+默认情况下，Flink 允许 subtask 共享 slot，即便它们是不同的 task 的 subtask，只要是来自于同一作业即可。结果就是一个 slot 可以持有整个作业管道。允许 *slot 共享*有两个主要优点：\n+\n+  - Flink 集群所需的 task slot 和作业中使用的最大并行度恰好一样。无需计算程序总共包含多少个 task（具有不同并行度）。\n+\n+  - 容易获得更好的资源利用。如果没有 slot 共享，非密集 subtask（*source/map()*）将阻塞和密集型 subtask（*window*） 一样多的资源。通过 slot 共享，我们示例中的基本并行度从 2 增加到 6，可以充分利用分配的资源，同时确保繁重的 subtask 在 TaskManager 之间公平分配。\n+\n+{{< img src=\"/fig/slot_sharing.svg\" alt=\"TaskManagers with shared Task Slots\" class=\"offset\" width=\"80%\" >}}\n+\n+## Flink 应用程序执行\n+\n+_Flink 应用程序_ 是从其 ``main()`` 方法产生的一个或多个 Flink 作业的任何用户程序。这些作业的执行可以在本地 JVM（`LocalEnvironment``）中进行，或具有多台机器的集群的远程设置（``RemoteEnvironment``）中进行。对于每个程序，[``ExecutionEnvironment``]({{ site.javadocs_baseurl }}/api/java/) 提供了一些方法来控制作业执行（例如设置并行度）并与外界交互（请参考 [Flink 程序剖析]({{< ref \"docs/dev/datastream/overview\" >}}#anatomy-of-a-flink-program) ）。\n+\n+Flink 应用程序的作业可以被提交到长期运行的 [Flink Session 集群]({{< ref \"docs/concepts/glossary\" >}}#flink-session-cluster)、专用的 [Flink Job 集群]({{< ref \"docs/concepts/glossary\" >}}#flink-job-cluster) 或 [Flink Application 集群]({{< ref \"docs/concepts/glossary\" >}}#flink-application-cluster)。这些选项之间的差异主要与集群的生命周期和资源隔离保证有关。\n+\n+### Flink Session 集群\n+\n+* **集群生命周期**：在 Flink Session 集群中，客户端连接到一个预先存在的、长期运行的集群，该集群可以接受多个作业提交。即使所有作业完成后，集群（和 JobManager）仍将继续运行直到手动停止 session 为止。因此，Flink Session 集群的寿命不受任何 Flink 作业寿命的约束。\n+\n+* **资源隔离**：TaskManager slot 由 ResourceManager 在提交作业时分配，并在作业完成时释放。由于所有作业都共享同一集群，因此在集群资源方面存在一些竞争 — 例如提交工作阶段的网络带宽。此共享设置的局限性在于，如果 TaskManager 崩溃，则在此 TaskManager 上运行 task 的所有作业都将失败；类似的，如果 JobManager 上发生一些致命错误，它将影响集群中正在运行的所有作业。\n+\n+* **其他注意事项**：拥有一个预先存在的集群可以节省大量时间申请资源和启动 TaskManager。有种场景很重要，作业执行时间短并且启动时间长会对端到端的用户体验产生负面的影响 — 就像对简短查询的交互式分析一样，希望作业可以使用现有资源快速执行计算。\n+\n+{{< hint info >}}\n+以前，Flink Session 集群也被称为 <i> session 模式</i>下的 Flink 集群。\n+{{< /hint >}}\n+\n+### Flink Job 集群\n+\n+* **集群生命周期**：在 Flink Job 集群中，可用的集群管理器（例如 YARN）用于为每个提交的作业启动一个集群，并且该集群仅可用于该作业。在这里，客户端首先从集群管理器请求资源启动 JobManager，然后将作业提交给在这个进程中运行的 Dispatcher。然后根据作业的资源请求惰性的分配 TaskManager。一旦作业完成，Flink Job 集群将被拆除。\n+\n+* **资源隔离**：JobManager 中的致命错误仅影响在 Flink Job 集群中运行的一个作业。\n+\n+* **其他注意事项**：由于 ResourceManager 必须应用并等待外部资源管理组件来启动 TaskManager 进程和分配资源，因此 Flink Job 集群更适合长期运行、具有高稳定性要求且对较长的启动时间不敏感的大型作业。\n+\n+{{< hint info >}}\n+以前，Flink Job 集群也被称为<i> job (or per-job) 模式</i>下的 Flink 集群。\n+{{< /hint >}}\n+{{< hint info >}}\n+Kubernetes 不支持 Flink Job 集群。 请参考 [Standalone Kubernetes]({{< ref \"docs/deployment/resource-providers/standalone/kubernetes\" >}}#per-job-cluster-mode) 和 [Native Kubernetes]({{< ref \"docs/deployment/resource-providers/native_kubernetes\" >}}#per-job-cluster-mode)。\n+{{< /hint >}}\n+\n+### Flink Application 集群\n+\n+* **集群生命周期**：Flink Application 集群是专用的 Flink 集群，仅从 Flink 应用程序执行作业，并且 ``main()``方法在集群上而不是客户端上运行。提交作业是一个单步骤过程：无需先启动 Flink 集群，然后将作业提交到现有的 session 集群；相反，将应用程序逻辑和依赖打包成一个可执行的作业 JAR 中，并且集群入口（``ApplicationClusterEntryPoint``）负责调用 ``main()``方法来提取 JobGraph。例如，这允许你像在 Kubernetes 上部署任何其他应用程序一样部署 Flink 应用程序。因此，Flink Application 集群的寿命与 Flink 应用程序的寿命有关。\n+\n+* **资源隔离**：在 Flink Application 集群中，ResourceManager 和 Dispatcher 作用于单个的 Flink 应用程序，相比于 Flink Session 集群，它提供了更好的隔离。\n+\n+{{< hint info >}}\n+Flink Job 集群可以看做是 Flink Application 集群”客户端运行“的替代方案。\n+{{< /hint >}}\n+\n+{{< top >}}"
        },
        {
            "sha": "c1ea57929b9c4ea487e42495d96230e4f24d7964",
            "filename": "docs/content.zh/docs/concepts/glossary.md",
            "status": "added",
            "additions": 145,
            "deletions": 0,
            "changes": 145,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/concepts/glossary.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/concepts/glossary.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/concepts/glossary.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,145 @@\n+---\n+title: 词汇表\n+weight: 11\n+type: docs\n+bookToc: false\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# 词汇表\n+\n+#### Flink Application Cluster\n+\n+A Flink Application Cluster is a dedicated [Flink Cluster](#flink-cluster) that\n+only executes [Flink Jobs](#flink-job) from one [Flink Application](#flink-application).\n+The lifetime of the [Flink Cluster](#flink-cluster) is bound to the lifetime of the Flink Application.\n+\n+#### Flink Job Cluster\n+\n+A Flink Job Cluster is a dedicated [Flink Cluster](#flink-cluster) that only\n+executes a single [Flink Job](#flink-job). The lifetime of the\n+[Flink Cluster](#flink-cluster) is bound to the lifetime of the Flink Job.\n+\n+#### Flink Cluster\n+\n+一般情况下，Flink 集群是由一个 [Flink JobManager](#flink-jobmanager) 和一个或多个 [Flink TaskManager](#flink-taskmanager) 进程组成的分布式系统。\n+\n+#### Event\n+\n+Event 是对应用程序建模的域的状态更改的声明。它可以同时为流或批处理应用程序的 input 和 output，也可以单独是 input 或者 output 中的一种。Event 是特殊类型的 [Record](#record)。\n+\n+#### ExecutionGraph\n+\n+见 [Physical Graph](#physical-graph)。\n+\n+#### Function\n+\n+Function 是由用户实现的，并封装了 Flink 程序的应用程序逻辑。大多数 Function 都由相应的 [Operator](#operator) 封装。\n+\n+#### Instance\n+\n+Instance 常用于描述运行时的特定类型(通常是 [Operator](#operator) 或者 [Function](#function))的一个具体实例。由于 Apache Flink 主要是用 Java 编写的，所以，这与 Java 中的 *Instance* 或 *Object* 的定义相对应。在 Apache Flink 的上下文中，*parallel instance* 也常用于强调同一 [Operator](#operator) 或者 [Function](#function) 的多个 instance 以并行的方式运行。\n+\n+#### Flink Application\n+\n+A Flink application is a Java Application that submits one or multiple [Flink\n+Jobs](#flink-job) from the `main()` method (or by some other means). Submitting\n+jobs is usually done by calling `execute()` on an execution environment.\n+\n+The jobs of an application can either be submitted to a long running [Flink\n+Session Cluster](#flink-session-cluster), to a dedicated [Flink Application\n+Cluster](#flink-application-cluster), or to a [Flink Job\n+Cluster](#flink-job-cluster).\n+\n+#### Flink Job\n+\n+A Flink Job is the runtime representation of a [logical graph](#logical-graph)\n+(also often called dataflow graph) that is created and submitted by calling\n+`execute()` in a [Flink Application](#flink-application).\n+\n+#### JobGraph\n+\n+见 [Logical Graph](#logical-graph)。\n+\n+#### Flink JobManager\n+\n+Flink JobManager 是 [Flink Cluster](#flink-cluster) 的主节点。它包含三个不同的组件：Flink Resource Manager、Flink Dispatcher、运行每个 [Flink Job](#flink-job) 的 [Flink JobMaster](#flink-jobmaster)。 \n+\n+\n+#### Flink JobMaster\n+\n+JobMaster 是在 [Flink JobManager](#flink-jobmanager) 运行中的组件之一。JobManager 负责监督单个作业 [Task](#task) 的执行。以前，整个 [Flink JobManager](#flink-jobmanager) 都叫做 JobManager。\n+\n+#### Logical Graph\n+\n+A logical graph is a directed graph where the nodes are  [Operators](#operator)\n+and the edges define input/output-relationships of the operators and correspond\n+to data streams or data sets. A logical graph is created by submitting jobs\n+from a [Flink Application](#flink-application).\n+\n+Logical graphs are also often referred to as *dataflow graphs*.\n+\n+#### Managed State\n+\n+Managed State 描述了已在框架中注册的应用程序的托管状态。对于托管状态，Apache Flink 会负责持久化和重伸缩等事宜。\n+\n+#### Operator\n+\n+[Logical Graph](#logical-graph) 的节点。算子执行某种操作，该操作通常由 [Function](#function) 执行。Source 和 Sink 是数据输入和数据输出的特殊算子。\n+\n+#### Operator Chain\n+\n+算子链由两个或多个连续的 [Operator](#operator) 组成，两者之间没有任何的重新分区。同一算子链内的算子可以彼此直接传递 record，而无需通过序列化或 Flink 的网络栈。\n+\n+#### Partition\n+\n+分区是整个数据流或数据集的独立子集。通过将每个 [Record](#record) 分配给一个或多个分区，来把数据流或数据集划分为多个分区。在运行期间，[Task](#task) 会消费数据流或数据集的分区。改变数据流或数据集分区方式的转换通常称为重分区。\n+\n+#### Physical Graph\n+\n+Physical graph 是一个在分布式运行时，把 [Logical Graph](#logical-graph) 转换为可执行的结果。节点是 [Task](#task)，边表示数据流或数据集的输入/输出关系或 [partition](#partition)。\n+\n+#### Record\n+\n+Record 是数据集或数据流的组成元素。[Operator](#operator) 和 [Function](#Function)接收 record 作为输入，并将 record 作为输出发出。\n+\n+#### Flink Session Cluster\n+\n+长时间运行的 [Flink Cluster](#flink-cluster)，它可以接受多个 [Flink Job](#flink-job) 的执行。此 [Flink Cluster](#flink-cluster) 的生命周期不受任何 [Flink Job](#flink-job) 生命周期的约束限制。以前，Flink Session Cluster 也称为 *session mode* 的 [Flink Cluster](#flink-cluster)，和 [Flink Application Cluster](#flink-application-cluster) 相对应。\n+\n+#### State Backend\n+\n+对于流处理程序，[Flink Job](#flink-job) 的 State Backend 决定了其 [state](#managed-state) 是如何存储在每个 TaskManager 上的（ TaskManager 的 Java 堆栈或嵌入式 RocksDB），以及它在 checkpoint 时的写入位置（ [Flink JobManager](#flink-jobmanager) 的 Java 堆或者 Filesystem）。\n+\n+#### Sub-Task\n+\n+Sub-Task 是负责处理数据流 [Partition](#partition) 的 [Task](#task)。\"Sub-Task\"强调的是同一个 [Operator](#operator) 或者 [Operator Chain](#operator-chain) 具有多个并行的 Task 。\n+\n+#### Task\n+\n+Task 是 [Physical Graph](#physical-graph) 的节点。它是基本的工作单元，由 Flink 的 runtime 来执行。Task 正好封装了一个 [Operator](#operator) 或者 [Operator Chain](#operator-chain) 的 *parallel instance*。 \n+\n+#### Flink TaskManager\n+\n+TaskManager 是 [Flink Cluster](#flink-cluster) 的工作进程。[Task](#task) 被调度到 TaskManager 上执行。TaskManager 相互通信，只为在后续的 Task 之间交换数据。\n+\n+#### Transformation\n+\n+Transformation 应用于一个或多个数据流或数据集，并产生一个或多个输出数据流或数据集。Transformation 可能会在每个记录的基础上更改数据流或数据集，但也可以只更改其分区或执行聚合。虽然 [Operator](#operator) 和 [Function](#function) 是 Flink API 的“物理”部分，但 Transformation 只是一个 API 概念。具体来说，大多数（但不是全部）Transformation 是由某些 [Operator](#operator) 实现的。"
        },
        {
            "sha": "12e512911f70b3f962c4697b9276cf17ba2292e3",
            "filename": "docs/content.zh/docs/concepts/overview.md",
            "status": "added",
            "additions": 50,
            "deletions": 0,
            "changes": 50,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/concepts/overview.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/concepts/overview.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/concepts/overview.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,50 @@\n+---\n+title: 概览 \n+weight: 1\n+type: docs\n+aliases: \n+  - /zh/concepts/\n+  - /zh/concepts/concepts.html\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# 概念透析\n+\n+[实践练习]({{< ref \"docs/learn-flink/overview\" >}})章节介绍了作为 Flink API 根基的有状态实时流处理的基本概念，并且举例说明了如何在 Flink 应用中使用这些机制。其中 [Data Pipelines & ETL]({{< ref \"docs/learn-flink/etl\" >}}#stateful-transformations) 小节介绍了有状态流处理的概念，并且在 [Fault Tolerance]({{< ref \"docs/learn-flink/fault_tolerance\" >}}) 小节中进行了深入介绍。[Streaming Analytics]({{< ref \"docs/learn-flink/streaming_analytics\" >}}) 小节介绍了实时流处理的概念。\n+\n+本章将深入分析 Flink 分布式运行时架构如何实现这些概念。\n+\n+## Flink 中的 API\n+\n+Flink 为流式/批式处理应用程序的开发提供了不同级别的抽象。\n+\n+{{< img src=\"/fig/levels_of_abstraction.svg\" alt=\"Programming levels of abstraction\" class=\"offset\" width=\"80%\" >}}\n+\n+  - Flink API 最底层的抽象为**有状态实时流处理**。其抽象实现是 [Process Function]({{< ref \"docs/dev/datastream/operators/process_function\" >}})，并且 **Process Function** 被 Flink 框架集成到了 [DataStream API]({{< ref \"docs/dev/datastream/overview\" >}}) 中来为我们使用。它允许用户在应用程序中自由地处理来自单流或多流的事件（数据），并提供具有全局一致性和容错保障的*状态*。此外，用户可以在此层抽象中注册事件时间（event time）和处理时间（processing time）回调方法，从而允许程序可以实现复杂计算。\n+\n+  - Flink API 第二层抽象是 **Core APIs**。实际上，许多应用程序不需要使用到上述最底层抽象的 API，而是可以使用 **Core APIs** 进行编程：其中包含 [DataStream API]({{< ref \"docs/dev/datastream/overview\" >}})（应用于有界/无界数据流场景）和 [DataSet API]({{< ref \"docs/dev/dataset/overview\" >}})（应用于有界数据集场景）两部分。Core APIs 提供的流式 API（Fluent API）为数据处理提供了通用的模块组件，例如各种形式的用户自定义转换（transformations）、联接（joins）、聚合（aggregations）、窗口（windows）和状态（state）操作等。此层 API 中处理的数据类型在每种编程语言中都有其对应的类。\n+\n+    *Process Function* 这类底层抽象和 *DataStream API* 的相互集成使得用户可以选择使用更底层的抽象 API 来实现自己的需求。*DataSet API* 还额外提供了一些原语，比如循环/迭代（loop/iteration）操作。\n+\n+  - Flink API 第三层抽象是 **Table API**。**Table API** 是以表（Table）为中心的声明式编程（DSL）API，例如在流式数据场景下，它可以表示一张正在动态改变的表。[Table API]({{< ref \"docs/dev/table/overview\" >}}) 遵循（扩展）关系模型：即表拥有 schema（类似于关系型数据库中的 schema），并且 Table API 也提供了类似于关系模型中的操作，比如 select、project、join、group-by 和 aggregate 等。Table API 程序是以声明的方式定义*应执行的逻辑操作*，而不是确切地指定程序*应该执行的代码*。尽管 Table API 使用起来很简洁并且可以由各种类型的用户自定义函数扩展功能，但还是比 Core API 的表达能力差。此外，Table API 程序在执行之前还会使用优化器中的优化规则对用户编写的表达式进行优化。\n+\n+    表和 *DataStream*/*DataSet* 可以进行无缝切换，Flink 允许用户在编写应用程序时将 *Table API* 与 *DataStream*/*DataSet* API 混合使用。\n+\n+  - Flink API 最顶层抽象是 **SQL**。这层抽象在语义和程序表达式上都类似于 *Table API*，但是其程序实现都是 SQL 查询表达式。[SQL]({{< ref \"docs/dev/table/overview\" >}}#sql) 抽象与 Table API 抽象之间的关联是非常紧密的，并且 SQL 查询语句可以在 *Table API* 中定义的表上执行。"
        },
        {
            "sha": "c78949508e89692b5070b351145839c3f057def3",
            "filename": "docs/content.zh/docs/concepts/stateful-stream-processing.md",
            "status": "added",
            "additions": 365,
            "deletions": 0,
            "changes": 365,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/concepts/stateful-stream-processing.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/concepts/stateful-stream-processing.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/concepts/stateful-stream-processing.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,365 @@\n+---\n+title: 有状态流处理\n+weight: 2\n+type: docs\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# 有状态流处理\n+\n+## What is State?\n+\n+While many operations in a dataflow simply look at one individual *event at a\n+time* (for example an event parser), some operations remember information\n+across multiple events (for example window operators). These operations are\n+called **stateful**.\n+\n+Some examples of stateful operations:\n+\n+  - When an application searches for certain event patterns, the state will\n+    store the sequence of events encountered so far.\n+  - When aggregating events per minute/hour/day, the state holds the pending\n+    aggregates.\n+  - When training a machine learning model over a stream of data points, the\n+    state holds the current version of the model parameters.\n+  - When historic data needs to be managed, the state allows efficient access\n+    to events that occurred in the past.\n+\n+Flink needs to be aware of the state in order to make it fault tolerant using\n+[checkpoints]({{< ref \"docs/dev/datastream/fault-tolerance/checkpointing\" >}})\n+and [savepoints]({{< ref \"docs/ops/state/savepoints\" >}}).\n+\n+Knowledge about the state also allows for rescaling Flink applications, meaning\n+that Flink takes care of redistributing state across parallel instances.\n+\n+[Queryable state]({{< ref \"docs/dev/datastream/fault-tolerance/queryable_state\" >}}) allows you to access state from outside of Flink during runtime.\n+\n+When working with state, it might also be useful to read about [Flink's state\n+backends]({{< ref \"docs/ops/state/state_backends\" >}}). Flink\n+provides different state backends that specify how and where state is stored.\n+\n+{{< top >}}\n+\n+## Keyed State\n+\n+Keyed state is maintained in what can be thought of as an embedded key/value\n+store.  The state is partitioned and distributed strictly together with the\n+streams that are read by the stateful operators. Hence, access to the key/value\n+state is only possible on *keyed streams*, i.e. after a keyed/partitioned data\n+exchange, and is restricted to the values associated with the current event's\n+key. Aligning the keys of streams and state makes sure that all state updates\n+are local operations, guaranteeing consistency without transaction overhead.\n+This alignment also allows Flink to redistribute the state and adjust the\n+stream partitioning transparently.\n+\n+{{< img src=\"/fig/state_partitioning.svg\" alt=\"State and Partitioning\" class=\"offset\" width=\"50%\" >}}\n+\n+Keyed State is further organized into so-called *Key Groups*. Key Groups are\n+the atomic unit by which Flink can redistribute Keyed State; there are exactly\n+as many Key Groups as the defined maximum parallelism.  During execution each\n+parallel instance of a keyed operator works with the keys for one or more Key\n+Groups.\n+\n+## State Persistence\n+\n+Flink implements fault tolerance using a combination of **stream replay** and\n+**checkpointing**. A checkpoint marks a specific point in each of the\n+input streams along with the corresponding state for each of the operators. A\n+streaming dataflow can be resumed from a checkpoint while maintaining\n+consistency *(exactly-once processing semantics)* by restoring the state of the\n+operators and replaying the records from the point of the checkpoint.\n+\n+The checkpoint interval is a means of trading off the overhead of fault\n+tolerance during execution with the recovery time (the number of records that\n+need to be replayed).\n+\n+The fault tolerance mechanism continuously draws snapshots of the distributed\n+streaming data flow. For streaming applications with small state, these\n+snapshots are very light-weight and can be drawn frequently without much impact\n+on performance.  The state of the streaming applications is stored at a\n+configurable place, usually in a distributed file system.\n+\n+In case of a program failure (due to machine-, network-, or software failure),\n+Flink stops the distributed streaming dataflow.  The system then restarts the\n+operators and resets them to the latest successful checkpoint. The input\n+streams are reset to the point of the state snapshot. Any records that are\n+processed as part of the restarted parallel dataflow are guaranteed to not have\n+affected the previously checkpointed state.\n+\n+{{< hint warning >}}\n+By default, checkpointing is disabled. See [Checkpointing]({{< ref \"docs/dev/datastream/fault-tolerance/checkpointing\" >}}) for details on how to enable and configure checkpointing.\n+{{< /hint >}}\n+\n+{{< hint info >}}\n+For this mechanism to realize its full guarantees, the data\n+stream source (such as message queue or broker) needs to be able to rewind the\n+stream to a defined recent point. [Apache Kafka](http://kafka.apache.org) has\n+this ability and Flink's connector to Kafka exploits this. See [Fault\n+Tolerance Guarantees of Data Sources and Sinks]({{< ref \"docs/connectors/datastream/guarantees\" >}}) for more information about the guarantees\n+provided by Flink's connectors.\n+{{< /hint >}}\n+\n+{{< hint info >}} \n+Because Flink's checkpoints are realized through distributed\n+snapshots, we use the words *snapshot* and *checkpoint* interchangeably. Often\n+we also use the term *snapshot* to mean either *checkpoint* or *savepoint*.\n+{{< /hint >}}\n+\n+### Checkpointing\n+\n+The central part of Flink's fault tolerance mechanism is drawing consistent\n+snapshots of the distributed data stream and operator state.  These snapshots\n+act as consistent checkpoints to which the system can fall back in case of a\n+failure. Flink's mechanism for drawing these snapshots is described in\n+\"[Lightweight Asynchronous Snapshots for Distributed\n+Dataflows](http://arxiv.org/abs/1506.08603)\". It is inspired by the standard\n+[Chandy-Lamport algorithm](http://research.microsoft.com/en-us/um/people/lamport/pubs/chandy.pdf)\n+for distributed snapshots and is specifically tailored to Flink's execution\n+model.\n+\n+Keep in mind that everything to do with checkpointing can be done\n+asynchronously. The checkpoint barriers don't travel in lock step and\n+operations can asynchronously snapshot their state.\n+\n+Since Flink 1.11, checkpoints can be taken with or without alignment. In this \n+section, we describe aligned checkpoints first.\n+\n+#### Barriers\n+\n+A core element in Flink's distributed snapshotting are the *stream barriers*.\n+These barriers are injected into the data stream and flow with the records as\n+part of the data stream. Barriers never overtake records, they flow strictly in\n+line.  A barrier separates the records in the data stream into the set of\n+records that goes into the current snapshot, and the records that go into the\n+next snapshot. Each barrier carries the ID of the snapshot whose records it\n+pushed in front of it. Barriers do not interrupt the flow of the stream and are\n+hence very lightweight. Multiple barriers from different snapshots can be in\n+the stream at the same time, which means that various snapshots may happen\n+concurrently.\n+\n+<div style=\"text-align: center\">\n+  {{< img src=\"/fig/stream_barriers.svg\" alt=\"Checkpoint barriers in data streams\" width=\"60%\" >}}\n+</div>\n+\n+Stream barriers are injected into the parallel data flow at the stream sources.\n+The point where the barriers for snapshot *n* are injected (let's call it\n+<i>S<sub>n</sub></i>) is the position in the source stream up to which the\n+snapshot covers the data. For example, in Apache Kafka, this position would be\n+the last record's offset in the partition. This position <i>S<sub>n</sub></i>\n+is reported to the *checkpoint coordinator* (Flink's JobManager).\n+\n+The barriers then flow downstream. When an intermediate operator has received a\n+barrier for snapshot *n* from all of its input streams, it emits a barrier for\n+snapshot *n* into all of its outgoing streams. Once a sink operator (the end of\n+a streaming DAG) has received the barrier *n* from all of its input streams, it\n+acknowledges that snapshot *n* to the checkpoint coordinator. After all sinks\n+have acknowledged a snapshot, it is considered completed.\n+\n+Once snapshot *n* has been completed, the job will never again ask the source\n+for records from before <i>S<sub>n</sub></i>, since at that point these records\n+(and their descendant records) will have passed through the entire data flow\n+topology.\n+\n+<div style=\"text-align: center\">\n+  {{< img src=\"/fig/stream_aligning.svg\" alt=\"Aligning data streams at operators with multiple inputs\" width=\"60%\" >}}\n+</div>\n+\n+Operators that receive more than one input stream need to *align* the input\n+streams on the snapshot barriers. The figure above illustrates this:\n+\n+  - As soon as the operator receives snapshot barrier *n* from an incoming\n+    stream, it cannot process any further records from that stream until it has\n+    received the barrier *n* from the other inputs as well. Otherwise, it would\n+    mix records that belong to snapshot *n* and with records that belong to\n+    snapshot *n+1*.\n+  - Once the last stream has received barrier *n*, the operator emits all\n+    pending outgoing records, and then emits snapshot *n* barriers itself.\n+  - It snapshots the state and resumes processing records from all input streams,\n+    processing records from the input buffers before processing the records\n+    from the streams.\n+  - Finally, the operator writes the state asynchronously to the state backend.\n+  \n+Note that the alignment is needed for all operators with multiple inputs and for \n+operators after a shuffle when they consume output streams of multiple upstream \n+subtasks.\n+\n+#### Snapshotting Operator State\n+\n+When operators contain any form of *state*, this state must be part of the\n+snapshots as well.\n+\n+Operators snapshot their state at the point in time when they have received all\n+snapshot barriers from their input streams, and before emitting the barriers to\n+their output streams. At that point, all updates to the state from records\n+before the barriers have been made, and no updates that depend on records\n+from after the barriers have been applied. Because the state of a snapshot may\n+be large, it is stored in a configurable *[state backend]({{< ref \"docs/ops/state/state_backends\" >}})*. By default, this is the JobManager's\n+memory, but for production use a distributed reliable storage should be\n+configured (such as HDFS). After the state has been stored, the operator\n+acknowledges the checkpoint, emits the snapshot barrier into the output\n+streams, and proceeds.\n+\n+The resulting snapshot now contains:\n+\n+  - For each parallel stream data source, the offset/position in the stream\n+    when the snapshot was started\n+  - For each operator, a pointer to the state that was stored as part of the\n+    snapshot\n+\n+<div style=\"text-align: center\">\n+  {{< img src=\"/fig/checkpointing.svg\" alt=\"Illustration of the Checkpointing Mechanism\" width=\"75%\" >}}\n+</div>\n+\n+#### Recovery\n+\n+Recovery under this mechanism is straightforward: Upon a failure, Flink selects\n+the latest completed checkpoint *k*. The system then re-deploys the entire\n+distributed dataflow, and gives each operator the state that was snapshotted as\n+part of checkpoint *k*. The sources are set to start reading the stream from\n+position <i>S<sub>k</sub></i>. For example in Apache Kafka, that means telling\n+the consumer to start fetching from offset <i>S<sub>k</sub></i>.\n+\n+If state was snapshotted incrementally, the operators start with the state of\n+the latest full snapshot and then apply a series of incremental snapshot\n+updates to that state.\n+\n+See [Restart Strategies]({{< ref \"docs/dev/execution/task_failure_recovery\" >}}#restart-strategies) for more information.\n+\n+### Unaligned Checkpointing\n+\n+Checkpointing can also be performed unaligned.\n+The basic idea is that checkpoints can overtake all in-flight data as long as \n+the in-flight data becomes part of the operator state.\n+\n+Note that this approach is actually closer to the [Chandy-Lamport algorithm\n+](http://research.microsoft.com/en-us/um/people/lamport/pubs/chandy.pdf), but\n+Flink still inserts the barrier in the sources to avoid overloading the\n+checkpoint coordinator.\n+\n+{{< img src=\"/fig/stream_unaligning.svg\" alt=\"Unaligned checkpointing\" >}}\n+\n+The figure depicts how an operator handles unaligned checkpoint barriers:\n+\n+- The operator reacts on the first barrier that is stored in its input buffers.\n+- It immediately forwards the barrier to the downstream operator by adding it \n+  to the end of the output buffers.\n+- The operator marks all overtaken records to be stored asynchronously and \n+  creates a snapshot of its own state.\n+ \n+Consequently, the operator only briefly stops the processing of input to mark\n+the buffers, forwards the barrier, and creates the snapshot of the other state.\n+  \n+Unaligned checkpointing ensures that barriers are arriving at the sink as fast \n+as possible. It's especially suited for applications with at least one slow \n+moving data path, where alignment times can reach hours. However, since it's\n+adding additional I/O pressure, it doesn't help when the I/O to the state \n+backends is the bottleneck. See the more in-depth discussion in \n+[ops]({{< ref \"docs/ops/state/checkpoints\" >}}#unaligned-checkpoints)\n+for other limitations.\n+\n+Note that savepoints will always be aligned.\n+\n+#### Unaligned Recovery\n+\n+Operators first recover the in-flight data before starting processing any data\n+from upstream operators in unaligned checkpointing. Aside from that, it \n+performs the same steps as during [recovery of aligned checkpoints](#recovery).\n+\n+### State Backends\n+\n+The exact data structures in which the key/values indexes are stored depends on\n+the chosen [state backend]({{< ref \"docs/ops/state/state_backends\" >}}). One state backend stores data in an in-memory\n+hash map, another state backend uses [RocksDB](http://rocksdb.org) as the\n+key/value store.  In addition to defining the data structure that holds the\n+state, the state backends also implement the logic to take a point-in-time\n+snapshot of the key/value state and store that snapshot as part of a\n+checkpoint. State backends can be configured without changing your application\n+logic.\n+\n+{{< img src=\"/fig/checkpoints.svg\" alt=\"checkpoints and snapshots\" class=\"offset\" width=\"60%\" >}}\n+\n+{{< top >}}\n+\n+### Savepoints\n+\n+All programs that use checkpointing can resume execution from a **savepoint**.\n+Savepoints allow both updating your programs and your Flink cluster without\n+losing any state.\n+\n+[Savepoints]({{< ref \"docs/ops/state/savepoints\" >}}) are\n+**manually triggered checkpoints**, which take a snapshot of the program and\n+write it out to a state backend. They rely on the regular checkpointing\n+mechanism for this.\n+\n+Savepoints are similar to checkpoints except that they are\n+**triggered by the user** and **don't automatically expire** when newer\n+checkpoints are completed.\n+\n+{{< top >}}\n+\n+### Exactly Once vs. At Least Once\n+\n+The alignment step may add latency to the streaming program. Usually, this\n+extra latency is on the order of a few milliseconds, but we have seen cases\n+where the latency of some outliers increased noticeably. For applications that\n+require consistently super low latencies (few milliseconds) for all records,\n+Flink has a switch to skip the stream alignment during a checkpoint. Checkpoint\n+snapshots are still drawn as soon as an operator has seen the checkpoint\n+barrier from each input.\n+\n+When the alignment is skipped, an operator keeps processing all inputs, even\n+after some checkpoint barriers for checkpoint *n* arrived. That way, the\n+operator also processes elements that belong to checkpoint *n+1* before the\n+state snapshot for checkpoint *n* was taken.  On a restore, these records will\n+occur as duplicates, because they are both included in the state snapshot of\n+checkpoint *n*, and will be replayed as part of the data after checkpoint *n*.\n+\n+{{< hint info >}}\n+Alignment happens only for operators with multiple predecessors\n+(joins) as well as operators with multiple senders (after a stream\n+repartitioning/shuffle).  Because of that, dataflows with only embarrassingly\n+parallel streaming operations (`map()`, `flatMap()`, `filter()`, ...) actually\n+give *exactly once* guarantees even in *at least once* mode.\n+{{< /hint >}}\n+\n+{{< top >}}\n+\n+## State and Fault Tolerance in Batch Programs\n+\n+Flink executes [batch programs]({{< ref \"docs/dev/dataset/overview\" >}}) as a special case of\n+streaming programs, where the streams are bounded (finite number of elements).\n+A *DataSet* is treated internally as a stream of data. The concepts above thus\n+apply to batch programs in the same way as well as they apply to streaming\n+programs, with minor exceptions:\n+\n+  - [Fault tolerance for batch programs]({{< ref \"docs/dev/execution/task_failure_recovery\" >}})\n+    does not use checkpointing.  Recovery happens by fully replaying the\n+    streams.  That is possible, because inputs are bounded. This pushes the\n+    cost more towards the recovery, but makes the regular processing cheaper,\n+    because it avoids checkpoints.\n+\n+  - Stateful operations in the DataSet API use simplified in-memory/out-of-core\n+    data structures, rather than key/value indexes.\n+\n+  - The DataSet API introduces special synchronized (superstep-based)\n+    iterations, which are only possible on bounded streams. For details, check\n+    out the [iteration docs]({{< ref \"docs/dev/dataset/iterations\" >}}).\n+\n+{{< top >}}"
        },
        {
            "sha": "473aa0d8c18956447e761f7396c125aa66bf9f75",
            "filename": "docs/content.zh/docs/concepts/time.md",
            "status": "added",
            "additions": 204,
            "deletions": 0,
            "changes": 204,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/concepts/time.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/concepts/time.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/concepts/time.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,204 @@\n+---\n+title: 及时流处理\n+weight: 3\n+type: docs\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# 及时流处理\n+\n+## Introduction\n+\n+Timely stream processing is an extension of [stateful stream processing]({{< ref \"docs/concepts/stateful-stream-processing\" >}}) in which time plays some role in the\n+computation. Among other things, this is the case when you do time series\n+analysis, when doing aggregations based on certain time periods (typically\n+called windows), or when you do event processing where the time when an event\n+occurred is important.\n+\n+In the following sections we will highlight some of the topics that you should\n+consider when working with timely Flink Applications.\n+\n+{{< top >}}\n+\n+## Notions of Time: Event Time and Processing Time\n+\n+When referring to time in a streaming program (for example to define windows),\n+one can refer to different notions of *time*:\n+\n+- **Processing time:** Processing time refers to the system time of the machine\n+  that is executing the respective operation.\n+\n+  When a streaming program runs on processing time, all time-based operations\n+  (like time windows) will use the system clock of the machines that run the\n+  respective operator. An hourly processing time window will include all\n+  records that arrived at a specific operator between the times when the system\n+  clock indicated the full hour. For example, if an application begins running\n+  at 9:15am, the first hourly processing time window will include events\n+  processed between 9:15am and 10:00am, the next window will include events\n+  processed between 10:00am and 11:00am, and so on.\n+\n+  Processing time is the simplest notion of time and requires no coordination\n+  between streams and machines.  It provides the best performance and the\n+  lowest latency. However, in distributed and asynchronous environments\n+  processing time does not provide determinism, because it is susceptible to\n+  the speed at which records arrive in the system (for example from the message\n+  queue), to the speed at which the records flow between operators inside the\n+  system, and to outages (scheduled, or otherwise).\n+\n+- **Event time:** Event time is the time that each individual event occurred on\n+  its producing device.  This time is typically embedded within the records\n+  before they enter Flink, and that *event timestamp* can be extracted from\n+  each record. In event time, the progress of time depends on the data, not on\n+  any wall clocks. Event time programs must specify how to generate *Event Time\n+  Watermarks*, which is the mechanism that signals progress in event time. This\n+  watermarking mechanism is described in a later section,\n+  [below](#event-time-and-watermarks).\n+\n+  In a perfect world, event time processing would yield completely consistent\n+  and deterministic results, regardless of when events arrive, or their\n+  ordering.  However, unless the events are known to arrive in-order (by\n+  timestamp), event time processing incurs some latency while waiting for\n+  out-of-order events. As it is only possible to wait for a finite period of\n+  time, this places a limit on how deterministic event time applications can\n+  be.\n+\n+  Assuming all of the data has arrived, event time operations will behave as\n+  expected, and produce correct and consistent results even when working with\n+  out-of-order or late events, or when reprocessing historic data. For example,\n+  an hourly event time window will contain all records that carry an event\n+  timestamp that falls into that hour, regardless of the order in which they\n+  arrive, or when they are processed. (See the section on [late\n+  events](#late-elements) for more information.)\n+\n+  Note that sometimes when event time programs are processing live data in\n+  real-time, they will use some *processing time* operations in order to\n+  guarantee that they are progressing in a timely fashion.\n+\n+{{< img src=\"/fig/event_processing_time.svg\" alt=\"Event Time and Processing Time\" width=\"80%\" >}}\n+\n+{{< top >}}\n+\n+## Event Time and Watermarks\n+\n+*Note: Flink implements many techniques from the Dataflow Model. For a good\n+introduction to event time and watermarks, have a look at the articles below.*\n+\n+  - [Streaming 101](https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-101) by Tyler Akidau\n+  - The [Dataflow Model paper](https://research.google.com/pubs/archive/43864.pdf)\n+\n+\n+A stream processor that supports *event time* needs a way to measure the\n+progress of event time.  For example, a window operator that builds hourly\n+windows needs to be notified when event time has passed beyond the end of an\n+hour, so that the operator can close the window in progress.\n+\n+*Event time* can progress independently of *processing time* (measured by wall\n+clocks).  For example, in one program the current *event time* of an operator\n+may trail slightly behind the *processing time* (accounting for a delay in\n+receiving the events), while both proceed at the same speed.  On the other\n+hand, another streaming program might progress through weeks of event time with\n+only a few seconds of processing, by fast-forwarding through some historic data\n+already buffered in a Kafka topic (or another message queue).\n+\n+------\n+\n+The mechanism in Flink to measure progress in event time is **watermarks**.\n+Watermarks flow as part of the data stream and carry a timestamp *t*. A\n+*Watermark(t)* declares that event time has reached time *t* in that stream,\n+meaning that there should be no more elements from the stream with a timestamp\n+*t' <= t* (i.e. events with timestamps older or equal to the watermark).\n+\n+The figure below shows a stream of events with (logical) timestamps, and\n+watermarks flowing inline. In this example the events are in order (with\n+respect to their timestamps), meaning that the watermarks are simply periodic\n+markers in the stream.\n+\n+{{< img src=\"/fig/stream_watermark_in_order.svg\" alt=\"A data stream with events (in order) and watermarks\" width=\"65%\" >}}\n+\n+Watermarks are crucial for *out-of-order* streams, as illustrated below, where\n+the events are not ordered by their timestamps.  In general a watermark is a\n+declaration that by that point in the stream, all events up to a certain\n+timestamp should have arrived.  Once a watermark reaches an operator, the\n+operator can advance its internal *event time clock* to the value of the\n+watermark.\n+\n+{{< img src=\"/fig/stream_watermark_out_of_order.svg\" alt=\"A data stream with events (out of order) and watermarks\" width=\"65%\" >}}\n+\n+Note that event time is inherited by a freshly created stream element (or\n+elements) from either the event that produced them or from watermark that\n+triggered creation of those elements.\n+\n+### Watermarks in Parallel Streams\n+\n+Watermarks are generated at, or directly after, source functions. Each parallel\n+subtask of a source function usually generates its watermarks independently.\n+These watermarks define the event time at that particular parallel source.\n+\n+As the watermarks flow through the streaming program, they advance the event\n+time at the operators where they arrive. Whenever an operator advances its\n+event time, it generates a new watermark downstream for its successor\n+operators.\n+\n+Some operators consume multiple input streams; a union, for example, or\n+operators following a *keyBy(...)* or *partition(...)* function.  Such an\n+operator's current event time is the minimum of its input streams' event times.\n+As its input streams update their event times, so does the operator.\n+\n+The figure below shows an example of events and watermarks flowing through\n+parallel streams, and operators tracking event time.\n+\n+{{< img src=\"/fig/parallel_streams_watermarks.svg\" alt=\"Parallel data streams and operators with events and watermarks\" class=\"center\" width=\"80%\" >}}\n+\n+## Lateness\n+\n+It is possible that certain elements will violate the watermark condition,\n+meaning that even after the *Watermark(t)* has occurred, more elements with\n+timestamp *t' <= t* will occur. In fact, in many real world setups, certain\n+elements can be arbitrarily delayed, making it impossible to specify a time by\n+which all elements of a certain event timestamp will have occurred.\n+Furthermore, even if the lateness can be bounded, delaying the watermarks by\n+too much is often not desirable, because it causes too much delay in the\n+evaluation of event time windows.\n+\n+For this reason, streaming programs may explicitly expect some *late* elements.\n+Late elements are elements that arrive after the system's event time clock (as\n+signaled by the watermarks) has already passed the time of the late element's\n+timestamp. See [Allowed Lateness]({{< ref \"docs/dev/datastream/operators/windows\" >}}#allowed-lateness) for more information on\n+how to work with late elements in event time windows.\n+\n+## Windowing\n+\n+Aggregating events (e.g., counts, sums) works differently on streams than in\n+batch processing.  For example, it is impossible to count all elements in a\n+stream, because streams are in general infinite (unbounded). Instead,\n+aggregates on streams (counts, sums, etc), are scoped by **windows**, such as\n+*\"count over the last 5 minutes\"*, or *\"sum of the last 100 elements\"*.\n+\n+Windows can be *time driven* (example: every 30 seconds) or *data driven*\n+(example: every 100 elements).  One typically distinguishes different types of\n+windows, such as *tumbling windows* (no overlap), *sliding windows* (with\n+overlap), and *session windows* (punctuated by a gap of inactivity).\n+\n+{{< img src=\"/fig/windows.svg\" alt=\"Time- and Count Windows\" class=\"offset\" width=\"80%\" >}}\n+\n+Please check out this [blog post](https://flink.apache.org/news/2015/12/04/Introducing-windows.html) for\n+additional examples of windows or take a look a [window documentation]({{< ref \"docs/dev/datastream/operators/windows\" >}}) of the DataStream API.\n+\n+{{< top >}}"
        },
        {
            "sha": "ee1ddc1be0fb52952e7833f1753a6dc949d66481",
            "filename": "docs/content.zh/docs/connectors/_index.md",
            "status": "added",
            "additions": 25,
            "deletions": 0,
            "changes": 25,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/_index.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/_index.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/_index.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,25 @@\n+---\n+title: Connectors\n+icon: <i class=\"fa fa-random title maindish\" aria-hidden=\"true\"></i>\n+bold: true\n+bookCollapseSection: true\n+weight: 6\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n\\ No newline at end of file"
        },
        {
            "sha": "fd7765e38ee868e67aa58f733e034e0a362ad625",
            "filename": "docs/content.zh/docs/connectors/dataset.md",
            "status": "added",
            "additions": 190,
            "deletions": 0,
            "changes": 190,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/dataset.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/dataset.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/dataset.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,190 @@\n+---\n+title:  \"DataSet Connectors\"\n+weight: 11\n+type: docs\n+aliases:\n+  - /zh/dev/batch/connectors.html\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# DataSet Connectors\n+\n+* TOC\n+\n+\n+## Reading from and writing to file systems\n+\n+The Apache Flink project supports multiple [file systems]({{< ref \"docs/deployment/filesystems/overview\" >}}) that can be used as backing stores\n+for input and output connectors. \n+\n+## Connecting to other systems using Input/OutputFormat wrappers for Hadoop\n+\n+Apache Flink allows users to access many different systems as data sources or sinks.\n+The system is designed for very easy extensibility. Similar to Apache Hadoop, Flink has the concept\n+of so called `InputFormat`s and `OutputFormat`s.\n+\n+One implementation of these `InputFormat`s is the `HadoopInputFormat`. This is a wrapper that allows\n+users to use all existing Hadoop input formats with Flink.\n+\n+This section shows some examples for connecting Flink to other systems.\n+[Read more about Hadoop compatibility in Flink]({{< ref \"docs/dev/dataset/hadoop_compatibility\" >}}).\n+\n+## Avro support in Flink\n+\n+Flink has extensive built-in support for [Apache Avro](http://avro.apache.org/). This allows to easily read from Avro files with Flink.\n+Also, the serialization framework of Flink is able to handle classes generated from Avro schemas. Be sure to include the Flink Avro dependency to the pom.xml of your project.\n+\n+```xml\n+<dependency>\n+  <groupId>org.apache.flink</groupId>\n+  <artifactId>flink-avro</artifactId>\n+  <version>{{< version >}}</version>\n+</dependency>\n+```\n+\n+In order to read data from an Avro file, you have to specify an `AvroInputFormat`.\n+\n+**Example**:\n+\n+```java\n+AvroInputFormat<User> users = new AvroInputFormat<User>(in, User.class);\n+DataSet<User> usersDS = env.createInput(users);\n+```\n+\n+Note that `User` is a POJO generated by Avro. Flink also allows to perform string-based key selection of these POJOs. For example:\n+\n+```java\n+usersDS.groupBy(\"name\")\n+```\n+\n+\n+Note that using the `GenericData.Record` type is possible with Flink, but not recommended. Since the record contains the full schema, its very data intensive and thus probably slow to use.\n+\n+Flink's POJO field selection also works with POJOs generated from Avro. However, the usage is only possible if the field types are written correctly to the generated class. If a field is of type `Object` you can not use the field as a join or grouping key.\n+Specifying a field in Avro like this `{\"name\": \"type_double_test\", \"type\": \"double\"},` works fine, however specifying it as a UNION-type with only one field (`{\"name\": \"type_double_test\", \"type\": [\"double\"]},`) will generate a field of type `Object`. Note that specifying nullable types (`{\"name\": \"type_double_test\", \"type\": [\"null\", \"double\"]},`) is possible!\n+\n+\n+\n+### Access Microsoft Azure Table Storage\n+\n+_Note: This example works starting from Flink 0.6-incubating_\n+\n+This example is using the `HadoopInputFormat` wrapper to use an existing Hadoop input format implementation for accessing [Azure's Table Storage](https://azure.microsoft.com/en-us/documentation/articles/storage-introduction/).\n+\n+1. Download and compile the `azure-tables-hadoop` project. The input format developed by the project is not yet available in Maven Central, therefore, we have to build the project ourselves.\n+Execute the following commands:\n+\n+```bash\n+git clone https://github.com/mooso/azure-tables-hadoop.git\n+cd azure-tables-hadoop\n+mvn clean install\n+```\n+\n+2. Setup a new Flink project using the quickstarts:\n+\n+```bash\n+curl https://flink.apache.org/q/quickstart.sh | bash\n+```\n+\n+3. Add the following dependencies (in the `<dependencies>` section) to your `pom.xml` file:\n+\n+```xml\n+<dependency>\n+   <groupId>org.apache.flink</groupId>\n+   <artifactId>flink-hadoop-compatibility{{< scala_version >}}</artifactId>\n+   <version>{{< version >}}</version>\n+</dependency>\n+<dependency>\n+ <groupId>com.microsoft.hadoop</groupId>\n+ <artifactId>microsoft-hadoop-azure</artifactId>\n+ <version>0.0.4</version>\n+</dependency>\n+```\n+\n+`flink-hadoop-compatibility` is a Flink package that provides the Hadoop input format wrappers.\n+`microsoft-hadoop-azure` is adding the project we've build before to our project.\n+\n+The project is now prepared for starting to code. We recommend to import the project into an IDE, such as Eclipse or IntelliJ. (Import as a Maven project!).\n+Browse to the code of the `Job.java` file. Its an empty skeleton for a Flink job.\n+\n+Paste the following code into it:\n+\n+```java\n+import java.util.Map;\n+import org.apache.flink.api.common.functions.MapFunction;\n+import org.apache.flink.api.java.DataSet;\n+import org.apache.flink.api.java.ExecutionEnvironment;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.hadoopcompatibility.mapreduce.HadoopInputFormat;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.mapreduce.Job;\n+import com.microsoft.hadoop.azure.AzureTableConfiguration;\n+import com.microsoft.hadoop.azure.AzureTableInputFormat;\n+import com.microsoft.hadoop.azure.WritableEntity;\n+import com.microsoft.windowsazure.storage.table.EntityProperty;\n+\n+public class AzureTableExample {\n+\n+  public static void main(String[] args) throws Exception {\n+    // set up the execution environment\n+    final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n+\n+    // create a  AzureTableInputFormat, using a Hadoop input format wrapper\n+    HadoopInputFormat<Text, WritableEntity> hdIf = new HadoopInputFormat<Text, WritableEntity>(new AzureTableInputFormat(), Text.class, WritableEntity.class, new Job());\n+\n+    // set the Account URI, something like: https://apacheflink.table.core.windows.net\n+    hdIf.getConfiguration().set(AzureTableConfiguration.Keys.ACCOUNT_URI.getKey(), \"TODO\");\n+    // set the secret storage key here\n+    hdIf.getConfiguration().set(AzureTableConfiguration.Keys.STORAGE_KEY.getKey(), \"TODO\");\n+    // set the table name here\n+    hdIf.getConfiguration().set(AzureTableConfiguration.Keys.TABLE_NAME.getKey(), \"TODO\");\n+\n+    DataSet<Tuple2<Text, WritableEntity>> input = env.createInput(hdIf);\n+    // a little example how to use the data in a mapper.\n+    DataSet<String> fin = input.map(new MapFunction<Tuple2<Text,WritableEntity>, String>() {\n+      @Override\n+      public String map(Tuple2<Text, WritableEntity> arg0) throws Exception {\n+        System.err.println(\"--------------------------------\\nKey = \"+arg0.f0);\n+        WritableEntity we = arg0.f1;\n+\n+        for(Map.Entry<String, EntityProperty> prop : we.getProperties().entrySet()) {\n+          System.err.println(\"key=\"+prop.getKey() + \" ; value (asString)=\"+prop.getValue().getValueAsString());\n+        }\n+\n+        return arg0.f0.toString();\n+      }\n+    });\n+\n+    // emit result (this works only locally)\n+    fin.print();\n+\n+    // execute program\n+    env.execute(\"Azure Example\");\n+  }\n+}\n+```\n+\n+The example shows how to access an Azure table and turn data into Flink's `DataSet` (more specifically, the type of the set is `DataSet<Tuple2<Text, WritableEntity>>`). With the `DataSet`, you can apply all known transformations to the DataSet.\n+\n+## Access MongoDB\n+\n+This [GitHub repository documents how to use MongoDB with Apache Flink (starting from 0.7-incubating)](https://github.com/okkam-it/flink-mongodb-test).\n+\n+{{< top >}}"
        },
        {
            "sha": "c4ae18206f40700ba8f4897cc4abbe78a2721b0a",
            "filename": "docs/content.zh/docs/connectors/datastream/_index.md",
            "status": "added",
            "additions": 23,
            "deletions": 0,
            "changes": 23,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/datastream/_index.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/datastream/_index.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/datastream/_index.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,23 @@\n+---\n+title: DataStream Connectors\n+bookCollapseSection: true\n+weight: 1\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n\\ No newline at end of file"
        },
        {
            "sha": "97eb6daf907bbc0856023cde93db3c8b0a536127",
            "filename": "docs/content.zh/docs/connectors/datastream/cassandra.md",
            "status": "added",
            "additions": 284,
            "deletions": 0,
            "changes": 284,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/datastream/cassandra.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/datastream/cassandra.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/datastream/cassandra.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,284 @@\n+---\n+title: Cassandra\n+weight: 3\n+type: docs\n+aliases:\n+  - /zh/dev/connectors/cassandra.html\n+  - /zh/apis/streaming/connectors/cassandra.html\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Apache Cassandra Connector\n+\n+This connector provides sinks that writes data into a [Apache Cassandra](https://cassandra.apache.org/) database.\n+\n+<!--\n+  TODO: Perhaps worth mentioning current DataStax Java Driver version to match Cassandra version on user side.\n+-->\n+\n+To use this connector, add the following dependency to your project:\n+\n+{{< artifact flink-connector-cassandra withScalaVersion >}}\n+\n+Note that the streaming connectors are currently __NOT__ part of the binary distribution. See how to link with them for cluster execution [here]({{< ref \"docs/dev/datastream/project-configuration\" >}}).\n+\n+## Installing Apache Cassandra\n+There are multiple ways to bring up a Cassandra instance on local machine:\n+\n+1. Follow the instructions from [Cassandra Getting Started page](http://cassandra.apache.org/doc/latest/getting_started/index.html).\n+2. Launch a container running Cassandra from [Official Docker Repository](https://hub.docker.com/_/cassandra/)\n+\n+## Cassandra Sinks\n+\n+### Configurations\n+\n+Flink's Cassandra sink are created by using the static CassandraSink.addSink(DataStream<IN> input) method.\n+This method returns a CassandraSinkBuilder, which offers methods to further configure the sink, and finally `build()` the sink instance.\n+\n+The following configuration methods can be used:\n+\n+1. _setQuery(String query)_\n+    * Sets the upsert query that is executed for every record the sink receives.\n+    * The query is internally treated as CQL statement.\n+    * __DO__ set the upsert query for processing __Tuple__ data type.\n+    * __DO NOT__ set the query for processing __POJO__ data types.\n+2. _setClusterBuilder()_\n+    * Sets the cluster builder that is used to configure the connection to cassandra with more sophisticated settings such as consistency level, retry policy and etc.\n+3. _setHost(String host[, int port])_\n+    * Simple version of setClusterBuilder() with host/port information to connect to Cassandra instances\n+4. _setMapperOptions(MapperOptions options)_\n+    * Sets the mapper options that are used to configure the DataStax ObjectMapper.\n+    * Only applies when processing __POJO__ data types.\n+5. _setMaxConcurrentRequests(int maxConcurrentRequests, Duration timeout)_\n+    * Sets the maximum allowed number of concurrent requests with a timeout for acquiring permits to execute.\n+    * Only applies when __enableWriteAheadLog()__ is not configured.\n+6. _enableWriteAheadLog([CheckpointCommitter committer])_\n+    * An __optional__ setting\n+    * Allows exactly-once processing for non-deterministic algorithms.\n+7. _setFailureHandler([CassandraFailureHandler failureHandler])_\n+    * An __optional__ setting\n+    * Sets the custom failure handler.\n+8. _build()_\n+    * Finalizes the configuration and constructs the CassandraSink instance.\n+\n+### Write-ahead Log\n+\n+A checkpoint committer stores additional information about completed checkpoints\n+in some resource. This information is used to prevent a full replay of the last\n+completed checkpoint in case of a failure.\n+You can use a `CassandraCommitter` to store these in a separate table in cassandra.\n+Note that this table will NOT be cleaned up by Flink.\n+\n+Flink can provide exactly-once guarantees if the query is idempotent (meaning it can be applied multiple\n+times without changing the result) and checkpointing is enabled. In case of a failure the failed\n+checkpoint will be replayed completely.\n+\n+Furthermore, for non-deterministic programs the write-ahead log has to be enabled. For such a program\n+the replayed checkpoint may be completely different than the previous attempt, which may leave the\n+database in an inconsistent state since part of the first attempt may already be written.\n+The write-ahead log guarantees that the replayed checkpoint is identical to the first attempt.\n+Note that that enabling this feature will have an adverse impact on latency.\n+\n+<p style=\"border-radius: 5px; padding: 5px\" class=\"bg-danger\"><b>Note</b>: The write-ahead log functionality is currently experimental. In many cases it is sufficient to use the connector without enabling it. Please report problems to the development mailing list.</p>\n+\n+### Checkpointing and Fault Tolerance\n+With checkpointing enabled, Cassandra Sink guarantees at-least-once delivery of action requests to C* instance.\n+\n+More details on [checkpoints docs]({{< ref \"docs/dev/datastream/fault-tolerance/checkpointing\" >}}) and [fault tolerance guarantee docs]({{< ref \"docs/connectors/datastream/guarantees\" >}})\n+\n+## Examples\n+\n+The Cassandra sinks currently support both Tuple and POJO data types, and Flink automatically detects which type of input is used. For general use case of those streaming data type, please refer to [Supported Data Types]({{< ref \"docs/dev/serialization/types_serialization\" >}}#supported-data-types). We show two implementations based on [SocketWindowWordCount](https://github.com/apache/flink/blob/master/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/socket/SocketWindowWordCount.java), for Pojo and Tuple data types respectively.\n+\n+In all these examples, we assumed the associated Keyspace `example` and Table `wordcount` have been created.\n+\n+{{< tabs \"ffc5c4d4-7872-479c-bfa6-206b9e96f6f3\" >}}\n+{{< tab \"CQL\" >}}\n+```sql\n+CREATE KEYSPACE IF NOT EXISTS example\n+    WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};\n+\n+CREATE TABLE IF NOT EXISTS example.wordcount (\n+    word text,\n+    count bigint,\n+    PRIMARY KEY(word)\n+);\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+### Cassandra Sink Example for Streaming Tuple Data Type\n+While storing the result with Java/Scala Tuple data type to a Cassandra sink, it is required to set a CQL upsert statement (via setQuery('stmt')) to persist each record back to the database. With the upsert query cached as `PreparedStatement`, each Tuple element is converted to parameters of the statement.\n+\n+For details about `PreparedStatement` and `BoundStatement`, please visit [DataStax Java Driver manual](https://docs.datastax.com/en/developer/java-driver/2.1/manual/statements/prepared/)\n+\n+{{< tabs \"1a84c6a0-0b2f-4f96-8cf8-43ec6dd3bc5d\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+// get the execution environment\n+final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n+\n+// get input data by connecting to the socket\n+DataStream<String> text = env.socketTextStream(hostname, port, \"\\n\");\n+\n+// parse the data, group it, window it, and aggregate the counts\n+DataStream<Tuple2<String, Long>> result = text\n+        .flatMap(new FlatMapFunction<String, Tuple2<String, Long>>() {\n+            @Override\n+            public void flatMap(String value, Collector<Tuple2<String, Long>> out) {\n+                // normalize and split the line\n+                String[] words = value.toLowerCase().split(\"\\\\s\");\n+\n+                // emit the pairs\n+                for (String word : words) {\n+                    //Do not accept empty word, since word is defined as primary key in C* table\n+                    if (!word.isEmpty()) {\n+                        out.collect(new Tuple2<String, Long>(word, 1L));\n+                    }\n+                }\n+            }\n+        })\n+        .keyBy(value -> value.f0)\n+        .window(TumblingProcessingTimeWindows.of(Time.seconds(5)))\n+        .sum(1);\n+\n+CassandraSink.addSink(result)\n+        .setQuery(\"INSERT INTO example.wordcount(word, count) values (?, ?);\")\n+        .setHost(\"127.0.0.1\")\n+        .build();\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment\n+\n+// get input data by connecting to the socket\n+val text: DataStream[String] = env.socketTextStream(hostname, port, '\\n')\n+\n+// parse the data, group it, window it, and aggregate the counts\n+val result: DataStream[(String, Long)] = text\n+  // split up the lines in pairs (2-tuples) containing: (word,1)\n+  .flatMap(_.toLowerCase.split(\"\\\\s\"))\n+  .filter(_.nonEmpty)\n+  .map((_, 1L))\n+  // group by the tuple field \"0\" and sum up tuple field \"1\"\n+  .keyBy(_._1)\n+  .window(TumblingProcessingTimeWindows.of(Time.seconds(5)))\n+  .sum(1)\n+\n+CassandraSink.addSink(result)\n+  .setQuery(\"INSERT INTO example.wordcount(word, count) values (?, ?);\")\n+  .setHost(\"127.0.0.1\")\n+  .build()\n+\n+result.print().setParallelism(1)\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+\n+### Cassandra Sink Example for Streaming POJO Data Type\n+An example of streaming a POJO data type and store the same POJO entity back to Cassandra. In addition, this POJO implementation needs to follow [DataStax Java Driver Manual](http://docs.datastax.com/en/developer/java-driver/2.1/manual/object_mapper/creating/) to annotate the class as each field of this entity is mapped to an associated column of the designated table using the DataStax Java Driver `com.datastax.driver.mapping.Mapper` class.\n+\n+The mapping of each table column can be defined through annotations placed on a field declaration in the Pojo class.  For details of the mapping, please refer to CQL documentation on [Definition of Mapped Classes](http://docs.datastax.com/en/developer/java-driver/3.1/manual/object_mapper/creating/) and [CQL Data types](https://docs.datastax.com/en/cql/3.1/cql/cql_reference/cql_data_types_c.html)\n+\n+{{< tabs \"d65ca6f5-acb2-4f2c-b5b6-d986eafca765\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+// get the execution environment\n+final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n+\n+// get input data by connecting to the socket\n+DataStream<String> text = env.socketTextStream(hostname, port, \"\\n\");\n+\n+// parse the data, group it, window it, and aggregate the counts\n+DataStream<WordCount> result = text\n+        .flatMap(new FlatMapFunction<String, WordCount>() {\n+            public void flatMap(String value, Collector<WordCount> out) {\n+                // normalize and split the line\n+                String[] words = value.toLowerCase().split(\"\\\\s\");\n+\n+                // emit the pairs\n+                for (String word : words) {\n+                    if (!word.isEmpty()) {\n+                        //Do not accept empty word, since word is defined as primary key in C* table\n+                        out.collect(new WordCount(word, 1L));\n+                    }\n+                }\n+            }\n+        })\n+        .keyBy(WordCount::getWord)\n+        .window(TumblingProcessingTimeWindows.of(Time.seconds(5)))\n+\n+        .reduce(new ReduceFunction<WordCount>() {\n+            @Override\n+            public WordCount reduce(WordCount a, WordCount b) {\n+                return new WordCount(a.getWord(), a.getCount() + b.getCount());\n+            }\n+        });\n+\n+CassandraSink.addSink(result)\n+        .setHost(\"127.0.0.1\")\n+        .setMapperOptions(() -> new Mapper.Option[]{Mapper.Option.saveNullFields(true)})\n+        .build();\n+\n+\n+@Table(keyspace = \"example\", name = \"wordcount\")\n+public class WordCount {\n+\n+    @Column(name = \"word\")\n+    private String word = \"\";\n+\n+    @Column(name = \"count\")\n+    private long count = 0;\n+\n+    public WordCount() {}\n+\n+    public WordCount(String word, long count) {\n+        this.setWord(word);\n+        this.setCount(count);\n+    }\n+\n+    public String getWord() {\n+        return word;\n+    }\n+\n+    public void setWord(String word) {\n+        this.word = word;\n+    }\n+\n+    public long getCount() {\n+        return count;\n+    }\n+\n+    public void setCount(long count) {\n+        this.count = count;\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getWord() + \" : \" + getCount();\n+    }\n+}\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+{{< top >}}"
        },
        {
            "sha": "2559151b00ea92367fa0b797d40cf57b7634ec36",
            "filename": "docs/content.zh/docs/connectors/datastream/elasticsearch.md",
            "status": "added",
            "additions": 471,
            "deletions": 0,
            "changes": 471,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/datastream/elasticsearch.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/datastream/elasticsearch.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/datastream/elasticsearch.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,471 @@\n+---\n+title: Elasticsearch\n+weight: 5\n+type: docs\n+aliases:\n+  - /zh/dev/connectors/elasticsearch.html\n+  - /zh/apis/streaming/connectors/elasticsearch.html\n+  - /zh/dev/connectors/elasticsearch2.html\n+  - /zh/apis/streaming/connectors/elasticsearch2.html\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Elasticsearch Connector\n+\n+This connector provides sinks that can request document actions to an\n+[Elasticsearch](https://elastic.co/) Index. To use this connector, add one\n+of the following dependencies to your project, depending on the version\n+of the Elasticsearch installation:\n+\n+<table class=\"table table-bordered\">\n+  <thead>\n+    <tr>\n+      <th class=\"text-left\">Elasticsearch version</th>\n+      <th class=\"text-left\">Maven Dependency</th>\n+    </tr>\n+  </thead>\n+  <tbody>\n+    <tr>\n+        <td>5.x</td>\n+        <td>{{< artifact flink-connector-elasticsearch5 withScalaVersion >}}</td>\n+    </tr>\n+    <tr>\n+        <td>6.x</td>\n+        <td>{{< artifact flink-connector-elasticsearch6 withScalaVersion >}}</td>\n+    </tr>\n+    <tr>\n+        <td>7 and later versions</td>\n+        <td>{{< artifact flink-connector-elasticsearch7 withScalaVersion >}}</td>\n+    </tr>\n+  </tbody>\n+</table>\n+\n+Note that the streaming connectors are currently not part of the binary\n+distribution. See [here]({{< ref \"docs/dev/datastream/project-configuration\" >}}) for information\n+about how to package the program with the libraries for cluster execution.\n+\n+## Installing Elasticsearch\n+\n+Instructions for setting up an Elasticsearch cluster can be found\n+[here](https://www.elastic.co/guide/en/elasticsearch/reference/current/setup.html).\n+Make sure to set and remember a cluster name. This must be set when\n+creating an `ElasticsearchSink` for requesting document actions against your cluster.\n+\n+## Elasticsearch Sink\n+\n+The `ElasticsearchSink` uses a `TransportClient` (before 6.x) or `RestHighLevelClient` (starting with 6.x) to communicate with an\n+Elasticsearch cluster.\n+\n+The example below shows how to configure and create a sink:\n+\n+{{< tabs \"51732edd-4218-470e-adad-b1ebb4021ae4\" >}}\n+{{< tab \"java, 5.x\" >}}\n+```java\n+import org.apache.flink.api.common.functions.RuntimeContext;\n+import org.apache.flink.streaming.api.datastream.DataStream;\n+import org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkFunction;\n+import org.apache.flink.streaming.connectors.elasticsearch.RequestIndexer;\n+import org.apache.flink.streaming.connectors.elasticsearch5.ElasticsearchSink;\n+\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.client.Requests;\n+\n+import java.net.InetAddress;\n+import java.net.InetSocketAddress;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+DataStream<String> input = ...;\n+\n+Map<String, String> config = new HashMap<>();\n+config.put(\"cluster.name\", \"my-cluster-name\");\n+// This instructs the sink to emit after every element, otherwise they would be buffered\n+config.put(\"bulk.flush.max.actions\", \"1\");\n+\n+List<InetSocketAddress> transportAddresses = new ArrayList<>();\n+transportAddresses.add(new InetSocketAddress(InetAddress.getByName(\"127.0.0.1\"), 9300));\n+transportAddresses.add(new InetSocketAddress(InetAddress.getByName(\"10.2.3.1\"), 9300));\n+\n+input.addSink(new ElasticsearchSink<>(config, transportAddresses, new ElasticsearchSinkFunction<String>() {\n+    public IndexRequest createIndexRequest(String element) {\n+        Map<String, String> json = new HashMap<>();\n+        json.put(\"data\", element);\n+    \n+        return Requests.indexRequest()\n+                .index(\"my-index\")\n+                .type(\"my-type\")\n+                .source(json);\n+    }\n+    \n+    @Override\n+    public void process(String element, RuntimeContext ctx, RequestIndexer indexer) {\n+        indexer.add(createIndexRequest(element));\n+    }\n+}));```\n+{{< /tab >}}\n+{{< tab \"java, Elasticsearch 6.x and above\" >}}\n+```java\n+import org.apache.flink.api.common.functions.RuntimeContext;\n+import org.apache.flink.streaming.api.datastream.DataStream;\n+import org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkFunction;\n+import org.apache.flink.streaming.connectors.elasticsearch.RequestIndexer;\n+import org.apache.flink.streaming.connectors.elasticsearch6.ElasticsearchSink;\n+\n+import org.apache.http.HttpHost;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.client.Requests;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+DataStream<String> input = ...;\n+\n+List<HttpHost> httpHosts = new ArrayList<>();\n+httpHosts.add(new HttpHost(\"127.0.0.1\", 9200, \"http\"));\n+httpHosts.add(new HttpHost(\"10.2.3.1\", 9200, \"http\"));\n+\n+// use a ElasticsearchSink.Builder to create an ElasticsearchSink\n+ElasticsearchSink.Builder<String> esSinkBuilder = new ElasticsearchSink.Builder<>(\n+    httpHosts,\n+    new ElasticsearchSinkFunction<String>() {\n+        public IndexRequest createIndexRequest(String element) {\n+            Map<String, String> json = new HashMap<>();\n+            json.put(\"data\", element);\n+        \n+            return Requests.indexRequest()\n+                    .index(\"my-index\")\n+                    .type(\"my-type\")\n+                    .source(json);\n+        }\n+        \n+        @Override\n+        public void process(String element, RuntimeContext ctx, RequestIndexer indexer) {\n+            indexer.add(createIndexRequest(element));\n+        }\n+    }\n+);\n+\n+// configuration for the bulk requests; this instructs the sink to emit after every element, otherwise they would be buffered\n+esSinkBuilder.setBulkFlushMaxActions(1);\n+\n+// provide a RestClientFactory for custom configuration on the internally created REST client\n+esSinkBuilder.setRestClientFactory(\n+  restClientBuilder -> {\n+    restClientBuilder.setDefaultHeaders(...)\n+    restClientBuilder.setMaxRetryTimeoutMillis(...)\n+    restClientBuilder.setPathPrefix(...)\n+    restClientBuilder.setHttpClientConfigCallback(...)\n+  }\n+);\n+\n+// finally, build and add the sink to the job's pipeline\n+input.addSink(esSinkBuilder.build());\n+```\n+{{< /tab >}}\n+{{< tab \"scala, 5.x\" >}}\n+```scala\n+import org.apache.flink.api.common.functions.RuntimeContext\n+import org.apache.flink.streaming.api.datastream.DataStream\n+import org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkFunction\n+import org.apache.flink.streaming.connectors.elasticsearch.RequestIndexer\n+import org.apache.flink.streaming.connectors.elasticsearch5.ElasticsearchSink\n+\n+import org.elasticsearch.action.index.IndexRequest\n+import org.elasticsearch.client.Requests\n+\n+import java.net.InetAddress\n+import java.net.InetSocketAddress\n+import java.util.ArrayList\n+import java.util.HashMap\n+import java.util.List\n+import java.util.Map\n+\n+val input: DataStream[String] = ...\n+\n+val config = new java.util.HashMap[String, String]\n+config.put(\"cluster.name\", \"my-cluster-name\")\n+// This instructs the sink to emit after every element, otherwise they would be buffered\n+config.put(\"bulk.flush.max.actions\", \"1\")\n+\n+val transportAddresses = new java.util.ArrayList[InetSocketAddress]\n+transportAddresses.add(new InetSocketAddress(InetAddress.getByName(\"127.0.0.1\"), 9300))\n+transportAddresses.add(new InetSocketAddress(InetAddress.getByName(\"10.2.3.1\"), 9300))\n+\n+input.addSink(new ElasticsearchSink(config, transportAddresses, new ElasticsearchSinkFunction[String] {\n+  def createIndexRequest(element: String): IndexRequest = {\n+    val json = new java.util.HashMap[String, String]\n+    json.put(\"data\", element)\n+    \n+    return Requests.indexRequest()\n+            .index(\"my-index\")\n+            .type(\"my-type\")\n+            .source(json)\n+  }\n+}))\n+```\n+{{< /tab >}}\n+{{< tab \"scala, Elasticsearch 6.x and above\" >}}\n+```scala\n+import org.apache.flink.api.common.functions.RuntimeContext\n+import org.apache.flink.streaming.api.datastream.DataStream\n+import org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkFunction\n+import org.apache.flink.streaming.connectors.elasticsearch.RequestIndexer\n+import org.apache.flink.streaming.connectors.elasticsearch6.ElasticsearchSink\n+\n+import org.apache.http.HttpHost\n+import org.elasticsearch.action.index.IndexRequest\n+import org.elasticsearch.client.Requests\n+\n+import java.util.ArrayList\n+import java.util.List\n+\n+val input: DataStream[String] = ...\n+\n+val httpHosts = new java.util.ArrayList[HttpHost]\n+httpHosts.add(new HttpHost(\"127.0.0.1\", 9200, \"http\"))\n+httpHosts.add(new HttpHost(\"10.2.3.1\", 9200, \"http\"))\n+\n+val esSinkBuilder = new ElasticsearchSink.Builder[String](\n+  httpHosts,\n+  new ElasticsearchSinkFunction[String] {\n+     def process(element: String, ctx: RuntimeContext, indexer: RequestIndexer) {\n+          val json = new java.util.HashMap[String, String]\n+          json.put(\"data\", element)\n+\n+          val rqst: IndexRequest = Requests.indexRequest\n+            .index(\"my-index\")\n+            .`type`(\"my-type\")\n+            .source(json)\n+\n+          indexer.add(rqst)\n+     } \n+  }\n+)\n+\n+// configuration for the bulk requests; this instructs the sink to emit after every element, otherwise they would be buffered\n+esSinkBuilder.setBulkFlushMaxActions(1)\n+\n+// provide a RestClientFactory for custom configuration on the internally created REST client\n+esSinkBuilder.setRestClientFactory(new RestClientFactory {\n+  override def configureRestClientBuilder(restClientBuilder: RestClientBuilder): Unit = {\n+       restClientBuilder.setDefaultHeaders(...)\n+       restClientBuilder.setMaxRetryTimeoutMillis(...)\n+       restClientBuilder.setPathPrefix(...)\n+       restClientBuilder.setHttpClientConfigCallback(...)\n+  }\n+})\n+\n+// finally, build and add the sink to the job's pipeline\n+input.addSink(esSinkBuilder.build)\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+For Elasticsearch versions that still uses the now deprecated `TransportClient` to communicate\n+with the Elasticsearch cluster (i.e., versions equal or below 5.x), note how a `Map` of `String`s\n+is used to configure the `ElasticsearchSink`. This config map will be directly\n+forwarded when creating the internally used `TransportClient`.\n+The configuration keys are documented in the Elasticsearch documentation\n+[here](https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html).\n+Especially important is the `cluster.name` parameter that must correspond to\n+the name of your cluster.\n+\n+For Elasticsearch 6.x and above, internally, the `RestHighLevelClient` is used for cluster communication.\n+By default, the connector uses the default configurations for the REST client. To have custom\n+configuration for the REST client, users can provide a `RestClientFactory` implementation when \n+setting up the `ElasticsearchClient.Builder` that builds the sink.\n+\n+Also note that the example only demonstrates performing a single index\n+request for each incoming element. Generally, the `ElasticsearchSinkFunction`\n+can be used to perform multiple requests of different types (ex.,\n+`DeleteRequest`, `UpdateRequest`, etc.). \n+\n+Internally, each parallel instance of the Flink Elasticsearch Sink uses\n+a `BulkProcessor` to send action requests to the cluster.\n+This will buffer elements before sending them in bulk to the cluster. The `BulkProcessor`\n+executes bulk requests one at a time, i.e. there will be no two concurrent\n+flushes of the buffered actions in progress.\n+\n+### Elasticsearch Sinks and Fault Tolerance\n+\n+With Flink’s checkpointing enabled, the Flink Elasticsearch Sink guarantees\n+at-least-once delivery of action requests to Elasticsearch clusters. It does\n+so by waiting for all pending action requests in the `BulkProcessor` at the\n+time of checkpoints. This effectively assures that all requests before the\n+checkpoint was triggered have been successfully acknowledged by Elasticsearch, before\n+proceeding to process more records sent to the sink.\n+\n+More details on checkpoints and fault tolerance are in the [fault tolerance docs]({{< ref \"docs/learn-flink/fault_tolerance\" >}}).\n+\n+To use fault tolerant Elasticsearch Sinks, checkpointing of the topology needs to be enabled at the execution environment:\n+\n+{{< tabs \"d00d1e93-4844-40d7-b0ec-9ec37e73145e\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n+env.enableCheckpointing(5000); // checkpoint every 5000 msecs\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+val env = StreamExecutionEnvironment.getExecutionEnvironment()\n+env.enableCheckpointing(5000) // checkpoint every 5000 msecs\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+<p style=\"border-radius: 5px; padding: 5px\" class=\"bg-danger\">\n+<b>NOTE</b>: Users can disable flushing if they wish to do so, by calling\n+<b>disableFlushOnCheckpoint()</b> on the created <b>ElasticsearchSink</b>. Be aware\n+that this essentially means the sink will not provide any strong\n+delivery guarantees anymore, even with checkpoint for the topology enabled.\n+</p>\n+\n+### Handling Failing Elasticsearch Requests\n+\n+Elasticsearch action requests may fail due to a variety of reasons, including\n+temporarily saturated node queue capacity or malformed documents to be indexed.\n+The Flink Elasticsearch Sink allows the user to specify how request\n+failures are handled, by simply implementing an `ActionRequestFailureHandler` and\n+providing it to the constructor.\n+\n+Below is an example:\n+\n+{{< tabs \"ddb958b3-5dd5-476e-b946-ace3335628b2\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+DataStream<String> input = ...;\n+\n+input.addSink(new ElasticsearchSink<>(\n+    config, transportAddresses,\n+    new ElasticsearchSinkFunction<String>() {...},\n+    new ActionRequestFailureHandler() {\n+        @Override\n+        void onFailure(ActionRequest action,\n+                Throwable failure,\n+                int restStatusCode,\n+                RequestIndexer indexer) throw Throwable {\n+\n+            if (ExceptionUtils.findThrowable(failure, EsRejectedExecutionException.class).isPresent()) {\n+                // full queue; re-add document for indexing\n+                indexer.add(action);\n+            } else if (ExceptionUtils.findThrowable(failure, ElasticsearchParseException.class).isPresent()) {\n+                // malformed document; simply drop request without failing sink\n+            } else {\n+                // for all other failures, fail the sink\n+                // here the failure is simply rethrown, but users can also choose to throw custom exceptions\n+                throw failure;\n+            }\n+        }\n+}));\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+val input: DataStream[String] = ...\n+\n+input.addSink(new ElasticsearchSink(\n+    config, transportAddresses,\n+    new ElasticsearchSinkFunction[String] {...},\n+    new ActionRequestFailureHandler {\n+        @throws(classOf[Throwable])\n+        override def onFailure(ActionRequest action,\n+                Throwable failure,\n+                int restStatusCode,\n+                RequestIndexer indexer) {\n+\n+            if (ExceptionUtils.findThrowable(failure, EsRejectedExecutionException.class).isPresent()) {\n+                // full queue; re-add document for indexing\n+                indexer.add(action)\n+            } else if (ExceptionUtils.findThrowable(failure, ElasticsearchParseException.class).isPresent()) {\n+                // malformed document; simply drop request without failing sink\n+            } else {\n+                // for all other failures, fail the sink\n+                // here the failure is simply rethrown, but users can also choose to throw custom exceptions\n+                throw failure\n+            }\n+        }\n+}))\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+The above example will let the sink re-add requests that failed due to\n+queue capacity saturation and drop requests with malformed documents, without\n+failing the sink. For all other failures, the sink will fail. If a `ActionRequestFailureHandler`\n+is not provided to the constructor, the sink will fail for any kind of error.\n+\n+Note that `onFailure` is called for failures that still occur only after the\n+`BulkProcessor` internally finishes all backoff retry attempts.\n+By default, the `BulkProcessor` retries to a maximum of 8 attempts with\n+an exponential backoff. For more information on the behaviour of the\n+internal `BulkProcessor` and how to configure it, please see the following section.\n+\n+By default, if a failure handler is not provided, the sink uses a\n+`NoOpFailureHandler` that simply fails for all kinds of exceptions. The\n+connector also provides a `RetryRejectedExecutionFailureHandler` implementation\n+that always re-add requests that have failed due to queue capacity saturation.\n+\n+<p style=\"border-radius: 5px; padding: 5px\" class=\"bg-danger\">\n+<b>IMPORTANT</b>: Re-adding requests back to the internal <b>BulkProcessor</b>\n+on failures will lead to longer checkpoints, as the sink will also\n+need to wait for the re-added requests to be flushed when checkpointing.\n+For example, when using <b>RetryRejectedExecutionFailureHandler</b>, checkpoints\n+will need to wait until Elasticsearch node queues have enough capacity for\n+all the pending requests. This also means that if re-added requests never\n+succeed, the checkpoint will never finish.\n+</p>\n+\n+### Configuring the Internal Bulk Processor\n+\n+The internal `BulkProcessor` can be further configured for its behaviour\n+on how buffered action requests are flushed, by setting the following values in\n+the provided `Map<String, String>`:\n+\n+ * **bulk.flush.max.actions**: Maximum amount of actions to buffer before flushing.\n+ * **bulk.flush.max.size.mb**: Maximum size of data (in megabytes) to buffer before flushing.\n+ * **bulk.flush.interval.ms**: Interval at which to flush regardless of the amount or size of buffered actions.\n+ \n+For versions 2.x and above, configuring how temporary request errors are\n+retried is also supported:\n+ \n+ * **bulk.flush.backoff.enable**: Whether or not to perform retries with backoff delay for a flush\n+ if one or more of its actions failed due to a temporary `EsRejectedExecutionException`.\n+ * **bulk.flush.backoff.type**: The type of backoff delay, either `CONSTANT` or `EXPONENTIAL`\n+ * **bulk.flush.backoff.delay**: The amount of delay for backoff. For constant backoff, this\n+ is simply the delay between each retry. For exponential backoff, this is the initial base delay.\n+ * **bulk.flush.backoff.retries**: The amount of backoff retries to attempt.\n+\n+More information about Elasticsearch can be found [here](https://elastic.co).\n+\n+## Packaging the Elasticsearch Connector into an Uber-Jar\n+\n+For the execution of your Flink program, it is recommended to build a\n+so-called uber-jar (executable jar) containing all your dependencies\n+(see [here]({{< ref \"docs/dev/datastream/project-configuration\" >}}) for further information).\n+\n+Alternatively, you can put the connector's jar file into Flink's `lib/` folder to make it available\n+system-wide, i.e. for all job being run.\n+\n+{{< top >}}"
        },
        {
            "sha": "329c7cf1e764c1ef134d78dff51ea92817ab9b87",
            "filename": "docs/content.zh/docs/connectors/datastream/file_sink.md",
            "status": "added",
            "additions": 742,
            "deletions": 0,
            "changes": 742,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/datastream/file_sink.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/datastream/file_sink.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/datastream/file_sink.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,742 @@\n+---\n+title: File Sink\n+weight: 6\n+type: docs\n+aliases:\n+  - /zh/dev/connectors/file_sink.html\n+  - /zh/apis/streaming/connectors/filesystem_sink.html\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# File Sink\n+\n+这个连接器提供了一个在流和批模式下统一的 Sink 来将分区文件写入到支持 [Flink `FileSystem`]({{< ref \"docs/deployment/filesystems/overview\" >}}) 接口的文件系统中，它对于流和批模式可以提供相同的一致性语义保证。File Sink 是现有的 [Streaming File Sink]({{< ref \"docs/connectors/datastream/streamfile_sink\" >}}) 的一个升级版本，后者仅在流模式下提供了精确一致性。\n+\n+File Sink 会将数据写入到桶中。由于输入流可能是无界的，因此每个桶中的数据被划分为多个有限大小的文件。如何分桶是可以配置的，默认使用基于时间的分桶策略，这种策略每个小时创建一个新的桶，桶中包含的文件将记录所有该小时内从流中接收到的数据。\n+\n+桶目录中的实际输出数据会被划分为多个部分文件（part file），每一个接收桶数据的 Sink Subtask ，至少包含一个部分文件（part file）。额外的部分文件（part file）将根据滚动策略创建，滚动策略是可以配置的。对于行编码格式（参考 [File Formats](#file-formats) ）默认的策略是根据文件大小和超时时间来滚动文件。超时时间指打开文件的最长持续时间，以及文件关闭前的最长非活动时间。批量编码格式必须在每次 Checkpoint 时滚动文件，但是用户也可以指定额外的基于文件大小和超时时间的策略。\n+\n+{{< hint info >}}\n+<b>重要:</b> 在流模式下使用 FileSink 时需要启用 Checkpoint ，每次做 Checkpoint 时写入完成。如果 Checkpoint 被禁用，部分文件（part file）将永远处于 'in-progress' 或 'pending' 状态，下游系统无法安全地读取。\n+{{< /hint >}}\n+\n+\n+{{< img src=\"/fig/streamfilesink_bucketing.png\" >}}\n+\n+## 文件格式\n+\n+ `FileSink` 支持行编码格式和批量编码格式，比如 [Apache Parquet](http://parquet.apache.org) 。\n+这两种变体随附了各自的构建器，可以使用以下静态方法创建：\n+\n+ - Row-encoded sink: `FileSink.forRowFormat(basePath, rowEncoder)`\n+ - Bulk-encoded sink: `FileSink.forBulkFormat(basePath, bulkWriterFactory)`\n+\n+创建行或批量编码的 Sink 时，我们需要指定存储桶的基本路径和数据的编码逻辑。\n+\n+更多配置操作以及不同数据格式的实现请参考 `FileSink` 。\n+\n+### 行编码格式\n+\n+行编码格式需要指定一个 `Encoder` 。Encoder 负责为每个处于 In-progress 状态文件的`OutputStream` 序列化数据。\n+\n+`除了桶分配器之外，RowFormatBuilder` 还允许用户指定：\n+\n+ - Custom `RollingPolicy`：自定义滚动策略以覆盖默认的 DefaultRollingPolicy。\n+ - bucketCheckInterval （默认为1分钟）：毫秒间隔，用于基于时间的滚动策略。\n+\n+字符串元素写入示例：\n+\n+\n+{{< tabs \"946da1d5-b046-404e-ab80-a5a5d251d8ee\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+import org.apache.flink.api.common.serialization.SimpleStringEncoder;\n+import org.apache.flink.core.fs.Path;\n+import org.apache.flink.connector.file.sink.FileSink;\n+import org.apache.flink.streaming.api.functions.sink.filesystem.rollingpolicies.DefaultRollingPolicy;\n+\n+DataStream<String> input = ...;\n+\n+final FileSink<String> sink = FileSink\n+    .forRowFormat(new Path(outputPath), new SimpleStringEncoder<String>(\"UTF-8\"))\n+    .withRollingPolicy(\n+        DefaultRollingPolicy.builder()\n+            .withRolloverInterval(TimeUnit.MINUTES.toMillis(15))\n+            .withInactivityInterval(TimeUnit.MINUTES.toMillis(5))\n+            .withMaxPartSize(1024 * 1024 * 1024)\n+            .build())\n+\t.build();\n+\n+input.sinkTo(sink);\n+\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+import org.apache.flink.api.common.serialization.SimpleStringEncoder\n+import org.apache.flink.core.fs.Path\n+import org.apache.flink.connector.file.sink.FileSink\n+import org.apache.flink.streaming.api.functions.sink.filesystem.rollingpolicies.DefaultRollingPolicy\n+\n+val input: DataStream[String] = ...\n+\n+val sink: FileSink[String] = FileSink\n+    .forRowFormat(new Path(outputPath), new SimpleStringEncoder[String](\"UTF-8\"))\n+    .withRollingPolicy(\n+        DefaultRollingPolicy.builder()\n+            .withRolloverInterval(TimeUnit.MINUTES.toMillis(15))\n+            .withInactivityInterval(TimeUnit.MINUTES.toMillis(5))\n+            .withMaxPartSize(1024 * 1024 * 1024)\n+            .build())\n+    .build()\n+\n+input.sinkTo(sink)\n+\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+这个例子创建了一个简单的 Sink ，将记录分配给默认的一小时时间桶。它还指定了一个滚动策略，该策略在以下三种情况下滚动处于 In-progress 状态的部分文件（part file）：\n+\n+ - 它至少包含 15 分钟的数据\n+ - 最近 5 分钟没有收到新的记录\n+ - 文件大小达到 1GB （写入最后一条记录后）\n+\n+### 批量编码格式\n+\n+批量编码 Sink 的创建与行编码 Sink 相似，不过在这里我们不是指定编码器  `Encoder` 而是指定 `BulkWriter.Factory` 。\n+`BulkWriter` 定义了如何添加、刷新元素，以及如何批量编码。\n+\n+Flink 有四个内置的 BulkWriter Factory ：\n+\n+ - `ParquetWriterFactory`\n+ - `AvroWriterFactory`\n+ - `SequenceFileWriterFactory`\n+ - `CompressWriterFactory`\n+ - `OrcBulkWriterFactory`\n+\n+{{< hint info >}}\n+<b>重要:</b> 批量编码模式仅支持 OnCheckpointRollingPolicy 策略, 在每次 checkpoint 的时候滚动文件。\n+<b>重要:</b> 批量编码模式必须使用继承自 CheckpointRollingPolicy 的滚动策略, 这些策略必须在每次 checkpoint 的时候滚动文件，但是用户也可以进一步指定额外的基于文件大小和超时时间的策略。\n+{{< /hint >}}\n+\n+#### Parquet 格式\n+\n+Flink 包含为不同 Avro 类型，创建 ParquetWriterFactory 的便捷方法，更多信息请参考 `ParquetAvroWriters` 。\n+\n+要编写其他 Parquet 兼容的数据格式，用户需要创建 ParquetWriterFactory 并实现 `ParquetBuilder` 接口。\n+\n+在应用中使用 Parquet 批量编码器，你需要添加以下依赖：\n+\n+{{< artifact flink-parquet withScalaVersion >}}\n+\n+这个例子使用 FileSink 将 Avro 数据写入 Parquet 格式：\n+\n+{{< tabs \"825da2a2-4bdf-4f2d-9138-2e99a72bb9d4\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+import org.apache.flink.connector.file.sink.FileSink;\n+import org.apache.flink.formats.parquet.avro.ParquetAvroWriters;\n+import org.apache.avro.Schema;\n+\n+\n+Schema schema = ...;\n+DataStream<GenericRecord> input = ...;\n+\n+final FileSink<GenericRecord> sink = FileSink\n+\t.forBulkFormat(outputBasePath, ParquetAvroWriters.forGenericRecord(schema))\n+\t.build();\n+\n+input.sinkTo(sink);\n+\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+import org.apache.flink.connector.file.sink.FileSink;\n+import org.apache.flink.formats.parquet.avro.ParquetAvroWriters\n+import org.apache.avro.Schema\n+\n+val schema: Schema = ...\n+val input: DataStream[GenericRecord] = ...\n+\n+val sink: FileSink[GenericRecord] = FileSink\n+    .forBulkFormat(outputBasePath, ParquetAvroWriters.forGenericRecord(schema))\n+    .build()\n+\n+input.sinkTo(sink)\n+\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+类似的，将 Protobuf 数据写入到 Parquet 格式可以通过：\n+\n+{{< tabs \"7f22c88d-e7dd-4299-aa23-02afc61a6319\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+import org.apache.flink.connector.file.sink.FileSink;\n+import org.apache.flink.formats.parquet.protobuf.ParquetProtoWriters;\n+\n+// ProtoRecord is a generated protobuf Message class.\n+DataStream<ProtoRecord> input = ...;\n+\n+final FileSink<ProtoRecord> sink = FileSink\n+\t.forBulkFormat(outputBasePath, ParquetProtoWriters.forType(ProtoRecord.class))\n+\t.build();\n+\n+input.sinkTo(sink);\n+\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+import org.apache.flink.connector.file.sink.FileSink;\n+import org.apache.flink.formats.parquet.protobuf.ParquetProtoWriters\n+\n+// ProtoRecord is a generated protobuf Message class.\n+val input: DataStream[ProtoRecord] = ...\n+\n+val sink: FileSink[ProtoRecord] = FileSink\n+    .forBulkFormat(outputBasePath, ParquetProtoWriters.forType(classOf[ProtoRecord]))\n+    .build()\n+\n+input.sinkTo(sink)\n+\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+#### Avro格式\n+\n+Flink 也提供了将数据写入 Avro 文件的内置支持。对于创建 AvroWriterFactory 的快捷方法，更多信息可以参考 \n+`AvroWriters`.\n+\n+使用Avro相关的Writer需要在项目中添加以下依赖：\n+\n+{{< artifact flink-avro >}}\n+\n+将数据写入 Avro 文件的 FileSink 算子可以通过如下方式创建：\n+\n+{{< tabs \"237658d5-98c7-43c7-9844-268df7ba7afc\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+import org.apache.flink.connector.file.sink.FileSink;\n+import org.apache.flink.formats.avro.AvroWriters;\n+import org.apache.avro.Schema;\n+\n+\n+Schema schema = ...;\n+DataStream<GenericRecord> input = ...;\n+\n+final FileSink<GenericRecord> sink = FileSink\n+\t.forBulkFormat(outputBasePath, AvroWriters.forGenericRecord(schema))\n+\t.build();\n+\n+input.sinkTo(sink);\n+\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+import org.apache.flink.connector.file.sink.FileSink;\n+import org.apache.flink.formats.avro.AvroWriters\n+import org.apache.avro.Schema\n+\n+val schema: Schema = ...\n+val input: DataStream[GenericRecord] = ...\n+\n+val sink: FileSink[GenericRecord] = FileSink\n+    .forBulkFormat(outputBasePath, AvroWriters.forGenericRecord(schema))\n+    .build()\n+\n+input.sinkTo(sink)\n+\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+如果想要创建自定义的 Avro Writer，例如启用压缩等，用户可以实现 `AvroBuilder`\n+接口并自行创建一个 `AvroWriterFactory` 实例：\n+\n+{{< tabs \"732055fb-ae45-49dd-81a1-8aadbb9e3d65\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+AvroWriterFactory<?> factory = new AvroWriterFactory<>((AvroBuilder<Address>) out -> {\n+\tSchema schema = ReflectData.get().getSchema(Address.class);\n+\tDatumWriter<Address> datumWriter = new ReflectDatumWriter<>(schema);\n+\n+\tDataFileWriter<Address> dataFileWriter = new DataFileWriter<>(datumWriter);\n+\tdataFileWriter.setCodec(CodecFactory.snappyCodec());\n+\tdataFileWriter.create(schema, out);\n+\treturn dataFileWriter;\n+});\n+\n+DataStream<Address> stream = ...\n+stream.sinkTo(FileSink.forBulkFormat(\n+\toutputBasePath,\n+\tfactory).build());\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+val factory = new AvroWriterFactory[Address](new AvroBuilder[Address]() {\n+    override def createWriter(out: OutputStream): DataFileWriter[Address] = {\n+        val schema = ReflectData.get.getSchema(classOf[Address])\n+        val datumWriter = new ReflectDatumWriter[Address](schema)\n+\n+        val dataFileWriter = new DataFileWriter[Address](datumWriter)\n+        dataFileWriter.setCodec(CodecFactory.snappyCodec)\n+        dataFileWriter.create(schema, out)\n+        dataFileWriter\n+    }\n+})\n+\n+val stream: DataStream[Address] = ...\n+stream.sinkTo(FileSink.forBulkFormat(\n+    outputBasePath,\n+    factory).build());\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+#### ORC Format\n+\n+为了使用基于批量编码的 ORC 格式，Flink提供了 `OrcBulkWriterFactory` ，它需要用户提供一个 `Vectorizer` 的具体实现。\n+\n+和其它基于列式存储的批量编码格式类似，Flink中的 `OrcBulkWriter` 将数据按批写出。它通过 ORC 的 VectorizedRowBatch 来实现这一点。\n+\n+由于输入数据必须先缓存为一个完整的 `VectorizedRowBatch` ，用户需要继承 `Vectorizer` 抽像类并且实现其中的 `vectorize(T element, VectorizedRowBatch batch)` 方法。方法参数中传入的 `VectorizedRowBatch` 使用户只需将输入 `element` 转化为 `ColumnVectors` 并将它存储到所提供的 `VectorizedRowBatch` 实例中。\n+\n+例如，如果输入元素的类型是 `Person` 并且它的定义如下：\n+\n+{{< tabs \"8d9329a5-d67d-4c17-b940-03616c0bd5d6\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+\n+class Person {\n+    private final String name;\n+    private final int age;\n+    ...\n+}\n+\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+那么用户可以采用如下方式在子类中将 `Person` 对象转化为 `VectorizedRowBatch` ：\n+\n+{{< tabs \"2462164c-3dfc-414c-8bab-e2e8256266d9\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+import org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector;\n+import org.apache.hadoop.hive.ql.exec.vector.LongColumnVector;\n+\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.nio.charset.StandardCharsets;\n+\n+public class PersonVectorizer extends Vectorizer<Person> implements Serializable {\n+\tpublic PersonVectorizer(String schema) {\n+\t\tsuper(schema);\n+\t}\n+\t@Override\n+\tpublic void vectorize(Person element, VectorizedRowBatch batch) throws IOException {\n+\t\tBytesColumnVector nameColVector = (BytesColumnVector) batch.cols[0];\n+\t\tLongColumnVector ageColVector = (LongColumnVector) batch.cols[1];\n+\t\tint row = batch.size++;\n+\t\tnameColVector.setVal(row, element.getName().getBytes(StandardCharsets.UTF_8));\n+\t\tageColVector.vector[row] = element.getAge();\n+\t}\n+}\n+\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+import java.nio.charset.StandardCharsets\n+import org.apache.hadoop.hive.ql.exec.vector.{BytesColumnVector, LongColumnVector}\n+\n+class PersonVectorizer(schema: String) extends Vectorizer[Person](schema) {\n+\n+  override def vectorize(element: Person, batch: VectorizedRowBatch): Unit = {\n+    val nameColVector = batch.cols(0).asInstanceOf[BytesColumnVector]\n+    val ageColVector = batch.cols(1).asInstanceOf[LongColumnVector]\n+    nameColVector.setVal(batch.size + 1, element.getName.getBytes(StandardCharsets.UTF_8))\n+    ageColVector.vector(batch.size + 1) = element.getAge\n+  }\n+\n+}\n+\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+为了在应用中使用 ORC 批量编码，用户需要添加如下依赖：\n+\n+{{< artifact flink-orc withScalaVersion >}}\n+\n+然后使用 ORC 格式的 `FileSink` 可以通过如下方式创建：\n+\n+{{< tabs \"4bc2aa30-6ea9-461f-aa24-8c36856edfcb\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+import org.apache.flink.connector.file.sink.FileSink;\n+import org.apache.flink.orc.writer.OrcBulkWriterFactory;\n+\n+String schema = \"struct<_col0:string,_col1:int>\";\n+DataStream<Person> input = ...;\n+\n+final OrcBulkWriterFactory<Person> writerFactory = new OrcBulkWriterFactory<>(new PersonVectorizer(schema));\n+\n+final FileSink<Person> sink = FileSink\n+\t.forBulkFormat(outputBasePath, writerFactory)\n+\t.build();\n+\n+input.sinkTo(sink);\n+\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+import org.apache.flink.connector.file.sink.FileSink;\n+import org.apache.flink.orc.writer.OrcBulkWriterFactory\n+\n+val schema: String = \"struct<_col0:string,_col1:int>\"\n+val input: DataStream[Person] = ...\n+val writerFactory = new OrcBulkWriterFactory(new PersonVectorizer(schema));\n+\n+val sink: FileSink[Person] = FileSink\n+    .forBulkFormat(outputBasePath, writerFactory)\n+    .build()\n+\n+input.sinkTo(sink)\n+\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+用户还可以通过 Hadoop `Configuration` 和 `Properties` 来设置 OrcBulkWriterFactory 中涉及的 Hadoop 属性和 ORC Writer 属性：\n+\n+{{< tabs \"79765e6f-43bf-47ac-801c-2f7da9ac4f87\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+String schema = ...;\n+Configuration conf = ...;\n+Properties writerProperties = new Properties();\n+\n+writerProps.setProperty(\"orc.compress\", \"LZ4\");\n+// 其它 ORC 支持的属性也可以类似设置。\n+\n+final OrcBulkWriterFactory<Person> writerFactory = new OrcBulkWriterFactory<>(\n+    new PersonVectorizer(schema), writerProperties, conf);\n+\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+val schema: String = ...\n+val conf: Configuration = ...\n+val writerProperties: Properties = new Properties()\n+\n+writerProps.setProperty(\"orc.compress\", \"LZ4\")\n+// 其它 ORC 支持的属性也可以类似设置。\n+\n+val writerFactory = new OrcBulkWriterFactory(\n+    new PersonVectorizer(schema), writerProperties, conf)\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+完整的 ORC Writer 的属性可以参考 [相关文档](https://orc.apache.org/docs/hive-config.html).\n+\n+给 ORC 文件添加自定义元数据可以通过在实现的 `vectorize(...)` 方法中调用 `addUserMetadata(...)` 实现：\n+\n+{{< tabs \"df5c8b4f-9db0-41b0-89e7-a74a3b473b35\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+\n+public class PersonVectorizer extends Vectorizer<Person> implements Serializable {\n+\t@Override\n+\tpublic void vectorize(Person element, VectorizedRowBatch batch) throws IOException {\n+\t\t...\n+\t\tString metadataKey = ...;\n+\t\tByteBuffer metadataValue = ...;\n+\t\tthis.addUserMetadata(metadataKey, metadataValue);\n+\t}\n+}\n+\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+\n+class PersonVectorizer(schema: String) extends Vectorizer[Person](schema) {\n+\n+  override def vectorize(element: Person, batch: VectorizedRowBatch): Unit = {\n+    ...\n+    val metadataKey: String = ...\n+    val metadataValue: ByteBuffer = ...\n+    addUserMetadata(metadataKey, metadataValue)\n+  }\n+\n+}\n+\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+#### Hadoop SequenceFile 格式\n+\n+在应用中使用 `SequenceFile` 批量编码器，你需要添加以下依赖：\n+\n+{{< artifact flink-sequence-file >}}\n+\n+简单的 `SequenceFile` 写入示例：\n+\n+{{< tabs \"addcc4bc-bd9c-473a-9d5a-d9d9b3efd7d2\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+import org.apache.flink.connector.file.sink.FileSink;\n+import org.apache.flink.configuration.GlobalConfiguration;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.io.LongWritable;\n+import org.apache.hadoop.io.SequenceFile;\n+import org.apache.hadoop.io.Text;\n+\n+\n+DataStream<Tuple2<LongWritable, Text>> input = ...;\n+Configuration hadoopConf = HadoopUtils.getHadoopConfiguration(GlobalConfiguration.loadConfiguration());\n+final FileSink<Tuple2<LongWritable, Text>> sink = FileSink\n+  .forBulkFormat(\n+    outputBasePath,\n+    new SequenceFileWriterFactory<>(hadoopConf, LongWritable.class, Text.class))\n+\t.build();\n+\n+input.sinkTo(sink);\n+\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+import org.apache.flink.connector.file.sink.FileSink;\n+import org.apache.flink.configuration.GlobalConfiguration\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.io.LongWritable\n+import org.apache.hadoop.io.SequenceFile\n+import org.apache.hadoop.io.Text;\n+\n+val input: DataStream[(LongWritable, Text)] = ...\n+val hadoopConf: Configuration = HadoopUtils.getHadoopConfiguration(GlobalConfiguration.loadConfiguration())\n+val sink: FileSink[(LongWritable, Text)] = FileSink\n+  .forBulkFormat(\n+    outputBasePath,\n+    new SequenceFileWriterFactory(hadoopConf, LongWritable.class, Text.class))\n+\t.build()\n+\n+input.sinkTo(sink)\n+\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+`SequenceFileWriterFactory` 支持附加构造函数参数指定压缩设置。\n+\n+## 桶分配\n+\n+桶分配逻辑定义了如何将数据结构化为基本输出目录中的子目录\n+\n+行格式和批量格式都使用 `DateTimeBucketAssigner` 作为默认的分配器。\n+默认情况下，DateTimeBucketAssigner 基于系统默认时区每小时创建一个桶，格式如下： `yyyy-MM-dd--HH` 。日期格式（即桶的大小）和时区都可以手动配置。\n+\n+我们可以在格式构建器上调用 `.withBucketAssigner(assigner)` 来自定义 `BucketAssigner` 。\n+\n+Flink 有两个内置的 BucketAssigners ：\n+\n+ - `DateTimeBucketAssigner：默认基于时间的分配器`\n+ - `BasePathBucketAssigner` ：将所有部分文件（part file）存储在基本路径中的分配器（单个全局桶）\n+\n+## 滚动策略\n+\n+在流模式下，滚动策略 `RollingPolicy` 定义了指定的文件在何时关闭（closed）并将其变为 Pending 状态，随后变为 Finished 状态。处于 Pending 状态的文件会在下一次 Checkpoint 时变为 Finished 状态，通过设置 Checkpoint 间隔时间，可以控制部分文件（part file）对下游读取者可用的速度、大小和数量。在批模式下，临时文件只会在作业处理完所有输入数据后才会变成 Finished 状态，此时滚动策略可以用来控制每个文件的大小。\n+\n+Flink 有两个内置的滚动策略：\n+\n+ - `DefaultRollingPolicy`\n+ - `OnCheckpointRollingPolicy`\n+\n+## 部分文件（part file） 生命周期\n+\n+为了在下游系统中使用 FileSink 的输出，我们需要了解输出文件的命名规则和生命周期。\n+\n+部分文件（part file）可以处于以下三种状态之一：\n+ 1. **In-progress** ：当前文件正在写入中。\n+ 2. **Pending** ：当处于 In-progress 状态的文件关闭（closed）了，就变为 Pending 状态。\n+ 3. **Finished** ：在成功的 Checkpoint 后（流模式）或作业处理完所有输入数据后（批模式），Pending 状态将变为 Finished 状态。\n+\n+处于 Finished 状态的文件不会再被修改，可以被下游系统安全地读取。\n+\n+{{< hint info >}}\n+<b>重要:</b> 部分文件的索引在每个 subtask 内部是严格递增的（按文件创建顺序）。但是索引并不总是连续的。当 Job 重启后，所有部分文件的索引从 `max part index + 1` 开始，\n+这里的 `max part index` 是所有 subtask 中索引的最大值。\n+{{< /hint >}}\n+\n+对于每个活动的桶，Writer 在任何时候都只有一个处于 In-progress 状态的部分文件（part file），但是可能有几个 Penging 和 Finished 状态的部分文件（part file）。\n+\n+**部分文件（part file）例子**\n+\n+为了更好地理解这些文件的生命周期，让我们来看一个包含 2 个 Sink Subtask 的简单例子：\n+\n+```\n+└── 2019-08-25--12\n+    ├── part-4005733d-a830-4323-8291-8866de98b582-0.inprogress.bd053eb0-5ecf-4c85-8433-9eff486ac334\n+    └── part-81fc4980-a6af-41c8-9937-9939408a734b-0.inprogress.ea65a428-a1d0-4a0b-bbc5-7a436a75e575\n+```\n+\n+当部分文件 `part-81fc4980-a6af-41c8-9937-9939408a734b-0` 被滚动（假设它变得太大了）时，它将成为 Pending 状态，但是它还没有被重命名。然后 Sink 会创建一个新的部分文件： `part-81fc4980-a6af-41c8-9937-9939408a734b-1`：\n+\n+```\n+└── 2019-08-25--12\n+    ├── part-4005733d-a830-4323-8291-8866de98b582-0.inprogress.bd053eb0-5ecf-4c85-8433-9eff486ac334\n+    ├── part-81fc4980-a6af-41c8-9937-9939408a734b-0.inprogress.ea65a428-a1d0-4a0b-bbc5-7a436a75e575\n+    └── part-81fc4980-a6af-41c8-9937-9939408a734b-1.inprogress.bc279efe-b16f-47d8-b828-00ef6e2fbd11\n+```\n+\n+ `part-81fc4980-a6af-41c8-9937-9939408a734b-0` 现在处于 Pending 状态等待完成，在下一次成功的 Checkpoint 后，它会变成 Finished 状态：\n+\n+```\n+└── 2019-08-25--12\n+    ├── part-4005733d-a830-4323-8291-8866de98b582-0.inprogress.bd053eb0-5ecf-4c85-8433-9eff486ac334\n+    ├── part-81fc4980-a6af-41c8-9937-9939408a734b-0\n+    └── part-81fc4980-a6af-41c8-9937-9939408a734b-1.inprogress.bc279efe-b16f-47d8-b828-00ef6e2fbd11\n+```\n+\n+根据分桶策略创建新的桶，但是这并不会影响当前处于 In-progress 状态的文件：\n+\n+```\n+└── 2019-08-25--12\n+    ├── part-4005733d-a830-4323-8291-8866de98b582-0.inprogress.bd053eb0-5ecf-4c85-8433-9eff486ac334\n+    ├── part-81fc4980-a6af-41c8-9937-9939408a734b-0\n+    └── part-81fc4980-a6af-41c8-9937-9939408a734b-1.inprogress.bc279efe-b16f-47d8-b828-00ef6e2fbd11\n+└── 2019-08-25--13\n+    └── part-4005733d-a830-4323-8291-8866de98b582-0.inprogress.2b475fec-1482-4dea-9946-eb4353b475f1\n+```\n+\n+因为分桶策略基于每条记录进行评估，所以旧桶仍然可以接受新的记录。\n+\n+### 部分文件的配置项\n+\n+已经完成的文件和进行中的文件仅能通过文件名格式进行区分。\n+\n+默认情况下，文件命名格式如下所示：\n+ - **In-progress / Pending:** `part-<uid>-<partFileIndex>.inprogress.uid`\n+ - **FINISHED:** `part-<uid>-<partFileIndex>`\n+ \n+其中 uid 是在 Sink 的各个 task 在启动时随机生成的 id，这些 id 是不支持容错的，在 task 重启后 id 会重新生成。\n+\n+Flink 允许用户通过 `OutputFileConfig` 指定部分文件名的前缀和后缀。\n+举例来说，前缀设置为 \"prefix\" 以及后缀设置为 \".ext\" 之后，Sink 创建的文件名如下所示：\n+\n+```\n+└── 2019-08-25--12\n+    ├── prefix-4005733d-a830-4323-8291-8866de98b582-0.ext\n+    ├── prefix-4005733d-a830-4323-8291-8866de98b582-1.ext.inprogress.bd053eb0-5ecf-4c85-8433-9eff486ac334\n+    ├── prefix-81fc4980-a6af-41c8-9937-9939408a734b-0.ext\n+    └── prefix-81fc4980-a6af-41c8-9937-9939408a734b-1.ext.inprogress.bc279efe-b16f-47d8-b828-00ef6e2fbd11\n+```\n+\n+用户可以通过如下方式设置 `OutputFileConfig`:\n+\n+{{< tabs \"074e85ae-45fa-4280-a017-1c836d7b583e\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+\n+OutputFileConfig config = OutputFileConfig\n+ .builder()\n+ .withPartPrefix(\"prefix\")\n+ .withPartSuffix(\".ext\")\n+ .build();\n+            \n+FileSink<Tuple2<Integer, Integer>> sink = FileSink\n+ .forRowFormat((new Path(outputPath), new SimpleStringEncoder<>(\"UTF-8\"))\n+ .withBucketAssigner(new KeyBucketAssigner())\n+ .withRollingPolicy(OnCheckpointRollingPolicy.build())\n+ .withOutputFileConfig(config)\n+ .build();\n+\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+\n+val config = OutputFileConfig\n+ .builder()\n+ .withPartPrefix(\"prefix\")\n+ .withPartSuffix(\".ext\")\n+ .build()\n+            \n+val sink = FileSink\n+ .forRowFormat(new Path(outputPath), new SimpleStringEncoder[String](\"UTF-8\"))\n+ .withBucketAssigner(new KeyBucketAssigner())\n+ .withRollingPolicy(OnCheckpointRollingPolicy.build())\n+ .withOutputFileConfig(config)\n+ .build()\n+\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+## 重要注意事项\n+\n+### 通用注意事项\n+\n+<span class=\"label label-danger\">重要提示 1</span>: 使用 Hadoop < 2.7 时，请使用 `OnCheckpointRollingPolicy` 滚动策略，该策略会在每次检查点时进行文件滚动。\n+这样做的原因是如果部分文件的生命周期跨多个检查点，当 `FileSink` 从之前的检查点进行恢复时会调用文件系统的 `truncate()` 方法清理 in-progress 文件中未提交的数据。\n+Hadoop 2.7 之前的版本不支持这个方法，因此 Flink 会报异常。\n+\n+<span class=\"label label-danger\">重要提示 2</span>: 鉴于 Flink 的 sink 以及 UDF 通常不会区分作业的正常结束（比如有限流）和异常终止，因此正常结束作业的最后一批 in-progress 文件不会被转换到 \"完成\" 状态。\n+\n+<span class=\"label label-danger\">重要提示 3</span>: Flink 以及 `FileSink` 不会覆盖已经提交的数据。因此如果尝试从一个包含 in-progress 文件的旧 checkpoint/savepoint 恢复，\n+且这些 in-progress 文件会被接下来的成功 checkpoint 提交，Flink 会因为无法找到 in-progress 文件而抛异常，从而恢复失败。\n+\n+<span class=\"label label-danger\">重要提示 4</span>: 目前 `FileSink` 只支持三种文件系统: HDFS、S3和Local。如果配置了不支持的文件系统，在执行的时候 Flink 会抛出异常。\n+\n+### Batch 模式\n+\n+<span class=\"label label-danger\">重要提示 1</span>: 尽管负责写出数据的 Writer 会使用用户提定的并发，负责提交文件的 Committer 将固定并发度为1。\n+\n+<span class=\"label label-danger\">Important Note 2</span>: 批模式下只有在所有输入都被处理后 Pending 文件才会被提交，即转为 Finished 状态。\n+\n+<span class=\"label label-danger\">Important Note 3</span>: 在高可用模式下，如果在 Committer 提交文件时发生了 JobManager 重启，已提交的数据可能会被重复产生。这一问题将在后续版本中修复。\n+\n+###  S3 特有的注意事项\n+\n+<span class=\"label label-danger\">重要提示 1</span>: 对于 S3，`FileSink`  只支持基于 [Hadoop](https://hadoop.apache.org/) \n+的文件系统实现，不支持基于 [Presto](https://prestodb.io/) 的实现。如果想使用 `FileSink` 向 S3 写入数据并且将 \n+checkpoint 放在基于 Presto 的文件系统，建议明确指定 *\"s3a://\"* （for Hadoop）作为sink的目标路径方案，并且为 checkpoint 路径明确指定 *\"s3p://\"* （for Presto）。\n+如果 Sink 和 checkpoint 都使用 *\"s3://\"* 路径的话，可能会导致不可预知的行为，因为双方的实现都在“监听”这个路径。\n+\n+<span class=\"label label-danger\">重要提示 2</span>: `FileSink` 使用 S3 的 [Multi-part Upload](https://docs.aws.amazon.com/AmazonS3/latest/dev/mpuoverview.html)\n+（后续使用MPU代替）特性可以保证精确一次的语义。这个特性支持以独立的块（因此被称为\"multi-part\"）模式上传文件，当 MPU 的所有部分文件\n+成功上传之后，可以合并成原始文件。对于失效的 MPUs，S3 提供了一个基于桶生命周期的规则，用户可以用这个规则来丢弃在指定时间内未完成的MPU。\n+如果在一些部分文件还未上传时触发 savepoint，并且这个规则设置的比较严格，这意味着相关的 MPU在作业重启之前可能会超时。后续的部分文件没\n+有写入到 savepoint, 那么在 Flink 作业从 savepoint 恢复时，会因为拿不到缺失的部分文件，导致任务失败并抛出异常。\n+\n+{{< top >}}"
        },
        {
            "sha": "1f60466d6465100ceed41fe0dc0e340fef1ebc10",
            "filename": "docs/content.zh/docs/connectors/datastream/guarantees.md",
            "status": "added",
            "additions": 141,
            "deletions": 0,
            "changes": 141,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/datastream/guarantees.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/datastream/guarantees.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/datastream/guarantees.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,141 @@\n+---\n+title: 容错保证\n+weight: 1\n+type: docs\n+aliases:\n+  - /zh/dev/connectors/guarantees.html\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Data Source 和 Sink 的容错保证\n+\n+当程序出现错误的时候，Flink 的容错机制能恢复并继续运行程序。这种错误包括机器硬件故障、网络故障、瞬态程序故障等等。\n+\n+只有当 source 参与了快照机制的时候，Flink 才能保证对自定义状态的精确一次更新。下表列举了 Flink 与其自带连接器的状态更新的保证。\n+\n+请阅读各个连接器的文档来了解容错保证的细节。\n+\n+<table class=\"table table-bordered\">\n+  <thead>\n+    <tr>\n+      <th class=\"text-left\" style=\"width: 25%\">Source</th>\n+      <th class=\"text-left\" style=\"width: 25%\">Guarantees</th>\n+      <th class=\"text-left\">Notes</th>\n+    </tr>\n+   </thead>\n+   <tbody>\n+        <tr>\n+            <td>Apache Kafka</td>\n+            <td>精确一次</td>\n+            <td>根据你的版本用恰当的 Kafka 连接器</td>\n+        </tr>\n+        <tr>\n+            <td>AWS Kinesis Streams</td>\n+            <td>精确一次</td>\n+            <td></td>\n+        </tr>\n+        <tr>\n+            <td>RabbitMQ</td>\n+            <td>至多一次 (v 0.10) / 精确一次 (v 1.0) </td>\n+            <td></td>\n+        </tr>\n+        <tr>\n+            <td>Twitter Streaming API</td>\n+            <td>至多一次</td>\n+            <td></td>\n+        </tr>\n+        <tr>\n+            <td>Google PubSub</td>\n+            <td>至少一次</td>\n+            <td></td>\n+        </tr>\n+        <tr>\n+            <td>Collections</td>\n+            <td>精确一次</td>\n+            <td></td>\n+        </tr>\n+        <tr>\n+            <td>Files</td>\n+            <td>精确一次</td>\n+            <td></td>\n+        </tr>\n+        <tr>\n+            <td>Sockets</td>\n+            <td>至多一次</td>\n+            <td></td>\n+        </tr>\n+  </tbody>\n+</table>\n+\n+为了保证端到端精确一次的数据交付（在精确一次的状态语义上更进一步），sink需要参与 checkpointing 机制。下表列举了 Flink 与其自带 sink 的交付保证（假设精确一次状态更新）。\n+\n+<table class=\"table table-bordered\">\n+  <thead>\n+    <tr>\n+      <th class=\"text-left\" style=\"width: 25%\">Sink</th>\n+      <th class=\"text-left\" style=\"width: 25%\">Guarantees</th>\n+      <th class=\"text-left\">Notes</th>\n+    </tr>\n+  </thead>\n+  <tbody>\n+    <tr>\n+        <td>Elasticsearch</td>\n+        <td>至少一次</td>\n+        <td></td>\n+    </tr>\n+    <tr>\n+        <td>Kafka producer</td>\n+        <td>至少一次 / 精确一次</td>\n+        <td>当使用事务生产者时，保证精确一次 (v 0.11+)</td>\n+    </tr>\n+    <tr>\n+        <td>Cassandra sink</td>\n+        <td>至少一次 / 精确一次</td>\n+        <td>只有当更新是幂等时，保证精确一次</td>\n+    </tr>\n+    <tr>\n+        <td>AWS Kinesis Streams</td>\n+        <td>至少一次</td>\n+        <td></td>\n+    </tr>\n+    <tr>\n+        <td>File sinks</td>\n+        <td>精确一次</td>\n+        <td></td>\n+    </tr>\n+    <tr>\n+        <td>Socket sinks</td>\n+        <td>至少一次</td>\n+        <td></td>\n+    </tr>\n+    <tr>\n+        <td>Standard output</td>\n+        <td>至少一次</td>\n+        <td></td>\n+    </tr>\n+    <tr>\n+        <td>Redis sink</td>\n+        <td>至少一次</td>\n+        <td></td>\n+    </tr>\n+  </tbody>\n+</table>\n+\n+{{< top >}}"
        },
        {
            "sha": "9bfb923e8d2316dc3391dd6f7051b341440f4957",
            "filename": "docs/content.zh/docs/connectors/datastream/jdbc.md",
            "status": "added",
            "additions": 61,
            "deletions": 0,
            "changes": 61,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/datastream/jdbc.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/datastream/jdbc.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/datastream/jdbc.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,61 @@\n+---\n+title: JDBC\n+weight: 10\n+type: docs\n+aliases:\n+  - /zh/dev/connectors/jdbc.html\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# JDBC Connector\n+\n+该连接器可以向 JDBC 数据库写入数据。\n+\n+添加下面的依赖以便使用该连接器（同时添加 JDBC 驱动）：\n+\n+{{< artifact flink-connector-jdbc withScalaVersion >}}\n+\n+注意该连接器目前还 __不是__ 二进制发行版的一部分，如何在集群中运行请参考 [这里]({{< ref \"docs/dev/datastream/project-configuration\" >}})。\n+\n+已创建的 JDBC Sink 能够保证至少一次的语义。\n+更有效的精确执行一次可以通过 upsert 语句或幂等更新实现。\n+\n+用法示例：\n+```java\n+StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n+env\n+        .fromElements(...)\n+        .addSink(JdbcSink.sink(\n+                \"insert into books (id, title, author, price, qty) values (?,?,?,?,?)\",\n+                (ps, t) -> {\n+                    ps.setInt(1, t.id);\n+                    ps.setString(2, t.title);\n+                    ps.setString(3, t.author);\n+                    ps.setDouble(4, t.price);\n+                    ps.setInt(5, t.qty);\n+                },\n+                new JdbcConnectionOptions.JdbcConnectionOptionsBuilder()\n+                        .withUrl(getDbMetadata().getUrl())\n+                        .withDriverName(getDbMetadata().getDriverClass())\n+                        .build()));\n+env.execute();\n+```\n+\n+更多细节请查看 API documentation 。"
        },
        {
            "sha": "048fb9771e412f45d070b2dae96ef035eac10e94",
            "filename": "docs/content.zh/docs/connectors/datastream/kafka.md",
            "status": "added",
            "additions": 499,
            "deletions": 0,
            "changes": 499,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/datastream/kafka.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/datastream/kafka.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/datastream/kafka.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,499 @@\n+---\n+title: Kafka\n+weight: 2\n+type: docs\n+aliases:\n+  - /zh/dev/connectors/kafka.html\n+  - /zh/apis/streaming/connectors/kafka.html\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Apache Kafka 连接器\n+\n+Flink 提供了 [Apache Kafka](https://kafka.apache.org) 连接器，用于从 Kafka topic 中读取或者向其中写入数据，可提供精确一次的处理语义。\n+\n+<a name=\"dependency\"></a>\n+\n+## 依赖\n+\n+Apache Flink 集成了通用的 Kafka 连接器，它会尽力与 Kafka client 的最新版本保持同步。该连接器使用的 Kafka client 版本可能会在 Flink 版本之间发生变化。\n+当前 Kafka client 向后兼容 0.10.0 或更高版本的 Kafka broker。\n+有关 Kafka 兼容性的更多细节，请参考  [Kafka 官方文档](https://kafka.apache.org/protocol.html#protocol_compatibility)。\n+\n+{{< artifact flink-connector-kafka withScalaVersion >}}\n+\n+Flink 目前的流连接器还不是二进制发行版的一部分。\n+[在此处]({{< ref \"docs/dev/datastream/project-configuration\" >}})可以了解到如何链接它们，从而在集群中运行。\n+\n+<a name=\"kafka-consumer\"></a>\n+\n+## Kafka Consumer\n+\n+Flink 的 Kafka consumer 称为 `FlinkKafkaConsumer`。它提供对一个或多个 Kafka topics 的访问。\n+\n+构造函数接受以下参数：\n+\n+1. Topic 名称或者名称列表\n+2. 用于反序列化 Kafka 数据的 DeserializationSchema 或者 KafkaDeserializationSchema\n+3. Kafka 消费者的属性。需要以下属性：\n+  - \"bootstrap.servers\"（以逗号分隔的 Kafka broker 列表）\n+  - \"group.id\" 消费组 ID\n+\n+{{< tabs \"fdf41307-604d-426f-9863-666250ce0cdc\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+Properties properties = new Properties();\n+properties.setProperty(\"bootstrap.servers\", \"localhost:9092\");\n+properties.setProperty(\"group.id\", \"test\");\n+DataStream<String> stream = env\n+    .addSource(new FlinkKafkaConsumer<>(\"topic\", new SimpleStringSchema(), properties));\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+val properties = new Properties()\n+properties.setProperty(\"bootstrap.servers\", \"localhost:9092\")\n+properties.setProperty(\"group.id\", \"test\")\n+val stream = env\n+    .addSource(new FlinkKafkaConsumer[String](\"topic\", new SimpleStringSchema(), properties))\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+<a name=\"the-deserializationschema\"></a>\n+\n+### `DeserializationSchema`\n+\n+Flink Kafka Consumer 需要知道如何将 Kafka 中的二进制数据转换为 Java 或者 Scala 对象。`KafkaDeserializationSchema` 允许用户指定这样的 schema，每条 Kafka 中的消息会调用 `T deserialize(ConsumerRecord<byte[], byte[]> record)` 反序列化。\n+\n+为了方便使用，Flink 提供了以下几种 schemas：\n+\n+1. `TypeInformationSerializationSchema`（和 `TypeInformationKeyValueSerializationSchema`) 基于 Flink 的 `TypeInformation` 创建 `schema`。\n+    如果该数据的读和写都发生在 Flink 中，那么这将是非常有用的。此 schema 是其他通用序列化方法的高性能 Flink 替代方案。\n+\n+2. `JsonDeserializationSchema`（和 `JSONKeyValueDeserializationSchema`）将序列化的 JSON 转化为 ObjectNode 对象，可以使用 `objectNode.get(\"field\").as(Int/String/...)()` 来访问某个字段。\n+    KeyValue objectNode 包含一个含所有字段的 key 和 values 字段，以及一个可选的\"metadata\"字段，可以访问到消息的 offset、partition、topic 等信息。\n+\n+3. `AvroDeserializationSchema` 使用静态提供的 schema 读取 Avro 格式的序列化数据。\n+    它能够从 Avro 生成的类（`AvroDeserializationSchema.forSpecific(...)`）中推断出 schema，或者可以与 `GenericRecords`\n+    一起使用手动提供的 schema（用 `AvroDeserializationSchema.forGeneric(...)`）。此反序列化 schema 要求序列化记录不能包含嵌入式架构！\n+\n+    - 此模式还有一个版本，可以在 [Confluent Schema Registry](https://docs.confluent.io/current/schema-registry/docs/index.html) 中查找编写器的 schema（用于编写记录的 schema）。\n+    - 使用这些反序列化 schema 记录将读取从 schema 注册表检索到的 schema 转换为静态提供的 schema（或者通过 `ConfluentRegistryAvroDeserializationSchema.forGeneric(...)` 或 `ConfluentRegistryAvroDeserializationSchema.forSpecific(...)`）。\n+\n+    <br>要使用此反序列化 schema 必须添加以下依赖：\n+\n+{{< tabs \"28c9b976-d85a-4d98-ad0b-7ca427c85b57\" >}}\n+{{< tab \"AvroDeserializationSchema\" >}}\n+```xml\n+<dependency>\n+  <groupId>org.apache.flink</groupId>\n+  <artifactId>flink-avro</artifactId>\n+  <version>{{< version >}}</version>\n+</dependency>\n+```\n+{{< /tab >}}\n+{{< tab \"ConfluentRegistryAvroDeserializationSchema\" >}}\n+```xml\n+<dependency>\n+  <groupId>org.apache.flink</groupId>\n+  <artifactId>flink-avro-confluent-registry</artifactId>\n+  <version>{{< version >}}</version>\n+</dependency>\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+当遇到因一些原因而无法反序列化的损坏消息时，反序列化 schema 会返回 `null`，以允许 Flink Kafka 消费者悄悄地跳过损坏的消息。请注意，由于 consumer 的容错能力（请参阅下面的部分以获取更多详细信息），在损坏的消息上失败作业将使 consumer 尝试再次反序列化消息。因此，如果反序列化仍然失败，则 consumer 将在该损坏的消息上进入不间断重启和失败的循环。\n+\n+<a name=\"kafka-consumers-start-position-configuration\"></a>\n+\n+### 配置 Kafka Consumer 开始消费的位置 \n+\n+Flink Kafka Consumer 允许通过配置来确定 Kafka 分区的起始位置。\n+\n+{{< tabs \"dd71055b-6b2d-4e61-8c4b-5e93aeaf939a\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n+\n+FlinkKafkaConsumer<String> myConsumer = new FlinkKafkaConsumer<>(...);\n+myConsumer.setStartFromEarliest();     // 尽可能从最早的记录开始\n+myConsumer.setStartFromLatest();       // 从最新的记录开始\n+myConsumer.setStartFromTimestamp(...); // 从指定的时间开始（毫秒）\n+myConsumer.setStartFromGroupOffsets(); // 默认的方法\n+\n+DataStream<String> stream = env.addSource(myConsumer);\n+...\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+val env = StreamExecutionEnvironment.getExecutionEnvironment()\n+\n+val myConsumer = new FlinkKafkaConsumer[String](...)\n+myConsumer.setStartFromEarliest()      // 尽可能从最早的记录开始\n+myConsumer.setStartFromLatest()        // 从最新的记录开始\n+myConsumer.setStartFromTimestamp(...)  // 从指定的时间开始（毫秒）\n+myConsumer.setStartFromGroupOffsets()  // 默认的方法\n+\n+val stream = env.addSource(myConsumer)\n+...\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+Flink Kafka Consumer 的所有版本都具有上述明确的起始位置配置方法。\n+\n+ * `setStartFromGroupOffsets`（默认方法）：从 Kafka brokers 中的 consumer 组（consumer 属性中的 `group.id` 设置）提交的偏移量中开始读取分区。\n+    如果找不到分区的偏移量，那么将会使用配置中的 `auto.offset.reset` 设置。\n+ * `setStartFromEarliest()` 或者 `setStartFromLatest()`：从最早或者最新的记录开始消费，在这些模式下，Kafka 中的 committed offset 将被忽略，不会用作起始位置。\n+ * `setStartFromTimestamp(long)`：从指定的时间戳开始。对于每个分区，其时间戳大于或等于指定时间戳的记录将用作起始位置。如果一个分区的最新记录早于指定的时间戳，则只从最新记录读取该分区数据。在这种模式下，Kafka 中的已提交 offset 将被忽略，不会用作起始位置。\n+\n+你也可以为每个分区指定 consumer 应该开始消费的具体 offset：\n+\n+{{< tabs \"3fc8a5ad-77df-4ebb-bc02-d954d1eb29a7\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+Map<KafkaTopicPartition, Long> specificStartOffsets = new HashMap<>();\n+specificStartOffsets.put(new KafkaTopicPartition(\"myTopic\", 0), 23L);\n+specificStartOffsets.put(new KafkaTopicPartition(\"myTopic\", 1), 31L);\n+specificStartOffsets.put(new KafkaTopicPartition(\"myTopic\", 2), 43L);\n+\n+myConsumer.setStartFromSpecificOffsets(specificStartOffsets);\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+val specificStartOffsets = new java.util.HashMap[KafkaTopicPartition, java.lang.Long]()\n+specificStartOffsets.put(new KafkaTopicPartition(\"myTopic\", 0), 23L)\n+specificStartOffsets.put(new KafkaTopicPartition(\"myTopic\", 1), 31L)\n+specificStartOffsets.put(new KafkaTopicPartition(\"myTopic\", 2), 43L)\n+\n+myConsumer.setStartFromSpecificOffsets(specificStartOffsets)\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+上面的例子中使用的配置是指定从 `myTopic` 主题的 0 、1 和 2 分区的指定偏移量开始消费。offset 值是 consumer 应该为每个分区读取的下一条消息。请注意：如果 consumer 需要读取在提供的 offset 映射中没有指定 offset 的分区，那么它将回退到该特定分区的默认组偏移行为（即 `setStartFromGroupOffsets()`）。\n+\n+\n+请注意：当 Job 从故障中自动恢复或使用 savepoint 手动恢复时，这些起始位置配置方法不会影响消费的起始位置。在恢复时，每个 Kafka 分区的起始位置由存储在 savepoint 或 checkpoint 中的 offset 确定（有关 checkpointing 的信息，请参阅下一节，以便为 consumer 启用容错功能）。\n+\n+<a name=\"kafka-consumers-and-fault-tolerance\"></a>\n+\n+### Kafka Consumer 和容错\n+\n+伴随着启用 Flink 的 checkpointing 后，Flink Kafka Consumer 将使用 topic 中的记录，并以一致的方式定期检查其所有 Kafka offset 和其他算子的状态。如果 Job 失败，Flink 会将流式程序恢复到最新 checkpoint 的状态，并从存储在 checkpoint 中的 offset 开始重新消费 Kafka 中的消息。\n+\n+因此，设置 checkpoint 的间隔定义了程序在发生故障时最多需要返回多少。\n+\n+为了使 Kafka Consumer 支持容错，需要在 [执行环境]({{< ref \"docs/deployment/config\" >}}#execution-checkpointing-interval) 中启用拓扑的 checkpointing。\n+\n+如果未启用 checkpoint，那么 Kafka consumer 将定期向 Zookeeper 提交 offset。\n+\n+<a name=\"kafka-consumers-topic-and-partition-discovery\"></a>\n+\n+### Kafka Consumer Topic 和分区发现\n+\n+<a name=\"partition-discovery\"></a>\n+\n+#### 分区发现\n+\n+Flink Kafka Consumer 支持发现动态创建的 Kafka 分区，并使用精准一次的语义保证去消耗它们。在初始检索分区元数据之后（即，当 Job 开始运行时）发现的所有分区将从最早可能的 offset 中消费。\n+\n+默认情况下，是禁用了分区发现的。若要启用它，请在提供的属性配置中为 `flink.partition-discovery.interval-millis` 设置大于 0 的值，表示发现分区的间隔是以毫秒为单位的。\n+\n+<a name=\"topic-discovery\"></a>\n+\n+#### Topic 发现\n+\n+在更高的级别上，Flink Kafka Consumer 还能够使用正则表达式基于 Topic 名称的模式匹配来发现 Topic。请看下面的例子：\n+\n+{{< tabs \"46a10932-ea0f-4cba-aa4e-e12930963406\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n+\n+Properties properties = new Properties();\n+properties.setProperty(\"bootstrap.servers\", \"localhost:9092\");\n+properties.setProperty(\"group.id\", \"test\");\n+\n+FlinkKafkaConsumer<String> myConsumer = new FlinkKafkaConsumer<>(\n+    java.util.regex.Pattern.compile(\"test-topic-[0-9]\"),\n+    new SimpleStringSchema(),\n+    properties);\n+\n+DataStream<String> stream = env.addSource(myConsumer);\n+...\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+val env = StreamExecutionEnvironment.getExecutionEnvironment()\n+\n+val properties = new Properties()\n+properties.setProperty(\"bootstrap.servers\", \"localhost:9092\")\n+properties.setProperty(\"group.id\", \"test\")\n+\n+val myConsumer = new FlinkKafkaConsumer[String](\n+  java.util.regex.Pattern.compile(\"test-topic-[0-9]\"),\n+  new SimpleStringSchema,\n+  properties)\n+\n+val stream = env.addSource(myConsumer)\n+...\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+在上面的例子中，当 Job 开始运行时，Consumer 将订阅名称与指定正则表达式匹配的所有主题（以 `test-topic` 开头并以单个数字结尾）。\n+\n+要允许 consumer 在作业开始运行后发现动态创建的主题，那么请为 `flink.partition-discovery.interval-millis` 设置非负值。这允许 consumer 发现名称与指定模式匹配的新主题的分区。\n+\n+<a name=\"kafka-consumers-offset-committing-behaviour-configuration\"></a>\n+\n+### Kafka Consumer 提交 Offset 的行为配置\n+\n+Flink Kafka Consumer 允许有配置如何将 offset 提交回 Kafka broker 的行为。请注意：Flink Kafka Consumer 不依赖于提交的 offset 来实现容错保证。提交的 offset 只是一种方法，用于公开 consumer 的进度以便进行监控。\n+\n+配置 offset 提交行为的方法是否相同，取决于是否为 job 启用了 checkpointing。\n+\n+ - *禁用 Checkpointing：* 如果禁用了 checkpointing，则 Flink Kafka Consumer 依赖于内部使用的 Kafka client 自动定期 offset 提交功能。\n+ 因此，要禁用或启用 offset 的提交，只需将 `enable.auto.commit` 或者 `auto.commit.interval.ms` 的Key 值设置为提供的 `Properties` 配置中的适当值。\n+\n+ - *启用 Checkpointing：* 如果启用了 checkpointing，那么当 checkpointing 完成时，Flink Kafka Consumer 将提交的 offset 存储在 checkpoint 状态中。\n+ 这确保 Kafka broker 中提交的 offset 与 checkpoint 状态中的 offset 一致。\n+ 用户可以通过调用 consumer 上的 `setCommitOffsetsOnCheckpoints(boolean)` 方法来禁用或启用 offset 的提交(默认情况下，这个值是 true )。\n+ 注意，在这个场景中，`Properties` 中的自动定期 offset 提交设置会被完全忽略。\n+\n+<a name=\"kafka-consumers-and-timestamp-extractionwatermark-emission\"></a>\n+\n+### Kafka Consumer 和 时间戳抽取以及 watermark 发送\n+\n+在许多场景中，记录的时间戳是(显式或隐式)嵌入到记录本身中。此外，用户可能希望定期或以不规则的方式 Watermark，例如基于 Kafka 流中包含当前事件时间的 watermark 的特殊记录。对于这些情况，Flink Kafka Consumer 允许指定 `AssignerWithPeriodicWatermarks` 或 `AssignerWithPunctuatedWatermarks`。\n+\n+你可以按照[此处]({{< ref \"docs/dev/datastream/event-time/generating_watermarks\" >}}})的说明指定自定义时间戳抽取器或者 Watermark 发送器，或者使用 [内置的]({{< ref \"docs/dev/datastream/event-time/built_in\" >}})。你也可以通过以下方式将其传递给你的 consumer：\n+\n+{{< tabs \"c706ebfc-5d9b-49b2-8899-f3ac259a55cc\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+Properties properties = new Properties();\n+properties.setProperty(\"bootstrap.servers\", \"localhost:9092\");\n+properties.setProperty(\"group.id\", \"test\");\n+\n+FlinkKafkaConsumer<String> myConsumer =\n+    new FlinkKafkaConsumer<>(\"topic\", new SimpleStringSchema(), properties);\n+myConsumer.assignTimestampsAndWatermarks(\n+    WatermarkStrategy.\n+        .forBoundedOutOfOrderness(Duration.ofSeconds(20)));\n+\n+DataStream<String> stream = env.addSource(myConsumer);\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+val properties = new Properties()\n+properties.setProperty(\"bootstrap.servers\", \"localhost:9092\")\n+properties.setProperty(\"group.id\", \"test\")\n+\n+val myConsumer =\n+    new FlinkKafkaConsumer(\"topic\", new SimpleStringSchema(), properties);\n+myConsumer.assignTimestampsAndWatermarks(\n+    WatermarkStrategy.\n+        .forBoundedOutOfOrderness(Duration.ofSeconds(20)))\n+\n+val stream = env.addSource(myConsumer)\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+**请注意**：如果 watermark assigner 依赖于从 Kafka 读取的消息来上涨其 watermark （通常就是这种情况），那么所有主题和分区都需要有连续的消息流。否则，整个应用程序的 watermark 将无法上涨，所有基于时间的算子（例如时间窗口或带有计时器的函数）也无法运行。单个的 Kafka 分区也会导致这种反应。考虑设置适当的 [idelness timeouts]({{< ref \"docs/dev/datastream/event-time/generating_watermarks\" >}}#dealing-with-idle-sources) 来缓解这个问题。\n+\n+<a name=\"kafka-producer\"></a>\n+\n+## Kafka Producer\n+\n+Flink Kafka Producer 被称为 `FlinkKafkaProducer`。它允许将消息流写入一个或多个 Kafka topic。\n+\n+构造器接收下列参数：\n+\n+1. 事件被写入的默认输出 topic\n+2. 序列化数据写入 Kafka 的 SerializationSchema / KafkaSerializationSchema\n+3. Kafka client 的 Properties。下列 property 是必须的：\n+\t* “bootstrap.servers” （逗号分隔 Kafka broker 列表）\n+4. 容错语义\n+\n+{{< tabs \"f6c1b77e-6b17-4fd3-837a-c9257e6c7c00\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+DataStream<String> stream = ...;\n+\n+Properties properties = new Properties();\n+properties.setProperty(\"bootstrap.servers\", \"localhost:9092\");\n+\n+FlinkKafkaProducer<String> myProducer = new FlinkKafkaProducer<String>(\n+        \"my-topic\",                  // 目标 topic\n+        new SimpleStringSchema()     // 序列化 schema\n+        properties,                  // producer 配置\n+        FlinkKafkaProducer.Semantic.EXACTLY_ONCE); // 容错\n+\n+stream.addSink(myProducer);\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+val stream: DataStream[String] = ...\n+\n+val properties = new Properties\n+properties.setProperty(\"bootstrap.servers\", \"localhost:9092\")\n+\n+val myProducer = new FlinkKafkaProducer[String](\n+        \"my-topic\",               // 目标 topic\n+        new SimpleStringSchema(), // 序列化 schema\n+        properties,               // producer 配置\n+        FlinkKafkaProducer.Semantic.EXACTLY_ONCE) // 容错\n+\n+stream.addSink(myProducer)\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+<a name=\"the-serializationschema\"></a>\n+\n+## `SerializationSchema`\n+\n+Flink Kafka Producer 需要知道如何将 Java/Scala 对象转化为二进制数据。\n+\n+`KafkaSerializationSchema` 允许用户指定这样的 schema。它会为每个记录调用 `ProducerRecord<byte[], byte[]> serialize(T element, @Nullable Long timestamp)` 方法，产生一个写入到 Kafka 的 `ProducerRecord`。\n+\n+用户可以对如何将数据写到 Kafka 进行细粒度的控制。你可以通过 producer record：\n+\n+* 设置 header 值\n+* 为每个 record 定义 key\n+* 指定数据的自定义分区\n+\n+<a name=\"kafka-producers-and-fault-tolerance\"></a>\n+\n+### Kafka Producer 和容错\n+\n+启用 Flink 的 checkpointing 后，`FlinkKafkaProducer` 可以提供精确一次的语义保证。\n+\n+除了启用 Flink 的 checkpointing，你也可以通过将适当的 `semantic` 参数传递给 `FlinkKafkaProducer` 来选择三种不同的操作模式：\n+\n+* `Semantic.NONE`：Flink 不会有任何语义的保证，产生的记录可能会丢失或重复。\n+* `Semantic.AT_LEAST_ONCE`（默认设置）：可以保证不会丢失任何记录（但是记录可能会重复）\n+* `Semantic.EXACTLY_ONCE`：使用 Kafka 事务提供精确一次语义。无论何时，在使用事务写入 Kafka 时，都要记得为所有消费 Kafka 消息的应用程序设置所需的 `isolation.level`（`read_committed` 或 `read_uncommitted` - 后者是默认值）。\n+\n+<a name=\"caveats\"></a>\n+\n+##### 注意事项\n+\n+`Semantic.EXACTLY_ONCE` 模式依赖于事务提交的能力。事务提交发生于触发 checkpoint 之前，以及从 checkpoint 恢复之后。如果从 Flink 应用程序崩溃到完全重启的时间超过了 Kafka 的事务超时时间，那么将会有数据丢失（Kafka 会自动丢弃超出超时时间的事务）。考虑到这一点，请根据预期的宕机时间来合理地配置事务超时时间。\n+\n+默认情况下，Kafka broker 将 `transaction.max.timeout.ms` 设置为 15 分钟。此属性不允许为大于其值的 producer 设置事务超时时间。\n+默认情况下，`FlinkKafkaProducer` 将 producer config 中的 `transaction.timeout.ms` 属性设置为 1 小时，因此在使用 `Semantic.EXACTLY_ONCE` 模式之前应该增加 `transaction.max.timeout.ms` 的值。\n+\n+在 `KafkaConsumer` 的 `read_committed` 模式中，任何未结束（既未中止也未完成）的事务将阻塞来自给定 Kafka topic 的未结束事务之后的所有读取数据。\n+换句话说，在遵循如下一系列事件之后：\n+\n+1. 用户启动了 `transaction1` 并使用它写了一些记录\n+2. 用户启动了 `transaction2` 并使用它编写了一些其他记录\n+3. 用户提交了 `transaction2`\n+\n+即使 `transaction2` 中的记录已提交，在提交或中止 `transaction1` 之前，消费者也不会看到这些记录。这有 2 层含义：\n+\n+ * 首先，在 Flink 应用程序的正常工作期间，用户可以预料 Kafka 主题中生成的记录的可见性会延迟，相当于已完成 checkpoint 之间的平均时间。\n+ * 其次，在 Flink 应用程序失败的情况下，此应用程序正在写入的供消费者读取的主题将被阻塞，直到应用程序重新启动或配置的事务超时时间过去后，才恢复正常。此标注仅适用于有多个 agent 或者应用程序写入同一 Kafka 主题的情况。\n+\n+**注意**：`Semantic.EXACTLY_ONCE` 模式为每个 `FlinkKafkaProducer` 实例使用固定大小的 KafkaProducer 池。每个 checkpoint 使用其中一个 producer。如果并发 checkpoint 的数量超过池的大小，`FlinkKafkaProducer` 将抛出异常，并导致整个应用程序失败。请合理地配置最大池大小和最大并发 checkpoint 数量。\n+\n+**注意**：`Semantic.EXACTLY_ONCE` 会尽一切可能不留下任何逗留的事务，否则会阻塞其他消费者从这个 Kafka topic 中读取数据。但是，如果 Flink 应用程序在第一次 checkpoint 之前就失败了，那么在重新启动此类应用程序后，系统中不会有先前池大小（pool size）相关的信息。因此，在第一次 checkpoint 完成前对 Flink 应用程序进行缩容，且并发数缩容倍数大于安全系数 `FlinkKafkaProducer.SAFE_SCALE_DOWN_FACTOR` 的值的话，是不安全的。\n+\n+<a name=\"kafka-connector-metrics\"></a>\n+\n+## Kafka 连接器指标\n+\n+Flink 的 Kafka 连接器通过 Flink 的 [metric 系统]({{< ref \"docs/ops/metrics\" >}}) 提供一些指标来分析 Kafka Connector 的状况。Producer 通过 Flink 的 metrics 系统为所有支持的版本导出 Kafka 的内部指标。consumer 从 Kafka 0.10 版本开始导出所有指标。Kafka 在其[文档](http://kafka.apache.org/documentation/#selector_monitoring)中列出了所有导出的指标。\n+\n+除了这些指标之外，所有 consumer 都暴露了每个主题分区的 `current-offsets` 和 `committed-offsets`。`current-offsets` 是指分区中的当前偏移量。指的是我们成功检索和发出的最后一个元素的偏移量。`committed-offsets` 是最后提交的偏移量。这为用户提供了 at-least-once 语义，用于提交给 Zookeeper 或 broker 的偏移量。对于 Flink 的偏移检查点，系统提供精准一次语义。\n+\n+提交给 ZK 或 broker 的偏移量也可以用来跟踪 Kafka consumer 的读取进度。每个分区中提交的偏移量和最近偏移量之间的差异称为 *consumer lag*。如果 Flink 拓扑消耗来自 topic 的数据的速度比添加新数据的速度慢，那么延迟将会增加，consumer 将会滞后。对于大型生产部署，我们建议监视该指标，以避免增加延迟。\n+\n+<a name=\"enabling-kerberos-authentication\"></a>\n+\n+## 启用 Kerberos 身份验证\n+\n+Flink 通过 Kafka 连接器提供了一流的支持，可以对 Kerberos 配置的 Kafka 安装进行身份验证。只需在 `flink-conf.yaml` 中配置 Flink。像这样为 Kafka 启用 Kerberos 身份验证：\n+\n+1. 通过设置以下内容配置 Kerberos 票据 \n+ - `security.kerberos.login.use-ticket-cache`：默认情况下，这个值是 `true`，Flink 将尝试在 `kinit` 管理的票据缓存中使用 Kerberos 票据。注意！在 YARN 上部署的 Flink  jobs 中使用 Kafka 连接器时，使用票据缓存的 Kerberos 授权将不起作用。使用 Mesos 进行部署时也是如此，因为 Mesos 部署不支持使用票据缓存进行授权。\n+ - `security.kerberos.login.keytab` 和 `security.kerberos.login.principal`：要使用 Kerberos keytabs，需为这两个属性设置值。\n+\n+2. 将 `KafkaClient` 追加到 `security.kerberos.login.contexts`：这告诉 Flink 将配置的 Kerberos 票据提供给 Kafka 登录上下文以用于 Kafka 身份验证。\n+\n+一旦启用了基于 Kerberos 的 Flink 安全性后，只需在提供的属性配置中包含以下两个设置（通过传递给内部 Kafka 客户端），即可使用 Flink Kafka Consumer 或 Producer 向 Kafk a进行身份验证：\n+\n+- 将 `security.protocol` 设置为 `SASL_PLAINTEXT`（默认为 `NONE`）：用于与 Kafka broker 进行通信的协议。使用独立 Flink 部署时，也可以使用 `SASL_SSL`；请在[此处](https://kafka.apache.org/documentation/#security_configclients)查看如何为 SSL 配置 Kafka 客户端。\n+- 将 `sasl.kerberos.service.name` 设置为 `kafka`（默认为 `kafka`）：此值应与用于 Kafka broker 配置的 `sasl.kerberos.service.name` 相匹配。客户端和服务器配置之间的服务名称不匹配将导致身份验证失败。\n+\n+有关 Kerberos 安全性 Flink 配置的更多信息，请参见[这里]({{< ref \"docs/deployment/config\" >}}})。你也可以在[这里]({{< ref \"docs/deployment/security/security-kerberos\" >}})进一步了解 Flink 如何在内部设置基于 kerberos 的安全性。\n+\n+<a name=\"upgrading-to-the-latest-connector-version\"></a>\n+\n+## 升级到最近的连接器版本\n+\n+通用的升级步骤概述见 [升级 Jobs 和 Flink 版本指南]({{< ref \"docs/ops/upgrading\" >}})。对于 Kafka，你还需要遵循这些步骤：\n+\n+* 不要同时升级 Flink 和 Kafka 连接器\n+* 确保你对 Consumer 设置了 `group.id`\n+* 在 Consumer 上设置 `setCommitOffsetsOnCheckpoints(true)`，以便读 offset 提交到 Kafka。务必在停止和恢复 savepoint 前执行此操作。你可能需要在旧的连接器版本上进行停止/重启循环来启用此设置。\n+* 在 Consumer 上设置 `setStartFromGroupOffsets(true)`，以便我们从 Kafka 获取读 offset。这只会在 Flink 状态中没有读 offset 时生效，这也是为什么下一步非要重要的原因。\n+* 修改 source/sink 分配到的 `uid`。这会确保新的 source/sink 不会从旧的 sink/source 算子中读取状态。\n+* 使用 `--allow-non-restored-state` 参数启动新 job，因为我们在 savepoint 中仍然有先前连接器版本的状态。\n+\n+<a name=\"troubleshooting\"></a>\n+\n+## 问题排查\n+\n+<div class=\"alert alert-warning\">\n+如果你在使用 Flink 时对 Kafka 有问题，请记住，Flink 只封装 <a href=\"https://kafka.apache.org/documentation/#consumerapi\">KafkaConsumer</a> 或 <a href=\"https://kafka.apache.org/documentation/#producerapi\">KafkaProducer</a>，你的问题可能独立于 Flink，有时可以通过升级 Kafka broker 程序、重新配置 Kafka broker 程序或在 Flink 中重新配置 <tt>KafkaConsumer</tt> 或 <tt>KafkaProducer</tt> 来解决。下面列出了一些常见问题的示例。\n+</div>\n+\n+<a name=\"data-loss\"></a>\n+\n+### 数据丢失\n+\n+根据你的 Kafka 配置，即使在 Kafka 确认写入后，你仍然可能会遇到数据丢失。特别要记住在 Kafka 的配置中设置以下属性：\n+\n+- `acks`\n+- `log.flush.interval.messages`\n+- `log.flush.interval.ms`\n+- `log.flush.*`\n+\n+上述选项的默认值是很容易导致数据丢失的。请参考 Kafka 文档以获得更多的解释。\n+\n+<a name=\"unknowntopicorpartitionexception\"></a>\n+\n+### UnknownTopicOrPartitionException\n+\n+导致此错误的一个可能原因是正在进行新的 leader 选举，例如在重新启动 Kafka broker 之后或期间。这是一个可重试的异常，因此 Flink job 应该能够重启并恢复正常运行。也可以通过更改 producer 设置中的 `retries` 属性来规避。但是，这可能会导致重新排序消息，反过来可以通过将 `max.in.flight.requests.per.connection` 设置为 1 来避免不需要的消息。\n+\n+{{< top >}}"
        },
        {
            "sha": "42f1455405f13dfb026dcfad2ec8f1e9b1e139b1",
            "filename": "docs/content.zh/docs/connectors/datastream/kinesis.md",
            "status": "added",
            "additions": 667,
            "deletions": 0,
            "changes": 667,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/datastream/kinesis.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/datastream/kinesis.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/datastream/kinesis.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,667 @@\n+---\n+title: Kinesis\n+weight: 4\n+type: docs\n+aliases:\n+  - /zh/dev/connectors/kinesis.html\n+  - /zh/apis/streaming/connectors/kinesis.html\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Amazon Kinesis Data Streams Connector\n+\n+The Kinesis connector provides access to [Amazon AWS Kinesis Streams](http://aws.amazon.com/kinesis/streams/).\n+\n+To use the connector, add the following Maven dependency to your project:\n+\n+{{< artifact flink-connector-kinesis withScalaVersion >}}\n+\n+{{< hint warning >}}\n+**Attention** Prior to Flink version 1.10.0 the `flink-connector-kinesis{{< scala_version >}}` has a dependency on code licensed under the [Amazon Software License](https://aws.amazon.com/asl/).\n+Linking to the prior versions of flink-connector-kinesis will include this code into your application.\n+{{< /hint >}}\n+\n+Due to the licensing issue, the `flink-connector-kinesis{{< scala_version >}}` artifact is not deployed to Maven central for the prior versions. Please see the version specific documentation for further information.\n+\n+## Using the Amazon Kinesis Streams Service\n+Follow the instructions from the [Amazon Kinesis Streams Developer Guide](https://docs.aws.amazon.com/streams/latest/dev/learning-kinesis-module-one-create-stream.html)\n+to setup Kinesis streams.\n+\n+## Configuring Access to Kinesis with IAM\n+Make sure to create the appropriate IAM policy to allow reading / writing to / from the Kinesis streams. See examples [here](https://docs.aws.amazon.com/streams/latest/dev/controlling-access.html).\n+\n+Depending on your deployment you would choose a different Credentials Provider to allow access to Kinesis.\n+By default, the `AUTO` Credentials Provider is used.\n+If the access key ID and secret key are set in the configuration, the `BASIC` provider is used.  \n+\n+A specific Credentials Provider can **optionally** be set by using the `AWSConfigConstants.AWS_CREDENTIALS_PROVIDER` setting.\n+ \n+Supported Credential Providers are:\n+* `AUTO` - Using the default AWS Credentials Provider chain that searches for credentials in the following order: `ENV_VARS`, `SYS_PROPS`, `WEB_IDENTITY_TOKEN`, `PROFILE` and EC2/ECS credentials provider.\n+* `BASIC` - Using access key ID and secret key supplied as configuration. \n+* `ENV_VAR` - Using `AWS_ACCESS_KEY_ID` & `AWS_SECRET_ACCESS_KEY` environment variables.\n+* `SYS_PROP` - Using Java system properties aws.accessKeyId and aws.secretKey.\n+* `PROFILE` - Use AWS credentials profile file to create the AWS credentials.\n+* `ASSUME_ROLE` - Create AWS credentials by assuming a role. The credentials for assuming the role must be supplied.\n+* `WEB_IDENTITY_TOKEN` - Create AWS credentials by assuming a role using Web Identity Token. \n+\n+## Kinesis Consumer\n+\n+The `FlinkKinesisConsumer` is an exactly-once parallel streaming data source that subscribes to multiple AWS Kinesis\n+streams within the same AWS service region, and can transparently handle resharding of streams while the job is running. Each subtask of the consumer is\n+responsible for fetching data records from multiple Kinesis shards. The number of shards fetched by each subtask will\n+change as shards are closed and created by Kinesis.\n+\n+Before consuming data from Kinesis streams, make sure that all streams are created with the status \"ACTIVE\" in the AWS dashboard.\n+\n+{{< tabs \"58b6c235-48ee-4cf7-aabc-41e0679a3370\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+Properties consumerConfig = new Properties();\n+consumerConfig.put(AWSConfigConstants.AWS_REGION, \"us-east-1\");\n+consumerConfig.put(AWSConfigConstants.AWS_ACCESS_KEY_ID, \"aws_access_key_id\");\n+consumerConfig.put(AWSConfigConstants.AWS_SECRET_ACCESS_KEY, \"aws_secret_access_key\");\n+consumerConfig.put(ConsumerConfigConstants.STREAM_INITIAL_POSITION, \"LATEST\");\n+\n+StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n+\n+DataStream<String> kinesis = env.addSource(new FlinkKinesisConsumer<>(\n+    \"kinesis_stream_name\", new SimpleStringSchema(), consumerConfig));\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+val consumerConfig = new Properties()\n+consumerConfig.put(AWSConfigConstants.AWS_REGION, \"us-east-1\")\n+consumerConfig.put(AWSConfigConstants.AWS_ACCESS_KEY_ID, \"aws_access_key_id\")\n+consumerConfig.put(AWSConfigConstants.AWS_SECRET_ACCESS_KEY, \"aws_secret_access_key\")\n+consumerConfig.put(ConsumerConfigConstants.STREAM_INITIAL_POSITION, \"LATEST\")\n+\n+val env = StreamExecutionEnvironment.getExecutionEnvironment\n+\n+val kinesis = env.addSource(new FlinkKinesisConsumer[String](\n+    \"kinesis_stream_name\", new SimpleStringSchema, consumerConfig))\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+The above is a simple example of using the consumer. Configuration for the consumer is supplied with a `java.util.Properties`\n+instance, the configuration keys for which can be found in `AWSConfigConstants` (AWS-specific parameters) and \n+`ConsumerConfigConstants` (Kinesis consumer parameters). The example\n+demonstrates consuming a single Kinesis stream in the AWS region \"us-east-1\". The AWS credentials are supplied using the basic method in which\n+the AWS access key ID and secret access key are directly supplied in the configuration. Also, data is being consumed\n+from the newest position in the Kinesis stream (the other option will be setting `ConsumerConfigConstants.STREAM_INITIAL_POSITION`\n+to `TRIM_HORIZON`, which lets the consumer start reading the Kinesis stream from the earliest record possible).\n+\n+Other optional configuration keys for the consumer can be found in `ConsumerConfigConstants`.\n+\n+Note that the configured parallelism of the Flink Kinesis Consumer source\n+can be completely independent of the total number of shards in the Kinesis streams.\n+When the number of shards is larger than the parallelism of the consumer,\n+then each consumer subtask can subscribe to multiple shards; otherwise\n+if the number of shards is smaller than the parallelism of the consumer,\n+then some consumer subtasks will simply be idle and wait until it gets assigned\n+new shards (i.e., when the streams are resharded to increase the\n+number of shards for higher provisioned Kinesis service throughput).\n+\n+Also note that the assignment of shards to subtasks may not be optimal when\n+shard IDs are not consecutive (as result of dynamic re-sharding in Kinesis).\n+For cases where skew in the assignment leads to significant imbalanced consumption,\n+a custom implementation of `KinesisShardAssigner` can be set on the consumer.\n+\n+### Configuring Starting Position\n+\n+The Flink Kinesis Consumer currently provides the following options to configure where to start reading Kinesis streams, simply by setting `ConsumerConfigConstants.STREAM_INITIAL_POSITION` to\n+one of the following values in the provided configuration properties (the naming of the options identically follows [the namings used by the AWS Kinesis Streams service](http://docs.aws.amazon.com/kinesis/latest/APIReference/API_GetShardIterator.html#API_GetShardIterator_RequestSyntax)):\n+\n+- `LATEST`: read all shards of all streams starting from the latest record.\n+- `TRIM_HORIZON`: read all shards of all streams starting from the earliest record possible (data may be trimmed by Kinesis depending on the retention settings).\n+- `AT_TIMESTAMP`: read all shards of all streams starting from a specified timestamp. The timestamp must also be specified in the configuration\n+properties by providing a value for `ConsumerConfigConstants.STREAM_INITIAL_TIMESTAMP`, in one of the following date pattern :\n+    - a non-negative double value representing the number of seconds that has elapsed since the Unix epoch (for example, `1459799926.480`).\n+    - a user defined pattern, which is a valid pattern for `SimpleDateFormat` provided by `ConsumerConfigConstants.STREAM_TIMESTAMP_DATE_FORMAT`.\n+    If `ConsumerConfigConstants.STREAM_TIMESTAMP_DATE_FORMAT` is not defined then the default pattern will be `yyyy-MM-dd'T'HH:mm:ss.SSSXXX`\n+    (for example, timestamp value is `2016-04-04` and pattern is `yyyy-MM-dd` given by user or timestamp value is `2016-04-04T19:58:46.480-00:00` without given a pattern).\n+\n+### Fault Tolerance for Exactly-Once User-Defined State Update Semantics\n+\n+With Flink's checkpointing enabled, the Flink Kinesis Consumer will consume records from shards in Kinesis streams and\n+periodically checkpoint each shard's progress. In case of a job failure, Flink will restore the streaming program to the\n+state of the latest complete checkpoint and re-consume the records from Kinesis shards, starting from the progress that\n+was stored in the checkpoint.\n+\n+The interval of drawing checkpoints therefore defines how much the program may have to go back at most, in case of a failure.\n+\n+To use fault tolerant Kinesis Consumers, checkpointing of the topology needs to be enabled at the execution environment:\n+\n+{{< tabs \"b1399ed7-5855-446d-9684-7a49de9b4c97\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n+env.enableCheckpointing(5000); // checkpoint every 5000 msecs\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+val env = StreamExecutionEnvironment.getExecutionEnvironment()\n+env.enableCheckpointing(5000) // checkpoint every 5000 msecs\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+Also note that Flink can only restart the topology if enough processing slots are available to restart the topology.\n+Therefore, if the topology fails due to loss of a TaskManager, there must still be enough slots available afterwards.\n+Flink on YARN supports automatic restart of lost YARN containers.\n+\n+### Using Enhanced Fan-Out\n+\n+[Enhanced Fan-Out (EFO)](https://aws.amazon.com/blogs/aws/kds-enhanced-fanout/) increases the maximum \n+number of concurrent consumers per Kinesis stream.\n+Without EFO, all concurrent consumers share a single read quota per shard. \n+Using EFO, each consumer gets a distinct dedicated read quota per shard, allowing read throughput to scale with the number of consumers. \n+Using EFO will [incur additional cost](https://aws.amazon.com/kinesis/data-streams/pricing/).\n+ \n+In order to enable EFO two additional configuration parameters are required:\n+\n+- `RECORD_PUBLISHER_TYPE`: Determines whether to use `EFO` or `POLLING`. The default `RecordPublisher` is `POLLING`.\n+- `EFO_CONSUMER_NAME`: A name to identify the consumer. \n+For a given Kinesis data stream, each consumer must have a unique name. \n+However, consumer names do not have to be unique across data streams. \n+Reusing a consumer name will result in existing subscriptions being terminated.\n+\n+The code snippet below shows a simple example configurating an EFO consumer.\n+\n+{{< tabs \"42345893-70c3-4678-a348-4c419b337eb1\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+Properties consumerConfig = new Properties();\n+consumerConfig.put(AWSConfigConstants.AWS_REGION, \"us-east-1\");\n+consumerConfig.put(ConsumerConfigConstants.STREAM_INITIAL_POSITION, \"LATEST\");\n+\n+consumerConfig.put(ConsumerConfigConstants.RECORD_PUBLISHER_TYPE, \n+    ConsumerConfigConstants.RecordPublisherType.EFO.name());\n+consumerConfig.put(ConsumerConfigConstants.EFO_CONSUMER_NAME, \"my-flink-efo-consumer\");\n+\n+StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n+\n+DataStream<String> kinesis = env.addSource(new FlinkKinesisConsumer<>(\n+    \"kinesis_stream_name\", new SimpleStringSchema(), consumerConfig));\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+val consumerConfig = new Properties()\n+consumerConfig.put(AWSConfigConstants.AWS_REGION, \"us-east-1\")\n+consumerConfig.put(ConsumerConfigConstants.STREAM_INITIAL_POSITION, \"LATEST\")\n+\n+consumerConfig.put(ConsumerConfigConstants.RECORD_PUBLISHER_TYPE, \n+    ConsumerConfigConstants.RecordPublisherType.EFO.name());\n+consumerConfig.put(ConsumerConfigConstants.EFO_CONSUMER_NAME, \"my-flink-efo-consumer\");\n+\n+val env = StreamExecutionEnvironment.getExecutionEnvironment()\n+\n+val kinesis = env.addSource(new FlinkKinesisConsumer[String](\n+    \"kinesis_stream_name\", new SimpleStringSchema, consumerConfig))\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+#### EFO Stream Consumer Registration/Deregistration\n+\n+In order to use EFO, a stream consumer must be registered against each stream you wish to consume.\n+By default, the `FlinkKinesisConsumer` will register the stream consumer automatically when the Flink job starts.\n+The stream consumer will be registered using the name provided by the `EFO_CONSUMER_NAME` configuration.\n+`FlinkKinesisConsumer` provides three registration strategies:\n+\n+- Registration\n+  - `LAZY` (default): Stream consumers are registered when the Flink job starts running.\n+    If the stream consumer already exists, it will be reused.\n+    This is the preferred strategy for the majority of applications.\n+    However, jobs with parallelism greater than 1 will result in tasks competing to register and acquire the stream consumer ARN.\n+    For jobs with very large parallelism this can result in an increased start-up time.\n+    The describe operation has a limit of 20 [transactions per second](https://docs.aws.amazon.com/kinesis/latest/APIReference/API_DescribeStreamConsumer.html),\n+    this means application startup time will increase by roughly `parallelism/20 seconds`.\n+  - `EAGER`: Stream consumers are registered in the `FlinkKinesisConsumer` constructor.\n+    If the stream consumer already exists, it will be reused. \n+    This will result in registration occurring when the job is constructed, \n+    either on the Flink Job Manager or client environment submitting the job.\n+    Using this strategy results in a single thread registering and retrieving the stream consumer ARN, \n+    reducing startup time over `LAZY` (with large parallelism).\n+    However, consider that the client environment will require access to the AWS services.\n+  - `NONE`: Stream consumer registration is not performed by `FlinkKinesisConsumer`.\n+    Registration must be performed externally using the [AWS CLI or SDK](https://aws.amazon.com/tools/)\n+    to invoke [RegisterStreamConsumer](https://docs.aws.amazon.com/kinesis/latest/APIReference/API_RegisterStreamConsumer.html).\n+    Stream consumer ARNs should be provided to the job via the consumer configuration.\n+- Deregistration\n+  - `LAZY|EAGER` (default): Stream consumers are deregistered when the job is shutdown gracefully.\n+    In the event that a job terminates within executing the shutdown hooks, stream consumers will remain active.\n+    In this situation the stream consumers will be gracefully reused when the application restarts. \n+  - `NONE`: Stream consumer deregistration is not performed by `FlinkKinesisConsumer`.\n+\n+Below is an example configuration to use the `EAGER` registration strategy:\n+\n+{{< tabs \"a85d716b-6c1c-46d8-9ee4-12d8380a0c06\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+Properties consumerConfig = new Properties();\n+consumerConfig.put(AWSConfigConstants.AWS_REGION, \"us-east-1\");\n+consumerConfig.put(ConsumerConfigConstants.STREAM_INITIAL_POSITION, \"LATEST\");\n+\n+consumerConfig.put(ConsumerConfigConstants.RECORD_PUBLISHER_TYPE, \n+    ConsumerConfigConstants.RecordPublisherType.EFO.name());\n+consumerConfig.put(ConsumerConfigConstants.EFO_CONSUMER_NAME, \"my-flink-efo-consumer\");\n+\n+consumerConfig.put(ConsumerConfigConstants.EFO_REGISTRATION_TYPE, \n+    ConsumerConfigConstants.EFORegistrationType.EAGER.name());\n+\n+StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n+\n+DataStream<String> kinesis = env.addSource(new FlinkKinesisConsumer<>(\n+    \"kinesis_stream_name\", new SimpleStringSchema(), consumerConfig));\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+val consumerConfig = new Properties()\n+consumerConfig.put(AWSConfigConstants.AWS_REGION, \"us-east-1\")\n+consumerConfig.put(ConsumerConfigConstants.STREAM_INITIAL_POSITION, \"LATEST\")\n+\n+consumerConfig.put(ConsumerConfigConstants.RECORD_PUBLISHER_TYPE, \n+    ConsumerConfigConstants.RecordPublisherType.EFO.name());\n+consumerConfig.put(ConsumerConfigConstants.EFO_CONSUMER_NAME, \"my-flink-efo-consumer\");\n+\n+consumerConfig.put(ConsumerConfigConstants.EFO_REGISTRATION_TYPE, \n+    ConsumerConfigConstants.EFORegistrationType.EAGER.name());\n+\n+val env = StreamExecutionEnvironment.getExecutionEnvironment()\n+\n+val kinesis = env.addSource(new FlinkKinesisConsumer[String](\n+    \"kinesis_stream_name\", new SimpleStringSchema, consumerConfig))\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+Below is an example configuration to use the `NONE` registration strategy:\n+\n+{{< tabs \"00b46c87-7740-4263-8040-2aa7e2960513\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+Properties consumerConfig = new Properties();\n+consumerConfig.put(AWSConfigConstants.AWS_REGION, \"us-east-1\");\n+consumerConfig.put(ConsumerConfigConstants.STREAM_INITIAL_POSITION, \"LATEST\");\n+\n+consumerConfig.put(ConsumerConfigConstants.RECORD_PUBLISHER_TYPE, \n+    ConsumerConfigConstants.RecordPublisherType.EFO.name());\n+consumerConfig.put(ConsumerConfigConstants.EFO_CONSUMER_NAME, \"my-flink-efo-consumer\");\n+\n+consumerConfig.put(ConsumerConfigConstants.EFO_REGISTRATION_TYPE, \n+    ConsumerConfigConstants.EFORegistrationType.NONE.name());\n+consumerConfig.put(ConsumerConfigConstants.efoConsumerArn(\"stream-name\"), \n+    \"arn:aws:kinesis:<region>:<account>>:stream/<stream-name>/consumer/<consumer-name>:<create-timestamp>\");\n+\n+StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n+\n+DataStream<String> kinesis = env.addSource(new FlinkKinesisConsumer<>(\n+    \"kinesis_stream_name\", new SimpleStringSchema(), consumerConfig));\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+val consumerConfig = new Properties()\n+consumerConfig.put(AWSConfigConstants.AWS_REGION, \"us-east-1\")\n+consumerConfig.put(ConsumerConfigConstants.STREAM_INITIAL_POSITION, \"LATEST\")\n+\n+consumerConfig.put(ConsumerConfigConstants.RECORD_PUBLISHER_TYPE, \n+    ConsumerConfigConstants.RecordPublisherType.EFO.name());\n+consumerConfig.put(ConsumerConfigConstants.EFO_CONSUMER_NAME, \"my-flink-efo-consumer\");\n+\n+consumerConfig.put(ConsumerConfigConstants.EFO_REGISTRATION_TYPE, \n+    ConsumerConfigConstants.EFORegistrationType.NONE.name());\n+consumerConfig.put(ConsumerConfigConstants.efoConsumerArn(\"stream-name\"), \n+    \"arn:aws:kinesis:<region>:<account>>:stream/<stream-name>/consumer/<consumer-name>:<create-timestamp>\");\n+\n+val env = StreamExecutionEnvironment.getExecutionEnvironment()\n+\n+val kinesis = env.addSource(new FlinkKinesisConsumer[String](\n+    \"kinesis_stream_name\", new SimpleStringSchema, consumerConfig))\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+### Event Time for Consumed Records\n+\n+If streaming topologies choose to use the [event time notion]({{< ref \"docs/concepts/time\" >}}) for record\n+timestamps, an *approximate arrival timestamp* will be used by default. This timestamp is attached to records by Kinesis once they\n+were successfully received and stored by streams. Note that this timestamp is typically referred to as a Kinesis server-side\n+timestamp, and there are no guarantees about the accuracy or order correctness (i.e., the timestamps may not always be\n+ascending).\n+\n+Users can choose to override this default with a custom timestamp, as described [here]({{< ref \"docs/dev/datastream/event-time/generating_watermarks\" >}}),\n+or use one from the [predefined ones]({{< ref \"docs/dev/datastream/event-time/built_in\" >}}). After doing so,\n+it can be passed to the consumer in the following way:\n+\n+{{< tabs \"8fbaf5cb-3b76-4c62-a74e-db51b60f6600\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+FlinkKinesisConsumer<String> consumer = new FlinkKinesisConsumer<>(\n+    \"kinesis_stream_name\",\n+    new SimpleStringSchema(),\n+    kinesisConsumerConfig);\n+consumer.setPeriodicWatermarkAssigner(new CustomAssignerWithPeriodicWatermarks());\n+DataStream<String> stream = env\n+\t.addSource(consumer)\n+\t.print();\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+val consumer = new FlinkKinesisConsumer[String](\n+    \"kinesis_stream_name\",\n+    new SimpleStringSchema(),\n+    kinesisConsumerConfig);\n+consumer.setPeriodicWatermarkAssigner(new CustomAssignerWithPeriodicWatermarks());\n+val stream = env\n+\t.addSource(consumer)\n+\t.print();\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+Internally, an instance of the assigner is executed per shard / consumer thread (see threading model below).\n+When an assigner is specified, for each record read from Kinesis, the extractTimestamp(T element, long previousElementTimestamp)\n+is called to assign a timestamp to the record and getCurrentWatermark() to determine the new watermark for the shard.\n+The watermark of the consumer subtask is then determined as the minimum watermark of all its shards and emitted periodically.\n+The per shard watermark is essential to deal with varying consumption speed between shards, that otherwise could lead\n+to issues with downstream logic that relies on the watermark, such as incorrect late data dropping.\n+\n+By default, the watermark is going to stall if shards do not deliver new records.\n+The property `ConsumerConfigConstants.SHARD_IDLE_INTERVAL_MILLIS` can be used to avoid this potential issue through a\n+timeout that will allow the watermark to progress despite of idle shards.\n+\n+### Event Time Alignment for Shard Consumers\n+\n+The Flink Kinesis Consumer optionally supports synchronization between parallel consumer subtasks (and their threads)\n+to avoid the event time skew related problems described in [Event time synchronization across sources](https://issues.apache.org/jira/browse/FLINK-10886).\n+\n+To enable synchronization, set the watermark tracker on the consumer:\n+\n+<div data-lang=\"java\" markdown=\"1\">\n+```java\n+JobManagerWatermarkTracker watermarkTracker =\n+    new JobManagerWatermarkTracker(\"myKinesisSource\");\n+consumer.setWatermarkTracker(watermarkTracker);\n+```\n+</div>\n+\n+The `JobManagerWatermarkTracker` will use a global aggregate to synchronize the per subtask watermarks. Each subtask\n+uses a per shard queue to control the rate at which records are emitted downstream based on how far ahead of the global\n+watermark the next record in the queue is.\n+\n+The \"emit ahead\" limit is configured via `ConsumerConfigConstants.WATERMARK_LOOKAHEAD_MILLIS`. Smaller values reduce\n+the skew but also the throughput. Larger values will allow the subtask to proceed further before waiting for the global\n+watermark to advance.\n+\n+Another variable in the throughput equation is how frequently the watermark is propagated by the tracker.\n+The interval can be configured via `ConsumerConfigConstants.WATERMARK_SYNC_MILLIS`.\n+Smaller values reduce emitter waits and come at the cost of increased communication with the job manager.\n+\n+Since records accumulate in the queues when skew occurs, increased memory consumption needs to be expected.\n+How much depends on the average record size. With larger sizes, it may be necessary to adjust the emitter queue capacity via\n+`ConsumerConfigConstants.WATERMARK_SYNC_QUEUE_CAPACITY`.\n+\n+### Threading Model\n+\n+The Flink Kinesis Consumer uses multiple threads for shard discovery and data consumption.\n+\n+#### Shard Discovery\n+\n+For shard discovery, each parallel consumer subtask will have a single thread that constantly queries Kinesis for shard\n+information even if the subtask initially did not have shards to read from when the consumer was started. In other words, if\n+the consumer is run with a parallelism of 10, there will be a total of 10 threads constantly querying Kinesis regardless\n+of the total amount of shards in the subscribed streams.\n+\n+#### Polling (default) Record Publisher\n+\n+For `POLLING` data consumption, a single thread will be created to consume each discovered shard. Threads will terminate when the\n+shard it is responsible of consuming is closed as a result of stream resharding. In other words, there will always be\n+one thread per open shard.\n+\n+#### Enhanced Fan-Out Record Publisher\n+\n+For `EFO` data consumption the threading model is the same as `POLLING`, with additional thread pools to handle \n+asynchronous communication with Kinesis. AWS SDK v2.x `KinesisAsyncClient` uses additional threads for \n+Netty to handle IO and asynchronous response. Each parallel consumer subtask will have their own instance of the `KinesisAsyncClient`.\n+In other words, if the consumer is run with a parallelism of 10, there will be a total of 10 `KinesisAsyncClient` instances.\n+A separate client will be created and subsequently destroyed when registering and deregistering stream consumers.\n+\n+### Internally Used Kinesis APIs\n+\n+The Flink Kinesis Consumer uses the [AWS Java SDK](http://aws.amazon.com/sdk-for-java/) internally to call Kinesis APIs\n+for shard discovery and data consumption. Due to Amazon's [service limits for Kinesis Streams](http://docs.aws.amazon.com/streams/latest/dev/service-sizes-and-limits.html)\n+on the APIs, the consumer will be competing with other non-Flink consuming applications that the user may be running.\n+Below is a list of APIs called by the consumer with description of how the consumer uses the API, as well as information\n+on how to deal with any errors or warnings that the Flink Kinesis Consumer may have due to these service limits.\n+\n+#### Shard Discovery\n+\n+- *[ListShards](https://docs.aws.amazon.com/kinesis/latest/APIReference/API_ListShards.html)*: this is constantly called\n+by a single thread in each parallel consumer subtask to discover any new shards as a result of stream resharding. By default,\n+the consumer performs the shard discovery at an interval of 10 seconds, and will retry indefinitely until it gets a result\n+from Kinesis. If this interferes with other non-Flink consuming applications, users can slow down the consumer of\n+calling this API by setting a value for `ConsumerConfigConstants.SHARD_DISCOVERY_INTERVAL_MILLIS` in the supplied\n+configuration properties. This sets the discovery interval to a different value. Note that this setting directly impacts\n+the maximum delay of discovering a new shard and starting to consume it, as shards will not be discovered during the interval.\n+\n+#### Polling (default) Record Publisher\n+\n+- *[GetShardIterator](https://docs.aws.amazon.com/kinesis/latest/APIReference/API_GetShardIterator.html)*: this is called\n+only once when per shard consuming threads are started, and will retry if Kinesis complains that the transaction limit for the\n+API has exceeded, up to a default of 3 attempts. Note that since the rate limit for this API is per shard (not per stream),\n+the consumer itself should not exceed the limit. Usually, if this happens, users can either try to slow down any other\n+non-Flink consuming applications of calling this API, or modify the retry behaviour of this API call in the consumer by\n+setting keys prefixed by `ConsumerConfigConstants.SHARD_GETITERATOR_*` in the supplied configuration properties.\n+\n+- *[GetRecords](https://docs.aws.amazon.com/kinesis/latest/APIReference/API_GetRecords.html)*: this is constantly called\n+by per shard consuming threads to fetch records from Kinesis. When a shard has multiple concurrent consumers (when there\n+are any other non-Flink consuming applications running), the per shard rate limit may be exceeded. By default, on each call\n+of this API, the consumer will retry if Kinesis complains that the data size / transaction limit for the API has exceeded,\n+up to a default of 3 attempts. Users can either try to slow down other non-Flink consuming applications, or adjust the throughput\n+of the consumer by setting the `ConsumerConfigConstants.SHARD_GETRECORDS_MAX` and\n+`ConsumerConfigConstants.SHARD_GETRECORDS_INTERVAL_MILLIS` keys in the supplied configuration properties. Setting the former\n+adjusts the maximum number of records each consuming thread tries to fetch from shards on each call (default is 10,000), while\n+the latter modifies the sleep interval between each fetch (default is 200). The retry behaviour of the\n+consumer when calling this API can also be modified by using the other keys prefixed by `ConsumerConfigConstants.SHARD_GETRECORDS_*`.\n+\n+#### Enhanced Fan-Out Record Publisher\n+\n+- *[SubscribeToShard](https://docs.aws.amazon.com/kinesis/latest/APIReference/API_SubscribeToShard.html)*: this is called\n+by per shard consuming threads to obtain shard subscriptions. A shard subscription is typically active for 5 minutes, \n+but subscriptions will be reaquired if any recoverable errors are thrown. Once a subscription is acquired, the consumer\n+will receive a stream of [SubscribeToShardEvents](https://docs.aws.amazon.com/kinesis/latest/APIReference/API_SubscribeToShardEvent.html)s.\n+Retry and backoff parameters can be configured using the `ConsumerConfigConstants.SUBSCRIBE_TO_SHARD_*` keys.\n+\n+- *[DescribeStreamSummary](https://docs.aws.amazon.com/kinesis/latest/APIReference/API_DescribeStreamSummary.html)*: this is called \n+once per stream, during stream consumer registration. By default, the `LAZY` registration strategy will scale the\n+number of calls by the job parallelism. `EAGER` will invoke this once per stream and `NONE` will not invoke this API. \n+Retry and backoff parameters can be configured using the \n+`ConsumerConfigConstants.STREAM_DESCRIBE_*` keys.\n+\n+- *[DescribeStreamConsumer](https://docs.aws.amazon.com/kinesis/latest/APIReference/API_DescribeStreamConsumer.html)*:\n+this is called during stream consumer registration and deregistration. For each stream this service will be invoked \n+periodically until the stream consumer is reported `ACTIVE`/`not found` for registration/deregistration. By default,\n+the `LAZY` registration strategy will scale the number of calls by the job parallelism. `EAGER` will call the service \n+once per stream for registration, and scale the number of calls by the job parallelism for deregistration. \n+`NONE` will not invoke this service. Retry and backoff parameters can be configured using the \n+`ConsumerConfigConstants.DESCRIBE_STREAM_CONSUMER_*` keys.  \n+\n+- *[RegisterStreamConsumer](https://docs.aws.amazon.com/kinesis/latest/APIReference/API_RegisterStreamConsumer.html)*: \n+this is called once per stream during stream consumer registration, unless the `NONE` registration strategy is configured.\n+Retry and backoff parameters can be configured using the `ConsumerConfigConstants.REGISTER_STREAM_*` keys.\n+\n+- *[DeregisterStreamConsumer](https://docs.aws.amazon.com/kinesis/latest/APIReference/API_DeregisterStreamConsumer.html)*: \n+this is called once per stream during stream consumer deregistration, unless the `NONE` registration strategy is configured.\n+Retry and backoff parameters can be configured using the `ConsumerConfigConstants.DEREGISTER_STREAM_*` keys.  \n+\n+## Kinesis Producer\n+\n+The `FlinkKinesisProducer` uses [Kinesis Producer Library (KPL)](http://docs.aws.amazon.com/streams/latest/dev/developing-producers-with-kpl.html) to put data from a Flink stream into a Kinesis stream.\n+\n+Note that the producer is not participating in Flink's checkpointing and doesn't provide exactly-once processing guarantees. Also, the Kinesis producer does not guarantee that records are written in order to the shards (See [here](https://github.com/awslabs/amazon-kinesis-producer/issues/23) and [here](http://docs.aws.amazon.com/kinesis/latest/APIReference/API_PutRecord.html#API_PutRecord_RequestSyntax) for more details).\n+\n+In case of a failure or a resharding, data will be written again to Kinesis, leading to duplicates. This behavior is usually called \"at-least-once\" semantics.\n+\n+To put data into a Kinesis stream, make sure the stream is marked as \"ACTIVE\" in the AWS dashboard.\n+\n+For the monitoring to work, the user accessing the stream needs access to the CloudWatch service.\n+\n+{{< tabs \"6df3b696-c2ca-4f44-bea0-96cf8275d61c\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+Properties producerConfig = new Properties();\n+// Required configs\n+producerConfig.put(AWSConfigConstants.AWS_REGION, \"us-east-1\");\n+producerConfig.put(AWSConfigConstants.AWS_ACCESS_KEY_ID, \"aws_access_key_id\");\n+producerConfig.put(AWSConfigConstants.AWS_SECRET_ACCESS_KEY, \"aws_secret_access_key\");\n+// Optional configs\n+producerConfig.put(\"AggregationMaxCount\", \"4294967295\");\n+producerConfig.put(\"CollectionMaxCount\", \"1000\");\n+producerConfig.put(\"RecordTtl\", \"30000\");\n+producerConfig.put(\"RequestTimeout\", \"6000\");\n+producerConfig.put(\"ThreadPoolSize\", \"15\");\n+\n+// Disable Aggregation if it's not supported by a consumer\n+// producerConfig.put(\"AggregationEnabled\", \"false\");\n+// Switch KinesisProducer's threading model\n+// producerConfig.put(\"ThreadingModel\", \"PER_REQUEST\");\n+\n+FlinkKinesisProducer<String> kinesis = new FlinkKinesisProducer<>(new SimpleStringSchema(), producerConfig);\n+kinesis.setFailOnError(true);\n+kinesis.setDefaultStream(\"kinesis_stream_name\");\n+kinesis.setDefaultPartition(\"0\");\n+\n+DataStream<String> simpleStringStream = ...;\n+simpleStringStream.addSink(kinesis);\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+val producerConfig = new Properties()\n+// Required configs\n+producerConfig.put(AWSConfigConstants.AWS_REGION, \"us-east-1\")\n+producerConfig.put(AWSConfigConstants.AWS_ACCESS_KEY_ID, \"aws_access_key_id\")\n+producerConfig.put(AWSConfigConstants.AWS_SECRET_ACCESS_KEY, \"aws_secret_access_key\")\n+// Optional KPL configs\n+producerConfig.put(\"AggregationMaxCount\", \"4294967295\")\n+producerConfig.put(\"CollectionMaxCount\", \"1000\")\n+producerConfig.put(\"RecordTtl\", \"30000\")\n+producerConfig.put(\"RequestTimeout\", \"6000\")\n+producerConfig.put(\"ThreadPoolSize\", \"15\")\n+\n+// Disable Aggregation if it's not supported by a consumer\n+// producerConfig.put(\"AggregationEnabled\", \"false\")\n+// Switch KinesisProducer's threading model\n+// producerConfig.put(\"ThreadingModel\", \"PER_REQUEST\")\n+\n+val kinesis = new FlinkKinesisProducer[String](new SimpleStringSchema, producerConfig)\n+kinesis.setFailOnError(true)\n+kinesis.setDefaultStream(\"kinesis_stream_name\")\n+kinesis.setDefaultPartition(\"0\")\n+\n+val simpleStringStream = ...\n+simpleStringStream.addSink(kinesis)\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+The above is a simple example of using the producer. To initialize `FlinkKinesisProducer`, users are required to pass in `AWS_REGION`, `AWS_ACCESS_KEY_ID`, and `AWS_SECRET_ACCESS_KEY` via a `java.util.Properties` instance. Users can also pass in KPL's configurations as optional parameters to customize the KPL underlying `FlinkKinesisProducer`. The full list of KPL configs and explanations can be found [here](https://github.com/awslabs/amazon-kinesis-producer/blob/master/java/amazon-kinesis-producer-sample/default_config.properties). The example demonstrates producing a single Kinesis stream in the AWS region \"us-east-1\".\n+\n+If users don't specify any KPL configs and values, `FlinkKinesisProducer` will use default config values of KPL, except `RateLimit`. `RateLimit` limits the maximum allowed put rate for a shard, as a percentage of the backend limits. KPL's default value is 150 but it makes KPL throw `RateLimitExceededException` too frequently and breaks Flink sink as a result. Thus `FlinkKinesisProducer` overrides KPL's default value to 100.\n+\n+Instead of a `SerializationSchema`, it also supports a `KinesisSerializationSchema`. The `KinesisSerializationSchema` allows to send the data to multiple streams. This is\n+done using the `KinesisSerializationSchema.getTargetStream(T element)` method. Returning `null` there will instruct the producer to write the element to the default stream.\n+Otherwise, the returned stream name is used.\n+\n+### Threading Model\n+\n+Since Flink 1.4.0, `FlinkKinesisProducer` switches its default underlying KPL from a one-thread-per-request mode to a thread-pool mode. KPL in thread-pool mode uses a queue and thread pool to execute requests to Kinesis. This limits the number of threads that KPL's native process may create, and therefore greatly lowers CPU utilization and improves efficiency. **Thus, We highly recommend Flink users use thread-pool model.** The default thread pool size is `10`. Users can set the pool size in `java.util.Properties` instance with key `ThreadPoolSize`, as shown in the above example.\n+\n+Users can still switch back to one-thread-per-request mode by setting a key-value pair of `ThreadingModel` and `PER_REQUEST` in `java.util.Properties`, as shown in the code commented out in above example.\n+\n+### Backpressure\n+\n+By default, `FlinkKinesisProducer` does not backpressure. Instead, records that\n+cannot be sent because of the rate restriction of 1 MB per second per shard are\n+buffered in an unbounded queue and dropped when their `RecordTtl` expires.\n+\n+To avoid data loss, you can enable backpressuring by restricting the size of the\n+internal queue:\n+\n+```\n+// 200 Bytes per record, 1 shard\n+kinesis.setQueueLimit(500);\n+```\n+\n+The value for `queueLimit` depends on the expected record size. To choose a good\n+value, consider that Kinesis is rate-limited to 1MB per second per shard. If\n+less than one second's worth of records is buffered, then the queue may not be\n+able to operate at full capacity. With the default `RecordMaxBufferedTime` of\n+100ms, a queue size of 100kB per shard should be sufficient. The `queueLimit`\n+can then be computed via\n+\n+```\n+queue limit = (number of shards * queue size per shard) / record size\n+```\n+\n+E.g. for 200Bytes per record and 8 shards, a queue limit of 4000 is a good\n+starting point. If the queue size limits throughput (below 1MB per second per\n+shard), try increasing the queue limit slightly.\n+\n+\n+## Using Custom Kinesis Endpoints\n+\n+It is sometimes desirable to have Flink operate as a consumer or producer against a Kinesis VPC endpoint or a non-AWS\n+Kinesis endpoint such as [Kinesalite](https://github.com/mhart/kinesalite); this is especially useful when performing\n+functional testing of a Flink application. The AWS endpoint that would normally be inferred by the AWS region set in the\n+Flink configuration must be overridden via a configuration property.\n+\n+To override the AWS endpoint, set the `AWSConfigConstants.AWS_ENDPOINT` and `AWSConfigConstants.AWS_REGION` properties. The region will be used to sign the endpoint URL.\n+\n+{{< tabs \"bcadd466-8416-4d3c-a6a7-c46eee0cbd4a\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+Properties producerConfig = new Properties();\n+producerConfig.put(AWSConfigConstants.AWS_REGION, \"us-east-1\");\n+producerConfig.put(AWSConfigConstants.AWS_ACCESS_KEY_ID, \"aws_access_key_id\");\n+producerConfig.put(AWSConfigConstants.AWS_SECRET_ACCESS_KEY, \"aws_secret_access_key\");\n+producerConfig.put(AWSConfigConstants.AWS_ENDPOINT, \"http://localhost:4567\");\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+val producerConfig = new Properties()\n+producerConfig.put(AWSConfigConstants.AWS_REGION, \"us-east-1\")\n+producerConfig.put(AWSConfigConstants.AWS_ACCESS_KEY_ID, \"aws_access_key_id\")\n+producerConfig.put(AWSConfigConstants.AWS_SECRET_ACCESS_KEY, \"aws_secret_access_key\")\n+producerConfig.put(AWSConfigConstants.AWS_ENDPOINT, \"http://localhost:4567\")\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+{{< top >}}"
        },
        {
            "sha": "ffcbbfc715f407047b146cd4cbf5eb66473c7e3f",
            "filename": "docs/content.zh/docs/connectors/datastream/nifi.md",
            "status": "added",
            "additions": 128,
            "deletions": 0,
            "changes": 128,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/datastream/nifi.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/datastream/nifi.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/datastream/nifi.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,128 @@\n+---\n+title: NiFi\n+weight: 8\n+type: docs\n+aliases:\n+  - /zh/dev/connectors/nifi.html\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Apache NiFi 连接器\n+\n+[Apache NiFi](https://nifi.apache.org/) 连接器提供了可以读取和写入的 Source 和 Sink。\n+使用这个连接器，需要在工程中添加下面的依赖:\n+\n+{{< artifact flink-connector-nifi withScalaVersion >}}\n+\n+注意这些连接器目前还没有包含在二进制发行版中。添加依赖、打包配置以及集群运行的相关信息请参考 [这里]({{< ref \"docs/dev/datastream/project-configuration\" >}})。\n+\n+#### 安装 Apache NiFi\n+\n+安装 Apache NiFi 集群请参考 [这里](https://nifi.apache.org/docs/nifi-docs/html/administration-guide.html#how-to-install-and-start-nifi)。\n+\n+#### Apache NiFi Source\n+\n+该连接器提供了一个 Source 可以用来从 Apache NiFi 读取数据到 Apache Flink。\n+\n+`NiFiSource(…)` 类有两个构造方法。\n+\n+- `NiFiSource(SiteToSiteConfig config)` - 构造一个 `NiFiSource(…)` ，需要指定参数 SiteToSiteConfig ，采用默认的等待时间 1000 ms。\n+\n+- `NiFiSource(SiteToSiteConfig config, long waitTimeMs)` - 构造一个 `NiFiSource(…)`，需要指定参数 SiteToSiteConfig 和等待时间（单位为毫秒）。\n+\n+示例:\n+\n+{{< tabs \"44ccc35b-83c3-464f-9464-995d4981f4d9\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+StreamExecutionEnvironment streamExecEnv = StreamExecutionEnvironment.getExecutionEnvironment();\n+\n+SiteToSiteClientConfig clientConfig = new SiteToSiteClient.Builder()\n+        .url(\"http://localhost:8080/nifi\")\n+        .portName(\"Data for Flink\")\n+        .requestBatchCount(5)\n+        .buildConfig();\n+\n+SourceFunction<NiFiDataPacket> nifiSource = new NiFiSource(clientConfig);\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+val streamExecEnv = StreamExecutionEnvironment.getExecutionEnvironment()\n+\n+val clientConfig: SiteToSiteClientConfig = new SiteToSiteClient.Builder()\n+       .url(\"http://localhost:8080/nifi\")\n+       .portName(\"Data for Flink\")\n+       .requestBatchCount(5)\n+       .buildConfig()\n+\n+val nifiSource = new NiFiSource(clientConfig)       \n+```       \n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+数据从 Apache NiFi Output Port 读取，Apache NiFi Output Port 也被称为 \"Data for Flink\"，是 Apache NiFi Site-to-site 协议配置的一部分。\n+\n+#### Apache NiFi Sink\n+\n+该连接器提供了一个 Sink 可以用来把 Apache Flink 的数据写入到 Apache NiFi。\n+\n+`NiFiSink(…)` 类只有一个构造方法。\n+\n+- `NiFiSink(SiteToSiteClientConfig, NiFiDataPacketBuilder<T>)` 构造一个 `NiFiSink(…)`，需要指定 `SiteToSiteConfig` 和  `NiFiDataPacketBuilder` 参数 ，`NiFiDataPacketBuilder` 可以将Flink数据转化成可以被NiFi识别的 `NiFiDataPacket`.\n+\n+示例:\n+\n+{{< tabs \"599dbd31-e2a4-4203-a428-0a4c95c8fd07\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+StreamExecutionEnvironment streamExecEnv = StreamExecutionEnvironment.getExecutionEnvironment();\n+\n+SiteToSiteClientConfig clientConfig = new SiteToSiteClient.Builder()\n+        .url(\"http://localhost:8080/nifi\")\n+        .portName(\"Data from Flink\")\n+        .requestBatchCount(5)\n+        .buildConfig();\n+\n+SinkFunction<NiFiDataPacket> nifiSink = new NiFiSink<>(clientConfig, new NiFiDataPacketBuilder<T>() {...});\n+\n+streamExecEnv.addSink(nifiSink);\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+val streamExecEnv = StreamExecutionEnvironment.getExecutionEnvironment()\n+\n+val clientConfig: SiteToSiteClientConfig = new SiteToSiteClient.Builder()\n+       .url(\"http://localhost:8080/nifi\")\n+       .portName(\"Data from Flink\")\n+       .requestBatchCount(5)\n+       .buildConfig()\n+\n+val nifiSink: NiFiSink[NiFiDataPacket] = new NiFiSink[NiFiDataPacket](clientConfig, new NiFiDataPacketBuilder<T>() {...})\n+\n+streamExecEnv.addSink(nifiSink)\n+```       \n+{{< /tab >}}\n+{{< /tabs >}}      \n+\n+更多关于 [Apache NiFi](https://nifi.apache.org) Site-to-Site Protocol 的信息请参考 [这里](https://nifi.apache.org/docs/nifi-docs/html/user-guide.html#site-to-site)。\n+\n+{{< top >}}"
        },
        {
            "sha": "889f38faf11f07136e0bb191730e609f858f0876",
            "filename": "docs/content.zh/docs/connectors/datastream/overview.md",
            "status": "added",
            "additions": 79,
            "deletions": 0,
            "changes": 79,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/datastream/overview.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/datastream/overview.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/datastream/overview.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,79 @@\n+---\n+title: 概览\n+weight: 1\n+type: docs\n+aliases:\n+  - /zh/dev/connectors/\n+  - /zh/apis/connectors.html\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# DataStream Connectors\n+\n+## 预定义的 Source 和 Sink\n+\n+一些比较基本的 Source 和 Sink 已经内置在 Flink 里。\n+[预定义 data sources]({{< ref \"docs/dev/datastream/overview\" >}}#data-sources) 支持从文件、目录、socket，以及 collections 和 iterators 中读取数据。\n+[预定义 data sinks]({{< ref \"docs/dev/datastream/overview\" >}}#data-sinks) 支持把数据写入文件、标准输出（stdout）、标准错误输出（stderr）和 socket。\n+\n+## 附带的连接器\n+\n+连接器可以和多种多样的第三方系统进行交互。目前支持以下系统:\n+\n+ * [Apache Kafka]({{< ref \"docs/connectors/datastream/kafka\" >}}) (source/sink)\n+ * [Apache Cassandra]({{< ref \"docs/connectors/datastream/cassandra\" >}}) (sink)\n+ * [Amazon Kinesis Streams]({{< ref \"docs/connectors/datastream/kinesis\" >}}) (source/sink)\n+ * [Elasticsearch]({{< ref \"docs/connectors/datastream/elasticsearch\" >}}) (sink)\n+ * [FileSystem（包括 Hadoop ） - 仅支持流]({{< ref \"docs/connectors/datastream/streamfile_sink\" >}}) (sink)\n+ * [FileSystem（包括 Hadoop ） - 流批统一]({{< ref \"docs/connectors/datastream/file_sink\" >}}) (sink)\n+ * [RabbitMQ]({{< ref \"docs/connectors/datastream/rabbitmq\" >}}) (source/sink)\n+ * [Apache NiFi]({{< ref \"docs/connectors/datastream/nifi\" >}}) (source/sink)\n+ * [Twitter Streaming API]({{< ref \"docs/connectors/datastream/twitter\" >}}) (source)\n+ * [Google PubSub]({{< ref \"docs/connectors/datastream/pubsub\" >}}) (source/sink)\n+ * [JDBC]({{< ref \"docs/connectors/datastream/jdbc\" >}}) (sink)\n+\n+请记住，在使用一种连接器时，通常需要额外的第三方组件，比如：数据存储服务器或者消息队列。\n+要注意这些列举的连接器是 Flink 工程的一部分，包含在发布的源码中，但是不包含在二进制发行版中。\n+更多说明可以参考对应的子部分。\n+\n+## Apache Bahir 中的连接器\n+\n+Flink 还有些一些额外的连接器通过 [Apache Bahir](https://bahir.apache.org/) 发布, 包括:\n+\n+ * [Apache ActiveMQ](https://bahir.apache.org/docs/flink/current/flink-streaming-activemq/) (source/sink)\n+ * [Apache Flume](https://bahir.apache.org/docs/flink/current/flink-streaming-flume/) (sink)\n+ * [Redis](https://bahir.apache.org/docs/flink/current/flink-streaming-redis/) (sink)\n+ * [Akka](https://bahir.apache.org/docs/flink/current/flink-streaming-akka/) (sink)\n+ * [Netty](https://bahir.apache.org/docs/flink/current/flink-streaming-netty/) (source)\n+\n+## 连接Fink的其他方法\n+\n+### 异步 I/O\n+\n+使用connector并不是唯一可以使数据进入或者流出Flink的方式。\n+一种常见的模式是从外部数据库或者 Web 服务查询数据得到初始数据流，然后通过 `Map` 或者 `FlatMap` 对初始数据流进行丰富和增强。\n+Flink 提供了[异步 I/O]({{< ref \"docs/dev/datastream/operators/asyncio\" >}}) API 来让这个过程更加简单、高效和稳定。\n+\n+### 可查询状态\n+\n+当 Flink 应用程序需要向外部存储推送大量数据时会导致 I/O 瓶颈问题出现。在这种场景下，如果对数据的读操作远少于写操作，那么让外部应用从 Flink 拉取所需的数据会是一种更好的方式。\n+[可查询状态]({{< ref \"docs/dev/datastream/fault-tolerance/queryable_state\" >}}) 接口可以实现这个功能，该接口允许被 Flink 托管的状态可以被按需查询。\n+\n+{{< top >}}"
        },
        {
            "sha": "f4194083aeba531684c4a9c424bd52014650a8f0",
            "filename": "docs/content.zh/docs/connectors/datastream/pubsub.md",
            "status": "added",
            "additions": 153,
            "deletions": 0,
            "changes": 153,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/datastream/pubsub.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/datastream/pubsub.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/datastream/pubsub.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,153 @@\n+---\n+title: Google Cloud PubSub\n+weight: 8\n+type: docs\n+aliases:\n+  - /zh/dev/connectors/pubsub.html\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Google Cloud PubSub\n+\n+这个连接器可向 [Google Cloud PubSub](https://cloud.google.com/pubsub) 读取与写入数据。添加下面的依赖来使用此连接器:\n+\n+{{< artifact flink-connector-pubsub withScalaVersion >}}\n+\n+<p style=\"border-radius: 5px; padding: 5px\" class=\"bg-danger\">\n+<b>注意</b>：此连接器最近才加到 Flink 里，还未接受广泛测试。\n+</p>\n+\n+注意连接器目前还不是二进制发行版的一部分，添加依赖、打包配置以及集群运行信息请参考[这里]({{< ref \"docs/dev/datastream/project-configuration\" >}})\n+\n+## Consuming or Producing PubSubMessages\n+\n+连接器可以接收和发送 Google PubSub 的信息。和 Google PubSub 一样，这个连接器能够保证`至少一次`的语义。\n+\n+### PubSub SourceFunction\n+\n+`PubSubSource` 类的对象由构建类来构建: `PubSubSource.newBuilder(...)`\n+\n+有多种可选的方法来创建 PubSubSource，但最低要求是要提供 Google Project、Pubsub 订阅和反序列化 PubSubMessages 的方法。\n+\n+Example:\n+\n+{{< tabs \"d2d1d8c9-12b6-4ca4-bf32-990c1c63d960\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+StreamExecutionEnvironment streamExecEnv = StreamExecutionEnvironment.getExecutionEnvironment();\n+\n+DeserializationSchema<SomeObject> deserializer = (...);\n+SourceFunction<SomeObject> pubsubSource = PubSubSource.newBuilder()\n+                                                      .withDeserializationSchema(deserializer)\n+                                                      .withProjectName(\"project\")\n+                                                      .withSubscriptionName(\"subscription\")\n+                                                      .build();\n+\n+streamExecEnv.addSource(source);\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+当前还不支持 PubSub 的 source functions [pulls](https://cloud.google.com/pubsub/docs/pull) messages 和 [push endpoints](https://cloud.google.com/pubsub/docs/push)。\n+\n+### PubSub Sink\n+\n+`PubSubSink` 类的对象由构建类来构建: `PubSubSink.newBuilder(...)`\n+\n+构建类的使用方式与 PubSubSource 类似。\n+\n+Example:\n+\n+{{< tabs \"2edf4665-456f-4380-8c5f-c5003cadf488\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+DataStream<SomeObject> dataStream = (...);\n+\n+SerializationSchema<SomeObject> serializationSchema = (...);\n+SinkFunction<SomeObject> pubsubSink = PubSubSink.newBuilder()\n+                                                .withSerializationSchema(serializationSchema)\n+                                                .withProjectName(\"project\")\n+                                                .withSubscriptionName(\"subscription\")\n+                                                .build()\n+\n+dataStream.addSink(pubsubSink);\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+### Google Credentials\n+\n+应用程序需要使用 [Credentials](https://cloud.google.com/docs/authentication/production) 来通过认证和授权才能使用 Google Cloud Platform 的资源，例如 PubSub。\n+\n+上述的两个构建类都允许你提供 Credentials, 但是连接器默认会通过环境变量: [GOOGLE_APPLICATION_CREDENTIALS](https://cloud.google.com/docs/authentication/production#obtaining_and_providing_service_account_credentials_manually) 来获取 Credentials 的路径。\n+\n+如果你想手动提供 Credentials，例如你想从外部系统读取 Credentials，你可以使用 `PubSubSource.newBuilder(...).withCredentials(...)`。\n+\n+### 集成测试\n+\n+在集成测试的时候，如果你不想直接连 PubSub 而是想读取和写入一个 docker container，可以参照 [PubSub testing locally](https://cloud.google.com/pubsub/docs/emulator)。\n+\n+下面的例子展示了如何使用 source 来从仿真器读取信息并发送回去：\n+\n+{{< tabs \"96e21898-1c58-4b39-a7ab-d0fa278df2ba\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+String hostAndPort = \"localhost:1234\";\n+DeserializationSchema<SomeObject> deserializationSchema = (...);\n+SourceFunction<SomeObject> pubsubSource = PubSubSource.newBuilder()\n+                                                      .withDeserializationSchema(deserializationSchema)\n+                                                      .withProjectName(\"my-fake-project\")\n+                                                      .withSubscriptionName(\"subscription\")\n+                                                      .withPubSubSubscriberFactory(new PubSubSubscriberFactoryForEmulator(hostAndPort, \"my-fake-project\", \"subscription\", 10, Duration.ofSeconds(15), 100))\n+                                                      .build();\n+SerializationSchema<SomeObject> serializationSchema = (...);\n+SinkFunction<SomeObject> pubsubSink = PubSubSink.newBuilder()\n+                                                .withSerializationSchema(serializationSchema)\n+                                                .withProjectName(\"my-fake-project\")\n+                                                .withSubscriptionName(\"subscription\")\n+                                                .withHostAndPortForEmulator(hostAndPort)\n+                                                .build();\n+\n+StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n+env.addSource(pubsubSource)\n+   .addSink(pubsubSink);\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+### 至少一次语义保证\n+\n+#### SourceFunction\n+\n+有很多原因导致会一个信息会被多次发出，例如 Google PubSub 的故障。\n+\n+另一个可能的原因是超过了确认的截止时间，即收到与确认信息之间的时间间隔。PubSubSource 只有在信息被成功快照之后才会确认以保证至少一次的语义。这意味着，如果你的快照间隔大于信息确认的截止时间，那么你订阅的信息很有可能会被多次处理。\n+\n+因此，我们建议把快照的间隔设置得比信息确认截止时间更短。\n+\n+参照 [PubSub](https://cloud.google.com/pubsub/docs/subscriber) 来增加信息确认截止时间。\n+\n+注意: `PubSubMessagesProcessedNotAcked` 显示了有多少信息正在等待下一个 checkpoint 还没被确认。\n+\n+#### SinkFunction\n+\n+Sink function 会把准备发到 PubSub 的信息短暂地缓存以提高性能。每次 checkpoint 前，它会刷新缓冲区，并且只有当所有信息成功发送到 PubSub 之后，checkpoint 才会成功完成。\n+\n+{{< top >}}"
        },
        {
            "sha": "d5477ffa0ad2a9a759057c5ab99411cad36897d0",
            "filename": "docs/content.zh/docs/connectors/datastream/rabbitmq.md",
            "status": "added",
            "additions": 182,
            "deletions": 0,
            "changes": 182,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/datastream/rabbitmq.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/datastream/rabbitmq.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/datastream/rabbitmq.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,182 @@\n+---\n+title: RabbitMQ\n+weight: 7\n+type: docs\n+aliases:\n+  - /zh/dev/connectors/rabbitmq.html\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# RabbitMQ 连接器\n+\n+## RabbitMQ 连接器的许可证\n+\n+Flink 的 RabbitMQ 连接器依赖了 \"RabbitMQ AMQP Java Client\"，它基于三种协议下发行：Mozilla Public License 1.1 (\"MPL\")、GNU General Public License version 2 (\"GPL\") 和 Apache License version 2 (\"ASL\")。\n+\n+Flink 自身既没有复用 \"RabbitMQ AMQP Java Client\" 的代码，也没有将 \"RabbitMQ AMQP Java Client\" 打二进制包。\n+\n+如果用户发布的内容是基于 Flink 的 RabbitMQ 连接器的（进而重新发布了 \"RabbitMQ AMQP Java Client\" ），那么一定要注意这可能会受到 Mozilla Public License 1.1 (\"MPL\")、GNU General Public License version 2 (\"GPL\")、Apache License version 2 (\"ASL\") 协议的限制.\n+\n+## RabbitMQ 连接器\n+\n+这个连接器可以访问 [RabbitMQ](http://www.rabbitmq.com/) 的数据流。使用这个连接器，需要在工程里添加下面的依赖：\n+\n+{{< artifact flink-connector-rabbitmq withScalaVersion >}}\n+\n+注意连接器现在没有包含在二进制发行版中。集群执行的相关信息请参考 [这里]({{< ref \"docs/dev/datastream/project-configuration\" >}}).\n+\n+### 安装 RabbitMQ\n+安装 RabbitMQ 请参考 [RabbitMQ 下载页面](http://www.rabbitmq.com/download.html)。安装完成之后，服务会自动拉起，应用程序就可以尝试连接到 RabbitMQ 了。\n+\n+### RabbitMQ Source\n+\n+`RMQSource` 负责从 RabbitMQ 中消费数据，可以配置三种不同级别的保证：\n+\n+1. **精确一次**: 保证精确一次需要以下条件 -\n+ - *开启 checkpointing*: 开启 checkpointing 之后，消息在 checkpoints \n+ 完成之后才会被确认（然后从 RabbitMQ 队列中删除）.\n+ - *使用关联标识（Correlation ids）*: 关联标识是 RabbitMQ 的一个特性，消息写入 RabbitMQ 时在消息属性中设置。\n+ 从 checkpoint 恢复时有些消息可能会被重复处理，source 可以利用关联标识对消息进行去重。\n+ - *非并发 source*: 为了保证精确一次的数据投递，source 必须是非并发的（并行度设置为1）。\n+  这主要是由于 RabbitMQ 分发数据时是从单队列向多个消费者投递消息的。\n+\n+2. **至少一次**:  在 checkpointing 开启的条件下，如果没有使用关联标识或者 source 是并发的，\n+那么 source 就只能提供至少一次的保证。\n+\n+3. **无任何保证**: 如果没有开启 checkpointing，source 就不能提供任何的数据投递保证。\n+使用这种设置时，source 一旦接收到并处理消息，消息就会被自动确认。\n+\n+下面是一个保证 exactly-once 的 RabbitMQ source 示例。 注释部分展示了更加宽松的保证应该如何配置。\n+\n+{{< tabs \"62892e62-eb37-4fed-aa0f-64690135b4d6\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n+// checkpointing is required for exactly-once or at-least-once guarantees\n+env.enableCheckpointing(...);\n+\n+final RMQConnectionConfig connectionConfig = new RMQConnectionConfig.Builder()\n+    .setHost(\"localhost\")\n+    .setPort(5000)\n+    ...\n+    .build();\n+    \n+final DataStream<String> stream = env\n+    .addSource(new RMQSource<String>(\n+        connectionConfig,            // config for the RabbitMQ connection\n+        \"queueName\",                 // name of the RabbitMQ queue to consume\n+        true,                        // use correlation ids; can be false if only at-least-once is required\n+        new SimpleStringSchema()))   // deserialization schema to turn messages into Java objects\n+    .setParallelism(1);              // non-parallel source is only required for exactly-once\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+val env = StreamExecutionEnvironment.getExecutionEnvironment\n+// checkpointing is required for exactly-once or at-least-once guarantees\n+env.enableCheckpointing(...)\n+\n+val connectionConfig = new RMQConnectionConfig.Builder()\n+    .setHost(\"localhost\")\n+    .setPort(5000)\n+    ...\n+    .build\n+    \n+val stream = env\n+    .addSource(new RMQSource[String](\n+        connectionConfig,            // config for the RabbitMQ connection\n+        \"queueName\",                 // name of the RabbitMQ queue to consume\n+        true,                        // use correlation ids; can be false if only at-least-once is required\n+        new SimpleStringSchema))     // deserialization schema to turn messages into Java objects\n+    .setParallelism(1)               // non-parallel source is only required for exactly-once\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+#### 服务质量 (QoS) / 消费者预取(Consumer Prefetch)\n+\n+RabbitMQ Source 通过 `RMQConnectionConfig` 类提供了一种简单的方式，来设置 source channel 上的 `basicQos`（见下方示例）。要注意的是这里的 prefetch count 是对单个 channel 设置的，并且由于每个并发的 source 都持有一个 connection/channel，因此这个值实际上会乘以 source 的并行度，来表示同一时间可以向这个 job 总共发送多少条未确认的消息。如果需要更复杂的配置，可以通过重写 `RMQSource#setupChannel(Connection)` 方法来实现手动配置。\n+\n+{{< tabs \"a899561b-bd98-4b65-a3a3-b81ee1f1f677\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+final RMQConnectionConfig connectionConfig = new RMQConnectionConfig.Builder()\n+    .setPrefetchCount(30_000)\n+    ...\n+    .build();\n+\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+val connectionConfig = new RMQConnectionConfig.Builder()\n+    .setPrefetchCount(30000)\n+    ...\n+    .build\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+RabbitMQ Source 默认情况下是不设置 prefetch count 的，这意味着 RabbitMQ 服务器将会无限制地向 source 发送消息。因此在生产环境中，最好要设置它。当消费海量数据的队列并且启用 checkpointing 时，消息只有在做完 checkpoint 后才会被确认，因此也许需要对 prefetch count 做一些调整来减少不必要的循环。\n+\n+更多关于 QoS 以及 prefetch 相关的内容可以参考 [这里](https://www.rabbitmq.com/confirms.html#channel-qos-prefetch).\n+更多关于在 AMQP 0-9-1 中可选的选项可以参考 [这里](https://www.rabbitmq.com/consumer-prefetch.html).\n+\n+### RabbitMQ Sink\n+该连接器提供了一个 `RMQSink` 类，用来向 RabbitMQ 队列发送数据。下面是设置 RabbitMQ sink 的代码示例：\n+\n+{{< tabs \"b8966b60-db25-4853-8382-751bbe1a89c7\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+final DataStream<String> stream = ...\n+\n+final RMQConnectionConfig connectionConfig = new RMQConnectionConfig.Builder()\n+    .setHost(\"localhost\")\n+    .setPort(5000)\n+    ...\n+    .build();\n+    \n+stream.addSink(new RMQSink<String>(\n+    connectionConfig,            // config for the RabbitMQ connection\n+    \"queueName\",                 // name of the RabbitMQ queue to send messages to\n+    new SimpleStringSchema()));  // serialization schema to turn Java objects to messages\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+val stream: DataStream[String] = ...\n+\n+val connectionConfig = new RMQConnectionConfig.Builder()\n+    .setHost(\"localhost\")\n+    .setPort(5000)\n+    ...\n+    .build\n+    \n+stream.addSink(new RMQSink[String](\n+    connectionConfig,         // config for the RabbitMQ connection\n+    \"queueName\",              // name of the RabbitMQ queue to send messages to\n+    new SimpleStringSchema))  // serialization schema to turn Java objects to messages\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+更多关于 RabbitMQ 的信息请参考 [这里](http://www.rabbitmq.com/).\n+\n+{{< top >}}"
        },
        {
            "sha": "01e62df07dfd304793aeed2a0633126c7e4c7188",
            "filename": "docs/content.zh/docs/connectors/datastream/streamfile_sink.md",
            "status": "added",
            "additions": 738,
            "deletions": 0,
            "changes": 738,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/datastream/streamfile_sink.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/datastream/streamfile_sink.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/datastream/streamfile_sink.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,738 @@\n+---\n+title: Streaming File Sink\n+weight: 6\n+type: docs\n+aliases:\n+  - /zh/dev/connectors/streamfile_sink.html\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Streaming File Sink\n+\n+\n+\n+这个连接器提供了一个 Sink 来将分区文件写入到支持 [Flink `FileSystem`]({{< ref \"docs/deployment/filesystems/overview\" >}}) 接口的文件系统中。\n+\n+Streaming File Sink 会将数据写入到桶中。由于输入流可能是无界的，因此每个桶中的数据被划分为多个有限大小的文件。如何分桶是可以配置的，默认使用基于时间的分桶策略，这种策略每个小时创建一个新的桶，桶中包含的文件将记录所有该小时内从流中接收到的数据。\n+\n+桶目录中的实际输出数据会被划分为多个部分文件（part file），每一个接收桶数据的 Sink Subtask ，至少包含一个部分文件（part file）。额外的部分文件（part file）将根据滚动策略创建，滚动策略是可以配置的。默认的策略是根据文件大小和超时时间来滚动文件。超时时间指打开文件的最长持续时间，以及文件关闭前的最长非活动时间。\n+\n+{{< hint info >}}\n+<b>重要:</b> 使用 StreamingFileSink 时需要启用 Checkpoint ，每次做 Checkpoint 时写入完成。如果 Checkpoint 被禁用，部分文件（part file）将永远处于 'in-progress' 或 'pending' 状态，下游系统无法安全地读取。\n+{{< /hint >}}\n+\n+{{< img src=\"/fig/streamfilesink_bucketing.png\" >}}\n+\n+## 文件格式\n+\n+ `StreamingFileSink` 支持行编码格式和批量编码格式，比如 [Apache Parquet](http://parquet.apache.org) 。\n+这两种变体随附了各自的构建器，可以使用以下静态方法创建：\n+\n+ - Row-encoded sink: `StreamingFileSink.forRowFormat(basePath, rowEncoder)`\n+ - Bulk-encoded sink: `StreamingFileSink.forBulkFormat(basePath, bulkWriterFactory)`\n+\n+创建行或批量编码的 Sink 时，我们需要指定存储桶的基本路径和数据的编码逻辑。\n+\n+更多配置操作以及不同数据格式的实现请参考 `StreamingFileSink` \n+\n+### 行编码格式\n+\n+行编码格式需要指定一个 `Encoder` 。Encoder 负责为每个处于 In-progress 状态文件的`OutputStream` 序列化数据。\n+\n+除了桶分配器之外，`RowFormatBuilder`  还允许用户指定：\n+\n+ - Custom `RollingPolicy` ：自定义滚动策略以覆盖默认的 DefaultRollingPolicy\n+ - bucketCheckInterval （默认为1分钟）：毫秒间隔，用于基于时间的滚动策略。\n+\n+字符串元素写入示例：\n+\n+\n+{{< tabs \"804d0538-5382-4b74-b389-8ab1403c804c\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+import org.apache.flink.api.common.serialization.SimpleStringEncoder;\n+import org.apache.flink.core.fs.Path;\n+import org.apache.flink.streaming.api.functions.sink.filesystem.StreamingFileSink;\n+import org.apache.flink.streaming.api.functions.sink.filesystem.rollingpolicies.DefaultRollingPolicy;\n+\n+DataStream<String> input = ...;\n+\n+final StreamingFileSink<String> sink = StreamingFileSink\n+    .forRowFormat(new Path(outputPath), new SimpleStringEncoder<String>(\"UTF-8\"))\n+    .withRollingPolicy(\n+        DefaultRollingPolicy.builder()\n+            .withRolloverInterval(TimeUnit.MINUTES.toMillis(15))\n+            .withInactivityInterval(TimeUnit.MINUTES.toMillis(5))\n+            .withMaxPartSize(1024 * 1024 * 1024)\n+            .build())\n+\t.build();\n+\n+input.addSink(sink);\n+\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+import org.apache.flink.api.common.serialization.SimpleStringEncoder\n+import org.apache.flink.core.fs.Path\n+import org.apache.flink.streaming.api.functions.sink.filesystem.StreamingFileSink\n+import org.apache.flink.streaming.api.functions.sink.filesystem.rollingpolicies.DefaultRollingPolicy\n+\n+val input: DataStream[String] = ...\n+\n+val sink: StreamingFileSink[String] = StreamingFileSink\n+    .forRowFormat(new Path(outputPath), new SimpleStringEncoder[String](\"UTF-8\"))\n+    .withRollingPolicy(\n+        DefaultRollingPolicy.builder()\n+            .withRolloverInterval(TimeUnit.MINUTES.toMillis(15))\n+            .withInactivityInterval(TimeUnit.MINUTES.toMillis(5))\n+            .withMaxPartSize(1024 * 1024 * 1024)\n+            .build())\n+    .build()\n+\n+input.addSink(sink)\n+\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+这个例子创建了一个简单的 Sink ，将记录分配给默认的一小时时间桶。它还指定了一个滚动策略，该策略在以下三种情况下滚动处于 In-progress 状态的部分文件（part file）：\n+\n+ - 它至少包含 15 分钟的数据\n+ - 最近 5 分钟没有收到新的记录\n+ - 文件大小达到 1GB （写入最后一条记录后）\n+\n+### 批量编码格式\n+\n+批量编码 Sink 的创建与行编码 Sink 相似，不过在这里我们不是指定编码器  `Encoder` 而是指定 BulkWriter.`Factory` 。\n+`BulkWriter` 定义了如何添加、刷新元素，以及如何批量编码。\n+\n+Flink 有四个内置的 BulkWriter Factory ：\n+\n+ - `ParquetWriterFactory`\n+ - `AvroWriterFactory`\n+ - `SequenceFileWriterFactory`\n+ - `CompressWriterFactory`\n+ - `OrcBulkWriterFactory`\n+\n+{{< hint info >}}\n+<b>重要:</b> 批量编码模式仅支持 OnCheckpointRollingPolicy 策略, 在每次 checkpoint 的时候切割文件。\n+{{< /hint >}}\n+\n+#### Parquet 格式\n+\n+Flink 包含为不同 Avro 类型，创建 ParquetWriterFactory 的便捷方法，更多信息请参考 `ParquetAvroWriters` 。\n+\n+要编写其他 Parquet 兼容的数据格式，用户需要创建 ParquetWriterFactory 并实现 `ParquetBuilder` 接口。\n+\n+在应用中使用 Parquet 批量编码器，你需要添加以下依赖：\n+\n+{{< artifact flink-parquet withScalaVersion >}}\n+\n+这个例子使用 StreamingFileSink 将 Avro 数据写入 Parquet 格式：\n+\n+{{< tabs \"7f839bbf-4d61-48ef-81a6-5649d53fcfae\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+import org.apache.flink.streaming.api.functions.sink.filesystem.StreamingFileSink;\n+import org.apache.flink.formats.parquet.avro.ParquetAvroWriters;\n+import org.apache.avro.Schema;\n+\n+\n+Schema schema = ...;\n+DataStream<GenericRecord> input = ...;\n+\n+final StreamingFileSink<GenericRecord> sink = StreamingFileSink\n+\t.forBulkFormat(outputBasePath, ParquetAvroWriters.forGenericRecord(schema))\n+\t.build();\n+\n+input.addSink(sink);\n+\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+import org.apache.flink.streaming.api.functions.sink.filesystem.StreamingFileSink\n+import org.apache.flink.formats.parquet.avro.ParquetAvroWriters\n+import org.apache.avro.Schema\n+\n+val schema: Schema = ...\n+val input: DataStream[GenericRecord] = ...\n+\n+val sink: StreamingFileSink[GenericRecord] = StreamingFileSink\n+    .forBulkFormat(outputBasePath, ParquetAvroWriters.forGenericRecord(schema))\n+    .build()\n+\n+input.addSink(sink)\n+\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+类似的，将 Protobuf 数据写入到 Parquet 格式可以通过：\n+\n+{{< tabs \"6207391f-278a-4eed-91aa-3112a2934e54\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+import org.apache.flink.streaming.api.functions.sink.filesystem.StreamingFileSink;\n+import org.apache.flink.formats.parquet.protobuf.ParquetProtoWriters;\n+\n+// ProtoRecord is a generated protobuf Message class.\n+DataStream<ProtoRecord> input = ...;\n+\n+final StreamingFileSink<ProtoRecord> sink = StreamingFileSink\n+\t.forBulkFormat(outputBasePath, ParquetProtoWriters.forType(ProtoRecord.class))\n+\t.build();\n+\n+input.addSink(sink);\n+\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+import org.apache.flink.streaming.api.functions.sink.filesystem.StreamingFileSink\n+import org.apache.flink.formats.parquet.protobuf.ParquetProtoWriters\n+\n+// ProtoRecord is a generated protobuf Message class.\n+val input: DataStream[ProtoRecord] = ...\n+\n+val sink: StreamingFileSink[ProtoRecord] = StreamingFileSink\n+    .forBulkFormat(outputBasePath, ParquetProtoWriters.forType(classOf[ProtoRecord]))\n+    .build()\n+\n+input.addSink(sink)\n+\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+#### Avro格式\n+\n+Flink 也提供了将数据写入 Avro 文件的内置支持。对于创建 AvroWriterFactory 的快捷方法，更多信息可以参考 \n+`AvroWriters`.\n+\n+使用Avro相关的Writer需要在项目中添加以下依赖：\n+\n+{{< artifact flink-avro >}}\n+\n+将数据写入 Avro 文件的 StreamingFileSink 算子可以通过如下方式创建：\n+\n+{{< tabs \"2df2f4da-8346-4ce3-bb4c-bcca28b29811\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+import org.apache.flink.streaming.api.functions.sink.filesystem.StreamingFileSink;\n+import org.apache.flink.formats.avro.AvroWriters;\n+import org.apache.avro.Schema;\n+\n+\n+Schema schema = ...;\n+DataStream<GenericRecord> input = ...;\n+\n+final StreamingFileSink<GenericRecord> sink = StreamingFileSink\n+\t.forBulkFormat(outputBasePath, AvroWriters.forGenericRecord(schema))\n+\t.build();\n+\n+input.addSink(sink);\n+\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+import org.apache.flink.streaming.api.functions.sink.filesystem.StreamingFileSink\n+import org.apache.flink.formats.avro.AvroWriters\n+import org.apache.avro.Schema\n+\n+val schema: Schema = ...\n+val input: DataStream[GenericRecord] = ...\n+\n+val sink: StreamingFileSink[GenericRecord] = StreamingFileSink\n+    .forBulkFormat(outputBasePath, AvroWriters.forGenericRecord(schema))\n+    .build()\n+\n+input.addSink(sink)\n+\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+如果想要创建自定义的 Avro Writer，例如启用压缩等，用户可以实现 `AvroBuilder`\n+接口并自行创建一个 `AvroWriterFactory` 实例：\n+\n+{{< tabs \"bc3ef729-afac-4ca7-ae2e-85368368a61f\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+AvroWriterFactory<?> factory = new AvroWriterFactory<>((AvroBuilder<Address>) out -> {\n+\tSchema schema = ReflectData.get().getSchema(Address.class);\n+\tDatumWriter<Address> datumWriter = new ReflectDatumWriter<>(schema);\n+\n+\tDataFileWriter<Address> dataFileWriter = new DataFileWriter<>(datumWriter);\n+\tdataFileWriter.setCodec(CodecFactory.snappyCodec());\n+\tdataFileWriter.create(schema, out);\n+\treturn dataFileWriter;\n+});\n+\n+DataStream<Address> stream = ...\n+stream.addSink(StreamingFileSink.forBulkFormat(\n+\toutputBasePath,\n+\tfactory).build());\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+val factory = new AvroWriterFactory[Address](new AvroBuilder[Address]() {\n+    override def createWriter(out: OutputStream): DataFileWriter[Address] = {\n+        val schema = ReflectData.get.getSchema(classOf[Address])\n+        val datumWriter = new ReflectDatumWriter[Address](schema)\n+\n+        val dataFileWriter = new DataFileWriter[Address](datumWriter)\n+        dataFileWriter.setCodec(CodecFactory.snappyCodec)\n+        dataFileWriter.create(schema, out)\n+        dataFileWriter\n+    }\n+})\n+\n+val stream: DataStream[Address] = ...\n+stream.addSink(StreamingFileSink.forBulkFormat(\n+    outputBasePath,\n+    factory).build());\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+#### ORC Format\n+\n+To enable the data to be bulk encoded in ORC format, Flink offers `OrcBulkWriterFactory`\n+which takes a concrete implementation of `Vectorizer`.\n+\n+Like any other columnar format that encodes data in bulk fashion, Flink's `OrcBulkWriter` writes the input elements in batches. It uses\n+ORC's `VectorizedRowBatch` to achieve this.\n+\n+Since the input element has to be transformed to a `VectorizedRowBatch`, users have to extend the abstract `Vectorizer`\n+class and override the `vectorize(T element, VectorizedRowBatch batch)` method. As you can see, the method provides an\n+instance of `VectorizedRowBatch` to be used directly by the users so users just have to write the logic to transform the\n+input `element` to `ColumnVectors` and set them in the provided `VectorizedRowBatch` instance.\n+\n+For example, if the input element is of type `Person` which looks like:\n+\n+{{< tabs \"a49d0a8c-1cd6-458a-a5a1-0ed645a1139d\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+\n+class Person {\n+    private final String name;\n+    private final int age;\n+    ...\n+}\n+\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+Then a child implementation to convert the element of type `Person` and set them in the `VectorizedRowBatch` can be like:\n+\n+{{< tabs \"7198abfc-97cf-4a81-8100-1dfe233d5608\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+import org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector;\n+import org.apache.hadoop.hive.ql.exec.vector.LongColumnVector;\n+\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.nio.charset.StandardCharsets;\n+\n+public class PersonVectorizer extends Vectorizer<Person> implements Serializable {\n+\tpublic PersonVectorizer(String schema) {\n+\t\tsuper(schema);\n+\t}\n+\t@Override\n+\tpublic void vectorize(Person element, VectorizedRowBatch batch) throws IOException {\n+\t\tBytesColumnVector nameColVector = (BytesColumnVector) batch.cols[0];\n+\t\tLongColumnVector ageColVector = (LongColumnVector) batch.cols[1];\n+\t\tint row = batch.size++;\n+\t\tnameColVector.setVal(row, element.getName().getBytes(StandardCharsets.UTF_8));\n+\t\tageColVector.vector[row] = element.getAge();\n+\t}\n+}\n+\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+import java.nio.charset.StandardCharsets\n+import org.apache.hadoop.hive.ql.exec.vector.{BytesColumnVector, LongColumnVector}\n+\n+class PersonVectorizer(schema: String) extends Vectorizer[Person](schema) {\n+\n+  override def vectorize(element: Person, batch: VectorizedRowBatch): Unit = {\n+    val nameColVector = batch.cols(0).asInstanceOf[BytesColumnVector]\n+    val ageColVector = batch.cols(1).asInstanceOf[LongColumnVector]\n+    nameColVector.setVal(batch.size + 1, element.getName.getBytes(StandardCharsets.UTF_8))\n+    ageColVector.vector(batch.size + 1) = element.getAge\n+  }\n+\n+}\n+\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+To use the ORC bulk encoder in an application, users need to add the following dependency:\n+\n+{{< artifact flink-orc withScalaVersion >}}\n+\n+And then a `StreamingFileSink` that writes data in ORC format can be created like this:\n+\n+{{< tabs \"fa7db9c6-8ad4-4cbd-82f8-9ec94f3371e6\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+import org.apache.flink.streaming.api.functions.sink.filesystem.StreamingFileSink;\n+import org.apache.flink.orc.writer.OrcBulkWriterFactory;\n+\n+String schema = \"struct<_col0:string,_col1:int>\";\n+DataStream<Person> input = ...;\n+\n+final OrcBulkWriterFactory<Person> writerFactory = new OrcBulkWriterFactory<>(new PersonVectorizer(schema));\n+\n+final StreamingFileSink<Person> sink = StreamingFileSink\n+\t.forBulkFormat(outputBasePath, writerFactory)\n+\t.build();\n+\n+input.addSink(sink);\n+\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+import org.apache.flink.streaming.api.functions.sink.filesystem.StreamingFileSink\n+import org.apache.flink.orc.writer.OrcBulkWriterFactory\n+\n+val schema: String = \"struct<_col0:string,_col1:int>\"\n+val input: DataStream[Person] = ...\n+val writerFactory = new OrcBulkWriterFactory(new PersonVectorizer(schema));\n+\n+val sink: StreamingFileSink[Person] = StreamingFileSink\n+    .forBulkFormat(outputBasePath, writerFactory)\n+    .build()\n+\n+input.addSink(sink)\n+\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+OrcBulkWriterFactory can also take Hadoop `Configuration` and `Properties` so that a custom Hadoop configuration and ORC\n+writer properties can be provided.\n+\n+{{< tabs \"97463c6c-ceeb-42c6-a281-f784d9cbafc6\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+String schema = ...;\n+Configuration conf = ...;\n+Properties writerProperties = new Properties();\n+\n+writerProps.setProperty(\"orc.compress\", \"LZ4\");\n+// Other ORC supported properties can also be set similarly.\n+\n+final OrcBulkWriterFactory<Person> writerFactory = new OrcBulkWriterFactory<>(\n+    new PersonVectorizer(schema), writerProperties, conf);\n+\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+val schema: String = ...\n+val conf: Configuration = ...\n+val writerProperties: Properties = new Properties()\n+\n+writerProps.setProperty(\"orc.compress\", \"LZ4\")\n+// Other ORC supported properties can also be set similarly.\n+\n+val writerFactory = new OrcBulkWriterFactory(\n+    new PersonVectorizer(schema), writerProperties, conf)\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+The complete list of ORC writer properties can be found [here](https://orc.apache.org/docs/hive-config.html).\n+\n+Users who want to add user metadata to the ORC files can do so by calling `addUserMetadata(...)` inside the overriding\n+`vectorize(...)` method.\n+\n+{{< tabs \"959c9327-80a3-4ef3-910a-e069b046f6d5\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+\n+public class PersonVectorizer extends Vectorizer<Person> implements Serializable {\n+\t@Override\n+\tpublic void vectorize(Person element, VectorizedRowBatch batch) throws IOException {\n+\t\t...\n+\t\tString metadataKey = ...;\n+\t\tByteBuffer metadataValue = ...;\n+\t\tthis.addUserMetadata(metadataKey, metadataValue);\n+\t}\n+}\n+\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+\n+class PersonVectorizer(schema: String) extends Vectorizer[Person](schema) {\n+\n+  override def vectorize(element: Person, batch: VectorizedRowBatch): Unit = {\n+    ...\n+    val metadataKey: String = ...\n+    val metadataValue: ByteBuffer = ...\n+    addUserMetadata(metadataKey, metadataValue)\n+  }\n+\n+}\n+\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+#### Hadoop SequenceFile 格式\n+\n+在应用中使用 SequenceFile 批量编码器，你需要添加以下依赖：\n+\n+{{< artifact flink-sequence-file withScalaVersion >}}\n+\n+简单的 SequenceFile 写入示例：\n+\n+{{< tabs \"466b0dac-1a2d-4472-8494-11764ef0a577\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+import org.apache.flink.streaming.api.functions.sink.filesystem.StreamingFileSink;\n+import org.apache.flink.configuration.GlobalConfiguration;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.io.LongWritable;\n+import org.apache.hadoop.io.SequenceFile;\n+import org.apache.hadoop.io.Text;\n+\n+\n+DataStream<Tuple2<LongWritable, Text>> input = ...;\n+Configuration hadoopConf = HadoopUtils.getHadoopConfiguration(GlobalConfiguration.loadConfiguration());\n+final StreamingFileSink<Tuple2<LongWritable, Text>> sink = StreamingFileSink\n+  .forBulkFormat(\n+    outputBasePath,\n+    new SequenceFileWriterFactory<>(hadoopConf, LongWritable.class, Text.class))\n+\t.build();\n+\n+input.addSink(sink);\n+\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+import org.apache.flink.streaming.api.functions.sink.filesystem.StreamingFileSink\n+import org.apache.flink.configuration.GlobalConfiguration\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.io.LongWritable\n+import org.apache.hadoop.io.SequenceFile\n+import org.apache.hadoop.io.Text;\n+\n+val input: DataStream[(LongWritable, Text)] = ...\n+val hadoopConf: Configuration = HadoopUtils.getHadoopConfiguration(GlobalConfiguration.loadConfiguration())\n+val sink: StreamingFileSink[(LongWritable, Text)] = StreamingFileSink\n+  .forBulkFormat(\n+    outputBasePath,\n+    new SequenceFileWriterFactory(hadoopConf, LongWritable.class, Text.class))\n+\t.build()\n+\n+input.addSink(sink)\n+\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+SequenceFileWriterFactory 支持附加构造函数参数指定压缩设置。\n+\n+## 桶分配\n+\n+桶分配逻辑定义了如何将数据结构化为基本输出目录中的子目录\n+\n+行格式和批量格式都使用 `DateTimeBucketAssigner` 作为默认的分配器。\n+默认情况下，DateTimeBucketAssigner 基于系统默认时区每小时创建一个桶，格式如下： `yyyy-MM-dd--HH` 。日期格式（即桶的大小）和时区都可以手动配置。\n+\n+我们可以在格式构建器上调用 `.withBucketAssigner(assigner)` 来自定义 `BucketAssigner` 。\n+\n+Flink 有两个内置的 BucketAssigners ：\n+\n+ - `DateTimeBucketAssigner` ：默认基于时间的分配器\n+ - `BasePathBucketAssigner` ：将所有部分文件（part file）存储在基本路径中的分配器（单个全局桶）\n+\n+## 滚动策略\n+\n+滚动策略 `RollingPolicy` 定义了指定的文件在何时关闭（closed）并将其变为 Pending 状态，随后变为 Finished 状态。处于 Pending 状态的文件会在下一次 Checkpoint 时变为 Finished 状态，通过设置 Checkpoint 间隔时间，可以控制部分文件（part file）对下游读取者可用的速度、大小和数量。\n+\n+Flink 有两个内置的滚动策略：\n+\n+ - `DefaultRollingPolicy`\n+ - `OnCheckpointRollingPolicy`\n+\n+## 部分文件（part file） 生命周期\n+\n+为了在下游系统中使用 StreamingFileSink 的输出，我们需要了解输出文件的命名规则和生命周期。\n+\n+部分文件（part file）可以处于以下三种状态之一：\n+ 1. **In-progress** ：当前文件正在写入中\n+ 2. **Pending** ：当处于 In-progress 状态的文件关闭（closed）了，就变为 Pending 状态\n+ 3. **Finished** ：在成功的 Checkpoint 后，Pending 状态将变为 Finished 状态\n+\n+处于 Finished 状态的文件不会再被修改，可以被下游系统安全地读取。\n+\n+<div class=\"alert alert-info\">\n+     <b>重要:</b> 部分文件的索引在每个 subtask 内部是严格递增的（按文件创建顺序）。但是索引并不总是连续的。当 Job 重启后，所有部分文件的索引从 `max part index + 1` 开始，\n+     这里的 `max part index` 是所有 subtask 中索引的最大值。\n+</div>\n+\n+对于每个活动的桶，Writer 在任何时候都只有一个处于 In-progress 状态的部分文件（part file），但是可能有几个 Penging 和 Finished 状态的部分文件（part file）。\n+\n+**部分文件（part file）例子**\n+\n+为了更好地理解这些文件的生命周期，让我们来看一个包含 2 个 Sink Subtask 的简单例子：\n+\n+```\n+└── 2019-08-25--12\n+    ├── part-0-0.inprogress.bd053eb0-5ecf-4c85-8433-9eff486ac334\n+    └── part-1-0.inprogress.ea65a428-a1d0-4a0b-bbc5-7a436a75e575\n+```\n+\n+当部分文件 `part-1-0` 被滚动（假设它变得太大了）时，它将成为 Pending 状态，但是它还没有被重命名。然后 Sink 会创建一个新的部分文件： `part-1-1`：\n+\n+```\n+└── 2019-08-25--12\n+    ├── part-0-0.inprogress.bd053eb0-5ecf-4c85-8433-9eff486ac334\n+    ├── part-1-0.inprogress.ea65a428-a1d0-4a0b-bbc5-7a436a75e575\n+    └── part-1-1.inprogress.bc279efe-b16f-47d8-b828-00ef6e2fbd11\n+```\n+\n+ `part-1-0` 现在处于 Pending 状态等待完成，在下一次成功的 Checkpoint 后，它会变成 Finished 状态：\n+\n+```\n+└── 2019-08-25--12\n+    ├── part-0-0.inprogress.bd053eb0-5ecf-4c85-8433-9eff486ac334\n+    ├── part-1-0\n+    └── part-1-1.inprogress.bc279efe-b16f-47d8-b828-00ef6e2fbd11\n+```\n+\n+根据分桶策略创建新的桶，但是这并不会影响当前处于 In-progress 状态的文件：\n+\n+```\n+└── 2019-08-25--12\n+    ├── part-0-0.inprogress.bd053eb0-5ecf-4c85-8433-9eff486ac334\n+    ├── part-1-0\n+    └── part-1-1.inprogress.bc279efe-b16f-47d8-b828-00ef6e2fbd11\n+└── 2019-08-25--13\n+    └── part-0-2.inprogress.2b475fec-1482-4dea-9946-eb4353b475f1\n+```\n+\n+因为分桶策略基于每条记录进行评估，所以旧桶仍然可以接受新的记录。\n+\n+### 部分文件的配置项\n+\n+已经完成的文件和进行中的文件仅能通过文件名格式进行区分。\n+\n+默认情况下，文件命名格式如下所示：\n+ - **In-progress / Pending:** `part-<subtaskIndex>-<partFileIndex>.inprogress.uid`\n+ - **FINISHED:** `part-<subtaskIndex>-<partFileIndex>`\n+\n+Flink 允许用户通过 `OutputFileConfig` 指定部分文件名的前缀和后缀。\n+举例来说，前缀设置为 \"prefix\" 以及后缀设置为 \".ext\" 之后，Sink 创建的文件名如下所示：\n+\n+```\n+└── 2019-08-25--12\n+    ├── prefix-0-0.ext\n+    ├── prefix-0-1.ext.inprogress.bd053eb0-5ecf-4c85-8433-9eff486ac334\n+    ├── prefix-1-0.ext\n+    └── prefix-1-1.ext.inprogress.bc279efe-b16f-47d8-b828-00ef6e2fbd11\n+```\n+\n+用户可以通过如下方式设置 `OutputFileConfig`:\n+\n+{{< tabs \"4ee26cce-7551-4a28-bc76-f8ba0e71ba80\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+\n+OutputFileConfig config = OutputFileConfig\n+ .builder()\n+ .withPartPrefix(\"prefix\")\n+ .withPartSuffix(\".ext\")\n+ .build();\n+\n+StreamingFileSink<Tuple2<Integer, Integer>> sink = StreamingFileSink\n+ .forRowFormat((new Path(outputPath), new SimpleStringEncoder<>(\"UTF-8\"))\n+ .withBucketAssigner(new KeyBucketAssigner())\n+ .withRollingPolicy(OnCheckpointRollingPolicy.build())\n+ .withOutputFileConfig(config)\n+ .build();\n+\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+\n+val config = OutputFileConfig\n+ .builder()\n+ .withPartPrefix(\"prefix\")\n+ .withPartSuffix(\".ext\")\n+ .build()\n+\n+val sink = StreamingFileSink\n+ .forRowFormat(new Path(outputPath), new SimpleStringEncoder[String](\"UTF-8\"))\n+ .withBucketAssigner(new KeyBucketAssigner())\n+ .withRollingPolicy(OnCheckpointRollingPolicy.build())\n+ .withOutputFileConfig(config)\n+ .build()\n+\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+## 重要注意事项\n+\n+### 通用注意事项\n+\n+<span class=\"label label-danger\">重要提示 1</span>: 使用 Hadoop < 2.7 时，请使用 `OnCheckpointRollingPolicy` 滚动策略，该策略会在每次检查点时进行文件切割。\n+这样做的原因是如果部分文件的生命周期跨多个检查点，当 `StreamingFileSink` 从之前的检查点进行恢复时会调用文件系统的 `truncate()` 方法清理 in-progress 文件中未提交的数据。\n+Hadoop 2.7 之前的版本不支持这个方法，因此 Flink 会报异常。\n+\n+<span class=\"label label-danger\">重要提示 2</span>: 鉴于 Flink 的 sink 以及 UDF 通常不会区分作业的正常结束（比如有限流）和异常终止，因此正常结束作业的最后一批 in-progress 文件不会被转换到 \"完成\" 状态。\n+\n+<span class=\"label label-danger\">重要提示 3</span>: Flink 以及 `StreamingFileSink` 不会覆盖已经提交的数据。因此如果尝试从一个包含 in-progress 文件的旧 checkpoint/savepoint 恢复，\n+且这些 in-progress 文件会被接下来的成功 checkpoint 提交，Flink 会因为无法找到 in-progress 文件而抛异常，从而恢复失败。\n+\n+<span class=\"label label-danger\">重要提示 4</span>: 目前 `StreamingFileSink` 只支持三种文件系统: HDFS、S3和Local。如果配置了不支持的文件系统，在执行的时候 Flink 会抛出异常。\n+\n+###  S3 特有的注意事项\n+\n+<span class=\"label label-danger\">重要提示 1</span>: 对于 S3，`StreamingFileSink`  只支持基于 [Hadoop](https://hadoop.apache.org/) \n+的文件系统实现，不支持基于 [Presto](https://prestodb.io/) 的实现。如果想使用 `StreamingFileSink` 向 S3 写入数据并且将 \n+checkpoint 放在基于 Presto 的文件系统，建议明确指定 *\"s3a://\"* （for Hadoop）作为sink的目标路径方案，并且为 checkpoint 路径明确指定 *\"s3p://\"* （for Presto）。\n+如果 Sink 和 checkpoint 都使用 *\"s3://\"* 路径的话，可能会导致不可预知的行为，因为双方的实现都在“监听”这个路径。\n+\n+<span class=\"label label-danger\">重要提示 2</span>: `StreamingFileSink` 使用 S3 的 [Multi-part Upload](https://docs.aws.amazon.com/AmazonS3/latest/dev/mpuoverview.html)\n+（后续使用MPU代替）特性可以保证精确一次的语义。这个特性支持以独立的块（因此被称为\"multi-part\"）模式上传文件，当 MPU 的所有部分文件\n+成功上传之后，可以合并成原始文件。对于失效的 MPUs，S3 提供了一个基于桶生命周期的规则，用户可以用这个规则来丢弃在指定时间内未完成的MPU。\n+如果在一些部分文件还未上传时触发 savepoint，并且这个规则设置的比较严格，这意味着相关的 MPU在作业重启之前可能会超时。后续的部分文件没\n+有写入到 savepoint, 那么在 Flink 作业从 savepoint 恢复时，会因为拿不到缺失的部分文件，导致任务失败并抛出异常。\n+\n+{{< top >}}"
        },
        {
            "sha": "171dbc400b3e1b1e1398967fd283bcb4cf7d6407",
            "filename": "docs/content.zh/docs/connectors/datastream/twitter.md",
            "status": "added",
            "additions": 80,
            "deletions": 0,
            "changes": 80,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/datastream/twitter.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/datastream/twitter.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/datastream/twitter.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,80 @@\n+---\n+title: Twitter\n+weight: 9\n+type: docs\n+aliases:\n+  - /zh/dev/connectors/twitter.html\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Twitter 连接器\n+\n+[Twitter Streaming API](https://dev.twitter.com/docs/streaming-apis) 提供了访问 Twitter 的 tweets 流的能力。\n+Flink Streaming 通过一个内置的 `TwitterSource` 类来创建到 tweets 流的连接。\n+使用 Twitter 连接器，需要在工程中添加下面的依赖：\n+\n+{{< artifact flink-connector-twitter withScalaVersion >}}\n+\n+注意：当前的二进制发行版还没有这些连接器。集群执行请参考[这里]({{< ref \"docs/dev/datastream/project-configuration\" >}}).\n+\n+#### 认证\n+使用 Twitter 流，用户需要先注册自己的程序，获取认证相关的必要信息。过程如下：\n+\n+#### 获取认证信息\n+首先，需要一个 Twitter 账号。可以通过 [twitter.com/signup](https://twitter.com/signup) 免费注册，\n+或者在 Twitter 的 [Application Management](https://apps.twitter.com/) 登录，然后点击 \"Create New App\"\n+ 按钮来注册应用,填写应用程序相关表格并且接受条款。选择应用程序之后，可以在 \"API Keys\" 标签页看到 API key 和 \n+ API secret（对应于`TwitterSource`中的`twitter-source.consumerKey` 和 `twitter-source.consumerSecret` ）。\n+请保管好这些信息并且不要将其发布到public的仓库。\n+\n+\n+#### 使用\n+和其他的连接器不同的是，`TwitterSource` 没有任何其他依赖。下面的示例代码就可以优雅的运行：\n+\n+{{< tabs \"976b5108-dc39-4108-ab77-d920b42f74d3\" >}}\n+{{< tab \"Java\" >}}\n+```java\n+Properties props = new Properties();\n+props.setProperty(TwitterSource.CONSUMER_KEY, \"\");\n+props.setProperty(TwitterSource.CONSUMER_SECRET, \"\");\n+props.setProperty(TwitterSource.TOKEN, \"\");\n+props.setProperty(TwitterSource.TOKEN_SECRET, \"\");\n+DataStream<String> streamSource = env.addSource(new TwitterSource(props));\n+```\n+{{< /tab >}}\n+{{< tab \"Scala\" >}}\n+```scala\n+val props = new Properties()\n+props.setProperty(TwitterSource.CONSUMER_KEY, \"\")\n+props.setProperty(TwitterSource.CONSUMER_SECRET, \"\")\n+props.setProperty(TwitterSource.TOKEN, \"\")\n+props.setProperty(TwitterSource.TOKEN_SECRET, \"\")\n+val streamSource = env.addSource(new TwitterSource(props))\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+`TwitterSource` 会发出包含了JSON object的字符串，这样的字符串表示一个Tweet.\n+\n+`flink-examples-streaming` 中的 `TwitterExample` 类是使用 `TwitterSource` 的完整示范。\n+\n+`TwitterSource` 默认使用 `StatusesSampleEndpoint`。`StatusesSampleEndpoint` 会返回一个 Tweets 的随机抽样。用户可以通过实现 `TwitterSource.EndpointInitializer` 接口来自定义 endpoint。\n+\n+{{< top >}}"
        },
        {
            "sha": "4c3be5788e0ec95f5c2fa85749d60d1ff1b3c688",
            "filename": "docs/content.zh/docs/connectors/table/_index.md",
            "status": "added",
            "additions": 23,
            "deletions": 0,
            "changes": 23,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/_index.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/_index.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/table/_index.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,23 @@\n+---\n+title: Table API Connectors\n+bookCollapseSection: true\n+weight: 2\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n\\ No newline at end of file"
        },
        {
            "sha": "a96cbdf761f1dd44e17b0ffeae7d0b18f1e255f3",
            "filename": "docs/content.zh/docs/connectors/table/blackhole.md",
            "status": "added",
            "additions": 85,
            "deletions": 0,
            "changes": 85,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/blackhole.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/blackhole.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/table/blackhole.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,85 @@\n+---\n+title: BlackHole\n+weight: 15\n+type: docs\n+aliases:\n+  - /zh/dev/table/connectors/blackhole.html\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# BlackHole SQL 连接器\n+\n+{{< label \"Sink: Bounded\" >}}\n+{{< label \"Sink: UnBounded\" >}}\n+\n+BlackHole 连接器允许接收所有输入记录。它被设计用于：\n+\n+- 高性能测试。\n+- UDF 输出，而不是实质性 sink。\n+\n+就像类 Unix 操作系统上的 /dev/null。\n+\n+BlackHole 连接器是内置的。\n+\n+如何创建 BlackHole 表\n+----------------\n+\n+```sql\n+CREATE TABLE blackhole_table (\n+  f0 INT,\n+  f1 INT,\n+  f2 STRING,\n+  f3 DOUBLE\n+) WITH (\n+  'connector' = 'blackhole'\n+);\n+```\n+\n+\n+或者，可以基于现有模式使用 [LIKE 子句]({{< ref \"docs/dev/table/sql/create\" >}}#create-table) 创建。\n+\n+```sql\n+CREATE TABLE blackhole_table WITH ('connector' = 'blackhole')\n+LIKE source_table (EXCLUDING ALL)\n+```\n+\n+连接器选项\n+----------------\n+\n+<table class=\"table table-bordered\">\n+    <thead>\n+      <tr>\n+        <th class=\"text-left\" style=\"width: 25%\">选项</th>\n+        <th class=\"text-center\" style=\"width: 9%\">是否必要</th>\n+        <th class=\"text-center\" style=\"width: 7%\">默认值</th>\n+        <th class=\"text-center\" style=\"width: 10%\">类型</th>\n+        <th class=\"text-center\" style=\"width: 50%\">描述</th>\n+      </tr>\n+    </thead>\n+    <tbody>\n+    <tr>\n+      <td><h5>connector</h5></td>\n+      <td>必要</td>\n+      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>String</td>\n+      <td>指定需要使用的连接器，此处应为‘blackhole’。</td>\n+    </tr>\n+    </tbody>\n+</table>"
        },
        {
            "sha": "287686faa74a79c0f8484bdfaa8b7da598f560bc",
            "filename": "docs/content.zh/docs/connectors/table/datagen.md",
            "status": "added",
            "additions": 149,
            "deletions": 0,
            "changes": 149,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/datagen.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/datagen.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/table/datagen.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,149 @@\n+---\n+title: DataGen\n+weight: 13\n+type: docs\n+aliases:\n+  - /zh/dev/table/connectors/datagen.html\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# DataGen SQL 连接器\n+\n+{{< label \"Scan Source: 有界\" >}}\n+{{< label \"Scan Source: 无界\" >}}\n+\n+DataGen 连接器允许按数据生成规则进行读取。\n+\n+DataGen 连接器可以使用[计算列语法]({{< ref \"docs/dev/table/sql/create\" >}}#create-table)。\n+这使您可以灵活地生成记录。\n+\n+DataGen 连接器是内置的。\n+\n+<span class=\"label label-danger\">注意</span> 不支持复杂类型: Array，Map，Row。 请用计算列构造这些类型。\n+\n+怎么创建一个 DataGen 的表\n+----------------\n+\n+表的有界性：当表中字段的数据全部生成完成后，source 就结束了。 因此，表的有界性取决于字段的有界性。\n+\n+每个列，都有两种生成数据的方法：\n+\n+- 随机生成器是默认的生成器，您可以指定随机生成的最大和最小值。char、varchar、string （类型）可以指定长度。它是无界的生成器。\n+\n+- 序列生成器，您可以指定序列的起始和结束值。它是有界的生成器，当序列数字达到结束值，读取结束。\n+\n+```sql\n+CREATE TABLE datagen (\n+ f_sequence INT,\n+ f_random INT,\n+ f_random_str STRING,\n+ ts AS localtimestamp,\n+ WATERMARK FOR ts AS ts\n+) WITH (\n+ 'connector' = 'datagen',\n+\n+ -- optional options --\n+\n+ 'rows-per-second'='5',\n+\n+ 'fields.f_sequence.kind'='sequence',\n+ 'fields.f_sequence.start'='1',\n+ 'fields.f_sequence.end'='1000',\n+\n+ 'fields.f_random.min'='1',\n+ 'fields.f_random.max'='1000',\n+\n+ 'fields.f_random_str.length'='10'\n+)\n+```\n+\n+\n+连接器参数\n+----------------\n+\n+<table class=\"table table-bordered\">\n+    <thead>\n+      <tr>\n+        <th class=\"text-left\" style=\"width: 25%\">参数</th>\n+        <th class=\"text-center\" style=\"width: 10%\">是否必选</th>\n+        <th class=\"text-center\" style=\"width: 10%\">默认值</th>\n+        <th class=\"text-center\" style=\"width: 10%\">数据类型</th>\n+        <th class=\"text-center\" style=\"width: 45%\">描述</th>\n+      </tr>\n+    </thead>\n+    <tbody>\n+    <tr>\n+      <td><h5>connector</h5></td>\n+      <td>必须</td>\n+      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>String</td>\n+      <td>指定要使用的连接器，这里是 'datagen'。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>rows-per-second</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">10000</td>\n+      <td>Long</td>\n+      <td>每秒生成的行数，用以控制数据发出速率。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>fields.#.kind</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">random</td>\n+      <td>String</td>\n+      <td>指定 '#' 字段的生成器。可以是 'sequence' 或 'random'。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>fields.#.min</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">(Minimum value of type)</td>\n+      <td>(Type of field)</td>\n+      <td>随机生成器的最小值，适用于数字类型。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>fields.#.max</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">(Maximum value of type)</td>\n+      <td>(Type of field)</td>\n+      <td>随机生成器的最大值，适用于数字类型。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>fields.#.length</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">100</td>\n+      <td>Integer</td>\n+      <td>随机生成器生成字符的长度，适用于 char、varchar、string。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>fields.#.start</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>(Type of field)</td>\n+      <td>序列生成器的起始值。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>fields.#.end</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>(Type of field)</td>\n+      <td>序列生成器的结束值。</td>\n+    </tr>\n+    </tbody>\n+</table>"
        },
        {
            "sha": "6409dd13942ed7e128d7c141c6502b01b3f86097",
            "filename": "docs/content.zh/docs/connectors/table/downloads.md",
            "status": "added",
            "additions": 48,
            "deletions": 0,
            "changes": 48,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/downloads.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/downloads.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/table/downloads.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,48 @@\n+---\n+title: 下载页面\n+weight: 100\n+type: docs\n+bookToc: false\n+aliases:\n+  - /dev/table/connectors/downloads.html\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# SQL Connectors 下载页面\n+\n+{{< unstable >}}\n+{{< hint info >}}\n+Download links are available only for stable releases.\n+{{< /hint >}}\n+{{< /unstable >}}\n+\n+The page contains links to optional sql-client connectors and formats that are not part of the binary distribution.\n+\n+# 可选的 SQL formats\n+-------------------\n+\n+{{< sql_optional_formats >}}\n+\n+# 可选的 SQL 连接器\n+-------------------  \n+\n+{{< sql_optional_connectors >}}\n+\n+"
        },
        {
            "sha": "0d4f06fd79ec35b3858c992aba9e5aa33eec8f48",
            "filename": "docs/content.zh/docs/connectors/table/elasticsearch.md",
            "status": "added",
            "additions": 266,
            "deletions": 0,
            "changes": 266,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/elasticsearch.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/elasticsearch.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/table/elasticsearch.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,266 @@\n+---\n+title: Elasticsearch\n+weight: 7\n+type: docs\n+aliases:\n+  - /zh/dev/table/connectors/elasticsearch.html\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Elasticsearch SQL 连接器\n+\n+{{< label \"Sink: Batch\" >}}\n+{{< label \"Sink: Streaming Append & Upsert Mode\" >}}\n+\n+Elasticsearch 连接器允许将数据写入到 Elasticsearch 引擎的索引中。本文档描述运行 SQL 查询时如何设置 Elasticsearch 连接器。\n+\n+连接器可以工作在 upsert 模式，使用 DDL 中定义的主键与外部系统交换 UPDATE/DELETE 消息。\n+\n+如果 DDL 中没有定义主键，那么连接器只能工作在 append 模式，只能与外部系统交换 INSERT 消息。\n+\n+依赖\n+------------\n+\n+{{< sql_download_table \"elastic\" >}}\n+\n+如何创建 Elasticsearch 表\n+----------------\n+\n+以下示例展示了如何创建 Elasticsearch sink 表：\n+\n+```sql\n+CREATE TABLE myUserTable (\n+  user_id STRING,\n+  user_name STRING\n+  uv BIGINT,\n+  pv BIGINT,\n+  PRIMARY KEY (user_id) NOT ENFORCED\n+) WITH (\n+  'connector' = 'elasticsearch-7',\n+  'hosts' = 'http://localhost:9200',\n+  'index' = 'users'\n+);\n+```\n+\n+连接器参数\n+----------------\n+\n+<table class=\"table table-bordered\">\n+    <thead>\n+      <tr>\n+        <th class=\"text-left\" style=\"width: 25%\">参数</th>\n+        <th class=\"text-center\" style=\"width: 8%\">是否必选</th>\n+        <th class=\"text-center\" style=\"width: 7%\">默认值</th>\n+        <th class=\"text-center\" style=\"width: 10%\">数据类型</th>\n+        <th class=\"text-center\" style=\"width: 50%\">描述</th>\n+      </tr>\n+    </thead>\n+    <tbody>\n+    <tr>\n+      <td><h5>connector</h5></td>\n+      <td>必选</td>\n+      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>String</td>\n+      <td>指定要使用的连接器，有效值为：\n+      <ul>\n+      <li><code>elasticsearch-6</code>：连接到 Elasticsearch 6.x 的集群。</li>\n+      <li><code>elasticsearch-7</code>：连接到 Elasticsearch 7.x 及更高版本的集群。</li>\n+      </ul></td>\n+    </tr>\n+    <tr>\n+      <td><h5>hosts</h5></td>\n+      <td>必选</td>\n+      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>String</td>\n+      <td>要连接到的一台或多台 Elasticsearch 主机，例如 <code>'http://host_name:9092;http://host_name:9093'</code>。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>index</h5></td>\n+      <td>必选</td>\n+      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>String</td>\n+      <td>Elasticsearch 中每条记录的索引。可以是一个静态索引（例如 <code>'myIndex'</code>）或一个动态索引（例如 <code>'index-{log_ts|yyyy-MM-dd}'</code>）。\n+       更多详细信息，请参见下面的<a href=\"#动态索引\">动态索引</a>部分。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>document-type</h5></td>\n+      <td>6.x 版本中必选</td>\n+      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>String</td>\n+      <td>Elasticsearch 文档类型。在 <code>elasticsearch-7</code> 中不再需要。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>document-id.key-delimiter</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">_</td>\n+      <td>String</td>\n+      <td>复合键的分隔符（默认为\"_\"），例如，指定为\"$\"将导致文档 ID 为\"KEY1$KEY2$KEY3\"。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>username</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>String</td>\n+      <td>用于连接 Elasticsearch 实例的用户名。请注意，Elasticsearch 没有预绑定安全特性，但你可以通过如下<a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/master/configuring-security.html\">指南</a>启用它来保护 Elasticsearch 集群。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>password</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>String</td>\n+      <td>用于连接 Elasticsearch 实例的密码。如果配置了<code>username</code>，则此选项也必须配置为非空字符串。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>failure-handler</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">fail</td>\n+      <td>String</td>\n+      <td>对 Elasticsearch 请求失败情况下的失败处理策略。有效策略为：\n+      <ul>\n+        <li><code>fail</code>：如果请求失败并因此导致作业失败，则抛出异常。</li>\n+        <li><code>ignore</code>：忽略失败并放弃请求。</li>\n+        <li><code>retry-rejected</code>：重新添加由于队列容量饱和而失败的请求。</li>\n+        <li>自定义类名称：使用 ActionRequestFailureHandler 的子类进行失败处理。</li>\n+      </ul>\n+      </td>\n+    </tr>\n+    <tr>\n+      <td><h5>sink.flush-on-checkpoint</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">true</td>\n+      <td>Boolean</td>\n+      <td>是否在 checkpoint 时执行 flush。禁用后，在 checkpoint 时 sink 将不会等待所有的 pending 请求被 Elasticsearch 确认。因此，sink 不会为请求的 at-least-once 交付提供任何有力保证。\n+      </td>\n+    </tr>\n+    <tr>\n+      <td><h5>sink.bulk-flush.max-actions</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">1000</td>\n+      <td>Integer</td>\n+      <td>每个批量请求的最大缓冲操作数。\n+      可以设置为<code>'0'</code>来禁用它。\n+      </td>\n+    </tr>\n+    <tr>\n+      <td><h5>sink.bulk-flush.max-size</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">2mb</td>\n+      <td>MemorySize</td>\n+      <td>每个批量请求的缓冲操作在内存中的最大值。单位必须为 MB。\n+      可以设置为<code>'0'</code>来禁用它。\n+      </td>\n+    </tr>\n+    <tr>\n+      <td><h5>sink.bulk-flush.interval</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">1s</td>\n+      <td>Duration</td>\n+      <td>flush 缓冲操作的间隔。\n+        可以设置为<code>'0'</code>来禁用它。注意，<code>'sink.bulk-flush.max-size'</code>和<code>'sink.bulk-flush.max-actions'</code>都设置为<code>'0'</code>的这种 flush 间隔设置允许对缓冲操作进行完全异步处理。\n+      </td>\n+    </tr>\n+    <tr>\n+      <td><h5>sink.bulk-flush.backoff.strategy</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">DISABLED</td>\n+      <td>String</td>\n+      <td>指定在由于临时请求错误导致任何 flush 操作失败时如何执行重试。有效策略为：\n+      <ul>\n+        <li><code>DISABLED</code>：不执行重试，即第一次请求错误后失败。</li>\n+        <li><code>CONSTANT</code>：等待重试之间的回退延迟。</li>\n+        <li><code>EXPONENTIAL</code>：先等待回退延迟，然后在重试之间指数递增。</li>\n+      </ul>\n+      </td>\n+    </tr>\n+    <tr>\n+      <td><h5>sink.bulk-flush.backoff.max-retries</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">8</td>\n+      <td>Integer</td>\n+      <td>最大回退重试次数。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>sink.bulk-flush.backoff.delay</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">50ms</td>\n+      <td>Duration</td>\n+      <td>每次回退尝试之间的延迟。对于 <code>CONSTANT</code> 回退策略，该值是每次重试之间的延迟。对于 <code>EXPONENTIAL</code> 回退策略，该值是初始的延迟。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>connection.max-retry-timeout</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>Duration</td>\n+      <td>最大重试超时时间。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>connection.path-prefix</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>String</td>\n+      <td>添加到每个 REST 通信中的前缀字符串，例如，<code>'/v1'</code>。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>format</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">json</td>\n+      <td>String</td>\n+      <td>Elasticsearch 连接器支持指定格式。该格式必须生成一个有效的 json 文档。\n+       默认使用内置的 <code>'json'</code> 格式。更多详细信息，请参阅 <a href=\"{{< ref \"docs/connectors/table/formats/overview\" >}}\">JSON Format</a> 页面。\n+      </td>\n+    </tr>\n+    </tbody>\n+</table>\n+\n+特性\n+----------------\n+\n+### Key 处理\n+\n+Elasticsearch sink 可以根据是否定义了主键来确定是在 upsert 模式还是 append 模式下工作。\n+如果定义了主键，Elasticsearch sink 将以 upsert 模式工作，该模式可以消费包含 UPDATE/DELETE 消息的查询。\n+如果未定义主键，Elasticsearch sink 将以 append 模式工作，该模式只能消费包含 INSERT 消息的查询。\n+\n+在 Elasticsearch 连接器中，主键用于计算 Elasticsearch 的文档 id，文档 id 为最多 512 字节且不包含空格的字符串。\n+Elasticsearch 连接器通过使用 `document-id.key-delimiter` 指定的键分隔符按照 DDL 中定义的顺序连接所有主键字段，为每一行记录生成一个文档 ID 字符串。\n+某些类型不允许作为主键字段，因为它们没有对应的字符串表示形式，例如，`BYTES`，`ROW`，`ARRAY`，`MAP` 等。\n+如果未指定主键，Elasticsearch 将自动生成文档 id。\n+\n+有关 PRIMARY KEY 语法的更多详细信息，请参见 [CREATE TABLE DDL]({{< ref \"docs/dev/table/sql/create\" >}}#create-table)。\n+\n+### 动态索引\n+\n+Elasticsearch sink 同时支持静态索引和动态索引。\n+\n+如果你想使用静态索引，则 `index` 选项值应为纯字符串，例如 `'myusers'`，所有记录都将被写入到 \"myusers\" 索引中。\n+\n+如果你想使用动态索引，你可以使用 `{field_name}` 来引用记录中的字段值来动态生成目标索引。\n+你也可以使用 `'{field_name|date_format_string}'` 将 `TIMESTAMP/DATE/TIME` 类型的字段值转换为 `date_format_string` 指定的格式。\n+`date_format_string` 与 Java 的 [DateTimeFormatter](https://docs.oracle.com/javase/8/docs/api/index.html) 兼容。\n+例如，如果选项值设置为 `'myusers-{log_ts|yyyy-MM-dd}'`，则 `log_ts` 字段值为 `2020-03-27 12:25:55` 的记录将被写入到 \"myusers-2020-03-27\" 索引中。\n+\n+\n+数据类型映射\n+----------------\n+\n+Elasticsearch 将文档存储在 JSON 字符串中。因此数据类型映射介于 Flink 数据类型和 JSON 数据类型之间。\n+Flink 为 Elasticsearch 连接器使用内置的 `'json'` 格式。更多类型映射的详细信息，请参阅 [JSON Format]({{< ref \"docs/connectors/table/formats/json\" >}}) 页面。\n+\n+{{< top >}}"
        },
        {
            "sha": "effd8fb49b209572778627456b8bb2a78acdd613",
            "filename": "docs/content.zh/docs/connectors/table/filesystem.md",
            "status": "added",
            "additions": 487,
            "deletions": 0,
            "changes": 487,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/filesystem.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/filesystem.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/table/filesystem.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,487 @@\n+---\n+title: FileSystem\n+weight: 8\n+type: docs\n+aliases:\n+  - /zh/dev/table/connectors/filesystem.html\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# FileSystem SQL Connector\n+\n+This connector provides access to partitioned files in filesystems\n+supported by the [Flink FileSystem abstraction]({{< ref \"docs/deployment/filesystems/overview\" >}}).\n+\n+The file system connector itself is included in Flink and does not require an additional dependency.\n+A corresponding format needs to be specified for reading and writing rows from and to a file system.\n+\n+The file system connector allows for reading and writing from a local or distributed filesystem. A filesystem table can be defined as:\n+\n+```sql\n+CREATE TABLE MyUserTable (\n+  column_name1 INT,\n+  column_name2 STRING,\n+  ...\n+  part_name1 INT,\n+  part_name2 STRING\n+) PARTITIONED BY (part_name1, part_name2) WITH (\n+  'connector' = 'filesystem',           -- required: specify the connector\n+  'path' = 'file:///path/to/whatever',  -- required: path to a directory\n+  'format' = '...',                     -- required: file system connector requires to specify a format,\n+                                        -- Please refer to Table Formats\n+                                        -- section for more details\n+  'partition.default-name' = '...',     -- optional: default partition name in case the dynamic partition\n+                                        -- column value is null/empty string\n+\n+  -- optional: the option to enable shuffle data by dynamic partition fields in sink phase, this can greatly\n+  -- reduce the number of file for filesystem sink but may lead data skew, the default value is false.\n+  'sink.shuffle-by-partition.enable' = '...',\n+  ...\n+)\n+```\n+\n+{{< hint info >}}\n+Make sure to include [Flink File System specific dependencies]({{< ref \"docs/deployment/filesystems/overview\" >}}).\n+{{< /hint >}}\n+\n+{{< hint info >}}\n+File system sources for streaming is still under development. In the future, the community will add support for common streaming use cases, i.e., partition and directory monitoring.\n+{{< /hint >}}\n+\n+{{< hint warning >}}\n+The behaviour of file system connector is much different from `previous legacy filesystem connector`:\n+the path parameter is specified for a directory not for a file and you can't get a human-readable file in the path that you declare.\n+{{< /hint >}}\n+\n+## Partition Files\n+\n+Flink's file system partition support uses the standard hive format. However, it does not require partitions to be pre-registered with a table catalog. Partitions are discovered and inferred based on directory structure. For example, a table partitioned based on the directory below would be inferred to contain `datetime` and `hour` partitions.\n+\n+```\n+path\n+└── datetime=2019-08-25\n+    └── hour=11\n+        ├── part-0.parquet\n+        ├── part-1.parquet\n+    └── hour=12\n+        ├── part-0.parquet\n+└── datetime=2019-08-26\n+    └── hour=6\n+        ├── part-0.parquet\n+```\n+\n+The file system table supports both partition inserting and overwrite inserting. See [INSERT Statement]({{< ref \"docs/dev/table/sql/insert\" >}}). When you insert overwrite to a partitioned table, only the corresponding partition will be overwritten, not the entire table.\n+\n+## File Formats\n+\n+The file system connector supports multiple formats:\n+\n+ - CSV: [RFC-4180](https://tools.ietf.org/html/rfc4180). Uncompressed.\n+ - JSON: Note JSON format for file system connector is not a typical JSON file but uncompressed [newline delimited JSON](http://jsonlines.org/).\n+ - Avro: [Apache Avro](http://avro.apache.org). Support compression by configuring `avro.codec`.\n+ - Parquet: [Apache Parquet](http://parquet.apache.org). Compatible with Hive.\n+ - Orc: [Apache Orc](http://orc.apache.org). Compatible with Hive.\n+ - Debezium-JSON: [debezium-json]({{< ref \"docs/connectors/table/formats/debezium\" >}}).\n+ - Canal-JSON: [canal-json]({{< ref \"docs/connectors/table/formats/canal\" >}}).\n+ - Raw: [raw]({{< ref \"docs/connectors/table/formats/raw\" >}}).\n+\n+## Streaming Sink\n+\n+The file system connector supports streaming writes, based on Flink's [Streaming File Sink]({{< ref \"docs/connectors/datastream/streamfile_sink\" >}})\n+to write records to file. Row-encoded Formats are csv and json. Bulk-encoded Formats are parquet, orc and avro.\n+\n+You can write SQL directly, insert the stream data into the non-partitioned table.\n+If it is a partitioned table, you can configure partition related operations. See [Partition Commit](filesystem.html#partition-commit) for details.\n+\n+### Rolling Policy\n+\n+Data within the partition directories are split into part files. Each partition will contain at least one part file for\n+each subtask of the sink that has received data for that partition. The in-progress part file will be closed and additional\n+part file will be created according to the configurable rolling policy. The policy rolls part files based on size,\n+a timeout that specifies the maximum duration for which a file can be open.\n+\n+<table class=\"table table-bordered\">\n+  <thead>\n+    <tr>\n+        <th class=\"text-left\" style=\"width: 20%\">Key</th>\n+        <th class=\"text-left\" style=\"width: 15%\">Default</th>\n+        <th class=\"text-left\" style=\"width: 10%\">Type</th>\n+        <th class=\"text-left\" style=\"width: 55%\">Description</th>\n+    </tr>\n+  </thead>\n+  <tbody>\n+    <tr>\n+        <td><h5>sink.rolling-policy.file-size</h5></td>\n+        <td style=\"word-wrap: break-word;\">128MB</td>\n+        <td>MemorySize</td>\n+        <td>The maximum part file size before rolling.</td>\n+    </tr>\n+    <tr>\n+        <td><h5>sink.rolling-policy.rollover-interval</h5></td>\n+        <td style=\"word-wrap: break-word;\">30 min</td>\n+        <td>Duration</td>\n+        <td>The maximum time duration a part file can stay open before rolling (by default 30 min to avoid to many small files).\n+        The frequency at which this is checked is controlled by the 'sink.rolling-policy.check-interval' option.</td>\n+    </tr>\n+    <tr>\n+        <td><h5>sink.rolling-policy.check-interval</h5></td>\n+        <td style=\"word-wrap: break-word;\">1 min</td>\n+        <td>Duration</td>\n+        <td>The interval for checking time based rolling policies. This controls the frequency to check whether a part file should rollover based on 'sink.rolling-policy.rollover-interval'.</td>\n+    </tr>\n+  </tbody>\n+</table>\n+\n+**NOTE:** For bulk formats (parquet, orc, avro), the rolling policy in combination with the checkpoint interval(pending files\n+become finished on the next checkpoint) control the size and number of these parts.\n+\n+**NOTE:** For row formats (csv, json), you can set the parameter `sink.rolling-policy.file-size` or `sink.rolling-policy.rollover-interval` in the connector properties and parameter `execution.checkpointing.interval` in flink-conf.yaml together\n+if you don't want to wait a long period before observe the data exists in file system. For other formats (avro, orc), you can just set parameter `execution.checkpointing.interval` in flink-conf.yaml.\n+\n+### File Compaction\n+\n+The file sink supports file compactions, which allows applications to have smaller checkpoint intervals without generating a large number of files.\n+\n+<table class=\"table table-bordered\">\n+  <thead>\n+    <tr>\n+        <th class=\"text-left\" style=\"width: 20%\">Key</th>\n+        <th class=\"text-left\" style=\"width: 15%\">Default</th>\n+        <th class=\"text-left\" style=\"width: 10%\">Type</th>\n+        <th class=\"text-left\" style=\"width: 55%\">Description</th>\n+    </tr>\n+  </thead>\n+  <tbody>\n+    <tr>\n+        <td><h5>auto-compaction</h5></td>\n+        <td style=\"word-wrap: break-word;\">false</td>\n+        <td>Boolean</td>\n+        <td>Whether to enable automatic compaction in streaming sink or not. The data will be written to temporary files. After the checkpoint is completed, the temporary files generated by a checkpoint will be compacted. The temporary files are invisible before compaction.</td>\n+    </tr>\n+    <tr>\n+        <td><h5>compaction.file-size</h5></td>\n+        <td style=\"word-wrap: break-word;\">(none)</td>\n+        <td>MemorySize</td>\n+        <td>The compaction target file size, the default value is the rolling file size.</td>\n+    </tr>\n+  </tbody>\n+</table>\n+\n+If enabled, file compaction will merge multiple small files into larger files based on the target file size.\n+When running file compaction in production, please be aware that:\n+- Only files in a single checkpoint are compacted, that is, at least the same number of files as the number of checkpoints is generated.\n+- The file before merging is invisible, so the visibility of the file may be: checkpoint interval + compaction time.\n+- If the compaction takes too long, it will backpressure the job and extend the time period of checkpoint.\n+\n+### Partition Commit\n+\n+After writing a partition, it is often necessary to notify downstream applications. For example, add the partition to a Hive metastore or writing a `_SUCCESS` file in the directory. The file system sink contains a partition commit feature that allows configuring custom policies. Commit actions are based on a combination of `triggers` and `policies`.\n+\n+- Trigger: The timing of the commit of the partition can be determined by the watermark with the time extracted from the partition, or by processing time.\n+- Policy: How to commit a partition, built-in policies support for the commit of success files and metastore, you can also implement your own policies, such as triggering hive's analysis to generate statistics, or merging small files, etc.\n+\n+**NOTE:** Partition Commit only works in dynamic partition inserting.\n+\n+#### Partition commit trigger\n+\n+To define when to commit a partition, providing partition commit trigger:\n+\n+<table class=\"table table-bordered\">\n+  <thead>\n+    <tr>\n+        <th class=\"text-left\" style=\"width: 20%\">Key</th>\n+        <th class=\"text-left\" style=\"width: 15%\">Default</th>\n+        <th class=\"text-left\" style=\"width: 10%\">Type</th>\n+        <th class=\"text-left\" style=\"width: 55%\">Description</th>\n+    </tr>\n+  </thead>\n+  <tbody>\n+    <tr>\n+        <td><h5>sink.partition-commit.trigger</h5></td>\n+        <td style=\"word-wrap: break-word;\">process-time</td>\n+        <td>String</td>\n+        <td>Trigger type for partition commit: 'process-time': based on the time of the machine, it neither requires partition time extraction nor watermark generation. Commit partition once the 'current system time' passes 'partition creation system time' plus 'delay'. 'partition-time': based on the time that extracted from partition values, it requires watermark generation. Commit partition once the 'watermark' passes 'time extracted from partition values' plus 'delay'.</td>\n+    </tr>\n+    <tr>\n+        <td><h5>sink.partition-commit.delay</h5></td>\n+        <td style=\"word-wrap: break-word;\">0 s</td>\n+        <td>Duration</td>\n+        <td>The partition will not commit until the delay time. If it is a daily partition, should be '1 d', if it is a hourly partition, should be '1 h'.</td>\n+    </tr>\n+    <tr>\n+        <td><h5>sink.partition-commit.watermark-time-zone</h5></td>\n+        <td style=\"word-wrap: break-word;\">UTC</td>\n+        <td>String</td>\n+        <td>The time zone to parse the long watermark value to TIMESTAMP value, the parsed watermark timestamp is used to compare with partition time to decide the partition should commit or not. This option is only take effect when `sink.partition-commit.trigger` is set to 'partition-time'. If this option is not configured correctly, e.g. source rowtime is defined on TIMESTAMP_LTZ column, but this config is not configured, then users may see the partition committed after a few hours. The default value is 'UTC', which means the watermark is defined on TIMESTAMP column or not defined. If the watermark is defined on TIMESTAMP_LTZ column, the time zone of watermark is the session time zone. The option value is either a full name such as 'America/Los_Angeles', or a custom timezone id such as 'GMT-08:00'.</td>\n+    </tr>        \n+  </tbody>\n+</table>\n+\n+There are two types of trigger:\n+- The first is partition processing time. It neither requires partition time extraction nor watermark\n+generation. The trigger of partition commit according to partition creation time and current system time. This trigger\n+is more universal, but not so precise. For example, data delay or failover will lead to premature partition commit.\n+- The second is the trigger of partition commit according to the time that extracted from partition values and watermark.\n+This requires that your job has watermark generation, and the partition is divided according to time, such as\n+hourly partition or daily partition.\n+\n+If you want to let downstream see the partition as soon as possible, no matter whether its data is complete or not:\n+- 'sink.partition-commit.trigger'='process-time' (Default value)\n+- 'sink.partition-commit.delay'='0s' (Default value)\n+Once there is data in the partition, it will immediately commit. Note: the partition may be committed multiple times.\n+\n+If you want to let downstream see the partition only when its data is complete, and your job has watermark generation, and you can extract the time from partition values:\n+- 'sink.partition-commit.trigger'='partition-time'\n+- 'sink.partition-commit.delay'='1h' ('1h' if your partition is hourly partition, depends on your partition type)\n+This is the most accurate way to commit partition, and it will try to ensure that the committed partitions are as data complete as possible.\n+\n+If you want to let downstream see the partition only when its data is complete, but there is no watermark, or the time cannot be extracted from partition values:\n+- 'sink.partition-commit.trigger'='process-time' (Default value)\n+- 'sink.partition-commit.delay'='1h' ('1h' if your partition is hourly partition, depends on your partition type)\n+Try to commit partition accurately, but data delay or failover will lead to premature partition commit.\n+\n+Late data processing: The record will be written into its partition when a record is supposed to be\n+written into a partition that has already been committed, and then the committing of this partition\n+will be triggered again.\n+\n+#### Partition Time Extractor\n+\n+Time extractors define extracting time from partition values.\n+\n+<table class=\"table table-bordered\">\n+  <thead>\n+    <tr>\n+        <th class=\"text-left\" style=\"width: 20%\">Key</th>\n+        <th class=\"text-left\" style=\"width: 15%\">Default</th>\n+        <th class=\"text-left\" style=\"width: 10%\">Type</th>\n+        <th class=\"text-left\" style=\"width: 55%\">Description</th>\n+    </tr>\n+  </thead>\n+  <tbody>\n+    <tr>\n+        <td><h5>partition.time-extractor.kind</h5></td>\n+        <td style=\"word-wrap: break-word;\">default</td>\n+        <td>String</td>\n+        <td>Time extractor to extract time from partition values. Support default and custom. For default, can configure timestamp pattern. For custom, should configure extractor class.</td>\n+    </tr>\n+    <tr>\n+        <td><h5>partition.time-extractor.class</h5></td>\n+        <td style=\"word-wrap: break-word;\">(none)</td>\n+        <td>String</td>\n+        <td>The extractor class for implement PartitionTimeExtractor interface.</td>\n+    </tr>\n+    <tr>\n+        <td><h5>partition.time-extractor.timestamp-pattern</h5></td>\n+        <td style=\"word-wrap: break-word;\">(none)</td>\n+        <td>String</td>\n+        <td>The 'default' construction way allows users to use partition fields to get a legal timestamp pattern. Default support 'yyyy-mm-dd hh:mm:ss' from first field. If timestamp should be extracted from a single partition field 'dt', can configure: '$dt'. If timestamp should be extracted from multiple partition fields, say 'year', 'month', 'day' and 'hour', can configure: '$year-$month-$day $hour:00:00'. If timestamp should be extracted from two partition fields 'dt' and 'hour', can configure: '$dt $hour:00:00'.</td>\n+    </tr>\n+  </tbody>\n+</table>\n+\n+The default extractor is based on a timestamp pattern composed of your partition fields. You can also specify an implementation for fully custom partition extraction based on the `PartitionTimeExtractor` interface.\n+\n+```java\n+\n+public class HourPartTimeExtractor implements PartitionTimeExtractor {\n+    @Override\n+    public LocalDateTime extract(List<String> keys, List<String> values) {\n+        String dt = values.get(0);\n+        String hour = values.get(1);\n+\t\treturn Timestamp.valueOf(dt + \" \" + hour + \":00:00\").toLocalDateTime();\n+\t}\n+}\n+\n+```\n+\n+#### Partition Commit Policy\n+\n+The partition commit policy defines what action is taken when partitions are committed.\n+\n+- The first is metastore, only hive table supports metastore policy, file system manages partitions through directory structure.\n+- The second is the success file, which will write an empty file in the directory corresponding to the partition. \n+\n+<table class=\"table table-bordered\">\n+  <thead>\n+    <tr>\n+        <th class=\"text-left\" style=\"width: 20%\">Key</th>\n+        <th class=\"text-left\" style=\"width: 15%\">Default</th>\n+        <th class=\"text-left\" style=\"width: 10%\">Type</th>\n+        <th class=\"text-left\" style=\"width: 55%\">Description</th>\n+    </tr>\n+  </thead>\n+  <tbody>\n+    <tr>\n+        <td><h5>sink.partition-commit.policy.kind</h5></td>\n+        <td style=\"word-wrap: break-word;\">(none)</td>\n+        <td>String</td>\n+        <td>Policy to commit a partition is to notify the downstream application that the partition has finished writing, the partition is ready to be read. metastore: add partition to metastore. Only hive table supports metastore policy, file system manages partitions through directory structure. success-file: add '_success' file to directory. Both can be configured at the same time: 'metastore,success-file'. custom: use policy class to create a commit policy. Support to configure multiple policies: 'metastore,success-file'.</td>\n+    </tr>\n+    <tr>\n+        <td><h5>sink.partition-commit.policy.class</h5></td>\n+        <td style=\"word-wrap: break-word;\">(none)</td>\n+        <td>String</td>\n+        <td>The partition commit policy class for implement PartitionCommitPolicy interface. Only work in custom commit policy.</td>\n+    </tr>\n+    <tr>\n+        <td><h5>sink.partition-commit.success-file.name</h5></td>\n+        <td style=\"word-wrap: break-word;\">_SUCCESS</td>\n+        <td>String</td>\n+        <td>The file name for success-file partition commit policy, default is '_SUCCESS'.</td>\n+    </tr>\n+  </tbody>\n+</table>\n+\n+You can extend the implementation of commit policy, The custom commit policy implementation like:\n+\n+```java\n+\n+public class AnalysisCommitPolicy implements PartitionCommitPolicy {\n+    private HiveShell hiveShell;\n+\t\n+    @Override\n+\tpublic void commit(Context context) throws Exception {\n+\t    if (hiveShell == null) {\n+\t        hiveShell = createHiveShell(context.catalogName());\n+\t    }\n+\t    \n+        hiveShell.execute(String.format(\n+            \"ALTER TABLE %s ADD IF NOT EXISTS PARTITION (%s = '%s') location '%s'\",\n+\t        context.tableName(),\n+\t        context.partitionKeys().get(0),\n+\t        context.partitionValues().get(0),\n+\t        context.partitionPath()));\n+\t    hiveShell.execute(String.format(\n+\t        \"ANALYZE TABLE %s PARTITION (%s = '%s') COMPUTE STATISTICS FOR COLUMNS\",\n+\t        context.tableName(),\n+\t        context.partitionKeys().get(0),\n+\t        context.partitionValues().get(0)));\n+\t}\n+}\n+\n+```\n+\n+## Sink Parallelism\n+\n+The parallelism of writing files into external file system (including Hive) can be configured by the corresponding table option, which is supported both in streaming mode and in batch mode. By default, the parallelism is configured to being the same as the parallelism of its last upstream chained operator. When the parallelism which is different from the parallelism of the upstream parallelism is configured, the operator of writing files and the operator compacting files (if used) will apply the parallelism.\n+\n+\n+<table class=\"table table-bordered\">\n+  <thead>\n+    <tr>\n+        <th class=\"text-left\" style=\"width: 20%\">Key</th>\n+        <th class=\"text-left\" style=\"width: 15%\">Default</th>\n+        <th class=\"text-left\" style=\"width: 10%\">Type</th>\n+        <th class=\"text-left\" style=\"width: 55%\">Description</th>\n+    </tr>\n+  </thead>\n+  <tbody>\n+    <tr>\n+        <td><h5>sink.parallelism</h5></td>\n+        <td style=\"word-wrap: break-word;\">(none)</td>\n+        <td>Integer</td>\n+        <td>Parallelism of writing files into external file system. The value should greater than zero otherwise exception will be thrown.</td>\n+    </tr>\n+    \n+  </tbody>\n+</table>\n+\n+**NOTE:** Currently, Configuring sink parallelism is supported if and only if the changelog mode of upstream is **INSERT-ONLY**. Otherwise, exception will be thrown.\n+\n+## Full Example\n+\n+The below examples show how the file system connector can be used to write a streaming query to write data from Kafka into a file system and runs a batch query to read that data back out.\n+\n+```sql\n+\n+CREATE TABLE kafka_table (\n+  user_id STRING,\n+  order_amount DOUBLE,\n+  log_ts TIMESTAMP(3),\n+  WATERMARK FOR log_ts AS log_ts - INTERVAL '5' SECOND -- Define watermark on TIMESTAMP column\n+) WITH (...);\n+\n+CREATE TABLE fs_table (\n+  user_id STRING,\n+  order_amount DOUBLE,\n+  dt STRING,\n+  `hour` STRING\n+) PARTITIONED BY (dt, `hour`) WITH (\n+  'connector'='filesystem',\n+  'path'='...',\n+  'format'='parquet',\n+  'sink.partition-commit.delay'='1 h',\n+  'sink.partition-commit.policy.kind'='success-file'\n+);\n+\n+-- streaming sql, insert into file system table\n+INSERT INTO fs_table \n+SELECT \n+    user_id, \n+    order_amount, \n+    DATE_FORMAT(log_ts, 'yyyy-MM-dd'),\n+    DATE_FORMAT(log_ts, 'HH') \n+FROM kafka_table;\n+\n+-- batch sql, select with partition pruning\n+SELECT * FROM fs_table WHERE dt='2020-05-20' and `hour`='12';\n+```\n+\n+If the watermark is defined on TIMESTAMP_LTZ column and used `partition-time` to commit, the `sink.partition-commit.watermark-time-zone` is required to set to the session time zone, otherwise the partition committed may happen after a few hours.  \n+```sql\n+\n+CREATE TABLE kafka_table (\n+  user_id STRING,\n+  order_amount DOUBLE,\n+  ts BIGINT, -- time in epoch milliseconds\n+  ts_ltz AS TO_TIMESTAMP_LTZ(ts, 3),\n+  WATERMARK FOR ts_ltz AS ts_ltz - INTERVAL '5' SECOND -- Define watermark on TIMESTAMP_LTZ column\n+) WITH (...);\n+\n+CREATE TABLE fs_table (\n+  user_id STRING,\n+  order_amount DOUBLE,\n+  dt STRING,\n+  `hour` STRING\n+) PARTITIONED BY (dt, `hour`) WITH (\n+  'connector'='filesystem',\n+  'path'='...',\n+  'format'='parquet',\n+  'partition.time-extractor.timestamp-pattern'='$dt $hour:00:00',\n+  'sink.partition-commit.delay'='1 h',\n+  'sink.partition-commit.trigger'='partition-time',\n+  'sink.partition-commit.watermark-time-zone'='Asia/Shanghai', -- Assume user configured time zone is 'Asia/Shanghai'\n+  'sink.partition-commit.policy.kind'='success-file'\n+);\n+\n+-- streaming sql, insert into file system table\n+INSERT INTO fs_table \n+SELECT \n+    user_id, \n+    order_amount, \n+    DATE_FORMAT(ts_ltz, 'yyyy-MM-dd'),\n+    DATE_FORMAT(ts_ltz, 'HH') \n+FROM kafka_table;\n+\n+-- batch sql, select with partition pruning\n+SELECT * FROM fs_table WHERE dt='2020-05-20' and `hour`='12';\n+```\n+\n+{{< top >}}"
        },
        {
            "sha": "8faac1684ff9665e9a1dbb471b99fd549c0c44cc",
            "filename": "docs/content.zh/docs/connectors/table/formats/_index.md",
            "status": "added",
            "additions": 23,
            "deletions": 0,
            "changes": 23,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/formats/_index.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/formats/_index.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/table/formats/_index.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,23 @@\n+---\n+title: Formats\n+bookCollapseSection: true\n+weight: 2\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n\\ No newline at end of file"
        },
        {
            "sha": "9ff6abaef6591701224ad6029326eec7b44aed05",
            "filename": "docs/content.zh/docs/connectors/table/formats/avro-confluent.md",
            "status": "added",
            "additions": 278,
            "deletions": 0,
            "changes": 278,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/formats/avro-confluent.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/formats/avro-confluent.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/table/formats/avro-confluent.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,278 @@\n+---\n+title: Confluent Avro\n+weight: 4\n+type: docs\n+aliases:\n+  - /zh/dev/table/connectors/formats/avro-confluent.html\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Confluent Avro Format\n+\n+<span class=\"label label-info\">Format: Serialization Schema</span>\n+<span class=\"label label-info\">Format: Deserialization Schema</span>\n+\n+\n+\n+Avro Schema Registry (``avro-confluent``) 格式能让你读取被 ``io.confluent.kafka.serializers.KafkaAvroSerializer`` 序列化的记录，以及可以写入成能被 ``io.confluent.kafka.serializers.KafkaAvroDeserializer`` 反序列化的记录。\n+\n+当以这种格式读取（反序列化）记录时，将根据记录中编码的 schema 版本 id 从配置的 Confluent Schema Registry 中获取 Avro writer schema ，而从 table schema 中推断出 reader schema。\n+\n+当以这种格式写入（序列化）记录时，Avro schema 是从 table schema 中推断出来的，并会用来检索要与数据一起编码的 schema id。我们会在配置的 Confluent Schema Registry 中配置的 [subject](https://docs.confluent.io/current/schema-registry/index.html#schemas-subjects-and-topics) 下，检索 schema id。subject 通过 `avro-confluent.schema-registry.subject` 参数来制定。\n+\n+Avro Schema Registry 格式只能与 [Apache Kafka SQL 连接器]({{< ref \"docs/connectors/table/kafka\" >}})或 [Upsert Kafka SQL 连接器]({{< ref \"docs/connectors/table/upsert-kafka\" >}})一起使用。\n+\n+依赖\n+------------\n+\n+{{< sql_download_table \"avro-confluent\" >}}\n+\n+如何创建使用 Avro-Confluent 格式的表\n+----------------\n+\n+以下是一个使用 Kafka 连接器和 Confluent Avro 格式创建表的示例。\n+\n+{{< tabs \"3df131fd-0e20-4635-a8f9-3574a764db7a\" >}}\n+{{< tab \"SQL\" >}}\n+\n+使用原始的 UTF-8 字符串作为 Kafka 的 key，Schema Registry 中注册的 Avro 记录作为 Kafka 的 values 的表的示例：\n+\n+```sql\n+CREATE TABLE user_created (\n+\n+  -- 该列映射到 Kafka 原始的 UTF-8 key\n+  the_kafka_key STRING,\n+  \n+  -- 映射到 Kafka value 中的 Avro 字段的一些列\n+  id STRING,\n+  name STRING,\n+  email STRING\n+\n+) WITH (\n+\n+  'connector' = 'kafka',\n+  'topic' = 'user_events_example1',\n+  'properties.bootstrap.servers' = 'localhost:9092',\n+\n+  -- UTF-8 字符串作为 Kafka 的 keys，使用表中的 'the_kafka_key' 列\n+  'key.format' = 'raw',\n+  'key.fields' = 'the_kafka_key',\n+\n+  'value.format' = 'avro-confluent',\n+  'value.avro-confluent.schema-registry.url' = 'http://localhost:8082',\n+  'value.fields-include' = 'EXCEPT_KEY'\n+)\n+```\n+\n+我们可以像下面这样将数据写入到 kafka 表中：\n+\n+```sql\n+INSERT INTO user_created\n+SELECT\n+  -- 将 user id 复制至映射到 kafka key 的列中\n+  id as the_kafka_key,\n+\n+  -- 所有的 values\n+  id, name, email\n+FROM some_table\n+```\n+\n+---\n+\n+Kafka 的 key 和 value 在 Schema Registry 中都注册为 Avro 记录的表的示例：\n+\n+```sql\n+CREATE TABLE user_created (\n+  \n+  -- 该列映射到 Kafka key 中的 Avro 字段 'id'\n+  kafka_key_id STRING,\n+  \n+  -- 映射到 Kafka value 中的 Avro 字段的一些列\n+  id STRING,\n+  name STRING, \n+  email STRING\n+  \n+) WITH (\n+\n+  'connector' = 'kafka',\n+  'topic' = 'user_events_example2',\n+  'properties.bootstrap.servers' = 'localhost:9092',\n+\n+  -- 注意：由于哈希分区，在 Kafka key 的上下文中，schema 升级几乎从不向后也不向前兼容。\n+  'key.format' = 'avro-confluent',\n+  'key.avro-confluent.schema-registry.url' = 'http://localhost:8082',\n+  'key.fields' = 'kafka_key_id',\n+\n+  -- 在本例中，我们希望 Kafka 的 key 和 value 的 Avro 类型都包含 'id' 字段\n+  -- => 给表中与 Kafka key 字段关联的列添加一个前缀来避免冲突\n+  'key.fields-prefix' = 'kafka_key_',\n+\n+  'value.format' = 'avro-confluent',\n+  'value.avro-confluent.schema-registry.url' = 'http://localhost:8082',\n+  'value.fields-include' = 'EXCEPT_KEY',\n+   \n+  -- 自 Flink 1.13 起，subjects 具有一个默认值, 但是可以被覆盖：\n+  'key.avro-confluent.schema-registry.subject' = 'user_events_example2-key2',\n+  'value.avro-confluent.schema-registry.subject' = 'user_events_example2-value2'\n+)\n+```\n+\n+---\n+使用 upsert-kafka 连接器，Kafka 的 value 在 Schema Registry 中注册为 Avro 记录的表的示例：\n+\n+```sql\n+CREATE TABLE user_created (\n+  \n+  -- 该列映射到 Kafka 原始的 UTF-8 key\n+  kafka_key_id STRING,\n+  \n+  -- 映射到 Kafka value 中的 Avro 字段的一些列\n+  id STRING, \n+  name STRING, \n+  email STRING, \n+  \n+  -- upsert-kafka 连接器需要一个主键来定义 upsert 行为\n+  PRIMARY KEY (kafka_key_id) NOT ENFORCED\n+\n+) WITH (\n+\n+  'connector' = 'upsert-kafka',\n+  'topic' = 'user_events_example3',\n+  'properties.bootstrap.servers' = 'localhost:9092',\n+\n+  -- UTF-8 字符串作为 Kafka 的 keys\n+  -- 在本例中我们不指定 'key.fields'，因为它由表的主键决定\n+  'key.format' = 'raw',\n+  \n+  -- 在本例中，我们希望 Kafka 的 key 和 value 的 Avro 类型都包含 'id' 字段\n+  -- => 给表中与 Kafka key 字段关联的列添加一个前缀来避免冲突\n+  'key.fields-prefix' = 'kafka_key_',\n+\n+  'value.format' = 'avro-confluent',\n+  'value.avro-confluent.schema-registry.url' = 'http://localhost:8082',\n+  'value.fields-include' = 'EXCEPT_KEY'\n+)\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+Format 参数\n+----------------\n+\n+<table class=\"table table-bordered\">\n+    <thead>\n+      <tr>\n+        <th class=\"text-left\" style=\"width: 25%\">参数</th>\n+        <th class=\"text-center\" style=\"width: 8%\">是否必选</th>\n+        <th class=\"text-center\" style=\"width: 7%\">默认值</th>\n+        <th class=\"text-center\" style=\"width: 10%\">类型</th>\n+        <th class=\"text-center\" style=\"width: 50%\">描述</th>\n+      </tr>\n+    </thead>\n+    <tbody>\n+        <tr>\n+            <td><h5>format</h5></td>\n+            <td>required</td>\n+            <td style=\"word-wrap: break-word;\">(none)</td>\n+            <td>String</td>\n+            <td>Specify what format to use, here should be <code>'avro-confluent'</code>.</td>\n+        </tr>\n+        <tr>\n+            <td><h5>avro-confluent.basic-auth.credentials-source</h5></td>\n+            <td>optional</td>\n+            <td style=\"word-wrap: break-word;\">(none)</td>\n+            <td>String</td>\n+            <td>Basic auth credentials source for Schema Registry</td>\n+        </tr>\n+        <tr>\n+            <td><h5>avro-confluent.basic-auth.user-info</h5></td>\n+            <td>optional</td>\n+            <td style=\"word-wrap: break-word;\">(none)</td>\n+            <td>String</td>\n+            <td>Basic auth user info for schema registry</td>\n+        </tr>\n+        <tr>\n+            <td><h5>avro-confluent.bearer-auth.credentials-source</h5></td>\n+            <td>optional</td>\n+            <td style=\"word-wrap: break-word;\">(none)</td>\n+            <td>String</td>\n+            <td>Bearer auth credentials source for Schema Registry</td>\n+        </tr>\n+        <tr>\n+            <td><h5>avro-confluent.bearer-auth.token</h5></td>\n+            <td>optional</td>\n+            <td style=\"word-wrap: break-word;\">(none)</td>\n+            <td>String</td>\n+            <td>Bearer auth token for Schema Registry</td>\n+        </tr>\n+        <tr>\n+            <td><h5>avro-confluent.ssl.keystore.location</h5></td>\n+            <td>optional</td>\n+            <td style=\"word-wrap: break-word;\">(none)</td>\n+            <td>String</td>\n+            <td>Location / File of SSL keystore</td>\n+        </tr>\n+        <tr>\n+            <td><h5>avro-confluent.ssl.keystore.password</h5></td>\n+            <td>optional</td>\n+            <td style=\"word-wrap: break-word;\">(none)</td>\n+            <td>String</td>\n+            <td>Password for SSL keystore</td>\n+        </tr>\n+        <tr>\n+            <td><h5>avro-confluent.ssl.truststore.location</h5></td>\n+            <td>optional</td>\n+            <td style=\"word-wrap: break-word;\">(none)</td>\n+            <td>String</td>\n+            <td>Location / File of SSL truststore</td>\n+        </tr>\n+        <tr>\n+            <td><h5>avro-confluent.ssl.truststore.password</h5></td>\n+            <td>optional</td>\n+            <td style=\"word-wrap: break-word;\">(none)</td>\n+            <td>String</td>\n+            <td>Password for SSL truststore</td>\n+        </tr>\n+        <tr>\n+            <td><h5>avro-confluent.schema-registry.subject</h5></td>\n+            <td>optional</td>\n+            <td style=\"word-wrap: break-word;\">(none)</td>\n+            <td>String</td>\n+            <td>The Confluent Schema Registry subject under which to register the schema used by this format during serialization. By default, 'kafka' and 'upsert-kafka' connectors use '&lt;topic_name&gt;-value' or '&lt;topic_name&gt;-key' as the default subject name if this format is used as the value or key format. But for other connectors (e.g. 'filesystem'), the subject option is required when used as sink.</td>\n+        </tr>\n+        <tr>\n+            <td><h5>avro-confluent.schema-registry.url</h5></td>\n+            <td>required</td>\n+            <td style=\"word-wrap: break-word;\">(none)</td>\n+            <td>String</td>\n+            <td>The URL of the Confluent Schema Registry to fetch/register schemas.</td>\n+        </tr>\n+    </tbody>\n+</table>\n+\n+数据类型映射\n+----------------\n+\n+目前 Apache Flink 都是从 table schema 去推断反序列化期间的 Avro reader schema 和序列化期间的 Avro writer schema。显式地定义 Avro schema 暂不支持。\n+[Apache Avro Format]({{< ref \"docs/connectors/table/formats/avro\" >}}#data-type-mapping)中描述了 Flink 数据类型和 Avro 类型的对应关系。 \n+\n+除了此处列出的类型之外，Flink 还支持读取/写入可为空（nullable）的类型。 Flink 将可为空的类型映射到 Avro `union(something, null)`, 其中 `something` 是从 Flink 类型转换的 Avro 类型。\n+\n+您可以参考 [Avro Specification](https://avro.apache.org/docs/current/spec.html) 以获取有关 Avro 类型的更多信息。"
        },
        {
            "sha": "7edb8bf3873e3b180de7afc7a1bd9586e66a6ce2",
            "filename": "docs/content.zh/docs/connectors/table/formats/avro.md",
            "status": "added",
            "additions": 198,
            "deletions": 0,
            "changes": 198,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/formats/avro.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/formats/avro.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/table/formats/avro.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,198 @@\n+---\n+title: Avro\n+weight: 4\n+type: docs\n+aliases:\n+  - /zh/dev/table/connectors/formats/avro.html\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Avro Format\n+\n+{{< label \"Format: Serialization Schema\" >}}\n+{{< label \"Format: Deserialization Schema\" >}}\n+\n+[Apache Avro](https://avro.apache.org/) format 允许基于 Avro schema 读取和写入 Avro 数据。目前，Avro schema 从 table schema 推导而来。\n+\n+依赖\n+------------\n+\n+{{< sql_download_table \"avro\" >}}\n+\n+\n+如何使用 Avro format 创建表\n+----------------\n+\n+这是使用 Kafka 连接器和 Avro format 创建表的示例。\n+\n+```sql\n+CREATE TABLE user_behavior (\n+  user_id BIGINT,\n+  item_id BIGINT,\n+  category_id BIGINT,\n+  behavior STRING,\n+  ts TIMESTAMP(3)\n+) WITH (\n+ 'connector' = 'kafka',\n+ 'topic' = 'user_behavior',\n+ 'properties.bootstrap.servers' = 'localhost:9092',\n+ 'properties.group.id' = 'testGroup',\n+ 'format' = 'avro'\n+)\n+```\n+\n+Format 参数\n+----------------\n+\n+<table class=\"table table-bordered\">\n+    <thead>\n+      <tr>\n+        <th class=\"text-left\" style=\"width: 25%\">参数</th>\n+        <th class=\"text-center\" style=\"width: 10%\">是否必选</th>\n+        <th class=\"text-center\" style=\"width: 10%\">默认值</th>\n+        <th class=\"text-center\" style=\"width: 10%\">类型</th>\n+        <th class=\"text-center\" style=\"width: 45%\">描述</th>\n+      </tr>\n+    </thead>\n+    <tbody>\n+    <tr>\n+      <td><h5>format</h5></td>\n+      <td>必要</td>\n+      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>String</td>\n+      <td>指定使用什么 format，这里应该是 <code>'avro'</code>。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>avro.codec</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>String</td>\n+      <td>仅用于 <a href=\"{{< ref \"docs/connectors/table/filesystem\" >}}\">filesystem</a>，avro 压缩编解码器。默认不压缩。目前支持：deflate、snappy、bzip2、xz。</td>\n+    </tr>\n+    </tbody>\n+</table>\n+\n+数据类型映射\n+----------------\n+\n+目前，Avro schema 通常是从 table schema 中推导而来。尚不支持显式定义 Avro schema。因此，下表列出了从 Flink 类型到 Avro 类型的类型映射。\n+\n+<table class=\"table table-bordered\">\n+    <thead>\n+      <tr>\n+        <th class=\"text-left\">Flink SQL 类型</th>\n+        <th class=\"text-left\">Avro 类型</th>\n+        <th class=\"text-left\">Avro 逻辑类型</th>\n+      </tr>\n+    </thead>\n+    <tbody>\n+    <tr>\n+      <td>CHAR / VARCHAR / STRING</td>\n+      <td>string</td>\n+      <td></td>\n+    </tr>\n+    <tr>\n+      <td><code>BOOLEAN</code></td>\n+      <td><code>boolean</code></td>\n+      <td></td>\n+    </tr>\n+    <tr>\n+      <td><code>BINARY / VARBINARY</code></td>\n+      <td><code>bytes</code></td>\n+      <td></td>\n+    </tr>\n+    <tr>\n+      <td><code>DECIMAL</code></td>\n+      <td><code>fixed</code></td>\n+      <td><code>decimal</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>TINYINT</code></td>\n+      <td><code>int</code></td>\n+      <td></td>\n+    </tr>\n+    <tr>\n+      <td><code>SMALLINT</code></td>\n+      <td><code>int</code></td>\n+      <td></td>\n+    </tr>\n+    <tr>\n+      <td><code>INT</code></td>\n+      <td><code>int</code></td>\n+      <td></td>\n+    </tr>\n+    <tr>\n+      <td><code>BIGINT</code></td>\n+      <td><code>long</code></td>\n+      <td></td>\n+    </tr>\n+    <tr>\n+      <td><code>FLOAT</code></td>\n+      <td><code>float</code></td>\n+      <td></td>\n+    </tr>\n+    <tr>\n+      <td><code>DOUBLE</code></td>\n+      <td><code>double</code></td>\n+      <td></td>\n+    </tr>\n+    <tr>\n+      <td><code>DATE</code></td>\n+      <td><code>int</code></td>\n+      <td><code>date</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>TIME</code></td>\n+      <td><code>int</code></td>\n+      <td><code>time-millis</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>TIMESTAMP</code></td>\n+      <td><code>long</code></td>\n+      <td><code>timestamp-millis</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>ARRAY</code></td>\n+      <td><code>array</code></td>\n+      <td></td>\n+    </tr>\n+    <tr>\n+      <td><code>MAP</code><br>\n+      (key 必须是 string/char/varchar 类型)</td>\n+      <td><code>map</code></td>\n+      <td></td>\n+    </tr>\n+    <tr>\n+      <td><code>MULTISET</code><br>\n+      (元素必须是 string/char/varchar 类型)</td>\n+      <td><code>map</code></td>\n+      <td></td>\n+    </tr>\n+    <tr>\n+      <td><code>ROW</code></td>\n+      <td><code>record</code></td>\n+      <td></td>\n+    </tr>\n+    </tbody>\n+</table>\n+\n+除了上面列出的类型，Flink 支持读取/写入 nullable 的类型。Flink 将 nullable 的类型映射到 Avro `union(something, null)`，其中 `something` 是从 Flink 类型转换的 Avro 类型。\n+\n+您可以参考 [Avro 规范](https://avro.apache.org/docs/current/spec.html) 获取更多有关 Avro 类型的信息。"
        },
        {
            "sha": "d7630f94f4203d0571465747f56ce01fe2481ff4",
            "filename": "docs/content.zh/docs/connectors/table/formats/canal.md",
            "status": "added",
            "additions": 305,
            "deletions": 0,
            "changes": 305,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/formats/canal.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/formats/canal.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/table/formats/canal.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,305 @@\n+---\n+title: Canal\n+weight: 6\n+type: docs\n+aliases:\n+  - /zh/dev/table/connectors/formats/canal.html\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Canal Format\n+\n+{{< label \"Changelog-Data-Capture Format\" >}}\n+{{< label \"Format: Serialization Schema\" >}}\n+{{< label \"Format: Deserialization Schema\" >}}\n+\n+[Canal](https://github.com/alibaba/canal/wiki) 是一个 CDC（ChangeLog Data Capture，变更日志数据捕获）工具，可以实时地将 MySQL 变更传输到其他系统。Canal 为变更日志提供了统一的数据格式，并支持使用 JSON 或 [protobuf](https://developers.google.com/protocol-buffers) 序列化消息（Canal 默认使用 protobuf）。\n+\n+Flink 支持将 Canal 的 JSON 消息解析为 INSERT / UPDATE / DELETE 消息到 Flink SQL 系统中。在很多情况下，利用这个特性非常的有用，例如\n+ - 将增量数据从数据库同步到其他系统\n+ - 日志审计\n+ - 数据库的实时物化视图\n+ - 关联维度数据库的变更历史，等等。\n+\n+Flink 还支持将 Flink SQL 中的 INSERT / UPDATE / DELETE 消息编码为 Canal 格式的 JSON 消息，输出到 Kafka 等存储中。\n+但需要注意的是，目前 Flink 还不支持将 UPDATE_BEFORE 和 UPDATE_AFTER 合并为一条 UPDATE 消息。因此，Flink 将 UPDATE_BEFORE 和 UPDATE_AFTER 分别编码为 DELETE 和 INSERT 类型的 Canal 消息。\n+\n+*注意：未来会支持 Canal protobuf 类型消息的解析以及输出 Canal 格式的消息。*\n+\n+依赖\n+------------\n+\n+{{< sql_download_table \"canal\" >}}\n+\n+*注意：有关如何部署 Canal 以将变更日志同步到消息队列，请参阅 [Canal 文档](https://github.com/alibaba/canal/wiki)。*\n+\n+\n+如何使用 Canal Format\n+----------------\n+\n+Canal 为变更日志提供了统一的格式，下面是一个从 MySQL 库 `products` 表中捕获更新操作的简单示例：\n+\n+```json\n+{\n+  \"data\": [\n+    {\n+      \"id\": \"111\",\n+      \"name\": \"scooter\",\n+      \"description\": \"Big 2-wheel scooter\",\n+      \"weight\": \"5.18\"\n+    }\n+  ],\n+  \"database\": \"inventory\",\n+  \"es\": 1589373560000,\n+  \"id\": 9,\n+  \"isDdl\": false,\n+  \"mysqlType\": {\n+    \"id\": \"INTEGER\",\n+    \"name\": \"VARCHAR(255)\",\n+    \"description\": \"VARCHAR(512)\",\n+    \"weight\": \"FLOAT\"\n+  },\n+  \"old\": [\n+    {\n+      \"weight\": \"5.15\"\n+    }\n+  ],\n+  \"pkNames\": [\n+    \"id\"\n+  ],\n+  \"sql\": \"\",\n+  \"sqlType\": {\n+    \"id\": 4,\n+    \"name\": 12,\n+    \"description\": 12,\n+    \"weight\": 7\n+  },\n+  \"table\": \"products\",\n+  \"ts\": 1589373560798,\n+  \"type\": \"UPDATE\"\n+}\n+```\n+\n+*注意：有关各个字段的含义，请参阅 [Canal 文档](https://github.com/alibaba/canal/wiki)*\n+\n+MySQL `products` 表有4列（`id`，`name`，`description` 和 `weight`）。上面的 JSON 消息是 `products` 表上的一个更新事件，表示 `id = 111` 的行数据上 `weight` 字段值从`5.15`变更成为 `5.18`。假设消息已经同步到了一个 Kafka 主题：`products_binlog`，那么就可以使用以下DDL来从这个主题消费消息并解析变更事件。\n+\n+```sql\n+CREATE TABLE topic_products (\n+  -- 元数据与 MySQL \"products\" 表完全相同\n+  id BIGINT,\n+  name STRING,\n+  description STRING,\n+  weight DECIMAL(10, 2)\n+) WITH (\n+ 'connector' = 'kafka',\n+ 'topic' = 'products_binlog',\n+ 'properties.bootstrap.servers' = 'localhost:9092',\n+ 'properties.group.id' = 'testGroup',\n+ 'format' = 'canal-json'  -- 使用 canal-json 格式\n+)\n+```\n+\n+将 Kafka 主题注册成 Flink 表之后，就可以将 Canal 消息用作变更日志源。\n+\n+```sql\n+-- 关于MySQL \"products\" 表的实时物化视图\n+-- 计算相同产品的最新平均重量\n+SELECT name, AVG(weight) FROM topic_products GROUP BY name;\n+\n+-- 将 MySQL \"products\" 表的所有数据和增量更改同步到\n+-- Elasticsearch \"products\" 索引以供将来搜索\n+INSERT INTO elasticsearch_products\n+SELECT * FROM topic_products;\n+```\n+\n+Available Metadata\n+------------------\n+\n+The following format metadata can be exposed as read-only (`VIRTUAL`) columns in a table definition.\n+\n+<span class=\"label label-danger\">Attention</span> Format metadata fields are only available if the\n+corresponding connector forwards format metadata. Currently, only the Kafka connector is able to expose\n+metadata fields for its value format.\n+\n+<table class=\"table table-bordered\">\n+    <thead>\n+    <tr>\n+      <th class=\"text-left\" style=\"width: 25%\">Key</th>\n+      <th class=\"text-center\" style=\"width: 40%\">Data Type</th>\n+      <th class=\"text-center\" style=\"width: 40%\">Description</th>\n+    </tr>\n+    </thead>\n+    <tbody>\n+    <tr>\n+      <td><code>database</code></td>\n+      <td><code>STRING NULL</code></td>\n+      <td>The originating database. Corresponds to the <code>database</code> field in the\n+      Canal record if available.</td>\n+    </tr>\n+    <tr>\n+      <td><code>table</code></td>\n+      <td><code>STRING NULL</code></td>\n+      <td>The originating database table. Corresponds to the <code>table</code> field in the\n+      Canal record if available.</td>\n+    </tr>\n+    <tr>\n+      <td><code>sql-type</code></td>\n+      <td><code>MAP&lt;STRING, INT&gt; NULL</code></td>\n+      <td>Map of various sql types. Corresponds to the <code>sqlType</code> field in the \n+      Canal record if available.</td>\n+    </tr>\n+    <tr>\n+      <td><code>pk-names</code></td>\n+      <td><code>ARRAY&lt;STRING&gt; NULL</code></td>\n+      <td>Array of primary key names. Corresponds to the <code>pkNames</code> field in the \n+      Canal record if available.</td>\n+    </tr>\n+    <tr>\n+      <td><code>ingestion-timestamp</code></td>\n+      <td><code>TIMESTAMP_LTZ(3) NULL</code></td>\n+      <td>The timestamp at which the connector processed the event. Corresponds to the <code>ts</code>\n+      field in the Canal record.</td>\n+    </tr>\n+    </tbody>\n+</table>\n+\n+The following example shows how to access Canal metadata fields in Kafka:\n+\n+```sql\n+CREATE TABLE KafkaTable (\n+  origin_database STRING METADATA FROM 'value.database' VIRTUAL,\n+  origin_table STRING METADATA FROM 'value.table' VIRTUAL,\n+  origin_sql_type MAP<STRING, INT> METADATA FROM 'value.sql-type' VIRTUAL,\n+  origin_pk_names ARRAY<STRING> METADATA FROM 'value.pk-names' VIRTUAL,\n+  origin_ts TIMESTAMP(3) METADATA FROM 'value.ingestion-timestamp' VIRTUAL,\n+  user_id BIGINT,\n+  item_id BIGINT,\n+  behavior STRING\n+) WITH (\n+  'connector' = 'kafka',\n+  'topic' = 'user_behavior',\n+  'properties.bootstrap.servers' = 'localhost:9092',\n+  'properties.group.id' = 'testGroup',\n+  'scan.startup.mode' = 'earliest-offset',\n+  'value.format' = 'canal-json'\n+);\n+```\n+\n+Format 参数\n+----------------\n+\n+<table class=\"table table-bordered\">\n+    <thead>\n+      <tr>\n+        <th class=\"text-left\" style=\"width: 25%\">选项</th>\n+        <th class=\"text-center\" style=\"width: 8%\">要求</th>\n+        <th class=\"text-center\" style=\"width: 7%\">默认</th>\n+        <th class=\"text-center\" style=\"width: 10%\">类型</th>\n+        <th class=\"text-center\" style=\"width: 50%\">描述</th>\n+      </tr>\n+    </thead>\n+    <tbody>\n+    <tr>\n+      <td><h5>format</h5></td>\n+      <td>必填</td>\n+      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>String</td>\n+      <td>指定要使用的格式，此处应为 <code>'canal-json'</code>.</td>\n+    </tr>\n+    <tr>\n+      <td><h5>canal-json.ignore-parse-errors</h5></td>\n+      <td>选填</td>\n+      <td style=\"word-wrap: break-word;\">false</td>\n+      <td>Boolean</td>\n+      <td>当解析异常时，是跳过当前字段或行，还是抛出错误失败（默认为 false，即抛出错误失败）。如果忽略字段的解析异常，则会将该字段值设置为<code>null</code>。</td>\n+    </tr>\n+    <tr>\n+       <td><h5>canal-json.timestamp-format.standard</h5></td>\n+       <td>选填</td>\n+       <td style=\"word-wrap: break-word;\"><code>'SQL'</code></td>\n+       <td>String</td>\n+       <td>指定输入和输出时间戳格式。当前支持的值是 <code>'SQL'</code> 和 <code>'ISO-8601'</code>:\n+       <ul>\n+         <li>选项 <code>'SQL'</code> 将解析 \"yyyy-MM-dd HH:mm:ss.s{precision}\" 格式的输入时间戳，例如 '2020-12-30 12:13:14.123'，并以相同格式输出时间戳。</li>\n+         <li>选项 <code>'ISO-8601'</code> 将解析 \"yyyy-MM-ddTHH:mm:ss.s{precision}\" 格式的输入时间戳，例如 '2020-12-30T12:13:14.123'，并以相同的格式输出时间戳。</li>\n+       </ul>\n+       </td>\n+    </tr>\n+    <tr>\n+       <td><h5>canal-json.map-null-key.mode</h5></td>\n+       <td>选填</td>\n+       <td style=\"word-wrap: break-word;\"><code>'FAIL'</code></td>\n+       <td>String</td>\n+       <td>指定处理 Map 中 key 值为空的方法. 当前支持的值有 <code>'FAIL'</code>, <code>'DROP'</code> 和 <code>'LITERAL'</code>:\n+       <ul>\n+         <li>Option <code>'FAIL'</code> 将抛出异常，如果遇到 Map 中 key 值为空的数据。</li>\n+         <li>Option <code>'DROP'</code> 将丢弃 Map 中 key 值为空的数据项。</li> \n+         <li>Option <code>'LITERAL'</code> 将使用字符串常量来替换 Map 中的空 key 值。字符串常量的值由 <code>'canal-json.map-null-key.literal'</code> 定义。</li>\n+       </ul>\n+       </td>\n+    </tr>\n+    <tr>\n+      <td><h5>canal-json.map-null-key.literal</h5></td>\n+      <td>选填</td>\n+      <td style=\"word-wrap: break-word;\">'null'</td>\n+      <td>String</td>\n+      <td>当 <code>'canal-json.map-null-key.mode'</code> 是 LITERAL 的时候，指定字符串常量替换 Map 中的空 key 值。</td>\n+    </tr>       \n+    <tr>\n+      <td><h5>canal-json.encode.decimal-as-plain-number</h5></td>\n+      <td>选填</td>\n+      <td style=\"word-wrap: break-word;\">false</td>\n+      <td>Boolean</td>\n+      <td>将所有 DECIMAL 类型的数据保持原状，不使用科学计数法表示。例：<code>0.000000027</code> 默认会表示为 <code>2.7E-8</code>。当此选项设为 true 时，则会表示为 <code>0.000000027</code>。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>canal-json.database.include</h5></td>\n+      <td>optional</td>\n+      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>String</td>\n+      <td>一个可选的正则表达式，通过正则匹配 Canal 记录中的 \"database\" 元字段，仅读取指定数据库的 changelog 记录。正则字符串与 Java 的 <a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html\">Pattern</a> 兼容。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>canal-json.table.include</h5></td>\n+      <td>optional</td>\n+      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>String</td>\n+      <td>一个可选的正则表达式，通过正则匹配 Canal 记录中的 \"table\" 元字段，仅读取指定表的 changelog 记录。正则字符串与 Java 的 <a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html\">Pattern</a> 兼容。</td>\n+    </tr>\n+    </tbody>\n+</table>\n+\n+注意事项\n+----------------\n+\n+### 重复的变更事件\n+\n+在正常的操作环境下，Canal 应用能以 **exactly-once** 的语义投递每条变更事件。在这种情况下，Flink 消费 Canal 产生的变更事件能够工作得很好。\n+然而，当有故障发生时，Canal 应用只能保证 **at-least-once** 的投递语义。\n+这也意味着，在非正常情况下，Canal 可能会投递重复的变更事件到消息队列中，当 Flink 从消息队列中消费的时候就会得到重复的事件。\n+这可能会导致 Flink query 的运行得到错误的结果或者非预期的异常。因此，建议在这种情况下，建议在这种情况下，将作业参数 [`table.exec.source.cdc-events-duplicate`]({{< ref \"docs/dev/table/config\" >}}#table-exec-source-cdc-events-duplicate) 设置成 `true`，并在该 source 上定义 PRIMARY KEY。\n+框架会生成一个额外的有状态算子，使用该 primary key 来对变更事件去重并生成一个规范化的 changelog 流。\n+\n+数据类型映射\n+----------------\n+\n+目前，Canal Format 使用 JSON Format 进行序列化和反序列化。 有关数据类型映射的更多详细信息，请参阅 [JSON Format 文档]({{< ref \"docs/connectors/table/formats/json\" >}}#data-type-mapping)。\n+"
        },
        {
            "sha": "417af014a479c060311d65323a6f8b429d3a2531",
            "filename": "docs/content.zh/docs/connectors/table/formats/csv.md",
            "status": "added",
            "additions": 228,
            "deletions": 0,
            "changes": 228,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/formats/csv.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/formats/csv.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/table/formats/csv.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,228 @@\n+---\n+title: CSV\n+weight: 2\n+type: docs\n+aliases:\n+  - /zh/dev/table/connectors/formats/csv.html\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# CSV Format\n+\n+{{< label \"Format: Serialization Schema\" >}}\n+{{< label \"Format: Deserialization Schema\" >}}\n+\n+[CSV](https://zh.wikipedia.org/wiki/%E9%80%97%E5%8F%B7%E5%88%86%E9%9A%94%E5%80%BC) Format 允许我们基于 CSV schema 进行解析和生成 CSV 数据。 目前 CSV schema 是基于 table schema 推断而来的。\n+\n+依赖\n+------------\n+\n+{{< sql_download_table \"csv\" >}}\n+\n+如何创建使用 CSV 格式的表\n+----------------\n+\n+\n+以下是一个使用 Kafka 连接器和 CSV 格式创建表的示例。\n+\n+```sql\n+CREATE TABLE user_behavior (\n+  user_id BIGINT,\n+  item_id BIGINT,\n+  category_id BIGINT,\n+  behavior STRING,\n+  ts TIMESTAMP(3)\n+) WITH (\n+ 'connector' = 'kafka',\n+ 'topic' = 'user_behavior',\n+ 'properties.bootstrap.servers' = 'localhost:9092',\n+ 'properties.group.id' = 'testGroup',\n+ 'format' = 'csv',\n+ 'csv.ignore-parse-errors' = 'true',\n+ 'csv.allow-comments' = 'true'\n+)\n+```\n+\n+Format 参数\n+----------------\n+\n+<table class=\"table table-bordered\">\n+    <thead>\n+      <tr>\n+        <th class=\"text-left\" style=\"width: 25%\">参数</th>\n+        <th class=\"text-center\" style=\"width: 10%\">是否必选</th>\n+        <th class=\"text-center\" style=\"width: 10%\">默认值</th>\n+        <th class=\"text-center\" style=\"width: 10%\">类型</th>\n+        <th class=\"text-center\" style=\"width: 45%\">描述</th>\n+      </tr>\n+    </thead>\n+    <tbody>\n+    <tr>\n+      <td><h5>format</h5></td>\n+      <td>必选</td>\n+      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>String</td>\n+      <td>指定要使用的格式，这里应该是 <code>'csv'</code>。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>csv.field-delimiter</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\"><code>,</code></td>\n+      <td>String</td>\n+      <td>字段分隔符 (默认<code>','</code>)，必须为单字符。你可以使用反斜杠字符指定一些特殊字符，例如 <code>'\\t'</code> 代表制表符。\n+      你也可以通过 unicode 编码在纯 SQL 文本中指定一些特殊字符，例如 <code>'csv.field-delimiter' = U&'\\0001'</code> 代表 <code>0x01</code> 字符。\n+      </td>\n+    </tr>\n+    <tr>\n+      <td><h5>csv.disable-quote-character</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">false</td>\n+      <td>Boolean</td>\n+      <td>是否禁止对引用的值使用引号 (默认是 false). 如果禁止，选项 <code>'csv.quote-character'</code> 不能设置。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>csv.quote-character</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\"><code>\"</code></td>\n+      <td>String</td>\n+      <td>用于围住字段值的引号字符 (默认<code>\"</code>).</td>\n+    </tr>\n+    <tr>\n+      <td><h5>csv.allow-comments</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">false</td>\n+      <td>Boolean</td>\n+      <td>是否允许忽略注释行（默认不允许），注释行以 <code>'#'</code> 作为起始字符。\n+      如果允许注释行，请确保 <code>csv.ignore-parse-errors</code> 也开启了从而允许空行。 \n+      </td>\n+    </tr>\n+    <tr>\n+      <td><h5>csv.ignore-parse-errors</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">false</td>\n+      <td>Boolean</td>\n+    <td>当解析异常时，是跳过当前字段或行，还是抛出错误失败（默认为 false，即抛出错误失败）。如果忽略字段的解析异常，则会将该字段值设置为<code>null</code>。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>csv.array-element-delimiter</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\"><code>;</code></td>\n+      <td>String</td>\n+      <td>分隔数组和行元素的字符串(默认<code>';'</code>).</td>\n+    </tr>\n+    <tr>\n+      <td><h5>csv.escape-character</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>String</td>\n+      <td>转义字符(默认关闭).</td>\n+    </tr>\n+    <tr>\n+      <td><h5>csv.null-literal</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>String</td>\n+      <td>是否将 \"null\" 字符串转化为 null 值。</td>\n+    </tr>\n+    </tbody>\n+</table>\n+\n+数据类型映射\n+----------------\n+\n+目前 CSV 的 schema 都是从 table schema 推断而来的。显式地定义 CSV schema 暂不支持。\n+Flink 的 CSV Format 数据使用 [jackson databind API](https://github.com/FasterXML/jackson-databind) 去解析 CSV 字符串。\n+\n+下面的表格列出了flink数据和CSV数据的对应关系。\n+\n+<table class=\"table table-bordered\">\n+    <thead>\n+      <tr>\n+        <th class=\"text-left\">Flink SQL 类型</th>\n+        <th class=\"text-left\">CSV 类型</th>\n+      </tr>\n+    </thead>\n+    <tbody>\n+    <tr>\n+      <td><code>CHAR / VARCHAR / STRING</code></td>\n+      <td><code>string</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>BOOLEAN</code></td>\n+      <td><code>boolean</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>BINARY / VARBINARY</code></td>\n+      <td><code>string with encoding: base64</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>DECIMAL</code></td>\n+      <td><code>number</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>TINYINT</code></td>\n+      <td><code>number</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>SMALLINT</code></td>\n+      <td><code>number</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>INT</code></td>\n+      <td><code>number</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>BIGINT</code></td>\n+      <td><code>number</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>FLOAT</code></td>\n+      <td><code>number</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>DOUBLE</code></td>\n+      <td><code>number</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>DATE</code></td>\n+      <td><code>string with format: date</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>TIME</code></td>\n+      <td><code>string with format: time</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>TIMESTAMP</code></td>\n+      <td><code>string with format: date-time</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>INTERVAL</code></td>\n+      <td><code>number</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>ARRAY</code></td>\n+      <td><code>array</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>ROW</code></td>\n+      <td><code>object</code></td>\n+    </tr>\n+    </tbody>\n+</table>"
        },
        {
            "sha": "daec7ed202f6e33a4540891915cb809790a10d99",
            "filename": "docs/content.zh/docs/connectors/table/formats/debezium.md",
            "status": "added",
            "additions": 441,
            "deletions": 0,
            "changes": 441,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/formats/debezium.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/formats/debezium.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/table/formats/debezium.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,441 @@\n+---\n+title: Debezium\n+weight: 5\n+type: docs\n+aliases:\n+  - /zh/dev/table/connectors/formats/debezium.html\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Debezium Format\n+\n+{{< label \"Changelog-Data-Capture Format\" >}}\n+{{< label \"Format: Serialization Schema\" >}}\n+{{< label \"Format: Deserialization Schema\" >}}\n+\n+[Debezium](https://debezium.io/) 是一个 CDC（Changelog Data Capture，变更数据捕获）的工具，可以把来自 MySQL、PostgreSQL、Oracle、Microsoft SQL Server 和许多其他数据库的更改实时流式传输到 Kafka 中。 Debezium 为变更日志提供了统一的格式结构，并支持使用 JSON 和 Apache Avro 序列化消息。\n+\n+Flink 支持将 Debezium JSON 和 Avro 消息解析为 INSERT / UPDATE / DELETE 消息到 Flink SQL 系统中。在很多情况下，利用这个特性非常的有用，例如\n+ - 将增量数据从数据库同步到其他系统\n+ - 日志审计\n+ - 数据库的实时物化视图\n+ - 关联维度数据库的变更历史，等等。\n+\n+Flink 还支持将 Flink SQL 中的 INSERT / UPDATE / DELETE 消息编码为 Debezium 格式的 JSON 或 Avro 消息，输出到 Kafka 等存储中。\n+但需要注意的是，目前 Flink 还不支持将 UPDATE_BEFORE 和 UPDATE_AFTER 合并为一条 UPDATE 消息。因此，Flink 将 UPDATE_BEFORE 和 UPDATE_AFTER 分别编码为 DELETE 和 INSERT 类型的 Debezium 消息。\n+\n+依赖\n+------------\n+\n+#### Debezium Avro\n+\n+{{< sql_download_table \"debezium-avro-confluent\" >}}\n+\n+#### Debezium Json\n+\n+{{< sql_download_table \"debezium-json\" >}}\n+\n+*注意: 请参考 [Debezium 文档](https://debezium.io/documentation/reference/1.3/index.html)，了解如何设置 Debezium Kafka Connect 用来将变更日志同步到 Kafka 主题。*\n+\n+\n+如何使用 Debezium Format\n+----------------\n+\n+\n+Debezium 为变更日志提供了统一的格式，这是一个 JSON 格式的从 MySQL product 表捕获的更新操作的简单示例:\n+\n+```json\n+{\n+  \"before\": {\n+    \"id\": 111,\n+    \"name\": \"scooter\",\n+    \"description\": \"Big 2-wheel scooter\",\n+    \"weight\": 5.18\n+  },\n+  \"after\": {\n+    \"id\": 111,\n+    \"name\": \"scooter\",\n+    \"description\": \"Big 2-wheel scooter\",\n+    \"weight\": 5.15\n+  },\n+  \"source\": {...},\n+  \"op\": \"u\",\n+  \"ts_ms\": 1589362330904,\n+  \"transaction\": null\n+}\n+```\n+\n+*注意: 请参考 [Debezium 文档](https://debezium.io/documentation/reference/1.3/connectors/mysql.html#mysql-connector-events_debezium)，了解每个字段的含义。*\n+\n+MySQL 产品表有4列（`id`、`name`、`description`、`weight`）。上面的 JSON 消息是 `products` 表上的一条更新事件，其中 `id = 111` 的行的 `weight` 值从 `5.18` 更改为 `5.15`。假设此消息已同步到 Kafka 主题 `products_binlog`，则可以使用以下 DDL 来使用此主题并解析更改事件。\n+\n+{{< tabs \"0b6703c1-021e-4506-a579-b72b8408c0cf\" >}}\n+{{< tab \"SQL\" >}}\n+```sql\n+CREATE TABLE topic_products (\n+  -- schema 与 MySQL 的 products 表完全相同\n+  id BIGINT,\n+  name STRING,\n+  description STRING,\n+  weight DECIMAL(10, 2)\n+) WITH (\n+ 'connector' = 'kafka',\n+ 'topic' = 'products_binlog',\n+ 'properties.bootstrap.servers' = 'localhost:9092',\n+ 'properties.group.id' = 'testGroup',\n+  -- 使用 'debezium-json' format 来解析 Debezium 的 JSON 消息\n+  -- 如果 Debezium 用 Avro 编码消息，请使用 'debezium-avro-confluent'\n+ 'format' = 'debezium-json'  -- 如果 Debezium 用 Avro 编码消息，请使用 'debezium-avro-confluent'\n+)\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+在某些情况下，用户在设置 Debezium Kafka Connect 时，可能会开启 Kafka 的配置 `'value.converter.schemas.enable'`，用来在消息体中包含 schema 信息。然后，Debezium JSON 消息可能如下所示:\n+\n+```json\n+{\n+  \"schema\": {...},\n+  \"payload\": {\n+    \"before\": {\n+      \"id\": 111,\n+      \"name\": \"scooter\",\n+      \"description\": \"Big 2-wheel scooter\",\n+      \"weight\": 5.18\n+    },\n+    \"after\": {\n+      \"id\": 111,\n+      \"name\": \"scooter\",\n+      \"description\": \"Big 2-wheel scooter\",\n+      \"weight\": 5.15\n+    },\n+    \"source\": {...},\n+    \"op\": \"u\",\n+    \"ts_ms\": 1589362330904,\n+    \"transaction\": null\n+  }\n+}\n+```\n+\n+为了解析这一类信息，你需要在上述 DDL WITH 子句中添加选项 `'debezium-json.schema-include' = 'true'`（默认为 false）。通常情况下，建议不要包含 schema 的描述，因为这样会使消息变得非常冗长，并降低解析性能。\n+\n+在将主题注册为 Flink 表之后，可以将 Debezium 消息用作变更日志源。\n+\n+{{< tabs \"6a84a0e8-2e56-49db-9089-e836290f8239\" >}}\n+{{< tab \"SQL\" >}}\n+```sql\n+-- MySQL \"products\" 的实时物化视图\n+-- 计算相同产品的最新平均重量\n+SELECT name, AVG(weight) FROM topic_products GROUP BY name;\n+\n+-- 将 MySQL \"products\" 表的所有数据和增量更改同步到\n+-- Elasticsearch \"products\" 索引，供将来查找\n+INSERT INTO elasticsearch_products\n+SELECT * FROM topic_products;\n+```\n+{{< /tab >}}\n+{{< /tabs >}}\n+\n+Available Metadata\n+------------------\n+\n+The following format metadata can be exposed as read-only (`VIRTUAL`) columns in a table definition.\n+\n+<span class=\"label label-danger\">Attention</span> Format metadata fields are only available if the\n+corresponding connector forwards format metadata. Currently, only the Kafka connector is able to expose\n+metadata fields for its value format.\n+\n+<table class=\"table table-bordered\">\n+    <thead>\n+    <tr>\n+      <th class=\"text-left\" style=\"width: 25%\">Key</th>\n+      <th class=\"text-center\" style=\"width: 40%\">Data Type</th>\n+      <th class=\"text-center\" style=\"width: 40%\">Description</th>\n+    </tr>\n+    </thead>\n+    <tbody>\n+    <tr>\n+      <td><code>schema</code></td>\n+      <td><code>STRING NULL</code></td>\n+      <td>JSON string describing the schema of the payload. Null if the schema is not included in\n+      the Debezium record.</td>\n+    </tr>\n+    <tr>\n+      <td><code>ingestion-timestamp</code></td>\n+      <td><code>TIMESTAMP_LTZ(3) NULL</code></td>\n+      <td>The timestamp at which the connector processed the event. Corresponds to the <code>ts_ms</code>\n+      field in the Debezium record.</td>\n+    </tr>\n+    <tr>\n+      <td><code>source.timestamp</code></td>\n+      <td><code>TIMESTAMP_LTZ(3) NULL</code></td>\n+      <td>The timestamp at which the source system created the event. Corresponds to the <code>source.ts_ms</code>\n+      field in the Debezium record.</td>\n+    </tr>\n+    <tr>\n+      <td><code>source.database</code></td>\n+      <td><code>STRING NULL</code></td>\n+      <td>The originating database. Corresponds to the <code>source.db</code> field in the\n+      Debezium record if available.</td>\n+    </tr>\n+    <tr>\n+      <td><code>source.schema</code></td>\n+      <td><code>STRING NULL</code></td>\n+      <td>The originating database schema. Corresponds to the <code>source.schema</code> field in the\n+      Debezium record if available.</td>\n+    </tr>\n+    <tr>\n+      <td><code>source.table</code></td>\n+      <td><code>STRING NULL</code></td>\n+      <td>The originating database table. Corresponds to the <code>source.table</code> or <code>source.collection</code>\n+      field in the Debezium record if available.</td>\n+    </tr>\n+    <tr>\n+      <td><code>source.properties</code></td>\n+      <td><code>MAP&lt;STRING, STRING&gt; NULL</code></td>\n+      <td>Map of various source properties. Corresponds to the <code>source</code> field in the Debezium record.</td>\n+    </tr>\n+    </tbody>\n+</table>\n+\n+The following example shows how to access Debezium metadata fields in Kafka:\n+\n+```sql\n+CREATE TABLE KafkaTable (\n+  origin_ts TIMESTAMP(3) METADATA FROM 'value.ingestion-timestamp' VIRTUAL,\n+  event_time TIMESTAMP(3) METADATA FROM 'value.source.timestamp' VIRTUAL,\n+  origin_database STRING METADATA FROM 'value.source.database' VIRTUAL,\n+  origin_schema STRING METADATA FROM 'value.source.schema' VIRTUAL,\n+  origin_table STRING METADATA FROM 'value.source.table' VIRTUAL,\n+  origin_properties MAP<STRING, STRING> METADATA FROM 'value.source.properties' VIRTUAL,\n+  user_id BIGINT,\n+  item_id BIGINT,\n+  behavior STRING\n+) WITH (\n+  'connector' = 'kafka',\n+  'topic' = 'user_behavior',\n+  'properties.bootstrap.servers' = 'localhost:9092',\n+  'properties.group.id' = 'testGroup',\n+  'scan.startup.mode' = 'earliest-offset',\n+  'value.format' = 'debezium-json'\n+);\n+```\n+\n+Format 参数\n+----------------\n+\n+Flink 提供了 `debezium-avro-confluent` 和 `debezium-json` 两种 format 来解析 Debezium 生成的 JSON 格式和 Avro 格式的消息。\n+请使用 `debezium-avro-confluent` 来解析 Debezium 的 Avro 消息，使用 `debezium-json` 来解析 Debezium 的 JSON 消息。\n+\n+#### Debezium Avro\n+\n+<table class=\"table table-bordered\">\n+    <thead>\n+      <tr>\n+        <th class=\"text-left\" style=\"width: 25%\">参数</th>\n+        <th class=\"text-center\" style=\"width: 10%\">是否必选</th>\n+        <th class=\"text-center\" style=\"width: 10%\">默认值</th>\n+        <th class=\"text-center\" style=\"width: 10%\">类型</th>\n+        <th class=\"text-center\" style=\"width: 45%\">描述</th>\n+      </tr>\n+    </thead>\n+    <tbody>\n+        <tr>\n+            <td><h5>format</h5></td>\n+            <td>required</td>\n+            <td style=\"word-wrap: break-word;\">(none)</td>\n+            <td>String</td>\n+            <td>Specify what format to use, here should be <code>'debezium-avro-confluent'</code>.</td>\n+        </tr>\n+        <tr>\n+            <td><h5>debezium-avro-confluent.basic-auth.credentials-source</h5></td>\n+            <td>optional</td>\n+            <td style=\"word-wrap: break-word;\">(none)</td>\n+            <td>String</td>\n+            <td>Basic auth credentials source for Schema Registry</td>\n+        </tr>\n+        <tr>\n+            <td><h5>debezium-avro-confluent.basic-auth.user-info</h5></td>\n+            <td>optional</td>\n+            <td style=\"word-wrap: break-word;\">(none)</td>\n+            <td>String</td>\n+            <td>Basic auth user info for schema registry</td>\n+        </tr>\n+        <tr>\n+            <td><h5>debezium-avro-confluent.bearer-auth.credentials-source</h5></td>\n+            <td>optional</td>\n+            <td style=\"word-wrap: break-word;\">(none)</td>\n+            <td>String</td>\n+            <td>Bearer auth credentials source for Schema Registry</td>\n+        </tr>\n+        <tr>\n+            <td><h5>debezium-avro-confluent.bearer-auth.token</h5></td>\n+            <td>optional</td>\n+            <td style=\"word-wrap: break-word;\">(none)</td>\n+            <td>String</td>\n+            <td>Bearer auth token for Schema Registry</td>\n+        </tr>\n+        <tr>\n+            <td><h5>debezium-avro-confluent.ssl.keystore.location</h5></td>\n+            <td>optional</td>\n+            <td style=\"word-wrap: break-word;\">(none)</td>\n+            <td>String</td>\n+            <td>Location / File of SSL keystore</td>\n+        </tr>\n+        <tr>\n+            <td><h5>debezium-avro-confluent.ssl.keystore.password</h5></td>\n+            <td>optional</td>\n+            <td style=\"word-wrap: break-word;\">(none)</td>\n+            <td>String</td>\n+            <td>Password for SSL keystore</td>\n+        </tr>\n+        <tr>\n+            <td><h5>debezium-avro-confluent.ssl.truststore.location</h5></td>\n+            <td>optional</td>\n+            <td style=\"word-wrap: break-word;\">(none)</td>\n+            <td>String</td>\n+            <td>Location / File of SSL truststore</td>\n+        </tr>\n+        <tr>\n+            <td><h5>debezium-avro-confluent.ssl.truststore.password</h5></td>\n+            <td>optional</td>\n+            <td style=\"word-wrap: break-word;\">(none)</td>\n+            <td>String</td>\n+            <td>Password for SSL truststore</td>\n+        </tr>\n+        <tr>\n+            <td><h5>debezium-avro-confluent.schema-registry.subject</h5></td>\n+            <td>optional</td>\n+            <td style=\"word-wrap: break-word;\">(none)</td>\n+            <td>String</td>\n+            <td>The Confluent Schema Registry subject under which to register the schema used by this format during serialization. By default, 'kafka' and 'upsert-kafka' connectors use '&lt;topic_name&gt;-value' or '&lt;topic_name&gt;-key' as the default subject name if this format is used as the value or key format. But for other connectors (e.g. 'filesystem'), the subject option is required when used as sink.</td>\n+        </tr>\n+        <tr>\n+            <td><h5>debezium-avro-confluent.schema-registry.url</h5></td>\n+            <td>required</td>\n+            <td style=\"word-wrap: break-word;\">(none)</td>\n+            <td>String</td>\n+            <td>The URL of the Confluent Schema Registry to fetch/register schemas.</td>\n+        </tr>\n+    </tbody>\n+</table>\n+\n+#### Debezium Json\n+\n+<table class=\"table table-bordered\">\n+    <thead>\n+      <tr>\n+        <th class=\"text-left\" style=\"width: 25%\">参数</th>\n+        <th class=\"text-center\" style=\"width: 10%\">是否必选</th>\n+        <th class=\"text-center\" style=\"width: 10%\">默认值</th>\n+        <th class=\"text-center\" style=\"width: 10%\">类型</th>\n+        <th class=\"text-center\" style=\"width: 45%\">描述</th>\n+      </tr>\n+    </thead>\n+    <tbody>\n+    <tr>\n+      <td><h5>format</h5></td>\n+      <td>必选</td>\n+      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>String</td>\n+      <td>指定要使用的格式，此处应为 <code>'debezium-json'</code>。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>debezium-json.schema-include</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">false</td>\n+      <td>Boolean</td>\n+      <td>设置 Debezium Kafka Connect 时，用户可以启用 Kafka 配置 <code>'value.converter.schemas.enable'</code> 以在消息中包含 schema。此选项表明 Debezium JSON 消息是否包含 schema。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>debezium-json.ignore-parse-errors</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">false</td>\n+      <td>Boolean</td>\n+      <td>当解析异常时，是跳过当前字段或行，还是抛出错误失败（默认为 false，即抛出错误失败）。如果忽略字段的解析异常，则会将该字段值设置为<code>null</code>。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>debezium-json.timestamp-format.standard</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\"><code>'SQL'</code></td>\n+      <td>String</td>\n+      <td>声明输入和输出的时间戳格式。当前支持的格式为<code>'SQL'</code> 以及 <code>'ISO-8601'</code>：\n+      <ul>\n+        <li>可选参数 <code>'SQL'</code> 将会以 \"yyyy-MM-dd HH:mm:ss.s{precision}\" 的格式解析时间戳, 例如 '2020-12-30 12:13:14.123'，且会以相同的格式输出。</li>\n+        <li>可选参数 <code>'ISO-8601'</code> 将会以 \"yyyy-MM-ddTHH:mm:ss.s{precision}\" 的格式解析输入时间戳, 例如 '2020-12-30T12:13:14.123' ，且会以相同的格式输出。</li>\n+      </ul>\n+      </td>\n+    </tr>\n+    <tr>\n+       <td><h5>debezium-json.map-null-key.mode</h5></td>\n+       <td>选填</td>\n+       <td style=\"word-wrap: break-word;\"><code>'FAIL'</code></td>\n+       <td>String</td>\n+       <td>指定处理 Map 中 key 值为空的方法. 当前支持的值有 <code>'FAIL'</code>, <code>'DROP'</code> 和 <code>'LITERAL'</code>:\n+       <ul>\n+         <li>Option <code>'FAIL'</code> 将抛出异常，如果遇到 Map 中 key 值为空的数据。</li>\n+         <li>Option <code>'DROP'</code> 将丢弃 Map 中 key 值为空的数据项。</li> \n+         <li>Option <code>'LITERAL'</code> 将使用字符串常量来替换 Map 中的空 key 值。字符串常量的值由 <code>'debezium-json.map-null-key.literal'</code> 定义。</li>\n+       </ul>\n+       </td>\n+    </tr>\n+    <tr>\n+      <td><h5>debezium-json.map-null-key.literal</h5></td>\n+      <td>选填</td>\n+      <td style=\"word-wrap: break-word;\">'null'</td>\n+      <td>String</td>\n+      <td>当 <code>'debezium-json.map-null-key.mode'</code> 是 LITERAL 的时候，指定字符串常量替换 Map 中的空 key 值。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>debezium-json.encode.decimal-as-plain-number</h5></td>\n+      <td>选填</td>\n+      <td style=\"word-wrap: break-word;\">false</td>\n+      <td>Boolean</td>\n+      <td>将所有 DECIMAL 类型的数据保持原状，不使用科学计数法表示。例：<code>0.000000027</code> 默认会表示为 <code>2.7E-8</code>。当此选项设为 true 时，则会表示为 <code>0.000000027</code>。</td>\n+    </tr>\n+    </tbody>\n+</table>\n+\n+\n+注意事项\n+----------------\n+\n+### 重复的变更事件\n+\n+在正常的操作环境下，Debezium 应用能以 **exactly-once** 的语义投递每条变更事件。在这种情况下，Flink 消费 Debezium 产生的变更事件能够工作得很好。\n+然而，当有故障发生时，Debezium 应用只能保证 **at-least-once** 的投递语义。可以查看 [Debezium 官方文档](https://debezium.io/documentation/faq/#what_happens_when_an_application_stops_or_crashes) 了解更多关于 Debezium 的消息投递语义。\n+这也意味着，在非正常情况下，Debezium 可能会投递重复的变更事件到 Kafka 中，当 Flink 从 Kafka 中消费的时候就会得到重复的事件。\n+这可能会导致 Flink query 的运行得到错误的结果或者非预期的异常。因此，建议在这种情况下，将作业参数 [`table.exec.source.cdc-events-duplicate`]({{< ref \"docs/dev/table/config\" >}}#table-exec-source-cdc-events-duplicate) 设置成 `true`，并在该 source 上定义 PRIMARY KEY。\n+框架会生成一个额外的有状态算子，使用该 primary key 来对变更事件去重并生成一个规范化的 changelog 流。\n+\n+### 消费 Debezium Postgres Connector 产生的数据\n+\n+如果你正在使用 [Debezium PostgreSQL Connector](https://debezium.io/documentation/reference/1.2/connectors/postgresql.html) 捕获变更到 Kafka，请确保被监控表的 [REPLICA IDENTITY](https://www.postgresql.org/docs/current/sql-altertable.html#SQL-CREATETABLE-REPLICA-IDENTITY) 已经被配置成 `FULL` 了，默认值是 `DEFAULT`。\n+否则，Flink SQL 将无法正确解析 Debezium 数据。\n+\n+当配置为 `FULL` 时，更新和删除事件将完整包含所有列的之前的值。当为其他配置时，更新和删除事件的 \"before\" 字段将只包含 primary key 字段的值，或者为 null（没有 primary key）。\n+你可以通过运行 `ALTER TABLE <your-table-name> REPLICA IDENTITY FULL` 来更改 `REPLICA IDENTITY` 的配置。\n+请阅读 [Debezium 关于 PostgreSQL REPLICA IDENTITY 的文档](https://debezium.io/documentation/reference/1.2/connectors/postgresql.html#postgresql-replica-identity) 了解更多。\n+\n+数据类型映射\n+----------------\n+\n+目前，Debezium Format 使用 JSON Format 进行序列化和反序列化。有关数据类型映射的更多详细信息，请参考 [JSON Format 文档]({{< ref \"docs/connectors/table/formats/json\" >}}#data-type-mapping) 和 [Confluent Avro Format 文档]({{< ref \"docs/connectors/table/formats/avro-confluent\" >}}#data-type-mapping)。\n+"
        },
        {
            "sha": "f7e3040de1fcccd6c5186827ab6d793f3288a9c4",
            "filename": "docs/content.zh/docs/connectors/table/formats/json.md",
            "status": "added",
            "additions": 231,
            "deletions": 0,
            "changes": 231,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/formats/json.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/formats/json.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/table/formats/json.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,231 @@\n+---\n+title: JSON\n+weight: 3\n+type: docs\n+aliases:\n+  - /zh/dev/table/connectors/formats/json.html\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# JSON Format\n+\n+{{< label \"Format: Serialization Schema\" >}}\n+{{< label \"Format: Deserialization Schema\" >}}\n+\n+[JSON](https://www.json.org/json-en.html) Format 能读写 JSON 格式的数据。当前，JSON schema 是从 table schema 中自动推导而得的。\n+\n+依赖\n+------------\n+\n+{{< sql_download_table \"json\" >}}\n+\n+如何创建一张基于 JSON Format 的表\n+----------------\n+\n+以下是一个利用 Kafka 以及 JSON Format 构建表的例子。\n+\n+```sql\n+CREATE TABLE user_behavior (\n+  user_id BIGINT,\n+  item_id BIGINT,\n+  category_id BIGINT,\n+  behavior STRING,\n+  ts TIMESTAMP(3)\n+) WITH (\n+ 'connector' = 'kafka',\n+ 'topic' = 'user_behavior',\n+ 'properties.bootstrap.servers' = 'localhost:9092',\n+ 'properties.group.id' = 'testGroup',\n+ 'format' = 'json',\n+ 'json.fail-on-missing-field' = 'false',\n+ 'json.ignore-parse-errors' = 'true'\n+)\n+```\n+\n+Format 参数\n+----------------\n+\n+<table class=\"table table-bordered\">\n+    <thead>\n+      <tr>\n+        <th class=\"text-left\" style=\"width: 25%\">参数</th>\n+        <th class=\"text-center\" style=\"width: 10%\">是否必须</th>\n+        <th class=\"text-center\" style=\"width: 10%\">默认值</th>\n+        <th class=\"text-center\" style=\"width: 10%\">类型</th>\n+        <th class=\"text-center\" style=\"width: 45%\">描述</th>\n+      </tr>\n+    </thead>\n+    <tbody>\n+    <tr>\n+      <td><h5>format</h5></td>\n+      <td>必选</td>\n+      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>String</td>\n+      <td>声明使用的格式，这里应为<code>'json'</code>。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>json.fail-on-missing-field</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">false</td>\n+      <td>Boolean</td>\n+      <td>当解析字段缺失时，是跳过当前字段或行，还是抛出错误失败（默认为 false，即抛出错误失败）。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>json.ignore-parse-errors</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">false</td>\n+      <td>Boolean</td>\n+      <td>当解析异常时，是跳过当前字段或行，还是抛出错误失败（默认为 false，即抛出错误失败）。如果忽略字段的解析异常，则会将该字段值设置为<code>null</code>。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>json.timestamp-format.standard</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\"><code>'SQL'</code></td>\n+      <td>String</td>\n+      <td>声明输入和输出的 <code>TIMESTAMP</code> 和 <code>TIMESTAMP_LTZ</code> 的格式。当前支持的格式为<code>'SQL'</code> 以及 <code>'ISO-8601'</code>：\n+      <ul>\n+        <li>可选参数 <code>'SQL'</code> 将会以 \"yyyy-MM-dd HH:mm:ss.s{precision}\" 的格式解析 TIMESTAMP, 例如 \"2020-12-30 12:13:14.123\"，\n+        以 \"yyyy-MM-dd HH:mm:ss.s{precision}'Z'\" 的格式解析 TIMESTAMP_LTZ, 例如 \"2020-12-30 12:13:14.123Z\" 且会以相同的格式输出。</li>\n+        <li>可选参数 <code>'ISO-8601'</code> 将会以 \"yyyy-MM-ddTHH:mm:ss.s{precision}\" 的格式解析输入 TIMESTAMP, 例如 \"2020-12-30T12:13:14.123\" ，\n+        以 \"yyyy-MM-ddTHH:mm:ss.s{precision}'Z'\" 的格式解析 TIMESTAMP_LTZ, 例如 \"2020-12-30T12:13:14.123Z\" 且会以相同的格式输出。</li>\n+      </ul>\n+      </td>\n+    </tr>\n+    <tr>\n+       <td><h5>json.map-null-key.mode</h5></td>\n+       <td>选填</td>\n+       <td style=\"word-wrap: break-word;\"><code>'FAIL'</code></td>\n+       <td>String</td>\n+       <td>指定处理 Map 中 key 值为空的方法. 当前支持的值有 <code>'FAIL'</code>, <code>'DROP'</code> 和 <code>'LITERAL'</code>:\n+       <ul>\n+         <li>Option <code>'FAIL'</code> 将抛出异常，如果遇到 Map 中 key 值为空的数据。</li>\n+         <li>Option <code>'DROP'</code> 将丢弃 Map 中 key 值为空的数据项。</li> \n+         <li>Option <code>'LITERAL'</code> 将使用字符串常量来替换 Map 中的空 key 值。字符串常量的值由 <code>'json.map-null-key.literal'</code> 定义。</li>\n+       </ul>\n+       </td>\n+    </tr>\n+    <tr>\n+      <td><h5>json.map-null-key.literal</h5></td>\n+      <td>选填</td>\n+      <td style=\"word-wrap: break-word;\">'null'</td>\n+      <td>String</td>\n+      <td>当 <code>'json.map-null-key.mode'</code> 是 LITERAL 的时候，指定字符串常量替换 Map 中的空 key 值。</td>\n+    </tr>        \n+    <tr>\n+      <td><h5>json.encode.decimal-as-plain-number</h5></td>\n+      <td>选填</td>\n+      <td style=\"word-wrap: break-word;\">false</td>\n+      <td>Boolean</td>\n+      <td>将所有 DECIMAL 类型的数据保持原状，不使用科学计数法表示。例：<code>0.000000027</code> 默认会表示为 <code>2.7E-8</code>。当此选项设为 true 时，则会表示为 <code>0.000000027</code>。</td>\n+    </tr>\n+    </tbody>\n+</table>\n+\n+数据类型映射关系\n+----------------\n+\n+当前，JSON schema 将会自动从 table schema 之中自动推导得到。不支持显式地定义 JSON schema。\n+\n+在 Flink 中，JSON Format 使用 [jackson databind API](https://github.com/FasterXML/jackson-databind) 去解析和生成 JSON。\n+\n+下表列出了 Flink 中的数据类型与 JSON 中的数据类型的映射关系。\n+\n+<table class=\"table table-bordered\">\n+    <thead>\n+      <tr>\n+        <th class=\"text-left\">Flink SQL 类型</th>\n+        <th class=\"text-left\">JSON 类型</th>\n+      </tr>\n+    </thead>\n+    <tbody>\n+    <tr>\n+      <td><code>CHAR / VARCHAR / STRING</code></td>\n+      <td><code>string</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>BOOLEAN</code></td>\n+      <td><code>boolean</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>BINARY / VARBINARY</code></td>\n+      <td><code>string with encoding: base64</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>DECIMAL</code></td>\n+      <td><code>number</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>TINYINT</code></td>\n+      <td><code>number</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>SMALLINT</code></td>\n+      <td><code>number</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>INT</code></td>\n+      <td><code>number</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>BIGINT</code></td>\n+      <td><code>number</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>FLOAT</code></td>\n+      <td><code>number</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>DOUBLE</code></td>\n+      <td><code>number</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>DATE</code></td>\n+      <td><code>string with format: date</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>TIME</code></td>\n+      <td><code>string with format: time</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>TIMESTAMP</code></td>\n+      <td><code>string with format: date-time</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>TIMESTAMP_WITH_LOCAL_TIME_ZONE</code></td>\n+      <td><code>string with format: date-time (with UTC time zone)</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>INTERVAL</code></td>\n+      <td><code>number</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>ARRAY</code></td>\n+      <td><code>array</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>MAP / MULTISET</code></td>\n+      <td><code>object</code></td>\n+    </tr>\n+    <tr>\n+      <td><code>ROW</code></td>\n+      <td><code>object</code></td>\n+    </tr>\n+    </tbody>\n+</table>"
        },
        {
            "sha": "205b1259296f2757f05b4f2e1926644cab490b81",
            "filename": "docs/content.zh/docs/connectors/table/formats/maxwell.md",
            "status": "added",
            "additions": 204,
            "deletions": 0,
            "changes": 204,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/formats/maxwell.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/formats/maxwell.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/table/formats/maxwell.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,204 @@\n+---\n+title: Maxwell\n+weight: 7\n+type: docs\n+aliases:\n+  - /zh/dev/table/connectors/formats/maxwell.html\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Maxwell Format\n+\n+{{< label \"Changelog-Data-Capture Format\" >}}\n+{{< label \"Format: Serialization Schema\" >}}\n+{{< label \"Format: Deserialization Schema\" >}}\n+\n+[Maxwell](https://maxwells-daemon.io/) is a CDC (Changelog Data Capture) tool that can stream changes in real-time from MySQL into Kafka, Kinesis and other streaming connectors. Maxwell provides a unified format schema for changelog and supports to serialize messages using JSON.\n+\n+Flink supports to interpret Maxwell JSON messages as INSERT/UPDATE/DELETE messages into Flink SQL system. This is useful in many cases to leverage this feature, such as\n+ - synchronizing incremental data from databases to other systems\n+ - auditing logs\n+ - real-time materialized views on databases\n+ - temporal join changing history of a database table and so on.\n+\n+Flink also supports to encode the INSERT/UPDATE/DELETE messages in Flink SQL as Maxwell JSON messages, and emit to external systems like Kafka.\n+However, currently Flink can't combine UPDATE_BEFORE and UPDATE_AFTER into a single UPDATE message. Therefore, Flink encodes UPDATE_BEFORE and UDPATE_AFTER as DELETE and INSERT Maxwell messages.\n+\n+Dependencies\n+------------\n+\n+{{< sql_download_table \"maxwell\" >}}\n+\n+*Note: please refer to [Maxwell documentation](http://maxwells-daemon.io/quickstart/) about how to synchronize changelog to Kafka topics with Maxwell JSON.*\n+\n+\n+How to use Maxwell format\n+----------------\n+\n+Maxwell provides a unified format for changelog, here is a simple example for an update operation captured from a MySQL `products` table in JSON format:\n+\n+```json\n+{\n+   \"database\":\"test\",\n+   \"table\":\"e\",\n+   \"type\":\"insert\",\n+   \"ts\":1477053217,\n+   \"xid\":23396,\n+   \"commit\":true,\n+   \"position\":\"master.000006:800911\",\n+   \"server_id\":23042,\n+   \"thread_id\":108,\n+   \"primary_key\": [1, \"2016-10-21 05:33:37.523000\"],\n+   \"primary_key_columns\": [\"id\", \"c\"],\n+   \"data\":{\n+     \"id\":111,\n+     \"name\":\"scooter\",\n+     \"description\":\"Big 2-wheel scooter\",\n+     \"weight\":5.15\n+   },\n+   \"old\":{\n+     \"weight\":5.18,\n+   }\n+}\n+```\n+\n+*Note: please refer to [Maxwell documentation](http://maxwells-daemon.io/dataformat/) about the meaning of each fields.*\n+\n+The MySQL `products` table has 4 columns (`id`, `name`, `description` and `weight`). The above JSON message is an update change event on the `products` table where the `weight` value of the row with `id = 111` is changed from `5.18` to `5.15`.\n+Assuming this messages is synchronized to Kafka topic `products_binlog`, then we can use the following DDL to consume this topic and interpret the change events.\n+\n+```sql\n+CREATE TABLE topic_products (\n+  -- schema is totally the same to the MySQL \"products\" table\n+  id BIGINT,\n+  name STRING,\n+  description STRING,\n+  weight DECIMAL(10, 2)\n+) WITH (\n+ 'connector' = 'kafka',\n+ 'topic' = 'products_binlog',\n+ 'properties.bootstrap.servers' = 'localhost:9092',\n+ 'properties.group.id' = 'testGroup',\n+ 'format' = 'maxwell-json'\n+)\n+```\n+\n+After registering the topic as a Flink table, then you can consume the Maxwell messages as a changelog source.\n+\n+```sql\n+-- a real-time materialized view on the MySQL \"products\"\n+-- which calculate the latest average of weight for the same products\n+SELECT name, AVG(weight) FROM topic_products GROUP BY name;\n+\n+-- synchronize all the data and incremental changes of MySQL \"products\" table to\n+-- Elasticsearch \"products\" index for future searching\n+INSERT INTO elasticsearch_products\n+SELECT * FROM topic_products;\n+```\n+\n+Format Options\n+----------------\n+\n+<div data-lang=\"Maxwell Json\" markdown=\"1\">\n+\n+<table class=\"table table-bordered\">\n+    <thead>\n+      <tr>\n+        <th class=\"text-left\" style=\"width: 25%\">Option</th>\n+        <th class=\"text-center\" style=\"width: 8%\">Required</th>\n+        <th class=\"text-center\" style=\"width: 7%\">Default</th>\n+        <th class=\"text-center\" style=\"width: 10%\">Type</th>\n+        <th class=\"text-center\" style=\"width: 50%\">Description</th>\n+      </tr>\n+    </thead>\n+    <tbody>\n+    <tr>\n+      <td><h5>format</h5></td>\n+      <td>required</td>\n+      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>String</td>\n+      <td>Specify what format to use, here should be <code>'maxwell-json'</code>.</td>\n+    </tr>\n+    <tr>\n+      <td><h5>maxwell-json.ignore-parse-errors</h5></td>\n+      <td>optional</td>\n+      <td style=\"word-wrap: break-word;\">false</td>\n+      <td>Boolean</td>\n+      <td>Skip fields and rows with parse errors instead of failing.\n+      Fields are set to null in case of errors.</td>\n+    </tr>\n+    <tr>\n+       <td><h5>maxwell-json.timestamp-format.standard</h5></td>\n+       <td>optional</td>\n+       <td style=\"word-wrap: break-word;\"><code>'SQL'</code></td>\n+       <td>String</td>\n+       <td>Specify the input and output timestamp format. Currently supported values are <code>'SQL'</code> and <code>'ISO-8601'</code>:\n+       <ul>\n+         <li>Option <code>'SQL'</code> will parse input timestamp in \"yyyy-MM-dd HH:mm:ss.s{precision}\" format, e.g '2020-12-30 12:13:14.123' and output timestamp in the same format.</li>\n+         <li>Option <code>'ISO-8601'</code>will parse input timestamp in \"yyyy-MM-ddTHH:mm:ss.s{precision}\" format, e.g '2020-12-30T12:13:14.123' and output timestamp in the same format.</li>\n+       </ul>\n+       </td>\n+    </tr>\n+    <tr>\n+      <td><h5>maxwell-json.map-null-key.mode</h5></td>\n+      <td>optional</td>\n+      <td style=\"word-wrap: break-word;\"><code>'FAIL'</code></td>\n+      <td>String</td>\n+      <td>Specify the handling mode when serializing null keys for map data. Currently supported values are <code>'FAIL'</code>, <code>'DROP'</code> and <code>'LITERAL'</code>:\n+      <ul>\n+        <li>Option <code>'FAIL'</code> will throw exception when encountering map with null key.</li>\n+        <li>Option <code>'DROP'</code> will drop null key entries for map data.</li>\n+        <li>Option <code>'LITERAL'</code> will replace null key with string literal. The string literal is defined by <code>maxwell-json.map-null-key.literal</code> option.</li>\n+      </ul>\n+      </td>\n+    </tr>\n+    <tr>\n+      <td><h5>maxwell-json.map-null-key.literal</h5></td>\n+      <td>optional</td>\n+      <td style=\"word-wrap: break-word;\">'null'</td>\n+      <td>String</td>\n+      <td>Specify string literal to replace null key when <code>'maxwell-json.map-null-key.mode'</code> is LITERAL.</td>\n+    </tr>\n+    <tr>\n+      <td><h5>maxwell-json.encode.decimal-as-plain-number</h5></td>\n+      <td>optional</td>\n+      <td style=\"word-wrap: break-word;\">false</td>\n+      <td>Boolean</td>\n+      <td>Encode all decimals as plain numbers instead of possible scientific notations. By default, decimals may be written using scientific notation. For example, <code>0.000000027</code> is encoded as <code>2.7E-8</code> by default, and will be written as <code>0.000000027</code> if set this option to true.</td>\n+    </tr>\n+    </tbody>\n+</table>\n+\n+</div>\n+\n+Caveats\n+----------------\n+\n+### Duplicate change events\n+\n+The Maxwell application allows to deliver every change event **exactly-once**. Flink works pretty well when consuming Maxwell produced events in this situation.\n+If Maxwell application works in **at-least-once** delivery, it may deliver duplicate change events to Kafka and Flink will get the duplicate events.\n+This may cause Flink query to get wrong results or unexpected exceptions. Thus, it is recommended to set job configuration [`table.exec.source.cdc-events-duplicate`]({{< ref \"docs/dev/table/config\" >}}#table-exec-source-cdc-events-duplicate) to `true` and define PRIMARY KEY on the source in this situation.\n+Framework will generate an additional stateful operator, and use the primary key to deduplicate the change events and produce a normalized changelog stream.\n+\n+Data Type Mapping\n+----------------\n+\n+Currently, the Maxwell format uses JSON for serialization and deserialization. Please refer to [JSON Format documentation]({{< ref \"docs/connectors/table/formats/json\" >}}#data-type-mapping) for more details about the data type mapping."
        },
        {
            "sha": "57877f0609777b0c5aa52de704cead729790eb69",
            "filename": "docs/content.zh/docs/connectors/table/formats/orc.md",
            "status": "added",
            "additions": 173,
            "deletions": 0,
            "changes": 173,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/formats/orc.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/formats/orc.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/table/formats/orc.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,173 @@\n+---\n+title: Orc\n+weight: 9\n+type: docs\n+aliases:\n+  - /zh/dev/table/connectors/formats/orc.html\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Orc Format\n+\n+{{< label \"Format: Serialization Schema\" >}}\n+{{< label \"Format: Deserialization Schema\" >}}\n+\n+\n+[Apache Orc](https://orc.apache.org/) Format 允许读写 ORC 数据。\n+\n+依赖\n+------------\n+\n+{{< sql_download_table \"orc\" >}}\n+\n+\n+如何用 Orc 格式创建一个表格\n+----------------\n+\n+下面是一个用 Filesystem connector 和 Orc format 创建表格的例子\n+\n+```sql\n+CREATE TABLE user_behavior (\n+  user_id BIGINT,\n+  item_id BIGINT,\n+  category_id BIGINT,\n+  behavior STRING,\n+  ts TIMESTAMP(3),\n+  dt STRING\n+) PARTITIONED BY (dt) WITH (\n+ 'connector' = 'filesystem',\n+ 'path' = '/tmp/user_behavior',\n+ 'format' = 'orc'\n+)\n+```\n+\n+Format 参数\n+----------------\n+\n+<table class=\"table table-bordered\">\n+    <thead>\n+      <tr>\n+        <th class=\"text-left\" style=\"width: 25%\">参数</th>\n+        <th class=\"text-center\" style=\"width: 10%\">是否必选</th>\n+        <th class=\"text-center\" style=\"width: 10%\">默认值</th>\n+        <th class=\"text-center\" style=\"width: 10%\">类型</th>\n+        <th class=\"text-center\" style=\"width: 45%\">描述</th>\n+      </tr>\n+    </thead>\n+    <tbody>\n+    <tr>\n+      <td><h5>format</h5></td>\n+      <td>必选</td>\n+      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>String</td>\n+      <td>指定要使用的格式，这里应该是 'orc'。</td>\n+    </tr>\n+    </tbody>\n+</table>\n+\n+Orc 格式也支持来源于 [Table properties](https://orc.apache.org/docs/hive-config.html#table-properties) 的表属性。 举个例子，你可以设置 `orc.compress=SNAPPY` 来允许spappy压缩。\n+\n+数据类型映射\n+----------------\n+\n+Orc 格式类型的映射和 Apache Hive 是兼容的。下面的表格列出了 Flink 类型的数据和 Orc 类型的数据的映射关系。\n+<table class=\"table table-bordered\">\n+    <thead>\n+      <tr>\n+        <th class=\"text-left\">Flink 数据类型</th>\n+        <th class=\"text-center\">Orc 物理类型</th>\n+        <th class=\"text-center\">Orc 逻辑类型</th>\n+      </tr>\n+    </thead>\n+    <tbody>\n+    <tr>\n+      <td>CHAR</td>\n+      <td>bytes</td>\n+      <td>CHAR</td>\n+    </tr>\n+    <tr>\n+      <td>VARCHAR</td>\n+      <td>bytes</td>\n+      <td>VARCHAR</td>\n+    </tr>\n+    <tr>\n+      <td>STRING</td>\n+      <td>bytes</td>\n+      <td>STRING</td>\n+    </tr>\n+    <tr>\n+      <td>BOOLEAN</td>\n+      <td>long</td>\n+      <td>BOOLEAN</td>\n+    </tr>\n+    <tr>\n+      <td>BYTES</td>\n+      <td>bytes</td>\n+      <td>BINARY</td>\n+    </tr>\n+    <tr>\n+      <td>DECIMAL</td>\n+      <td>decimal</td>\n+      <td>DECIMAL</td>\n+    </tr>\n+    <tr>\n+      <td>TINYINT</td>\n+      <td>long</td>\n+      <td>BYTE</td>\n+    </tr>\n+    <tr>\n+      <td>SMALLINT</td>\n+      <td>long</td>\n+      <td>SHORT</td>\n+    </tr>\n+    <tr>\n+      <td>INT</td>\n+      <td>long</td>\n+      <td>INT</td>\n+    </tr>\n+    <tr>\n+      <td>BIGINT</td>\n+      <td>long</td>\n+      <td>LONG</td>\n+    </tr>\n+    <tr>\n+      <td>FLOAT</td>\n+      <td>double</td>\n+      <td>FLOAT</td>\n+    </tr>\n+    <tr>\n+      <td>DOUBLE</td>\n+      <td>double</td>\n+      <td>DOUBLE</td>\n+    </tr>\n+    <tr>\n+      <td>DATE</td>\n+      <td>long</td>\n+      <td>DATE</td>\n+    </tr>\n+    <tr>\n+      <td>TIMESTAMP</td>\n+      <td>timestamp</td>\n+      <td>TIMESTAMP</td>\n+    </tr>\n+    </tbody>\n+</table>\n+\n+<span class=\"label label-danger\">注意</span> 复合数据类型: 数组、 映射和行类型暂不支持。"
        },
        {
            "sha": "ebb1da703b56fa9dde046fdf037f29d064c2b7ab",
            "filename": "docs/content.zh/docs/connectors/table/formats/overview.md",
            "status": "added",
            "additions": 99,
            "deletions": 0,
            "changes": 99,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/formats/overview.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/formats/overview.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/table/formats/overview.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,99 @@\n+---\n+title: \"Formats\"\n+weight: 1\n+type: docs\n+aliases:\n+  - /dev/table/connectors/formats/\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Formats\n+\n+Flink 提供了一套与表连接器（table connector）一起使用的表格式（table format）。表格式是一种存储格式，定义了如何把二进制数据映射到表的列上。\n+\n+Flink 支持以下格式：\n+\n+<table class=\"table table-bordered\">\n+    <thead>\n+      <tr>\n+        <th class=\"text-left\">Formats</th>\n+        <th class=\"text-left\">Supported Connectors</th>\n+      </tr>\n+    </thead>\n+    <tbody>\n+        <tr>\n+          <td><a href=\"{{< ref \"docs/connectors/table/formats/csv\" >}}\">CSV</a></td>\n+          <td><a href=\"{{< ref \"docs/connectors/table/kafka\" >}}\">Apache Kafka</a>,\n+          <a href=\"{{< ref \"docs/connectors/table/upsert-kafka\" >}}\">Upsert Kafka</a>,\n+          <a href=\"{{< ref \"docs/connectors/table/kinesis\" >}}\">Amazon Kinesis Data Streams</a>,\n+          <a href=\"{{< ref \"docs/connectors/table/filesystem\" >}}\">Filesystem</a></td>\n+        </tr>\n+        <tr>\n+         <td><a href=\"{{< ref \"docs/connectors/table/formats/json\" >}}\">JSON</a></td>\n+         <td><a href=\"{{< ref \"docs/connectors/table/kafka\" >}}\">Apache Kafka</a>,\n+          <a href=\"{{< ref \"docs/connectors/table/upsert-kafka\" >}}\">Upsert Kafka</a>,\n+          <a href=\"{{< ref \"docs/connectors/table/kinesis\" >}}\">Amazon Kinesis Data Streams</a>,\n+          <a href=\"{{< ref \"docs/connectors/table/filesystem\" >}}\">Filesystem</a>,\n+          <a href=\"{{< ref \"docs/connectors/table/elasticsearch\" >}}\">Elasticsearch</a></td>\n+        </tr>\n+        <tr>\n+          <td><a href=\"{{< ref \"docs/connectors/table/formats/avro\" >}}\">Apache Avro</a></td>\n+          <td><a href=\"{{< ref \"docs/connectors/table/kafka\" >}}\">Apache Kafka</a>,\n+           <a href=\"{{< ref \"docs/connectors/table/upsert-kafka\" >}}\">Upsert Kafka</a>,\n+           <a href=\"{{< ref \"docs/connectors/table/kinesis\" >}}\">Amazon Kinesis Data Streams</a>,\n+           <a href=\"{{< ref \"docs/connectors/table/filesystem\" >}}\">Filesystem</a></td>\n+        </tr>\n+        <tr>\n+          <td><a href=\"{{< ref \"docs/connectors/table/formats/avro-confluent\" >}}\">Confluent Avro</a></td>\n+          <td><a href=\"{{< ref \"docs/connectors/table/kafka\" >}}\">Apache Kafka</a>,\n+           <a href=\"{{< ref \"docs/connectors/table/upsert-kafka\" >}}\">Upsert Kafka</a></td>\n+        </tr>\n+        <tr>\n+         <td><a href=\"{{< ref \"docs/connectors/table/formats/debezium\" >}}\">Debezium CDC</a></td>\n+          <td><a href=\"{{< ref \"docs/connectors/table/kafka\" >}}\">Apache Kafka</a>,\n+           <a href=\"{{< ref \"docs/connectors/table/filesystem\" >}}\">Filesystem</a></td>\n+        </tr>\n+        <tr>\n+         <td><a href=\"{{< ref \"docs/connectors/table/formats/canal\" >}}\">Canal CDC</a></td>\n+          <td><a href=\"{{< ref \"docs/connectors/table/kafka\" >}}\">Apache Kafka</a>,\n+           <a href=\"{{< ref \"docs/connectors/table/filesystem\" >}}\">Filesystem</a></td>\n+        </tr>\n+        <tr>\n+         <td><a href=\"{{< ref \"docs/connectors/table/formats/maxwell\" >}}\">Maxwell CDC</a></td>\n+          <td><a href=\"{{< ref \"docs/connectors/table/kafka\" >}}\">Apache Kafka</a>,\n+           <a href=\"{{< ref \"docs/connectors/table/filesystem\" >}}\">Filesystem</a></td>\n+        </tr>\n+        <tr>\n+         <td><a href=\"{{< ref \"docs/connectors/table/formats/parquet\" >}}\">Apache Parquet</a></td>\n+         <td><a href=\"{{< ref \"docs/connectors/table/filesystem\" >}}\">Filesystem</a></td>\n+        </tr>\n+        <tr>\n+         <td><a href=\"{{< ref \"docs/connectors/table/formats/orc\" >}}\">Apache ORC</a></td>\n+         <td><a href=\"{{< ref \"docs/connectors/table/filesystem\" >}}\">Filesystem</a></td>\n+        </tr>\n+        <tr>\n+        <td><a href=\"{{< ref \"docs/connectors/table/formats/raw\" >}}\">Raw</a></td>\n+        <td><a href=\"{{< ref \"docs/connectors/table/kafka\" >}}\">Apache Kafka</a>,\n+          <a href=\"{{< ref \"docs/connectors/table/upsert-kafka\" >}}\">Upsert Kafka</a>,\n+          <a href=\"{{< ref \"docs/connectors/table/kinesis\" >}}\">Amazon Kinesis Data Streams</a>,\n+          <a href=\"{{< ref \"docs/connectors/table/filesystem\" >}}\">Filesystem</a></td>\n+        </tr>\n+    </tbody>\n+</table>"
        },
        {
            "sha": "a736770ad058fef748eaadc8f78ddf50396172ea",
            "filename": "docs/content.zh/docs/connectors/table/formats/parquet.md",
            "status": "added",
            "additions": 180,
            "deletions": 0,
            "changes": 180,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/formats/parquet.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/formats/parquet.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/table/formats/parquet.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,180 @@\n+---\n+title: Parquet\n+weight: 8\n+type: docs\n+aliases:\n+  - /zh/dev/table/connectors/formats/parquet.html\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Parquet 格式\n+\n+{{< label \"Format: Serialization Schema\" >}}\n+{{< label \"Format: Deserialization Schema\" >}}\n+\n+[Apache Parquet](https://parquet.apache.org/) 格式允许读写 Parquet 数据.\n+\n+依赖\n+------------\n+\n+{{< sql_download_table \"parquet\" >}}\n+\n+如何创建基于 Parquet 格式的表\n+----------------\n+\n+以下为用 Filesystem 连接器和 Parquet 格式创建表的示例，\n+\n+```sql\n+CREATE TABLE user_behavior (\n+  user_id BIGINT,\n+  item_id BIGINT,\n+  category_id BIGINT,\n+  behavior STRING,\n+  ts TIMESTAMP(3),\n+  dt STRING\n+) PARTITIONED BY (dt) WITH (\n+ 'connector' = 'filesystem',\n+ 'path' = '/tmp/user_behavior',\n+ 'format' = 'parquet'\n+)\n+```\n+\n+Format 参数\n+----------------\n+\n+<table class=\"table table-bordered\">\n+    <thead>\n+      <tr>\n+        <th class=\"text-left\" style=\"width: 25%\">参数</th>\n+        <th class=\"text-center\" style=\"width: 8%\">是否必须</th>\n+        <th class=\"text-center\" style=\"width: 7%\">默认值</th>\n+        <th class=\"text-center\" style=\"width: 10%\">类型</th>\n+        <th class=\"text-center\" style=\"width: 50%\">描述</th>\n+      </tr>\n+    </thead>\n+    <tbody>\n+    <tr>\n+      <td><h5>format</h5></td>\n+      <td>必选</td>\n+      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>String</td>\n+      <td>指定使用的格式，此处应为\"parquet\"。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>parquet.utc-timezone</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">false</td>\n+      <td>Boolean</td>\n+      <td>使用 UTC 时区或本地时区在纪元时间和 LocalDateTime 之间进行转换。Hive 0.x/1.x/2.x 使用本地时区，但 Hive 3.x 使用 UTC 时区。</td>\n+    </tr>\n+    </tbody>\n+</table>\n+\n+Parquet 格式也支持 [ParquetOutputFormat](https://www.javadoc.io/doc/org.apache.parquet/parquet-hadoop/1.10.0/org/apache/parquet/hadoop/ParquetOutputFormat.html) 的配置。\n+例如, 可以配置 `parquet.compression=GZIP` 来开启 gzip 压缩。\n+\n+数据类型映射\n+----------------\n+\n+目前，Parquet 格式类型映射与 Apache Hive 兼容，但与 Apache Spark 有所不同：\n+\n+- Timestamp：不论精度，映射 timestamp 类型至 int96。\n+- Decimal：根据精度，映射 decimal 类型至固定长度字节的数组。\n+\n+下表列举了 Flink 中的数据类型与 JSON 中的数据类型的映射关系。\n+\n+<table class=\"table table-bordered\">\n+    <thead>\n+      <tr>\n+        <th class=\"text-left\">Flink 数据类型</th>\n+        <th class=\"text-center\">Parquet 类型</th>\n+        <th class=\"text-center\">Parquet 逻辑类型</th>\n+      </tr>\n+    </thead>\n+    <tbody>\n+    <tr>\n+      <td>CHAR / VARCHAR / STRING</td>\n+      <td>BINARY</td>\n+      <td>UTF8</td>\n+    </tr>\n+    <tr>\n+      <td>BOOLEAN</td>\n+      <td>BOOLEAN</td>\n+      <td></td>\n+    </tr>\n+    <tr>\n+      <td>BINARY / VARBINARY</td>\n+      <td>BINARY</td>\n+      <td></td>\n+    </tr>\n+    <tr>\n+      <td>DECIMAL</td>\n+      <td>FIXED_LEN_BYTE_ARRAY</td>\n+      <td>DECIMAL</td>\n+    </tr>\n+    <tr>\n+      <td>TINYINT</td>\n+      <td>INT32</td>\n+      <td>INT_8</td>\n+    </tr>\n+    <tr>\n+      <td>SMALLINT</td>\n+      <td>INT32</td>\n+      <td>INT_16</td>\n+    </tr>\n+    <tr>\n+      <td>INT</td>\n+      <td>INT32</td>\n+      <td></td>\n+    </tr>\n+    <tr>\n+      <td>BIGINT</td>\n+      <td>INT64</td>\n+      <td></td>\n+    </tr>\n+    <tr>\n+      <td>FLOAT</td>\n+      <td>FLOAT</td>\n+      <td></td>\n+    </tr>\n+    <tr>\n+      <td>DOUBLE</td>\n+      <td>DOUBLE</td>\n+      <td></td>\n+    </tr>\n+    <tr>\n+      <td>DATE</td>\n+      <td>INT32</td>\n+      <td>DATE</td>\n+    </tr>\n+    <tr>\n+      <td>TIME</td>\n+      <td>INT32</td>\n+      <td>TIME_MILLIS</td>\n+    </tr>\n+    <tr>\n+      <td>TIMESTAMP</td>\n+      <td>INT96</td>\n+      <td></td>\n+    </tr>\n+    </tbody>\n+</table>\n+\n+<span class=\"label label-danger\">注意</span> 暂不支持复合数据类型（Array、Map 与 Row）。"
        },
        {
            "sha": "5bd721c1498e741f15a489b52e7d0007ff19b111",
            "filename": "docs/content.zh/docs/connectors/table/formats/raw.md",
            "status": "added",
            "additions": 172,
            "deletions": 0,
            "changes": 172,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/formats/raw.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/formats/raw.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/table/formats/raw.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,172 @@\n+---\n+title: Raw\n+weight: 10\n+type: docs\n+aliases:\n+  - /zh/dev/table/connectors/formats/raw.html\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Raw Format\n+\n+{{< label \"Format: Serialization Schema\" >}}\n+{{< label \"Format: Deserialization Schema\" >}}\n+\n+Raw format 允许读写原始（基于字节）值作为单个列。\n+\n+注意: 这种格式将 `null` 值编码成 `byte[]` 类型的 `null`。这样在 `upsert-kafka` 中使用时可能会有限制，因为 `upsert-kafka` 将 `null` 值视为 墓碑消息（在键上删除）。因此，如果该字段可能具有 `null` 值，我们建议避免使用 `upsert-kafka` 连接器和 `raw` format 作为 `value.format`。\n+\n+Raw format 连接器是内置的。\n+\n+示例\n+----------------\n+\n+例如，你可能在 Kafka 中具有原始日志数据，并希望使用 Flink SQL 读取和分析此类数据。\n+\n+```\n+47.29.201.179 - - [28/Feb/2019:13:17:10 +0000] \"GET /?p=1 HTTP/2.0\" 200 5316 \"https://domain.com/?p=1\" \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.119 Safari/537.36\" \"2.75\"\n+```\n+\n+下面的代码创建了一张表，使用 `raw` format 以 UTF-8 编码的形式从中读取（也可以写入）底层的 Kafka topic 作为匿名字符串值：\n+\n+```sql\n+CREATE TABLE nginx_log (\n+  log STRING\n+) WITH (\n+  'connector' = 'kafka',\n+  'topic' = 'nginx_log',\n+  'properties.bootstrap.servers' = 'localhost:9092',\n+  'properties.group.id' = 'testGroup',\n+  'format' = 'raw'\n+)\n+```\n+\n+然后，你可以将原始数据读取为纯字符串，之后使用用户自定义函数将其分为多个字段进行进一步分析。例如 示例中的 `my_split`。\n+\n+```sql\n+SELECT t.hostname, t.datetime, t.url, t.browser, ...\n+FROM(\n+  SELECT my_split(log) as t FROM nginx_log\n+);\n+```\n+\n+相对应的，你也可以将一个 STRING 类型的列以 UTF-8 编码的匿名字符串值写入 Kafka topic。\n+\n+Format 参数\n+----------------\n+\n+<table class=\"table table-bordered\">\n+    <thead>\n+      <tr>\n+        <th class=\"text-left\" style=\"width: 25%\">参数</th>\n+        <th class=\"text-center\" style=\"width: 8%\">是否必选</th>\n+        <th class=\"text-center\" style=\"width: 7%\">默认值</th>\n+        <th class=\"text-center\" style=\"width: 10%\">类型</th>\n+        <th class=\"text-center\" style=\"width: 50%\">描述</th>\n+      </tr>\n+    </thead>\n+    <tbody>\n+    <tr>\n+      <td><h5>format</h5></td>\n+      <td>必选</td>\n+      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>String</td>\n+      <td>指定要使用的格式, 这里应该是 'raw'。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>raw.charset</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">UTF-8</td>\n+      <td>String</td>\n+      <td>指定字符集来编码文本字符串。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>raw.endianness</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">big-endian</td>\n+      <td>String</td>\n+      <td>指定字节序来编码数字值的字节。有效值为'big-endian'和'little-endian'。\n+      更多细节可查阅 <a href=\"https://zh.wikipedia.org/wiki/字节序\">字节序</a>。</td>\n+    </tr>\n+    </tbody>\n+</table>\n+\n+数据类型映射\n+----------------\n+\n+下表详细说明了这种格式支持的 SQL 类型，包括用于编码和解码的序列化类和反序列化类的详细信息。\n+\n+<table class=\"table table-bordered\">\n+    <thead>\n+      <tr>\n+        <th class=\"text-left\">Flink SQL 类型</th>\n+        <th class=\"text-left\">值</th>\n+      </tr>\n+    </thead>\n+    <tbody>\n+    <tr>\n+      <td><code>CHAR / VARCHAR / STRING</code></td>\n+      <td>UTF-8（默认）编码的文本字符串。<br>\n+       编码字符集可以通过 'raw.charset' 进行配置。</td>\n+    </tr>\n+    <tr>\n+      <td><code>BINARY / VARBINARY / BYTES</code></td>\n+      <td>字节序列本身。</td>\n+    </tr>\n+    <tr>\n+      <td><code>BOOLEAN</code></td>\n+      <td>表示布尔值的单个字节，0表示 false, 1 表示 true。</td>\n+    </tr>\n+    <tr>\n+      <td><code>TINYINT</code></td>\n+      <td>有符号数字值的单个字节。</td>\n+    </tr>\n+    <tr>\n+      <td><code>SMALLINT</code></td>\n+      <td>采用big-endian（默认）编码的两个字节。<br>\n+       字节序可以通过 'raw.endianness' 配置。</td>\n+    </tr>\n+    <tr>\n+      <td><code>INT</code></td>\n+      <td>采用 big-endian （默认）编码的四个字节。<br>\n+       字节序可以通过 'raw.endianness' 配置。</td>\n+    </tr>\n+    <tr>\n+      <td><code>BIGINT</code></td>\n+      <td>采用 big-endian （默认）编码的八个字节。<br>\n+       字节序可以通过 'raw.endianness' 配置。</td>\n+    </tr>\n+    <tr>\n+      <td><code>FLOAT</code></td>\n+      <td>采用 IEEE 754 格式和 big-endian （默认）编码的四个字节。<br>\n+       字节序可以通过 'raw.endianness' 配置。</td>\n+    </tr>\n+    <tr>\n+      <td><code>DOUBLE</code></td>\n+      <td>采用 IEEE 754 格式和 big-endian （默认）编码的八个字节。<br>\n+       字节序可以通过 'raw.endianness' 配置。</td>\n+    </tr>\n+    <tr>\n+      <td><code>RAW</code></td>\n+      <td>通过 RAW 类型的底层 TypeSerializer 序列化的字节序列。</td>\n+    </tr>\n+    </tbody>\n+</table>\n+"
        },
        {
            "sha": "930c134619b365644897e9d2df8a44c5c2d7c94b",
            "filename": "docs/content.zh/docs/connectors/table/hbase.md",
            "status": "added",
            "additions": 336,
            "deletions": 0,
            "changes": 336,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/hbase.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/hbase.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/table/hbase.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,336 @@\n+---\n+title: HBase\n+weight: 9\n+type: docs\n+aliases:\n+  - /zh/dev/table/connectors/hbase.html\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# HBase SQL 连接器\n+\n+{{< label \"Scan Source: Bounded\" >}}\n+{{< label \"Lookup Source: Sync Mode\" >}}\n+{{< label \"Sink: Batch\" >}}\n+{{< label \"Sink: Streaming Upsert Mode\" >}}\n+\n+HBase 连接器支持读取和写入 HBase 集群。本文档介绍如何使用 HBase 连接器基于 HBase 进行 SQL 查询。\n+\n+HBase 连接器在 upsert 模式下运行，可以使用 DDL 中定义的主键与外部系统交换更新操作消息。但是主键只能基于 HBase 的 rowkey 字段定义。如果没有声明主键，HBase 连接器默认取 rowkey 作为主键。\n+\n+依赖\n+------------\n+\n+{{< sql_download_table \"hbase\" >}}\n+\n+\n+如何使用 HBase 表\n+----------------\n+\n+所有 HBase 表的列簇必须定义为 ROW 类型，字段名对应列簇名（column family），嵌套的字段名对应列限定符名（column qualifier）。用户只需在表结构中声明查询中使用的的列簇和列限定符。除了 ROW 类型的列，剩下的原子数据类型字段（比如，STRING, BIGINT）将被识别为 HBase 的 rowkey，一张表中只能声明一个 rowkey。rowkey 字段的名字可以是任意的，如果是保留关键字，需要用反引号。\n+\n+```sql\n+-- 在 Flink SQL 中注册 HBase 表 \"mytable\"\n+CREATE TABLE hTable (\n+ rowkey INT,\n+ family1 ROW<q1 INT>,\n+ family2 ROW<q2 STRING, q3 BIGINT>,\n+ family3 ROW<q4 DOUBLE, q5 BOOLEAN, q6 STRING>,\n+ PRIMARY KEY (rowkey) NOT ENFORCED\n+) WITH (\n+ 'connector' = 'hbase-1.4',\n+ 'table-name' = 'mytable',\n+ 'zookeeper.quorum' = 'localhost:2181'\n+);\n+\n+-- 用 ROW(...) 构造函数构造列簇，并往 HBase 表写数据。\n+-- 假设 \"T\" 的表结构是 [rowkey, f1q1, f2q2, f2q3, f3q4, f3q5, f3q6]\n+INSERT INTO hTable\n+SELECT rowkey, ROW(f1q1), ROW(f2q2, f2q3), ROW(f3q4, f3q5, f3q6) FROM T;\n+\n+-- 从 HBase 表扫描数据\n+SELECT rowkey, family1, family3.q4, family3.q6 FROM hTable;\n+\n+-- temporal join HBase 表，将 HBase 表作为维表\n+SELECT * FROM myTopic\n+LEFT JOIN hTable FOR SYSTEM_TIME AS OF myTopic.proctime\n+ON myTopic.key = hTable.rowkey;\n+```\n+\n+连接器参数\n+----------------\n+\n+<table class=\"table table-bordered\">\n+    <thead>\n+      <tr>\n+        <th class=\"text-left\" style=\"width: 25%\">参数</th>\n+        <th class=\"text-center\" style=\"width: 10%\">是否必选</th>\n+        <th class=\"text-center\" style=\"width: 10%\">默认值</th>\n+        <th class=\"text-center\" style=\"width: 10%\">数据类型</th>\n+        <th class=\"text-center\" style=\"width: 45%\">描述</th>\n+      </tr>\n+    </thead>\n+    <tbody>\n+    <tr>\n+      <td><h5>connector</h5></td>\n+      <td>必选</td>\n+      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>String</td>\n+      <td>指定使用的连接器, 支持的值如下 :\n+        <ul>\n+            <li><code>hbase-1.4</code>: 连接 HBase 1.4.x 集群</li>\n+            <li><code>hbase-2.2</code>: 连接 HBase 2.2.x 集群</li>\n+        </ul>\n+      </td>\n+    </tr>\n+    <tr>\n+      <td><h5>table-name</h5></td>\n+      <td>必选</td>\n+      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>String</td>\n+      <td>连接的 HBase 表名。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>zookeeper.quorum</h5></td>\n+      <td>必选</td>\n+      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>String</td>\n+      <td>HBase Zookeeper quorum 信息。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>zookeeper.znode.parent</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">/hbase</td>\n+      <td>String</td>\n+      <td>HBase 集群的 Zookeeper 根目录。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>null-string-literal</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">null</td>\n+      <td>String</td>\n+      <td>当字符串值为 <code>null</code> 时的存储形式，默认存成 \"null\" 字符串。HBase 的 source 和 sink 的编解码将所有数据类型（除字符串外）将 <code>null</code> 值以空字节来存储。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>sink.buffer-flush.max-size</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">2mb</td>\n+      <td>MemorySize</td>\n+      <td>写入的参数选项。每次写入请求缓存行的最大大小。它能提升写入 HBase 数据库的性能，但是也可能增加延迟。设置为 \"0\" 关闭此选项。\n+      </td>\n+    </tr>\n+    <tr>\n+      <td><h5>sink.buffer-flush.max-rows</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">1000</td>\n+      <td>Integer</td>\n+      <td>写入的参数选项。 每次写入请求缓存的最大行数。它能提升写入 HBase 数据库的性能，但是也可能增加延迟。设置为 \"0\" 关闭此选项。\n+      </td>\n+    </tr>\n+    <tr>\n+      <td><h5>sink.buffer-flush.interval</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">1s</td>\n+      <td>Duration</td>\n+      <td>写入的参数选项。刷写缓存行的间隔。它能提升写入 HBase 数据库的性能，但是也可能增加延迟。设置为 \"0\" 关闭此选项。注意：\"sink.buffer-flush.max-size\" 和 \"sink.buffer-flush.max-rows\" 同时设置为 \"0\"，刷写选项整个异步处理缓存行为。\n+      </td>\n+    </tr>\n+    <tr>\n+      <td><h5>sink.parallelism</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>Integer</td>\n+      <td>为 HBase sink operator 定义并行度。默认情况下，并行度由框架决定，和链在一起的上游 operator 一样。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>lookup.async</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">false</td>\n+      <td>Boolean</td>\n+      <td>是否启用异步查找。如果为真，查找将是异步的。注意：异步方式只支持 hbase-2.2 连接器</td>\n+    </tr>\n+    <tr>\n+      <td><h5>lookup.cache.max-rows</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">(无)</td>\n+      <td>Integer</td>\n+      <td>查找缓存的最大行数，超过这个值，最旧的行将过期。注意：\"lookup.cache.max-rows\" 和 \"lookup.cache.ttl\" 必须同时被设置。默认情况下，查找缓存是禁用的。 </td>\n+    </tr>\n+    <tr>\n+      <td><h5>lookup.cache.ttl</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">(无)</td>\n+      <td>Duration</td>\n+      <td>查找缓存中每一行的最大生存时间，在这段时间内，最老的行将过期。注意：\"lookup.cache.max-rows\" 和 \"lookup.cache.ttl\" 必须同时被设置。默认情况下，查找缓存是禁用的。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>lookup.max-retries</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">3</td>\n+      <td>Integer</td>\n+      <td>查找数据库失败时的最大重试次数。</td>\n+    </tr>\n+    <tr>\n+      <td><h5>properties.*</h5></td>\n+      <td>可选</td>\n+      <td style=\"word-wrap: break-word;\">(无)</td>\n+      <td>String</td>\n+      <td>\n+         可以设置任意 HBase 的配置项。后缀名必须匹配在 <a href=\"http://hbase.apache.org/2.3/book.html#hbase_default_configurations\">HBase 配置文档</a> 中定义的配置键。Flink 将移除 \"properties.\" 配置键前缀并将变换后的配置键和值传入底层的 HBase 客户端。\n+         例如您可以设置 <code>'properties.hbase.security.authentication' = 'kerberos'</code> 等kerberos认证参数。\n+      </td>\n+    </tr>\n+    </tbody>\n+</table>\n+\n+\n+\n+数据类型映射表\n+----------------\n+\n+HBase 以字节数组存储所有数据。在读和写过程中要序列化和反序列化数据。\n+\n+Flink 的 HBase 连接器利用 HBase（Hadoop) 的工具类 `org.apache.hadoop.hbase.util.Bytes` 进行字节数组和 Flink 数据类型转换。\n+\n+Flink 的 HBase 连接器将所有数据类型（除字符串外）`null` 值编码成空字节。对于字符串类型，`null` 值的字面值由`null-string-literal`选项值决定。\n+\n+数据类型映射表如下：\n+\n+<table class=\"table table-bordered\">\n+    <thead>\n+      <tr>\n+        <th class=\"text-left\">Flink 数据类型</th>\n+        <th class=\"text-left\">HBase 转换</th>\n+      </tr>\n+    </thead>\n+    <tbody>\n+    <tr>\n+      <td><code>CHAR / VARCHAR / STRING</code></td>\n+      <td>\n+{{< highlight \"java\" >}}\n+byte[] toBytes(String s)\n+String toString(byte[] b)\n+{{< /highlight >}}\n+      </td>\n+    </tr>\n+    <tr>\n+      <td><code>BOOLEAN</code></td>\n+      <td>\n+{{< highlight \"java\" >}}\n+byte[] toBytes(boolean b)\n+boolean toBoolean(byte[] b)\n+{{< /highlight >}}\n+      </td>\n+    </tr>\n+    <tr>\n+      <td><code>BINARY / VARBINARY</code></td>\n+      <td>返回 <code>byte[]</code>。</td>\n+    </tr>\n+    <tr>\n+      <td><code>DECIMAL</code></td>\n+      <td>\n+{{< highlight \"java\" >}}\n+byte[] toBytes(BigDecimal v)\n+BigDecimal toBigDecimal(byte[] b)\n+{{< /highlight >}}\n+      </td>\n+    </tr>\n+    <tr>\n+      <td><code>TINYINT</code></td>\n+      <td>\n+{{< highlight \"java\" >}}\n+new byte[] { val }\n+bytes[0] // returns first and only byte from bytes\n+{{< /highlight >}}\n+      </td>\n+    </tr>\n+    <tr>\n+      <td><code>SMALLINT</code></td>\n+      <td>\n+{{< highlight \"java\" >}}\n+byte[] toBytes(short val)\n+short toShort(byte[] bytes)\n+{{< /highlight >}}\n+      </td>\n+    </tr>\n+    <tr>\n+      <td><code>INT</code></td>\n+      <td>\n+{{< highlight \"java\" >}}\n+byte[] toBytes(int val)\n+int toInt(byte[] bytes)\n+{{< /highlight >}}\n+      </td>\n+    </tr>\n+    <tr>\n+      <td><code>BIGINT</code></td>\n+      <td>\n+{{< highlight \"java\" >}}\n+byte[] toBytes(long val)\n+long toLong(byte[] bytes)\n+{{< /highlight >}}\n+      </td>\n+    </tr>\n+    <tr>\n+      <td><code>FLOAT</code></td>\n+      <td>\n+{{< highlight \"java\" >}}\n+byte[] toBytes(float val)\n+float toFloat(byte[] bytes)\n+{{< /highlight >}}\n+      </td>\n+    </tr>\n+    <tr>\n+      <td><code>DOUBLE</code></td>\n+      <td>\n+{{< highlight \"java\" >}}\n+byte[] toBytes(double val)\n+double toDouble(byte[] bytes)\n+{{< /highlight >}}\n+      </td>\n+    </tr>\n+    <tr>\n+      <td><code>DATE</code></td>\n+      <td>从 1970-01-01 00:00:00 UTC 开始的天数，int 值。</td>\n+    </tr>\n+    <tr>\n+      <td><code>TIME</code></td>\n+      <td>从 1970-01-01 00:00:00 UTC 开始天的毫秒数，int 值。</td>\n+    </tr>\n+    <tr>\n+      <td><code>TIMESTAMP</code></td>\n+      <td>从 1970-01-01 00:00:00 UTC 开始的毫秒数，long 值。</td>\n+    </tr>\n+    <tr>\n+      <td><code>ARRAY</code></td>\n+      <td>不支持</td>\n+    </tr>\n+    <tr>\n+      <td><code>MAP / MULTISET</code></td>\n+      <td>不支持</td>\n+    </tr>\n+    <tr>\n+      <td><code>ROW</code></td>\n+      <td>不支持</td>\n+    </tr>\n+    </tbody>\n+</table>\n+\n+{{< top >}}"
        },
        {
            "sha": "615740adb5005802b42563fd6e322c7a15856773",
            "filename": "docs/content.zh/docs/connectors/table/hive/_index.md",
            "status": "added",
            "additions": 23,
            "deletions": 0,
            "changes": 23,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/hive/_index.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/hive/_index.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/table/hive/_index.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,23 @@\n+---\n+title: Hive\n+bookCollapseSection: true\n+weight: 16\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n\\ No newline at end of file"
        },
        {
            "sha": "0353a1be80bfcf7e733c4909917c0dfddc781f6f",
            "filename": "docs/content.zh/docs/connectors/table/hive/hive_catalog.md",
            "status": "added",
            "additions": 397,
            "deletions": 0,
            "changes": 397,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/hive/hive_catalog.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/hive/hive_catalog.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/table/hive/hive_catalog.md?ref=09f868827166da872cb8d683c3c959231e96ae40",
            "patch": "@@ -0,0 +1,397 @@\n+---\n+title: \"Hive Catalog\"\n+weight: 2\n+type: docs\n+aliases:\n+  - /zh/dev/table/connectors/hive/hive_catalog.html\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+# Hive Catalog\n+\n+Hive Metastore has evolved into the de facto metadata hub over the years in Hadoop ecosystem. Many companies have a single\n+Hive Metastore service instance in their production to manage all of their metadata, either Hive metadata or non-Hive metadata,\n+ as the source of truth.\n+ \n+For users who have both Hive and Flink deployments, `HiveCatalog` enables them to use Hive Metastore to manage Flink's metadata.\n+\n+For users who have just Flink deployment, `HiveCatalog` is the only persistent catalog provided out-of-box by Flink.\n+Without a persistent catalog, users using [Flink SQL CREATE DDL]({{< ref \"docs/dev/table/sql/create\" >}}) have to repeatedly\n+create meta-objects like a Kafka table in each session, which wastes a lot of time. `HiveCatalog` fills this gap by empowering\n+users to create tables and other meta-objects only once, and reference and manage them with convenience later on across sessions.\n+\n+\n+## Set up HiveCatalog\n+\n+### Dependencies\n+\n+Setting up a `HiveCatalog` in Flink requires the same [dependencies]({{< ref \"docs/connectors/table/hive/overview\" >}}#dependencies) \n+as those of an overall Flink-Hive integration.\n+\n+### Configuration\n+\n+Setting up a `HiveCatalog` in Flink requires the same [configuration]({{< ref \"docs/connectors/table/hive/overview\" >}}#connecting-to-hive) \n+as those of an overall Flink-Hive integration.\n+\n+\n+## How to use HiveCatalog\n+\n+Once configured properly, `HiveCatalog` should just work out of box. Users can create Flink meta-objects with DDL, and should\n+see them immediately afterwards.\n+\n+`HiveCatalog` can be used to handle two kinds of tables: Hive-compatible tables and generic tables. Hive-compatible tables\n+are those stored in a Hive-compatible way, in terms of both metadata and data in the storage layer. Therefore, Hive-compatible tables\n+created via Flink can be queried from Hive side.\n+\n+Generic tables, on the other hand, are specific to Flink. When creating generic tables with `HiveCatalog`, we're just using\n+HMS to persist the metadata. While these tables are visible to Hive, it's unlikely Hive is able to understand\n+the metadata. And therefore using such tables in Hive leads to undefined behavior.\n+\n+Flink uses the property '*is_generic*' to tell whether a table is Hive-compatible or generic. When creating a table with\n+`HiveCatalog`, it's by default considered generic. If you'd like to create a Hive-compatible table, make sure to set\n+`is_generic` to false in your table properties.\n+\n+As stated above, generic tables shouldn't be used from Hive. In Hive CLI, you can call `DESCRIBE FORMATTED` for a table and\n+decide whether it's generic or not by checking the `is_generic` property. Generic tables will have `is_generic=true`.\n+\n+### Example\n+\n+We will walk through a simple example here.\n+\n+#### step 1: set up a Hive Metastore\n+\n+Have a Hive Metastore running. \n+\n+Here, we set up a local Hive Metastore and our `hive-site.xml` file in local path `/opt/hive-conf/hive-site.xml`.\n+We have some configs like the following:\n+\n+```xml\n+\n+<configuration>\n+   <property>\n+      <name>javax.jdo.option.ConnectionURL</name>\n+      <value>jdbc:mysql://localhost/metastore?createDatabaseIfNotExist=true</value>\n+      <description>metadata is stored in a MySQL server</description>\n+   </property>\n+\n+   <property>\n+      <name>javax.jdo.option.ConnectionDriverName</name>\n+      <value>com.mysql.jdbc.Driver</value>\n+      <description>MySQL JDBC driver class</description>\n+   </property>\n+\n+   <property>\n+      <name>javax.jdo.option.ConnectionUserName</name>\n+      <value>...</value>\n+      <description>user name for connecting to mysql server</description>\n+   </property>\n+\n+   <property>\n+      <name>javax.jdo.option.ConnectionPassword</name>\n+      <value>...</value>\n+      <description>password for connecting to mysql server</description>\n+   </property>\n+\n+   <property>\n+       <name>hive.metastore.uris</name>\n+       <value>thrift://localhost:9083</value>\n+       <description>IP address (or fully-qualified domain name) and port of the metastore host</description>\n+   </property>\n+\n+   <property>\n+       <name>hive.metastore.schema.verification</name>\n+       <value>true</value>\n+   </property>\n+\n+</configuration>\n+```\n+\n+\n+Test connection to the HMS with Hive Cli. Running some commands, we can see we have a database named `default` and there's no table in it.\n+\n+\n+```bash\n+\n+hive> show databases;\n+OK\n+default\n+Time taken: 0.032 seconds, Fetched: 1 row(s)\n+\n+hive> show tables;\n+OK\n+Time taken: 0.028 seconds, Fetched: 0 row(s)\n+```\n+\n+\n+#### step 2: configure Flink cluster and SQL CLI\n+\n+Add all Hive dependencies to `/lib` dir in Flink distribution, and modify SQL CLI's yaml config file `sql-cli-defaults.yaml` as following:\n+\n+```yaml\n+\n+execution:\n+    planner: blink\n+    type: streaming\n+    ...\n+    current-catalog: myhive  # set the HiveCatalog as the current catalog of the session\n+    current-database: mydatabase\n+    \n+catalogs:\n+   - name: myhive\n+     type: hive\n+     hive-conf-dir: /opt/hive-conf  # contains hive-site.xml\n+```\n+\n+\n+#### step 3: set up a Kafka cluster\n+\n+Bootstrap a local Kafka 2.3.0 cluster with a topic named \"test\", and produce some simple data to the topic as tuple of name and age.\n+\n+```bash\n+\n+localhost$ bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test\n+>tom,15\n+>john,21\n+\n+```\n+\n+\n+These message can be seen by starting a Kafka console consumer.\n+\n+```bash\n+localhost$ bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning\n+\n+tom,15\n+john,21\n+\n+```\n+\n+\n+#### step 4: start SQL Client, and create a Kafka table with Flink SQL DDL\n+\n+Start Flink SQL Client, create a simple Kafka 2.3.0 table via DDL, and verify its schema.\n+\n+```bash\n+\n+Flink SQL> CREATE TABLE mykafka (name String, age Int) WITH (\n+   'connector.type' = 'kafka',\n+   'connector.version' = 'universal',\n+   'connector.topic' = 'test',\n+   'connector.properties.bootstrap.servers' = 'localhost:9092',\n+   'format.type' = 'csv',\n+   'update-mode' = 'append'\n+);\n+[INFO] Table has been created.\n+\n+Flink SQL> DESCRIBE mykafka;\n+root\n+ |-- name: STRING\n+ |-- age: INT\n+\n+```\n+\n+Verify the table is also visible to Hive via Hive Cli, and note that the table has property `is_generic=true`:\n+\n+```bash\n+hive> show tables;\n+OK\n+mykafka\n+Time taken: 0.038 seconds, Fetched: 1 row(s)\n+\n+hive> describe formatted mykafka;\n+OK\n+# col_name            \tdata_type           \tcomment\n+\n+\n+# Detailed Table Information\n+Database:           \tdefault\n+Owner:              \tnull\n+CreateTime:         \t......\n+LastAccessTime:     \tUNKNOWN\n+Retention:          \t0\n+Location:           \t......\n+Table Type:         \tMANAGED_TABLE\n+Table Parameters:\n+\tflink.connector.properties.bootstrap.servers\tlocalhost:9092\n+\tflink.connector.topic\ttest\n+\tflink.connector.type\tkafka\n+\tflink.connector.version\tuniversal\n+\tflink.format.type   \tcsv\n+\tflink.generic.table.schema.0.data-type\tVARCHAR(2147483647)\n+\tflink.generic.table.schema.0.name\tname\n+\tflink.generic.table.schema.1.data-type\tINT\n+\tflink.generic.table.schema.1.name\tage\n+\tflink.update-mode   \tappend\n+\tis_generic          \ttrue\n+\ttransient_lastDdlTime\t......\n+\n+# Storage Information\n+SerDe Library:      \torg.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\n+InputFormat:        \torg.apache.hadoop.mapred.TextInputFormat\n+OutputFormat:       \torg.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat\n+Compressed:         \tNo\n+Num Buckets:        \t-1\n+Bucket Columns:     \t[]\n+Sort Columns:       \t[]\n+Storage Desc Params:\n+\tserialization.format\t1\n+Time taken: 0.158 seconds, Fetched: 36 row(s)\n+\n+```\n+\n+\n+#### step 5: run Flink SQL to query the Kafka table\n+\n+Run a simple select query from Flink SQL Client in a Flink cluster, either standalone or yarn-session.\n+\n+```bash\n+Flink SQL> select * from mykafka;\n+\n+```\n+\n+\n+Produce some more messages in the Kafka topic\n+\n+```bash\n+localhost$ bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning\n+\n+tom,15\n+john,21\n+kitty,30\n+amy,24\n+kaiky,18\n+\n+```\n+\n+\n+You should see results produced by Flink in SQL Client now, as:\n+\n+\n+```bash\n+             SQL Query Result (Table)\n+ Refresh: 1 s    Page: Last of 1     \n+\n+        name                       age\n+         tom                        15\n+        john                        21\n+       kitty                        30\n+         amy                        24\n+       kaiky                        18\n+\n+```\n+\n+## Supported Types\n+\n+`HiveCatalog` supports all Flink types for generic tables.\n+\n+For Hive-compatible tables, `HiveCatalog` needs to map Flink data types to corresponding Hive types as described in\n+the following table:\n+\n+<table class=\"table table-bordered\">\n+  <thead>\n+    <tr>\n+      <th class=\"text-center\" style=\"width: 25%\">Flink Data Type</th>\n+      <th class=\"text-center\">Hive Data Type</th>\n+    </tr>\n+  </thead>\n+  <tbody>\n+    <tr>\n+        <td class=\"text-center\">CHAR(p)</td>\n+        <td class=\"text-center\">CHAR(p)</td>\n+    </tr>\n+    <tr>\n+        <td class=\"text-center\">VARCHAR(p)</td>\n+        <td class=\"text-center\">VARCHAR(p)</td>\n+    </tr>\n+        <tr>\n+        <td class=\"text-center\">STRING</td>\n+        <td class=\"text-center\">STRING</td>\n+    </tr>\n+    <tr>\n+        <td class=\"text-center\">BOOLEAN</td>\n+        <td class=\"text-center\">BOOLEAN</td>\n+    </tr>\n+    <tr>\n+        <td class=\"text-center\">TINYINT</td>\n+        <td class=\"text-center\">TINYINT</td>\n+    </tr>\n+    <tr>\n+        <td class=\"text-center\">SMALLINT</td>\n+        <td class=\"text-center\">SMALLINT</td>\n+    </tr>\n+    <tr>\n+        <td class=\"text-center\">INT</td>\n+        <td class=\"text-center\">INT</td>\n+    </tr>\n+    <tr>\n+        <td class=\"text-center\">BIGINT</td>\n+        <td class=\"text-center\">LONG</td>\n+    </tr>\n+    <tr>\n+        <td class=\"text-center\">FLOAT</td>\n+        <td class=\"text-center\">FLOAT</td>\n+    </tr>\n+    <tr>\n+        <td class=\"text-center\">DOUBLE</td>\n+        <td class=\"text-center\">DOUBLE</td>\n+    </tr>\n+    <tr>\n+        <td class=\"text-center\">DECIMAL(p, s)</td>\n+        <td class=\"text-center\">DECIMAL(p, s)</td>\n+    </tr>\n+    <tr>\n+        <td class=\"text-center\">DATE</td>\n+        <td class=\"text-center\">DATE</td>\n+    </tr>\n+    <tr>\n+        <td class=\"text-center\">TIMESTAMP(9)</td>\n+        <td class=\"text-center\">TIMESTAMP</td>\n+    </tr>\n+    <tr>\n+        <td class=\"text-center\">BYTES</td>\n+        <td class=\"text-center\">BINARY</td>\n+    </tr>\n+    <tr>\n+        <td class=\"text-center\">ARRAY&lt;T&gt;</td>\n+        <td class=\"text-center\">LIST&lt;T&gt;</td>\n+    </tr>\n+    <tr>\n+        <td class=\"text-center\">MAP<K, V></td>\n+        <td class=\"text-center\">MAP<K, V></td>\n+    </tr>\n+    <tr>\n+        <td class=\"text-center\">ROW</td>\n+        <td class=\"text-center\">STRUCT</td>\n+    </tr>\n+  </tbody>\n+</table>\n+\n+Something to note about the type mapping:\n+* Hive's `CHAR(p)` has a maximum length of 255\n+* Hive's `VARCHAR(p)` has a maximum length of 65535\n+* Hive's `MAP` only supports primitive key types while Flink's `MAP` can be any data type\n+* Hive's `UNION` type is not supported\n+* Hive's `TIMESTAMP` always has precision 9 and doesn't support other precisions. Hive UDFs, on the other hand, can process `TIMESTAMP` values with a precision <= 9.\n+* Hive doesn't support Flink's `TIMESTAMP_WITH_TIME_ZONE`, `TIMESTAMP_WITH_LOCAL_TIME_ZONE`, and `MULTISET`\n+* Flink's `INTERVAL` type cannot be mapped to Hive `INTERVAL` type yet\n+\n+## Scala Shell\n+\n+NOTE: since blink planner is not well supported in Scala Shell at the moment, it's **NOT** recommended to use Hive connector in Scala Shell."
        },
        {
            "sha": "d87e94d2bddb3e183ad21528bef32a15608a35a2",
            "filename": "docs/content.zh/docs/connectors/table/hive/hive_dialect.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/hive/hive_dialect.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/hive/hive_dialect.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/table/hive/hive_dialect.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "4d1d071b290eeaafd795f2c986111ae89dd032f9",
            "filename": "docs/content.zh/docs/connectors/table/hive/hive_functions.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/hive/hive_functions.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/hive/hive_functions.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/table/hive/hive_functions.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "6d45f8dd298be79cc0b852183c9ec30310eca96e",
            "filename": "docs/content.zh/docs/connectors/table/hive/hive_read_write.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/hive/hive_read_write.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/hive/hive_read_write.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/table/hive/hive_read_write.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "bc685f20e05b1bce035405fe799ed8e261cffeb7",
            "filename": "docs/content.zh/docs/connectors/table/hive/overview.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/hive/overview.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/hive/overview.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/table/hive/overview.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "d31e40714170d4a432db90718d96b86ba1008df4",
            "filename": "docs/content.zh/docs/connectors/table/jdbc.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/jdbc.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/jdbc.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/table/jdbc.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "709e616274fa37ceb9524fefc47069430b87ae49",
            "filename": "docs/content.zh/docs/connectors/table/kafka.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/kafka.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/kafka.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/table/kafka.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "dfbc8d8b006638bbcb597f2e3af32dd09829366a",
            "filename": "docs/content.zh/docs/connectors/table/kinesis.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/kinesis.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/kinesis.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/table/kinesis.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "51fce6ddcfbf633aa1ee127dd26234231cf74f9f",
            "filename": "docs/content.zh/docs/connectors/table/overview.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/overview.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/overview.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/table/overview.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "6354389d70705694701151459a02458d1025ac17",
            "filename": "docs/content.zh/docs/connectors/table/print.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/print.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/print.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/table/print.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "d269e6717e506b05ba3f6a741c4463269bd4cb16",
            "filename": "docs/content.zh/docs/connectors/table/upsert-kafka.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/upsert-kafka.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/connectors/table/upsert-kafka.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/connectors/table/upsert-kafka.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "e7d0c95f80d2eba05418e544009653f0392d1f47",
            "filename": "docs/content.zh/docs/deployment/_index.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/_index.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/_index.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/_index.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "cf0dc114583256614e09871dcc04802884b2fdec",
            "filename": "docs/content.zh/docs/deployment/advanced/_index.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/advanced/_index.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/advanced/_index.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/advanced/_index.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "95144c2b2aa8266b2b466a664269ac503e364766",
            "filename": "docs/content.zh/docs/deployment/advanced/external_resources.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/advanced/external_resources.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/advanced/external_resources.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/advanced/external_resources.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "27944bd4d94413fa497bcd81fdba87c996253654",
            "filename": "docs/content.zh/docs/deployment/advanced/historyserver.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/advanced/historyserver.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/advanced/historyserver.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/advanced/historyserver.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "e276ffca8fd72eb03eb71fd0c98de2bc8d030f33",
            "filename": "docs/content.zh/docs/deployment/advanced/logging.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/advanced/logging.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/advanced/logging.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/advanced/logging.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "cd43d0094beac099a98ab57cf2ce573aa13066f5",
            "filename": "docs/content.zh/docs/deployment/cli.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/cli.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/cli.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/cli.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "94add122b769a3c1a0b88588be27ef0a33fadcf4",
            "filename": "docs/content.zh/docs/deployment/config.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/config.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/config.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/config.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "e4046ce38d7522e32118d59671a0b404526270a9",
            "filename": "docs/content.zh/docs/deployment/elastic_scaling.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/elastic_scaling.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/elastic_scaling.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/elastic_scaling.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "e77dee7bead36c2505e64221188b79e6cd203ae9",
            "filename": "docs/content.zh/docs/deployment/filesystems/_index.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/filesystems/_index.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/filesystems/_index.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/filesystems/_index.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "728882126023ce52a47478bcd355ed7b55241a4a",
            "filename": "docs/content.zh/docs/deployment/filesystems/azure.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/filesystems/azure.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/filesystems/azure.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/filesystems/azure.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "a9d73a6cc0f5af418901a7871adb1f81bdec5b5e",
            "filename": "docs/content.zh/docs/deployment/filesystems/common.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/filesystems/common.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/filesystems/common.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/filesystems/common.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "e94108e63f16cf3aafe5ec62c9a896ac49e57e5a",
            "filename": "docs/content.zh/docs/deployment/filesystems/gcs.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/filesystems/gcs.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/filesystems/gcs.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/filesystems/gcs.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "07dfb38396b8a7b1ce14db7bd2c2d05374f71248",
            "filename": "docs/content.zh/docs/deployment/filesystems/oss.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/filesystems/oss.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/filesystems/oss.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/filesystems/oss.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "1636e8076f8e42140c2f89da6949c597aa3d09af",
            "filename": "docs/content.zh/docs/deployment/filesystems/overview.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/filesystems/overview.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/filesystems/overview.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/filesystems/overview.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "962a9f1e62ee6128855787e587a65958e9e6b902",
            "filename": "docs/content.zh/docs/deployment/filesystems/plugins.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/filesystems/plugins.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/filesystems/plugins.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/filesystems/plugins.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "07c48bcbdbfa15a3ced4bbae4dbca7d9513e940b",
            "filename": "docs/content.zh/docs/deployment/filesystems/s3.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/filesystems/s3.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/filesystems/s3.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/filesystems/s3.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "3eb199e032282820ac0e02d51119b9aa83477e0d",
            "filename": "docs/content.zh/docs/deployment/ha/_index.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/ha/_index.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/ha/_index.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/ha/_index.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "8bfb0eeaa09c077ee2f2327ade1dde2af10acca2",
            "filename": "docs/content.zh/docs/deployment/ha/kubernetes_ha.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/ha/kubernetes_ha.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/ha/kubernetes_ha.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/ha/kubernetes_ha.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "0c5034b4e9f7cd0b059a7263e19208d4fbefc511",
            "filename": "docs/content.zh/docs/deployment/ha/overview.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/ha/overview.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/ha/overview.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/ha/overview.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "3ab017e58aa97233e7ea65c77ee568047e78d4e4",
            "filename": "docs/content.zh/docs/deployment/ha/zookeeper_ha.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/ha/zookeeper_ha.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/ha/zookeeper_ha.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/ha/zookeeper_ha.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "6bf26fc91fc575e60ce52565d053e37ae16a8bcc",
            "filename": "docs/content.zh/docs/deployment/memory/_index.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/memory/_index.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/memory/_index.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/memory/_index.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "c4b76deaa1597ff6c5f3c88257349dccd66340e1",
            "filename": "docs/content.zh/docs/deployment/memory/mem_migration.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/memory/mem_migration.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/memory/mem_migration.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/memory/mem_migration.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "ca8b97036c1a4cfd481c3a7b4df4d7a7c085f173",
            "filename": "docs/content.zh/docs/deployment/memory/mem_setup.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/memory/mem_setup.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/memory/mem_setup.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/memory/mem_setup.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "107f04d11ac7dd6246c0b166eab67e381a9b90f0",
            "filename": "docs/content.zh/docs/deployment/memory/mem_setup_jobmanager.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/memory/mem_setup_jobmanager.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/memory/mem_setup_jobmanager.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/memory/mem_setup_jobmanager.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "6fdae8666df02268bf8a16fad06f9ac89065582b",
            "filename": "docs/content.zh/docs/deployment/memory/mem_setup_tm.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/memory/mem_setup_tm.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/memory/mem_setup_tm.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/memory/mem_setup_tm.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "164f9219241006edc51731e07dfac6195c01384a",
            "filename": "docs/content.zh/docs/deployment/memory/mem_trouble.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/memory/mem_trouble.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/memory/mem_trouble.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/memory/mem_trouble.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "bfb0d4c751faa927d44ad09bb9293bb6e451e0d6",
            "filename": "docs/content.zh/docs/deployment/memory/mem_tuning.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/memory/mem_tuning.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/memory/mem_tuning.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/memory/mem_tuning.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "223f429a0d874757f7332c935594b2b67c278903",
            "filename": "docs/content.zh/docs/deployment/metric_reporters.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/metric_reporters.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/metric_reporters.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/metric_reporters.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "649d07d5b425429ed03cdb961a95621595765154",
            "filename": "docs/content.zh/docs/deployment/overview.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/overview.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/overview.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/overview.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "691e1a0f09e60f9f81d5a41e32f3f84295a52d3b",
            "filename": "docs/content.zh/docs/deployment/repls/_index.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/repls/_index.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/repls/_index.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/repls/_index.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "f29e64787c4b994b9bc16886207dca045dcfcd68",
            "filename": "docs/content.zh/docs/deployment/repls/python_shell.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/repls/python_shell.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/repls/python_shell.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/repls/python_shell.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "889dea1bbe366e360a29545dcdea46e42beafa51",
            "filename": "docs/content.zh/docs/deployment/repls/scala_shell.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/repls/scala_shell.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/repls/scala_shell.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/repls/scala_shell.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "625b33ad57645b564cde1c0ed94f812a5f26da23",
            "filename": "docs/content.zh/docs/deployment/resource-providers/_index.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/resource-providers/_index.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/resource-providers/_index.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/resource-providers/_index.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "be2a63c36636655b6e117b57c75b40b1bbc5074f",
            "filename": "docs/content.zh/docs/deployment/resource-providers/mesos.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/resource-providers/mesos.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/resource-providers/mesos.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/resource-providers/mesos.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "526198e32651e23f2413c0d9ce4d7c1513630d12",
            "filename": "docs/content.zh/docs/deployment/resource-providers/native_kubernetes.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/resource-providers/native_kubernetes.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/resource-providers/native_kubernetes.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/resource-providers/native_kubernetes.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "32605a375e1b1693d0794069280cf8274b6bc33f",
            "filename": "docs/content.zh/docs/deployment/resource-providers/standalone/_index.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/resource-providers/standalone/_index.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/resource-providers/standalone/_index.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/resource-providers/standalone/_index.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "11962cb3f47510c179ac4cd063980a263ca7aa2b",
            "filename": "docs/content.zh/docs/deployment/resource-providers/standalone/docker.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/resource-providers/standalone/docker.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/resource-providers/standalone/docker.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/resource-providers/standalone/docker.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "b9f51ce71a23a36f4ca699abf2c6680f068f7ca3",
            "filename": "docs/content.zh/docs/deployment/resource-providers/standalone/kubernetes.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/resource-providers/standalone/kubernetes.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/resource-providers/standalone/kubernetes.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/resource-providers/standalone/kubernetes.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "9718cf38da08b9859352d0f5962831aa17689967",
            "filename": "docs/content.zh/docs/deployment/resource-providers/standalone/overview.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/resource-providers/standalone/overview.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/resource-providers/standalone/overview.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/resource-providers/standalone/overview.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "91d7c126e78891c08ccb01081ffa239e46ebf57e",
            "filename": "docs/content.zh/docs/deployment/resource-providers/yarn.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/resource-providers/yarn.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/resource-providers/yarn.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/resource-providers/yarn.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "d098fefc680fed8c61f926cfc2bf8a59ce192096",
            "filename": "docs/content.zh/docs/deployment/security/_index.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/security/_index.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/security/_index.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/security/_index.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "936220d3dcfea27ddb484dd98c207b248c8b2225",
            "filename": "docs/content.zh/docs/deployment/security/security-kerberos.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/security/security-kerberos.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/security/security-kerberos.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/security/security-kerberos.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "744149fa2b0812a1cecbf919d7799eab0e3e5cd1",
            "filename": "docs/content.zh/docs/deployment/security/security-ssl.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/security/security-ssl.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/deployment/security/security-ssl.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/deployment/security/security-ssl.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "db2c9ee264ce80fd45fb1ae3a302978194319c2c",
            "filename": "docs/content.zh/docs/dev/_index.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/_index.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/_index.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/_index.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "44d728e62aa395dc03674317f2737a76e5d91acb",
            "filename": "docs/content.zh/docs/dev/dataset/_index.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/dataset/_index.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/dataset/_index.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/dataset/_index.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "bcd56576c827887f6a6ba03bc43ea20b8e894c4b",
            "filename": "docs/content.zh/docs/dev/dataset/cluster_execution.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/dataset/cluster_execution.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/dataset/cluster_execution.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/dataset/cluster_execution.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "b2a572e89c9f79cea87e15b519f24c6be57893df",
            "filename": "docs/content.zh/docs/dev/dataset/examples.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/dataset/examples.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/dataset/examples.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/dataset/examples.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "ee6ad86d0ef38fa7dad2ed55d5b338bc9a3781fa",
            "filename": "docs/content.zh/docs/dev/dataset/hadoop_compatibility.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/dataset/hadoop_compatibility.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/dataset/hadoop_compatibility.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/dataset/hadoop_compatibility.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "aa56a0b78d6c3595149110d9c587d0e9ac3cb352",
            "filename": "docs/content.zh/docs/dev/dataset/iterations.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/dataset/iterations.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/dataset/iterations.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/dataset/iterations.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "55ae80d25da1b20e413ae1536edeb8ccb8da9ac3",
            "filename": "docs/content.zh/docs/dev/dataset/local_execution.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/dataset/local_execution.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/dataset/local_execution.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/dataset/local_execution.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "6b51e8e754fce3e7d0d1a2424a5b04c085f019ed",
            "filename": "docs/content.zh/docs/dev/dataset/overview.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/dataset/overview.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/dataset/overview.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/dataset/overview.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "fd36ca0412d3c15aff64e450446b8b1168988bd0",
            "filename": "docs/content.zh/docs/dev/dataset/transformations.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/dataset/transformations.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/dataset/transformations.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/dataset/transformations.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "b4ac43ec24ca6f7c8e7d7e67e1a14310f8895ece",
            "filename": "docs/content.zh/docs/dev/dataset/zip_elements_guide.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/dataset/zip_elements_guide.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/dataset/zip_elements_guide.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/dataset/zip_elements_guide.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "1a3281350eb61d5cd3bd199d59790d01f8da5ab6",
            "filename": "docs/content.zh/docs/dev/datastream/_index.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/_index.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/_index.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/datastream/_index.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "29a2024ee1356c7c4c82d466280500677f1401ba",
            "filename": "docs/content.zh/docs/dev/datastream/application_parameters.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/application_parameters.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/application_parameters.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/datastream/application_parameters.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "c11a544830afb477d0cb9383aa110bc85c914054",
            "filename": "docs/content.zh/docs/dev/datastream/event-time/_index.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/event-time/_index.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/event-time/_index.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/datastream/event-time/_index.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "a33e12d03e5e9fbffdf66f8ed45c1e3854c45e7f",
            "filename": "docs/content.zh/docs/dev/datastream/event-time/built_in.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/event-time/built_in.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/event-time/built_in.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/datastream/event-time/built_in.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "8bcd0e6b54f21c3ae7174bb2c158fd6fec4661ee",
            "filename": "docs/content.zh/docs/dev/datastream/event-time/generating_watermarks.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/event-time/generating_watermarks.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/event-time/generating_watermarks.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/datastream/event-time/generating_watermarks.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "969f1579f06ddcf6953517f6677e34c9ce915ebf",
            "filename": "docs/content.zh/docs/dev/datastream/execution_mode.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/execution_mode.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/execution_mode.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/datastream/execution_mode.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "90212a5364c999c10b9ef55f627cb220a4fc2810",
            "filename": "docs/content.zh/docs/dev/datastream/experimental.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/experimental.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/experimental.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/datastream/experimental.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "c6abd401c973f406f90b80b86ff94c6afd04f77a",
            "filename": "docs/content.zh/docs/dev/datastream/fault-tolerance/_index.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/fault-tolerance/_index.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/fault-tolerance/_index.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/datastream/fault-tolerance/_index.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "e6e5b12d24f0e1d6aece1dc515c02f2d85a19290",
            "filename": "docs/content.zh/docs/dev/datastream/fault-tolerance/broadcast_state.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/fault-tolerance/broadcast_state.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/fault-tolerance/broadcast_state.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/datastream/fault-tolerance/broadcast_state.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "e7e53e660df63ea77c031f5e99d311e38d1e63bd",
            "filename": "docs/content.zh/docs/dev/datastream/fault-tolerance/checkpointing.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/fault-tolerance/checkpointing.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/fault-tolerance/checkpointing.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/datastream/fault-tolerance/checkpointing.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "905e5f0c46a974d7957e75c3b85ab29d1fdca48d",
            "filename": "docs/content.zh/docs/dev/datastream/fault-tolerance/custom_serialization.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/fault-tolerance/custom_serialization.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/fault-tolerance/custom_serialization.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/datastream/fault-tolerance/custom_serialization.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "779f89b8d78342be34dbf3f25faffa4fa256e910",
            "filename": "docs/content.zh/docs/dev/datastream/fault-tolerance/queryable_state.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/fault-tolerance/queryable_state.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/fault-tolerance/queryable_state.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/datastream/fault-tolerance/queryable_state.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "fef9d655f5aef0622709c72962c3448c0502a88a",
            "filename": "docs/content.zh/docs/dev/datastream/fault-tolerance/schema_evolution.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/fault-tolerance/schema_evolution.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/fault-tolerance/schema_evolution.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/datastream/fault-tolerance/schema_evolution.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "13a856995f67cc6887415ae282e48ab9cc29a427",
            "filename": "docs/content.zh/docs/dev/datastream/fault-tolerance/state.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/fault-tolerance/state.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/fault-tolerance/state.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/datastream/fault-tolerance/state.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "68821981731313cdc0712b1007cbe86cd93d88c2",
            "filename": "docs/content.zh/docs/dev/datastream/fault-tolerance/state_backends.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/fault-tolerance/state_backends.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/fault-tolerance/state_backends.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/datastream/fault-tolerance/state_backends.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "d04596f08428e4a1c6ce2225c76daa917fdd40f7",
            "filename": "docs/content.zh/docs/dev/datastream/java_lambdas.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/java_lambdas.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/java_lambdas.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/datastream/java_lambdas.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "a7a6856130ac8bb968b293b5ee1e23ddd88a0d26",
            "filename": "docs/content.zh/docs/dev/datastream/operators/_index.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/operators/_index.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/operators/_index.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/datastream/operators/_index.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "fc7fb521bb85552b1334d33f47a9179393629083",
            "filename": "docs/content.zh/docs/dev/datastream/operators/asyncio.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/operators/asyncio.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/operators/asyncio.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/datastream/operators/asyncio.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "4889e65d59ae92efdb8e3d7ec9a200105e917b15",
            "filename": "docs/content.zh/docs/dev/datastream/operators/joining.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/operators/joining.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/operators/joining.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/datastream/operators/joining.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "a01978b935a7ffedba5eef0e625919da48b6498a",
            "filename": "docs/content.zh/docs/dev/datastream/operators/overview.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/operators/overview.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/operators/overview.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/datastream/operators/overview.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "314d1f33c0a21d864c5135e36ed54780c8a81361",
            "filename": "docs/content.zh/docs/dev/datastream/operators/process_function.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/operators/process_function.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/operators/process_function.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/datastream/operators/process_function.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "0c5caff486b1730cf5b621933d188e1145f38f30",
            "filename": "docs/content.zh/docs/dev/datastream/operators/windows.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/operators/windows.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/operators/windows.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/datastream/operators/windows.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "03dbe9e7036b48912159e11328c863aa08a11778",
            "filename": "docs/content.zh/docs/dev/datastream/overview.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/overview.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/overview.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/datastream/overview.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "3e8f40b94cbfd2a6a20d44f41bffbb386c0fe246",
            "filename": "docs/content.zh/docs/dev/datastream/project-configuration.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/project-configuration.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/project-configuration.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/datastream/project-configuration.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "cc332f84f95c327e06e97bd13ecbb927a3eefbdb",
            "filename": "docs/content.zh/docs/dev/datastream/scala_api_extensions.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/scala_api_extensions.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/scala_api_extensions.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/datastream/scala_api_extensions.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "9e5cb35b02e3ac23b9ed97c2d4c2acd6d3d06250",
            "filename": "docs/content.zh/docs/dev/datastream/side_output.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/side_output.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/side_output.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/datastream/side_output.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "8358cf170378e109545f369771f9d16eb7693d4d",
            "filename": "docs/content.zh/docs/dev/datastream/sources.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/sources.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/sources.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/datastream/sources.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "1c2b6b271506dc339df5fc1f7df9ac0d0200e155",
            "filename": "docs/content.zh/docs/dev/datastream/testing.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/testing.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/testing.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/datastream/testing.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "8f56200aff781d519c0628c50b34e393ac60ebbb",
            "filename": "docs/content.zh/docs/dev/datastream/user_defined_functions.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/user_defined_functions.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/datastream/user_defined_functions.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/datastream/user_defined_functions.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "1998692790b9456bf2336000778ec87690a078a9",
            "filename": "docs/content.zh/docs/dev/execution/_index.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/execution/_index.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/execution/_index.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/execution/_index.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "a67db76056b979b6b9bb591ba5709d3d7094d795",
            "filename": "docs/content.zh/docs/dev/execution/execution_configuration.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/execution/execution_configuration.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/execution/execution_configuration.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/execution/execution_configuration.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "ffaadefb344129cbcfca597591f27ab325e7e16b",
            "filename": "docs/content.zh/docs/dev/execution/execution_plans.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/execution/execution_plans.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/execution/execution_plans.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/execution/execution_plans.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "f6974c1d3721e2b5b774582ccd01d168d58a7019",
            "filename": "docs/content.zh/docs/dev/execution/packaging.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/execution/packaging.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/execution/packaging.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/execution/packaging.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "bd5f336be357f6110d0eba2864c61f01b849ef7f",
            "filename": "docs/content.zh/docs/dev/execution/parallel.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/execution/parallel.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/execution/parallel.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/execution/parallel.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "afb0dca35e1d3e4be9a89de26eb2622b21403e3f",
            "filename": "docs/content.zh/docs/dev/execution/task_failure_recovery.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/execution/task_failure_recovery.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/execution/task_failure_recovery.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/execution/task_failure_recovery.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "3e96ddc20a61c359b64f790dba3fa7fb2aa3a575",
            "filename": "docs/content.zh/docs/dev/python/_index.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/_index.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/_index.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/python/_index.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "8bfd12456b8e08e171dc7bf8a0c058205426ad35",
            "filename": "docs/content.zh/docs/dev/python/datastream/_index.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/datastream/_index.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/datastream/_index.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/python/datastream/_index.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "8adfd40476f1e8ee4773379d2911bb35f88c433e",
            "filename": "docs/content.zh/docs/dev/python/datastream/data_types.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/datastream/data_types.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/datastream/data_types.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/python/datastream/data_types.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "85f70a8dd9f35c1db5727aa72032143626e6cb09",
            "filename": "docs/content.zh/docs/dev/python/datastream/intro_to_datastream_api.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/datastream/intro_to_datastream_api.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/datastream/intro_to_datastream_api.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/python/datastream/intro_to_datastream_api.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "574fa3e76207dd50bd0c0a5e29dc2585188d160e",
            "filename": "docs/content.zh/docs/dev/python/datastream/operators/_index.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/datastream/operators/_index.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/datastream/operators/_index.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/python/datastream/operators/_index.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "b486811725b0d45558d3930bff0f9638806dbadd",
            "filename": "docs/content.zh/docs/dev/python/datastream/operators/overview.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/datastream/operators/overview.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/datastream/operators/overview.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/python/datastream/operators/overview.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "d9f772b22f913362257a76887fc94c6c439a092e",
            "filename": "docs/content.zh/docs/dev/python/datastream/operators/process_function.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/datastream/operators/process_function.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/datastream/operators/process_function.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/python/datastream/operators/process_function.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "a79d7c744db4d9f61209da589cfc4b01e2ee78c0",
            "filename": "docs/content.zh/docs/dev/python/datastream/operators/windows.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/datastream/operators/windows.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/datastream/operators/windows.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/python/datastream/operators/windows.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "47422305812daefd7a646fe56ffbd8f524995ed4",
            "filename": "docs/content.zh/docs/dev/python/datastream/state.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/datastream/state.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/datastream/state.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/python/datastream/state.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "d5fb30252205a636c9ff31990f89682eaca833e3",
            "filename": "docs/content.zh/docs/dev/python/datastream_tutorial.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/datastream_tutorial.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/datastream_tutorial.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/python/datastream_tutorial.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "e5da443998005e1064fbd80539dac12df3942e0e",
            "filename": "docs/content.zh/docs/dev/python/debugging.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/debugging.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/debugging.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/python/debugging.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "c277ad05128ccb1bb0c6a7f058dfd205cf563242",
            "filename": "docs/content.zh/docs/dev/python/dependency_management.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/dependency_management.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/dependency_management.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/python/dependency_management.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "2a547bac8ffca7a8ecf3972fcd813d3a1b8985f6",
            "filename": "docs/content.zh/docs/dev/python/environment_variables.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/environment_variables.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/environment_variables.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/python/environment_variables.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "54faf6b9a15c2df6da08b763c2342fe0d6257ccf",
            "filename": "docs/content.zh/docs/dev/python/faq.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/faq.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/faq.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/python/faq.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "a0d0c1dffe92837f30ae129e303626a174c07e0a",
            "filename": "docs/content.zh/docs/dev/python/installation.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/installation.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/installation.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/python/installation.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "90025d031961d056fd9cea89b14fd57064c6d9ac",
            "filename": "docs/content.zh/docs/dev/python/overview.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/overview.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/overview.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/python/overview.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "93906c79d3df3628b50756cc3127d12f28f76cfc",
            "filename": "docs/content.zh/docs/dev/python/python_config.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/python_config.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/python_config.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/python/python_config.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "99e824f1d35db07453b0a7be56ebeed6a3b02cbb",
            "filename": "docs/content.zh/docs/dev/python/table/_index.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/table/_index.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/table/_index.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/python/table/_index.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "3c84a0724b1e6c9b109f48536d309e7763ed3ae4",
            "filename": "docs/content.zh/docs/dev/python/table/catalogs.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/table/catalogs.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/table/catalogs.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/python/table/catalogs.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "675440959384dc791c54f20626aa17cb8089767d",
            "filename": "docs/content.zh/docs/dev/python/table/conversion_of_pandas.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/table/conversion_of_pandas.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/table/conversion_of_pandas.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/python/table/conversion_of_pandas.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "781a5c65f58ddfb7b3717a051f16e172f5feaadd",
            "filename": "docs/content.zh/docs/dev/python/table/intro_to_table_api.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/table/intro_to_table_api.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/table/intro_to_table_api.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/python/table/intro_to_table_api.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "e00af42c5d0f0b15963a8eeffd207a1693f355a6",
            "filename": "docs/content.zh/docs/dev/python/table/metrics.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/table/metrics.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/table/metrics.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/python/table/metrics.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "ac1e49b9048e582c4382839b391802563a39f61f",
            "filename": "docs/content.zh/docs/dev/python/table/operations/_index.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/table/operations/_index.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/table/operations/_index.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/python/table/operations/_index.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "80e156edc690abbd16f8b67d98934b358b64c5f4",
            "filename": "docs/content.zh/docs/dev/python/table/operations/operations.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/table/operations/operations.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/table/operations/operations.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/python/table/operations/operations.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "846fc96589b40a332aaafa93043f20da5256e112",
            "filename": "docs/content.zh/docs/dev/python/table/operations/row_based_operations.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/table/operations/row_based_operations.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/table/operations/row_based_operations.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/python/table/operations/row_based_operations.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "94e461b4071cbb9b9dd3d3cbd706f6dfbc925296",
            "filename": "docs/content.zh/docs/dev/python/table/python_table_api_connectors.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/table/python_table_api_connectors.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/table/python_table_api_connectors.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/python/table/python_table_api_connectors.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "25f379c3dd6ae93b8fc49c2ba0f2111fd38f764e",
            "filename": "docs/content.zh/docs/dev/python/table/python_types.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/table/python_types.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/table/python_types.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/python/table/python_types.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "3da2fd5825c8ec50d10ebdfceb07d3f94009900c",
            "filename": "docs/content.zh/docs/dev/python/table/sql.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/table/sql.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/table/sql.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/python/table/sql.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "2b282b3930027c0b62eda9ba61a077cebd2b4d84",
            "filename": "docs/content.zh/docs/dev/python/table/system_functions.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/table/system_functions.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/table/system_functions.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/python/table/system_functions.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "75c925ff5b7f81236c0e648534d6396ef6670336",
            "filename": "docs/content.zh/docs/dev/python/table/table_environment.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/table/table_environment.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/table/table_environment.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/python/table/table_environment.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        },
        {
            "sha": "492a33074942f8b61aa85b8c17501af2229bf5fb",
            "filename": "docs/content.zh/docs/dev/python/table/udfs/_index.md",
            "status": "added",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/apache/flink/blob/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/table/udfs/_index.md",
            "raw_url": "https://github.com/apache/flink/raw/09f868827166da872cb8d683c3c959231e96ae40/docs/content.zh/docs/dev/python/table/udfs/_index.md",
            "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/content.zh/docs/dev/python/table/udfs/_index.md?ref=09f868827166da872cb8d683c3c959231e96ae40"
        }
    ]
}