{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6gJ3Q6a2RfqJ"
   },
   "source": [
    "**pandas data frames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "id": "V0ynHeOPRzYJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wGuhMQTJZfmz"
   },
   "source": [
    "read file csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "id": "_DoPoAipSubP"
   },
   "outputs": [],
   "source": [
    "read_data_file = pd.read_csv('type_smells.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "id": "ykuprLAqTABW"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(read_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispen_bf = df['dispen_bf']\n",
    "object_bf = df['object_bf']\n",
    "bloater_bf = df['bloater_bf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispen_at = df['dispen_at']\n",
    "object_at = df['object_at']\n",
    "bloater_at = df['bloater_at']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wb81PePpyGj"
   },
   "source": [
    "part of smell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "commit_befor_sm = df.filter(regex='_befor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "commit_after_sm = df.filter(regex='_after')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_befor_sm = df.filter(regex='_bf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_after_sm = df.filter(regex='_at')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      6\n",
       "1     12\n",
       "2      9\n",
       "3      5\n",
       "4      7\n",
       "5      2\n",
       "6     18\n",
       "7      4\n",
       "8      2\n",
       "9      4\n",
       "10     4\n",
       "11     2\n",
       "12     1\n",
       "13    26\n",
       "14     7\n",
       "15    14\n",
       "16    21\n",
       "17     2\n",
       "18    11\n",
       "19    32\n",
       "20     3\n",
       "21    12\n",
       "22    10\n",
       "23     6\n",
       "24     7\n",
       "25    12\n",
       "26     4\n",
       "27     2\n",
       "28     1\n",
       "29     5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commit_after_sm.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['commit_after'] = commit_after_sm.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "commit_after = df['commit_after']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      9\n",
       "1     11\n",
       "2      9\n",
       "3     18\n",
       "4      4\n",
       "5     12\n",
       "6      3\n",
       "7      7\n",
       "8      6\n",
       "9      3\n",
       "10    11\n",
       "11    12\n",
       "12    22\n",
       "13     1\n",
       "14     7\n",
       "15    12\n",
       "16    29\n",
       "17     1\n",
       "18     2\n",
       "19    44\n",
       "20    12\n",
       "21     2\n",
       "22     6\n",
       "23    10\n",
       "24     7\n",
       "25     2\n",
       "26     8\n",
       "27     8\n",
       "28    12\n",
       "29    24\n",
       "dtype: int64"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commit_befor_sm.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['commit_befor'] = commit_befor_sm.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "commit_befor = df['commit_befor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cal_smell']  = commit_after_sm.sum(axis=1) - commit_befor_sm.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_smell =  df['cal_smell']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvCZj_gLp_Xu"
   },
   "source": [
    "columns list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "No2h4SagqucU",
    "outputId": "7f1cdfb4-3b21-4533-99c5-c926941ba9fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['url',\n",
       " 'commit',\n",
       " 'parents',\n",
       " 's106_before',\n",
       " 's106_after',\n",
       " 's112_before',\n",
       " 's112_after',\n",
       " 's119_before',\n",
       " 's119_after',\n",
       " 's1123_before',\n",
       " 's1123_after',\n",
       " 's1133_before',\n",
       " 's1133_after',\n",
       " 's1141_before',\n",
       " 's1141_after',\n",
       " 's1155_before',\n",
       " 's1155_after',\n",
       " 's1168_before',\n",
       " 's1168_after',\n",
       " 's1172_before',\n",
       " 's1172_after',\n",
       " 's1181_before',\n",
       " 's1181_after',\n",
       " 's1187_before',\n",
       " 's1187_after',\n",
       " 's1192_before',\n",
       " 's1192_after',\n",
       " 's1199_before',\n",
       " 's1199_after',\n",
       " 's1610_before',\n",
       " 's1610_after',\n",
       " 's1612_before',\n",
       " 'S1612_after',\n",
       " 's1643_before',\n",
       " 's1643_after',\n",
       " 's1874_before',\n",
       " 's1874_after',\n",
       " 's1948_before',\n",
       " 's1948_after',\n",
       " 's1199_before.1',\n",
       " 's1199_after.1',\n",
       " 's2139_before',\n",
       " 's2139_after',\n",
       " 's2699_before',\n",
       " 's2699_after',\n",
       " 's2293_before',\n",
       " 's2293_after',\n",
       " 's3011_before',\n",
       " 's3011_after',\n",
       " 's3400_before',\n",
       " 's3400_after',\n",
       " 's3415_before',\n",
       " 's3415_after',\n",
       " 's3358_before',\n",
       " 's3358_after',\n",
       " 's3740_before',\n",
       " 's3740_after',\n",
       " 's3776_before',\n",
       " 's3776_after',\n",
       " 's4042_before',\n",
       " 's4042_after',\n",
       " 's5411_before',\n",
       " 's5411_after',\n",
       " 's5777_before',\n",
       " 's5777_after',\n",
       " 's5993_before',\n",
       " 's5993_after',\n",
       " 's6212_before',\n",
       " 's6212_after',\n",
       " 's6213_before',\n",
       " 's6213_after',\n",
       " 'dispen_bf',\n",
       " 'object_bf',\n",
       " 'bloater_bf',\n",
       " 'dispen_at',\n",
       " 'object_at',\n",
       " 'bloater_at',\n",
       " 'number_group_befor',\n",
       " 'group_smell_befor',\n",
       " 'number_group_after',\n",
       " 'group_smell_after',\n",
       " 'open_time',\n",
       " 'closed_time',\n",
       " 'changed_file',\n",
       " 'additions',\n",
       " 'deletions',\n",
       " 'Dev',\n",
       " 'commit_after',\n",
       " 'commit_befor',\n",
       " 'cal_smell']"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "id": "rLlM1p-zrUNy"
   },
   "outputs": [],
   "source": [
    "rule  = df[{\n",
    "     's106_before',\n",
    " 's106_after',\n",
    " 's112_before',\n",
    " 's112_after',\n",
    " 's119_before',\n",
    " 's119_after',\n",
    " 's1123_before',\n",
    " 's1123_after',\n",
    " 's1133_before',\n",
    " 's1133_after',\n",
    " 's1141_before',\n",
    " 's1141_after',\n",
    " 's1155_before',\n",
    " 's1155_after',\n",
    " 's1168_before',\n",
    " 's1168_after',\n",
    " 's1172_before',\n",
    " 's1172_after',\n",
    " 's1181_before',\n",
    " 's1181_after',\n",
    " 's1187_before',\n",
    " 's1187_after',\n",
    " 's1192_before',\n",
    " 's1192_after',\n",
    " 's1199_before',\n",
    " 's1199_after',\n",
    " 's1610_before',\n",
    " 's1610_after',\n",
    " 's1612_before',\n",
    " 'S1612_after',\n",
    " 's1643_before',\n",
    " 's1643_after',\n",
    " 's1874_before',\n",
    " 's1874_after',\n",
    " 's1948_before',\n",
    " 's1948_after',\n",
    " 's1199_before.1',\n",
    " 's1199_after.1',\n",
    " 's2139_before',\n",
    " 's2139_after',\n",
    " 's2699_before',\n",
    " 's2699_after',\n",
    " 's2293_before',\n",
    " 's2293_after',\n",
    " 's3011_before',\n",
    " 's3011_after',\n",
    " 's3400_before',\n",
    " 's3400_after',\n",
    " 's3415_before',\n",
    " 's3415_after',\n",
    " 's3358_before',\n",
    " 's3358_after',\n",
    " 's3740_before',\n",
    " 's3740_after',\n",
    " 's3776_before',\n",
    " 's3776_after',\n",
    " 's4042_before',\n",
    " 's4042_after',\n",
    " 's5411_before',\n",
    " 's5411_after',\n",
    " 's5777_before',\n",
    " 's5777_after',\n",
    " 's5993_before',\n",
    " 's5993_after',\n",
    " 's6212_before',\n",
    " 's6212_after',\n",
    " 's6213_before',\n",
    " 's6213_after'\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3uriqWZGZwrl"
   },
   "source": [
    "Set data type time  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "id": "H1TspvmCT-Gd"
   },
   "outputs": [],
   "source": [
    "data_time = df[{'open_time' , 'closed_time' }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "id": "KRILzAv9jvQn"
   },
   "outputs": [],
   "source": [
    "open_time = pd.to_datetime(df['open_time'])\n",
    "closed_time = pd.to_datetime(df['closed_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "id": "DG_ZTQ8aUN3C"
   },
   "outputs": [],
   "source": [
    "df['cla_time'] = pd.to_datetime(df['closed_time']) - pd.to_datetime(df['open_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "id": "GrEvaXY-UpmO"
   },
   "outputs": [],
   "source": [
    "cal_time = df['cla_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('17 days 02:22:30')"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_time.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sn8xUCKtnEBT"
   },
   "source": [
    "Information issus on GitHub "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "id": "vgi32aodUAtE"
   },
   "outputs": [],
   "source": [
    "data_file = df[{'changed_file' , 'additions'  , 'deletions' , 'Dev' }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "id": "KWSne01bkFQY"
   },
   "outputs": [],
   "source": [
    "changed_file = df['changed_file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "id": "gCXDNGK0lEZW"
   },
   "outputs": [],
   "source": [
    "additions = df['additions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "id": "f9aEipWMlHOr"
   },
   "outputs": [],
   "source": [
    "deletions = df['deletions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "id": "NOFcZIdZlKDK"
   },
   "outputs": [],
   "source": [
    "Dev = df['Dev']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ltDICOQkmYQM"
   },
   "source": [
    "data frame containing information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "id": "3907RNDUifhL"
   },
   "outputs": [],
   "source": [
    "data_flink = pd.DataFrame({  'commit_befor ' : commit_befor , 'commit_after' : commit_after, 'cal_smell' : cal_smell , \n",
    "                              'dispen_bf' :dispen_bf , 'object_bf' : object_bf , 'bloater_bf':bloater_bf ,\n",
    "                              'dispen_at' :dispen_at , 'object_at' : object_at , 'bloater_af': bloater_at ,\n",
    "                              'open_time' : open_time , 'closed_time' : closed_time , 'cal_time' : cal_time,\n",
    "                              'changed_file' : changed_file , 'additions' : additions , 'deletions': deletions , 'dev': Dev ,\n",
    "                              \n",
    "                            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commit_befor</th>\n",
       "      <th>commit_after</th>\n",
       "      <th>cal_smell</th>\n",
       "      <th>dispen_bf</th>\n",
       "      <th>object_bf</th>\n",
       "      <th>bloater_bf</th>\n",
       "      <th>dispen_at</th>\n",
       "      <th>object_at</th>\n",
       "      <th>bloater_af</th>\n",
       "      <th>open_time</th>\n",
       "      <th>closed_time</th>\n",
       "      <th>cal_time</th>\n",
       "      <th>changed_file</th>\n",
       "      <th>additions</th>\n",
       "      <th>deletions</th>\n",
       "      <th>dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [commit_befor , commit_after, cal_smell, dispen_bf, object_bf, bloater_bf, dispen_at, object_at, bloater_af, open_time, closed_time, cal_time, changed_file, additions, deletions, dev]\n",
       "Index: []"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_flink[data_flink['cal_time'] < timedelta (minutes = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_flink['cal_time_binaly'] = data_flink['cal_time'].apply(lambda x:  0 if x > timedelta (days = 17) else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_flink['open_time'] = pd.DatetimeIndex(data_flink['open_time']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_flink['closed_time'] = pd.DatetimeIndex(data_flink['closed_time']).month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop_nan = data_flink.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "X ,y = df_drop_nan.iloc[:, [ True , False,  False , True , True ,True , False , False , False ,True , False , False, False , False , False , False,False]] , df_drop_nan['cal_time_binaly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X, y = load_iris(return_X_y=True)\n",
    "clf = LogisticRegression(random_state=0).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "ARDR = linear_model.ARDRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "GNB  = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "Bay = linear_model.BayesianRidge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 87, in __call__\n",
      "    score = scorer._score(cached_call, estimator,\n",
      "  File \"C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 202, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 92, in _check_targets\n",
      "    raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 87, in __call__\n",
      "    score = scorer._score(cached_call, estimator,\n",
      "  File \"C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 202, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 92, in _check_targets\n",
      "    raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 87, in __call__\n",
      "    score = scorer._score(cached_call, estimator,\n",
      "  File \"C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 202, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 92, in _check_targets\n",
      "    raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 87, in __call__\n",
      "    score = scorer._score(cached_call, estimator,\n",
      "  File \"C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 202, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 92, in _check_targets\n",
      "    raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 87, in __call__\n",
      "    score = scorer._score(cached_call, estimator,\n",
      "  File \"C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 202, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 92, in _check_targets\n",
      "    raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan])"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(Bay , X , y , cv=5 ,scoring= \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.10929843, -0.07993542, -0.08047206, -0.01624578, -0.09693246,\n",
       "        0.0442123 ,  0.0162179 , -0.07034072, -0.01413609, -0.11504543,\n",
       "       -0.12443567, -0.01901705, -0.12662487, -0.13729283, -0.25433634,\n",
       "       -0.0487154 , -0.05686199, -0.04958143, -0.05392576, -0.0262976 ,\n",
       "       -0.07191378,  0.03408097, -0.14589655,  0.14698144,  0.05678867,\n",
       "       -0.04242583,  0.07436184, -0.09705741, -0.1216644 , -0.00466634,\n",
       "        0.00584741,  0.04531398, -0.15670189, -0.14553034, -0.02387556,\n",
       "       -0.10231261, -0.13371952, -0.13120447, -0.02405926, -0.05389695,\n",
       "       -0.03356276,  0.06319143, -0.03370403,  0.21608823,  0.13713921,\n",
       "        0.02804924, -0.05124063, -0.02731242, -0.08391834, -0.0632433 ,\n",
       "        1.24550337,  1.30954556,  1.36326572,  1.19066956,  1.34300381,\n",
       "        1.26073265,  1.41766315,  0.89507554,  1.20786201,  1.23403671,\n",
       "        1.03265399,  1.33542818,  1.03040604,  1.40569946,  1.10143193,\n",
       "        1.22500288,  1.46656982,  1.07154344,  1.40789599,  1.09970721,\n",
       "        1.66063509,  1.15121032,  1.50128316,  1.30553969,  1.19335109,\n",
       "        1.24264442,  1.33860808,  1.5603188 ,  1.41285203,  0.91253289,\n",
       "        1.08790673,  1.0067    ,  1.11618886,  1.64800817,  1.49511356,\n",
       "        1.4477684 ,  1.36509364,  1.25728299,  1.24527233,  1.24695053,\n",
       "        1.14159131,  1.26551326,  1.03827804,  0.82076797,  1.15234599,\n",
       "        1.08684307,  1.14616277,  1.13643761,  0.81033174,  1.12497186,\n",
       "        2.20233632,  1.68661597,  1.89440088,  1.70233474,  1.96962895,\n",
       "        2.01182117,  1.49648003,  1.78883897,  1.71998371,  2.1678783 ,\n",
       "        1.70265318,  1.69189851,  1.82818688,  1.73092798,  1.9832145 ,\n",
       "        1.92917733,  1.66877741,  2.08614857,  2.1878501 ,  1.41577981,\n",
       "        1.8817859 ,  1.68017427,  1.80813198,  1.50889433,  1.75222033,\n",
       "        1.57069473,  1.49247228,  1.49711722,  1.79814312,  1.42360352,\n",
       "        1.672489  ,  1.66888991,  1.86527312,  1.32857132,  1.36409996,\n",
       "        1.90514216,  1.95658359,  1.55739442,  1.48893094,  1.71180753,\n",
       "        1.9554305 ,  1.8021134 ,  1.6376526 ,  1.91755377,  2.02074034,\n",
       "        1.83793075,  1.60714726,  1.64947095,  1.86661593,  1.53935018])"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "y_pred = cross_val_predict(Bay,X,y,cv=5)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-386-c0773a102a14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0m\u001b[0;32m     93\u001b[0m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "accuracy_score(y, y_pred , normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-141-e3419813a807>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'precision = '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'recall_score = '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'f1_score'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1652\u001b[0m     \"\"\"\n\u001b[1;32m-> 1653\u001b[1;33m     p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n\u001b[0m\u001b[0;32m   1654\u001b[0m                                                  \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1655\u001b[0m                                                  \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1461\u001b[1;33m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0m\u001b[0;32m   1462\u001b[0m                                     pos_label)\n\u001b[0;32m   1463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1289\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'multiclass'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m                 \u001b[0maverage_options\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'samples'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1291\u001b[1;33m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[0m\u001b[0;32m   1292\u001b[0m                              \u001b[1;34m\"choose another average setting, one of %r.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1293\u001b[0m                              % (y_type, average_options))\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "print('precision = ', precision_score(y,y_pred))\n",
    "print('recall_score = ', recall_score(y,y_pred))\n",
    "print('f1_score',f1_score(y,y_pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of Untitled0.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "ad7eca264feaa10a42b7f6be2a1e8f577a569f64740e80c71f143d2c89abf5fc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
