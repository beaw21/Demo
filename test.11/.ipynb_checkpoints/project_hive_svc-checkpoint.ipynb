{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data_file = pd.read_pickle('../hive.pkl')\n",
    "df = pd.DataFrame(read_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = df[['commit_befor ', 'dispen_bf', 'object_bf', 'bloater_bf', 'open_time',]]\n",
    "X = df[['commit_befor ', 'commit_after', 'cal_smell', 'dispen_bf', 'object_bf',\n",
    "       'bloater_bf', 'dispen_at', 'object_at', 'bloater_af', 'open_time',\n",
    "       'closed_time','changed_file', 'additions', 'deletions',\n",
    "       'dev']]\n",
    "y = df['cal_time_binaly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train ,X_test ,y_train , y_test = X[:20], X[20:],y[:20],y[20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.33333333, 0.83333333, 0.5       , 0.5       ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(clf , X , y , cv=5 , scoring= \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "y_pred = cross_val_predict(clf,X,y,cv=5)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test =cross_val_predict(clf,X_test,y_test,cv=5)\n",
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  7],\n",
       "       [ 4, 12]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision =  0.631578947368421\n",
      "recall_score =  0.75\n",
      "f1_score 0.6857142857142857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "print('precision = ', precision_score(y,y_pred))\n",
    "print('recall_score = ', recall_score(y,y_pred))\n",
    "print('f1_score',f1_score(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y         16\n",
       "y_pred    19\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame={\"y\":y,\"y_pred\": y_pred}\n",
    "pd.DataFrame(frame).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=SVC(),\n",
       "             param_grid={'C': [0.01, 0.1, 1], 'gamma': ['scale', 'auto'],\n",
       "                         'random_state': [2]},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "  \n",
    "    'C': [0.01 , 0.1 ,1],\n",
    "    'gamma' : ['scale' , 'auto'],\n",
    "    'random_state':[2]\n",
    "  \n",
    "}\n",
    "svc = SVC()\n",
    "clf = GridSearchCV(svc , parameters , cv=3 , scoring='f1_macro')\n",
    "clf.fit(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_clf = clf.best_estimator_.predict(X)\n",
    "y_pred_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision =  0.26666666666666666\n",
      "recall_score =  0.5\n",
      "f1_score 0.3478260869565218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "print('precision = ', precision_score(y,y_pred_clf ,average='macro'))\n",
    "print('recall_score = ', recall_score(y,y_pred_clf ,average='macro'))\n",
    "print('f1_score',f1_score(y,y_pred_clf ,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, kernel='linear')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "\n",
    "def f_importances(coef, names):\n",
    "    \n",
    "    names = np.arange(1)\n",
    "    imp = coef\n",
    "    imp,names = zip(*sorted(zip(imp,names)))\n",
    "    plt.barh(range(len(names)), imp, align='center')\n",
    "    plt.yticks(range(len(names)), names)\n",
    "    plt.show()\n",
    "\n",
    "features_names = X.columns\n",
    "svm1 = svm.SVC(kernel='linear',C=1)\n",
    "svm1.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.77855187e-02, -2.75163333e-02,  6.02691854e-02,\n",
       "        -3.45297481e-02,  0.00000000e+00, -5.18078189e-02,\n",
       "        -1.44795171e-03,  7.26870788e-02, -8.14905864e-02,\n",
       "        -5.30451794e-02, -2.14402840e-02,  7.66312400e-02,\n",
       "         5.06830211e-03, -1.85293106e-02, -6.50521303e-17]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm1.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from itertools import product "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('commit_befor ', 'commit_after')\n",
      "precision_score = 0.5625\n",
      "recall_score = 1.0\n",
      "f_1= 0.76\n",
      "('commit_befor ', 'cal_smell')\n",
      "precision_score = 0.9375\n",
      "recall_score = 0.7142857142857143\n",
      "f_1= 0.7532314923619272\n",
      "('commit_befor ', 'dispen_bf')\n",
      "precision_score = 0.25\n",
      "recall_score = 0.8\n",
      "f_1= 0.5238095238095237\n",
      "('commit_befor ', 'object_bf')\n",
      "precision_score = 0.0\n",
      "recall_score = 0.0\n",
      "f_1= 0.3181818181818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('commit_befor ', 'bloater_bf')\n",
      "precision_score = 0.0\n",
      "recall_score = 0.0\n",
      "f_1= 0.3181818181818182\n",
      "('commit_befor ', 'dispen_at')\n",
      "precision_score = 0.375\n",
      "recall_score = 0.8571428571428571\n",
      "f_1= 0.6122209165687424\n",
      "('commit_befor ', 'object_at')\n",
      "precision_score = 0.25\n",
      "recall_score = 0.8\n",
      "f_1= 0.5238095238095237\n",
      "('commit_befor ', 'bloater_af')\n",
      "precision_score = 0.9375\n",
      "recall_score = 0.7142857142857143\n",
      "f_1= 0.7532314923619272\n",
      "('commit_befor ', 'open_time')\n",
      "precision_score = 0.6875\n",
      "recall_score = 1.0\n",
      "f_1= 0.8316498316498315\n",
      "('commit_befor ', 'closed_time')\n",
      "precision_score = 0.5625\n",
      "recall_score = 0.75\n",
      "f_1= 0.6651785714285715\n",
      "('commit_befor ', 'changed_file')\n",
      "precision_score = 0.0625\n",
      "recall_score = 1.0\n",
      "f_1= 0.38440492476060195\n",
      "('commit_befor ', 'additions')\n",
      "precision_score = 0.8125\n",
      "recall_score = 0.5909090909090909\n",
      "f_1= 0.5693779904306221\n",
      "('commit_befor ', 'deletions')\n",
      "precision_score = 0.0\n",
      "recall_score = 0.0\n",
      "f_1= 0.3181818181818182\n",
      "('commit_befor ', 'dev')\n",
      "precision_score = 0.3125\n",
      "recall_score = 0.8333333333333334\n",
      "f_1= 0.569377990430622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('commit_after', 'cal_smell')\n",
      "precision_score = 0.6875\n",
      "recall_score = 0.9166666666666666\n",
      "f_1= 0.7991071428571429\n",
      "('commit_after', 'dispen_bf')\n",
      "precision_score = 0.5625\n",
      "recall_score = 0.9\n",
      "f_1= 0.7285067873303168\n",
      "('commit_after', 'object_bf')\n",
      "precision_score = 0.0\n",
      "recall_score = 0.0\n",
      "f_1= 0.3181818181818182\n",
      "('commit_after', 'bloater_bf')\n",
      "precision_score = 0.4375\n",
      "recall_score = 1.0\n",
      "f_1= 0.6827262044653349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('commit_after', 'dispen_at')\n",
      "precision_score = 0.0\n",
      "recall_score = 0.0\n",
      "f_1= 0.3181818181818182\n",
      "('commit_after', 'object_at')\n",
      "precision_score = 0.0\n",
      "recall_score = 0.0\n",
      "f_1= 0.3181818181818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('commit_after', 'bloater_af')\n",
      "precision_score = 0.4375\n",
      "recall_score = 0.6363636363636364\n",
      "f_1= 0.5622895622895623\n",
      "('commit_after', 'open_time')\n",
      "precision_score = 0.625\n",
      "recall_score = 0.8333333333333334\n",
      "f_1= 0.7321428571428572\n",
      "('commit_after', 'closed_time')\n",
      "precision_score = 0.5\n",
      "recall_score = 0.6666666666666666\n",
      "f_1= 0.5982142857142858\n",
      "('commit_after', 'changed_file')\n",
      "precision_score = 0.625\n",
      "recall_score = 1.0\n",
      "f_1= 0.7963800904977376\n",
      "('commit_after', 'additions')\n",
      "precision_score = 0.75\n",
      "recall_score = 0.6\n",
      "f_1= 0.5833333333333333\n",
      "('commit_after', 'deletions')\n",
      "precision_score = 0.0\n",
      "recall_score = 0.0\n",
      "f_1= 0.3181818181818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('commit_after', 'dev')\n",
      "precision_score = 0.0\n",
      "recall_score = 0.0\n",
      "f_1= 0.3181818181818182\n",
      "('cal_smell', 'dispen_bf')\n",
      "precision_score = 0.5625\n",
      "recall_score = 1.0\n",
      "f_1= 0.76\n",
      "('cal_smell', 'object_bf')\n",
      "precision_score = 0.0\n",
      "recall_score = 0.0\n",
      "f_1= 0.3181818181818182\n",
      "('cal_smell', 'bloater_bf')\n",
      "precision_score = 0.875\n",
      "recall_score = 0.7368421052631579\n",
      "f_1= 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cal_smell', 'dispen_at')\n",
      "precision_score = 0.625\n",
      "recall_score = 0.9090909090909091\n",
      "f_1= 0.7643097643097643\n",
      "('cal_smell', 'object_at')\n",
      "precision_score = 0.625\n",
      "recall_score = 0.9090909090909091\n",
      "f_1= 0.7643097643097643\n",
      "('cal_smell', 'bloater_af')\n",
      "precision_score = 0.5625\n",
      "recall_score = 0.9\n",
      "f_1= 0.7285067873303168\n",
      "('cal_smell', 'open_time')\n",
      "precision_score = 0.625\n",
      "recall_score = 1.0\n",
      "f_1= 0.7963800904977376\n",
      "('cal_smell', 'closed_time')\n",
      "precision_score = 0.5625\n",
      "recall_score = 1.0\n",
      "f_1= 0.76\n",
      "('cal_smell', 'changed_file')\n",
      "precision_score = 0.5625\n",
      "recall_score = 1.0\n",
      "f_1= 0.76\n",
      "('cal_smell', 'additions')\n",
      "precision_score = 0.8125\n",
      "recall_score = 0.5909090909090909\n",
      "f_1= 0.5693779904306221\n",
      "('cal_smell', 'deletions')\n",
      "precision_score = 0.0\n",
      "recall_score = 0.0\n",
      "f_1= 0.3181818181818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cal_smell', 'dev')\n",
      "precision_score = 0.5625\n",
      "recall_score = 1.0\n",
      "f_1= 0.76\n",
      "('dispen_bf', 'object_bf')\n",
      "precision_score = 0.0\n",
      "recall_score = 0.0\n",
      "f_1= 0.3181818181818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dispen_bf', 'bloater_bf')\n",
      "precision_score = 0.6875\n",
      "recall_score = 0.6470588235294118\n",
      "f_1= 0.6296296296296298\n",
      "('dispen_bf', 'dispen_at')\n",
      "precision_score = 0.3125\n",
      "recall_score = 1.0\n",
      "f_1= 0.5970695970695971\n",
      "('dispen_bf', 'object_at')\n",
      "precision_score = 0.125\n",
      "recall_score = 1.0\n",
      "f_1= 0.4444444444444444\n",
      "('dispen_bf', 'bloater_af')\n",
      "precision_score = 0.0\n",
      "recall_score = 0.0\n",
      "f_1= 0.3181818181818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dispen_bf', 'open_time')\n",
      "precision_score = 0.75\n",
      "recall_score = 0.8571428571428571\n",
      "f_1= 0.7999999999999999\n",
      "('dispen_bf', 'closed_time')\n",
      "precision_score = 0.5625\n",
      "recall_score = 0.6\n",
      "f_1= 0.5661846496106784\n",
      "('dispen_bf', 'changed_file')\n",
      "precision_score = 0.75\n",
      "recall_score = 0.9230769230769231\n",
      "f_1= 0.8331479421579533\n",
      "('dispen_bf', 'additions')\n",
      "precision_score = 0.8125\n",
      "recall_score = 0.5909090909090909\n",
      "f_1= 0.5693779904306221\n",
      "('dispen_bf', 'deletions')\n",
      "precision_score = 0.0\n",
      "recall_score = 0.0\n",
      "f_1= 0.3181818181818182\n",
      "('dispen_bf', 'dev')\n",
      "precision_score = 0.3125\n",
      "recall_score = 0.8333333333333334\n",
      "f_1= 0.569377990430622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('object_bf', 'bloater_bf')\n",
      "precision_score = 0.375\n",
      "recall_score = 0.6666666666666666\n",
      "f_1= 0.5542857142857143\n",
      "('object_bf', 'dispen_at')\n",
      "precision_score = 0.25\n",
      "recall_score = 0.8\n",
      "f_1= 0.5238095238095237\n",
      "('object_bf', 'object_at')\n",
      "precision_score = 0.0\n",
      "recall_score = 0.0\n",
      "f_1= 0.3181818181818182\n",
      "('object_bf', 'bloater_af')\n",
      "precision_score = 0.0\n",
      "recall_score = 0.0\n",
      "f_1= 0.3181818181818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('object_bf', 'open_time')\n",
      "precision_score = 0.5625\n",
      "recall_score = 1.0\n",
      "f_1= 0.76\n",
      "('object_bf', 'closed_time')\n",
      "precision_score = 0.5625\n",
      "recall_score = 0.6\n",
      "f_1= 0.5661846496106784\n",
      "('object_bf', 'changed_file')\n",
      "precision_score = 0.8125\n",
      "recall_score = 0.9285714285714286\n",
      "f_1= 0.8666666666666666\n",
      "('object_bf', 'additions')\n",
      "precision_score = 0.8125\n",
      "recall_score = 0.5909090909090909\n",
      "f_1= 0.5693779904306221\n",
      "('object_bf', 'deletions')\n",
      "precision_score = 0.0\n",
      "recall_score = 0.0\n",
      "f_1= 0.3181818181818182\n",
      "('object_bf', 'dev')\n",
      "precision_score = 0.0\n",
      "recall_score = 0.0\n",
      "f_1= 0.3181818181818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('bloater_bf', 'dispen_at')\n",
      "precision_score = 0.25\n",
      "recall_score = 0.8\n",
      "f_1= 0.5238095238095237\n",
      "('bloater_bf', 'object_at')\n",
      "precision_score = 0.125\n",
      "recall_score = 1.0\n",
      "f_1= 0.4444444444444444\n",
      "('bloater_bf', 'bloater_af')\n",
      "precision_score = 0.8125\n",
      "recall_score = 0.7647058823529411\n",
      "f_1= 0.7643097643097644\n",
      "('bloater_bf', 'open_time')\n",
      "precision_score = 0.6875\n",
      "recall_score = 0.7333333333333333\n",
      "f_1= 0.6996662958843158\n",
      "('bloater_bf', 'closed_time')\n",
      "precision_score = 0.4375\n",
      "recall_score = 0.6363636363636364\n",
      "f_1= 0.5622895622895623\n",
      "('bloater_bf', 'changed_file')\n",
      "precision_score = 0.5625\n",
      "recall_score = 0.9\n",
      "f_1= 0.7285067873303168\n",
      "('bloater_bf', 'additions')\n",
      "precision_score = 0.8125\n",
      "recall_score = 0.5909090909090909\n",
      "f_1= 0.5693779904306221\n",
      "('bloater_bf', 'deletions')\n",
      "precision_score = 0.0\n",
      "recall_score = 0.0\n",
      "f_1= 0.3181818181818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('bloater_bf', 'dev')\n",
      "precision_score = 0.8125\n",
      "recall_score = 0.6190476190476191\n",
      "f_1= 0.6122209165687427\n",
      "('dispen_at', 'object_at')\n",
      "precision_score = 0.1875\n",
      "recall_score = 1.0\n",
      "f_1= 0.49935815147625157\n",
      "('dispen_at', 'bloater_af')\n",
      "precision_score = 0.25\n",
      "recall_score = 1.0\n",
      "f_1= 0.55\n",
      "('dispen_at', 'open_time')\n",
      "precision_score = 0.0\n",
      "recall_score = 0.0\n",
      "f_1= 0.3181818181818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dispen_at', 'closed_time')\n",
      "precision_score = 0.5625\n",
      "recall_score = 0.6\n",
      "f_1= 0.5661846496106784\n",
      "('dispen_at', 'changed_file')\n",
      "precision_score = 0.5\n",
      "recall_score = 0.8888888888888888\n",
      "f_1= 0.6914285714285715\n",
      "('dispen_at', 'additions')\n",
      "precision_score = 0.8125\n",
      "recall_score = 0.5909090909090909\n",
      "f_1= 0.5693779904306221\n",
      "('dispen_at', 'deletions')\n",
      "precision_score = 0.0\n",
      "recall_score = 0.0\n",
      "f_1= 0.3181818181818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dispen_at', 'dev')\n",
      "precision_score = 0.375\n",
      "recall_score = 0.8571428571428571\n",
      "f_1= 0.6122209165687424\n",
      "('object_at', 'bloater_af')\n",
      "precision_score = 0.0\n",
      "recall_score = 0.0\n",
      "f_1= 0.3181818181818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('object_at', 'open_time')\n",
      "precision_score = 0.3125\n",
      "recall_score = 0.625\n",
      "f_1= 0.513888888888889\n",
      "('object_at', 'closed_time')\n",
      "precision_score = 0.5\n",
      "recall_score = 0.5714285714285714\n",
      "f_1= 0.5333333333333333\n",
      "('object_at', 'changed_file')\n",
      "precision_score = 0.625\n",
      "recall_score = 0.9090909090909091\n",
      "f_1= 0.7643097643097643\n",
      "('object_at', 'additions')\n",
      "precision_score = 0.8125\n",
      "recall_score = 0.5909090909090909\n",
      "f_1= 0.5693779904306221\n",
      "('object_at', 'deletions')\n",
      "precision_score = 0.0\n",
      "recall_score = 0.0\n",
      "f_1= 0.3181818181818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('object_at', 'dev')\n",
      "precision_score = 0.1875\n",
      "recall_score = 0.75\n",
      "f_1= 0.475\n",
      "('bloater_af', 'open_time')\n",
      "precision_score = 0.625\n",
      "recall_score = 0.7692307692307693\n",
      "f_1= 0.6996662958843158\n",
      "('bloater_af', 'closed_time')\n",
      "precision_score = 0.5\n",
      "recall_score = 0.8888888888888888\n",
      "f_1= 0.6914285714285715\n",
      "('bloater_af', 'changed_file')\n",
      "precision_score = 0.625\n",
      "recall_score = 1.0\n",
      "f_1= 0.7963800904977376\n",
      "('bloater_af', 'additions')\n",
      "precision_score = 0.75\n",
      "recall_score = 0.6\n",
      "f_1= 0.5833333333333333\n",
      "('bloater_af', 'deletions')\n",
      "precision_score = 0.0\n",
      "recall_score = 0.0\n",
      "f_1= 0.3181818181818182\n",
      "('bloater_af', 'dev')\n",
      "precision_score = 0.25\n",
      "recall_score = 0.8\n",
      "f_1= 0.5238095238095237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('open_time', 'closed_time')\n",
      "precision_score = 0.75\n",
      "recall_score = 1.0\n",
      "f_1= 0.8660714285714286\n",
      "('open_time', 'changed_file')\n",
      "precision_score = 0.0\n",
      "recall_score = 0.0\n",
      "f_1= 0.3181818181818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('open_time', 'additions')\n",
      "precision_score = 0.8125\n",
      "recall_score = 0.5909090909090909\n",
      "f_1= 0.5693779904306221\n",
      "('open_time', 'deletions')\n",
      "precision_score = 0.0\n",
      "recall_score = 0.0\n",
      "f_1= 0.3181818181818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('open_time', 'dev')\n",
      "precision_score = 0.3125\n",
      "recall_score = 1.0\n",
      "f_1= 0.5970695970695971\n",
      "('closed_time', 'changed_file')\n",
      "precision_score = 0.6875\n",
      "recall_score = 0.9166666666666666\n",
      "f_1= 0.7991071428571429\n",
      "('closed_time', 'additions')\n",
      "precision_score = 0.8125\n",
      "recall_score = 0.5909090909090909\n",
      "f_1= 0.5693779904306221\n",
      "('closed_time', 'deletions')\n",
      "precision_score = 0.0\n",
      "recall_score = 0.0\n",
      "f_1= 0.3181818181818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('closed_time', 'dev')\n",
      "precision_score = 0.5625\n",
      "recall_score = 0.6\n",
      "f_1= 0.5661846496106784\n",
      "('changed_file', 'additions')\n",
      "precision_score = 0.75\n",
      "recall_score = 0.6\n",
      "f_1= 0.5833333333333333\n",
      "('changed_file', 'deletions')\n",
      "precision_score = 0.0\n",
      "recall_score = 0.0\n",
      "f_1= 0.3181818181818182\n",
      "('changed_file', 'dev')\n",
      "precision_score = 0.75\n",
      "recall_score = 0.9230769230769231\n",
      "f_1= 0.8331479421579533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('additions', 'deletions')\n",
      "precision_score = 0.5625\n",
      "recall_score = 0.6428571428571429\n",
      "f_1= 0.6000000000000001\n",
      "('additions', 'dev')\n",
      "precision_score = 0.8125\n",
      "recall_score = 0.5909090909090909\n",
      "f_1= 0.5693779904306221\n",
      "('deletions', 'dev')\n",
      "precision_score = 0.0\n",
      "recall_score = 0.0\n",
      "f_1= 0.3181818181818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "result = itertools.combinations(X ,2)\n",
    "\n",
    "for item in result:\n",
    "    df  = pd.DataFrame(item)\n",
    "    X[list (item)]\n",
    "    parameters = {\n",
    "    'C': [0.01 , 0.1 ,1],\n",
    "    'gamma' : ['scale' , 'auto'],\n",
    "    'random_state':[2]\n",
    "    }\n",
    "    svc = SVC()\n",
    "    clf = GridSearchCV(svc , parameters , cv=3 , scoring='f1_macro')\n",
    "    clf.fit(X_train[list (item)],y_train)\n",
    "    clf.predict(X_test[list (item)])\n",
    "    #print('predict=',clf.predict(X_test[list (item)]))\n",
    "    #print(X_test)\n",
    "    #print(\"y_train = \",y_train)\n",
    "    print(item)\n",
    "    print(\"precision_score =\",precision_score(clf.predict(X[list(item)]),y))\n",
    "    print(\"recall_score =\", recall_score(clf.predict(X[list(item)]),y))\n",
    "    print(\"f_1=\",f1_score(clf.predict(X[list(item)]),y,average='macro'))\n",
    "    #print(\"f_1_X-test=\",f1_score(clf.predict(X_test[list(item)]),y_test,average='macro'))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of Untitled0.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "ad7eca264feaa10a42b7f6be2a1e8f577a569f64740e80c71f143d2c89abf5fc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
