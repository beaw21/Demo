{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data_file = pd.read_pickle('../hive.pkl')\n",
    "df = pd.DataFrame(read_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = df[['commit_befor ', 'dispen_bf', 'object_bf', 'bloater_bf', 'open_time',]]\n",
    "X = df[[ 'dispen_bf', 'object_bf', 'bloater_bf', ]]\n",
    "y = df['cal_time_binaly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train ,X_test ,y_train , y_test = X[:20], X[20:],y[:20],y[20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66666667, 0.33333333, 0.33333333, 0.5       , 0.66666667])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(clf , X , y , cv=5 , scoring= \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "y_pred = cross_val_predict(clf,X,y,cv=5)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 0, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test =cross_val_predict(clf,X_test,y_test,cv=5)\n",
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3, 11],\n",
       "       [ 4, 12]], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision =  0.5217391304347826\n",
      "recall_score =  0.75\n",
      "f1_score 0.6153846153846153\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "print('precision = ', precision_score(y,y_pred))\n",
    "print('recall_score = ', recall_score(y,y_pred))\n",
    "print('f1_score',f1_score(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y         16\n",
       "y_pred    23\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame={\"y\":y,\"y_pred\": y_pred}\n",
    "pd.DataFrame(frame).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=SVC(),\n",
       "             param_grid={'C': [0.01, 0.1, 1], 'gamma': ['scale', 'auto'],\n",
       "                         'random_state': [2]},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "  \n",
    "    'C': [0.01 , 0.1 ,1],\n",
    "    'gamma' : ['scale' , 'auto'],\n",
    "    'random_state':[2]\n",
    "  \n",
    "}\n",
    "svc = SVC()\n",
    "clf = GridSearchCV(svc , parameters , cv=3 , scoring='f1_macro')\n",
    "clf.fit(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_clf = clf.best_estimator_.predict(X)\n",
    "y_pred_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision =  0.7857142857142857\n",
      "recall_score =  0.5714285714285714\n",
      "f1_score 0.48863636363636365\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "print('precision = ', precision_score(y,y_pred_clf ,average='macro'))\n",
    "print('recall_score = ', recall_score(y,y_pred_clf ,average='macro'))\n",
    "print('f1_score',f1_score(y,y_pred_clf ,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, kernel='linear')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "\n",
    "def f_importances(coef, names):\n",
    "    \n",
    "    names = np.arange(1)\n",
    "    imp = coef\n",
    "    imp,names = zip(*sorted(zip(imp,names)))\n",
    "    plt.barh(range(len(names)), imp, align='center')\n",
    "    plt.yticks(range(len(names)), names)\n",
    "    plt.show()\n",
    "\n",
    "features_names = X.columns\n",
    "svm1 = svm.SVC(kernel='linear',C=1)\n",
    "svm1.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.93371166,  0.        , -0.03223859]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm1.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from itertools import product "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dispen_bf', 'object_bf')\n",
      "precision_score = 0.0\n",
      "recall_score = 0.0\n",
      "f_1= 0.3181818181818182\n",
      "('dispen_bf', 'bloater_bf')\n",
      "precision_score = 0.6875\n",
      "recall_score = 0.6470588235294118\n",
      "f_1= 0.6296296296296298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beauz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('object_bf', 'bloater_bf')\n",
      "precision_score = 0.375\n",
      "recall_score = 0.6666666666666666\n",
      "f_1= 0.5542857142857143\n"
     ]
    }
   ],
   "source": [
    "result = itertools.combinations(X ,2)\n",
    "\n",
    "for item in result:\n",
    "    df  = pd.DataFrame(item)\n",
    "    X[list (item)]\n",
    "    parameters = {\n",
    "    'C': [0.01 , 0.1 ,1],\n",
    "    'gamma' : ['scale' , 'auto'],\n",
    "    'random_state':[2]\n",
    "    }\n",
    "    svc = SVC()\n",
    "    clf = GridSearchCV(svc , parameters , cv=3 , scoring='f1_macro')\n",
    "    clf.fit(X_train[list (item)],y_train)\n",
    "    clf.predict(X_test[list (item)])\n",
    "    #print('predict=',clf.predict(X_test[list (item)]))\n",
    "    #print(X_test)\n",
    "    #print(\"y_train = \",y_train)\n",
    "    print(item)\n",
    "    print(\"precision_score =\",precision_score(clf.predict(X[list(item)]),y))\n",
    "    print(\"recall_score =\", recall_score(clf.predict(X[list(item)]),y))\n",
    "    print(\"f_1=\",f1_score(clf.predict(X[list(item)]),y,average='macro'))\n",
    "    #print(\"f_1_X-test=\",f1_score(clf.predict(X_test[list(item)]),y_test,average='macro'))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of Untitled0.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "ad7eca264feaa10a42b7f6be2a1e8f577a569f64740e80c71f143d2c89abf5fc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
